<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>构建自己的大模型</title>
      <link href="/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
      <url>/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="请用高中生可以理解的方式介绍下大语言模型"><a href="#请用高中生可以理解的方式介绍下大语言模型" class="headerlink" title="请用高中生可以理解的方式介绍下大语言模型"></a>请用高中生可以理解的方式介绍下大语言模型</h2><p><strong>一句话理解：大语言模型（LLM）就是一个“超级会聊天、会写作的人工智能大脑”，它通过学习海量的文字，学会了如何像人一样理解和生成语言。</strong></p><hr><h3 id="🧠-什么是大语言模型？"><a href="#🧠-什么是大语言模型？" class="headerlink" title="🧠 什么是大语言模型？"></a>🧠 什么是大语言模型？</h3><ul><li><strong>“大”</strong>：指的是它学过的内容非常多，参数（就像大脑里的“神经元连接”）可能有上亿甚至上千亿个。</li><li><strong>“语言”</strong>：它的主要能力是处理文字，比如理解问题、写文章、翻译语言、写代码。</li><li><strong>“模型”</strong>：就是一个经过训练的计算机程序，能根据输入预测最合适的输出。</li></ul><hr><h3 id="📚-它是怎么学会的？"><a href="#📚-它是怎么学会的？" class="headerlink" title="📚 它是怎么学会的？"></a>📚 它是怎么学会的？</h3><p>想象一下：</p><ul><li>如果你每天读成千上万本书、看无数文章和对话，你会慢慢发现语言里的规律。</li><li>大语言模型也是这样，它被“喂”了海量的文本数据，然后通过数学和算法，学会了<strong>“下一个词最可能是什么”</strong>。</li><li>比如输入“今天的天气真…”，它可能预测“好”“热”“冷”等词，并根据上下文选出最合理的。</li></ul><hr><h3 id="🍔-打个比方"><a href="#🍔-打个比方" class="headerlink" title="🍔 打个比方"></a>🍔 打个比方</h3><ul><li><strong>传统程序</strong>：像菜谱，必须严格按照步骤写死，才能做出一道菜。</li><li><strong>大语言模型</strong>：像一个见多识广的厨师，见过无数菜谱和做法。你只要告诉他“我想吃酸辣的”，他就能灵活组合出一道新菜。</li></ul><hr><h3 id="🚀-它能做什么？"><a href="#🚀-它能做什么？" class="headerlink" title="🚀 它能做什么？"></a>🚀 它能做什么？</h3><ul><li><strong>写作</strong>：写作文、写故事、写新闻。</li><li><strong>学习</strong>：帮你总结知识点、解释难题。</li><li><strong>翻译</strong>：在不同语言之间自由切换。</li><li><strong>编程</strong>：写代码、找错误。</li></ul><hr><h3 id="⚡-为什么叫“大”？"><a href="#⚡-为什么叫“大”？" class="headerlink" title="⚡ 为什么叫“大”？"></a>⚡ 为什么叫“大”？</h3><ul><li>数据量大：学习了海量的文本。</li><li>参数量大：模型内部的“神经元连接”非常多。</li><li>能力大：能处理各种复杂的语言任务。</li></ul><hr><p>👉 <strong>总结</strong>：大语言模型就像一个“读过无数书的超级学霸”，它不是真的理解世界，但它非常擅长根据学到的规律来“预测和生成语言”，所以看起来就像在和你自然对话。</p><p>要不要我帮你做一个 <strong>“大语言模型速记卡片”</strong>，用图表把“它是什么、怎么学、能做什么”整理成一页，像复习提纲一样？</p><h2 id="大语言模型如何训练？"><a href="#大语言模型如何训练？" class="headerlink" title="大语言模型如何训练？"></a>大语言模型如何训练？</h2><p><strong>简答版</strong>：大语言模型的训练分为三个主要阶段：<strong>预训练 → 微调 → 强化学习</strong>。先用海量文本学会“语言规律”，再通过人工示例学会“听懂指令”，最后用人类反馈不断优化，让回答更符合人类期望。</p><hr><h3 id="🧩-训练流程分解"><a href="#🧩-训练流程分解" class="headerlink" title="🧩 训练流程分解"></a>🧩 训练流程分解</h3><ol><li><p><strong>预训练（Pretraining）</strong></p><ul><li><strong>目标</strong>：让模型学会语言的基本规律（语法、语义、上下文）。</li><li><strong>方法</strong>：给模型大量文本（书籍、网页、新闻），让它预测“下一个词”。</li><li><strong>比喻</strong>：就像高中生先读了三年语文课本和作文集，积累了大量词汇和语感。</li></ul></li><li><p><strong>有监督微调（Supervised Fine-Tuning, SFT）</strong></p><ul><li><strong>目标</strong>：让模型学会“听懂人类指令”。</li><li><strong>方法</strong>：人工写一些“问题—理想答案”的示例，模型模仿这些答案。</li><li><strong>比喻</strong>：像老师出题并给出标准答案，学生学会如何答题。</li></ul></li><li><p><strong>人类反馈强化学习（RLHF, Reinforcement Learning with Human Feedback）</strong></p><ul><li><strong>目标</strong>：让模型回答更符合人类偏好（比如更礼貌、更有逻辑）。</li><li><strong>方法</strong>：人类对模型的多个回答打分，模型学会“哪种回答更受欢迎”。</li><li><strong>比喻</strong>：像作文比赛，评委打分，学生根据反馈不断改进写作风格。</li></ul></li></ol><hr><h3 id="⚙️-技术要点"><a href="#⚙️-技术要点" class="headerlink" title="⚙️ 技术要点"></a>⚙️ 技术要点</h3><ul><li><strong>架构</strong>：大多数基于 Transformer（注意力机制能捕捉长距离关系）。</li><li><strong>数据</strong>：规模巨大，通常是 TB 级别的文本。</li><li><strong>算力</strong>：需要成千上万张 GPU/TPU 并行训练。</li><li><strong>参数</strong>：模型内部的“神经元连接”可能达到数百亿甚至上万亿。</li></ul><hr><h3 id="📖-打个生活比方"><a href="#📖-打个生活比方" class="headerlink" title="📖 打个生活比方"></a>📖 打个生活比方</h3><ul><li><strong>预训练</strong>：像背了整本《新华字典》和无数作文范文。</li><li><strong>微调</strong>：老师专门教你“如何写高考作文”。</li><li><strong>强化学习</strong>：考官打分，你根据分数调整写作风格。</li></ul><hr><p>👉 <strong>总结</strong>：大语言模型的训练就像培养一个“超级学霸”。先让它读遍天下书（预训练），再教它如何答题（微调），最后通过打分不断修正（强化学习），最终才能成为一个既懂知识又会交流的“语言高手”。</p><hr><p>要不要我帮你整理一个<strong>“大语言模型训练三阶段速记卡片”</strong>，用图表形式把“预训练—微调—强化学习”的逻辑串起来，像考试复习提纲一样？</p><ul><li><a href="https://blog.csdn.net/l01011_/article/details/148157725">CSDN 博客《从零开始训练大语言模型的全过程》</a></li><li><a href="https://zhuanlan.zhihu.com/p/636270877">知乎《从零开始训练大模型》</a></li></ul><h2 id="如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过-api-的方式提供给外部程序使用？"><a href="#如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过-api-的方式提供给外部程序使用？" class="headerlink" title="如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？"></a>如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？</h2><h1 id="从零构建大语言模型"><a href="#从零构建大语言模型" class="headerlink" title="从零构建大语言模型"></a>从零构建大语言模型</h1><p>下面用清晰、可落地的步骤，带你从“白纸”到“能通过 API 提供服务”的完整路径。每个环节都点到为止，足够高中生理解，也能让你动手实践。</p><hr><h3 id="路线概览"><a href="#路线概览" class="headerlink" title="路线概览"></a>路线概览</h3><ul><li><strong>目标:</strong> 从零定义模型 → 训练 → 微调 → 部署为 API</li><li><strong>核心环节:</strong> 分词与数据 → 模型结构 → 训练策略 → 对齐与评测 → 推理优化 → API 服务</li></ul><hr><h3 id="基础准备与数据管线"><a href="#基础准备与数据管线" class="headerlink" title="基础准备与数据管线"></a>基础准备与数据管线</h3><ul><li><strong>数据来源:</strong> 开源文本语料、你的领域数据、对话日志、代码仓库等。</li><li><strong>清洗与划分:</strong> 去重、去噪、分训练/验证/测试集。</li><li><strong>分词器与词表:</strong> BPE/WordPiece 等；词表大小影响记忆与速度。</li><li><strong>格式化训练样本:</strong> 以“指令+上下文+期望输出”组织，保证一致的提示格式。</li><li><strong>度量与基线:</strong> 先为小模型设基线（如困惑度、准确率），再逐步扩大规模。</li></ul><hr><h3 id="定义“大模型”的关键参数"><a href="#定义“大模型”的关键参数" class="headerlink" title="定义“大模型”的关键参数"></a>定义“大模型”的关键参数</h3><ul><li><strong>模型架构:</strong> 以 Transformer 为主（自注意力 + 前馈网络）。</li><li><strong>核心维度:</strong><ul><li><strong>词表大小:</strong> 决定可直接识别的“词/子词”的范围。</li><li><strong>嵌入维度:</strong> 每个词的向量维度，决定表达能力。</li><li><strong>层数:</strong> 堆叠的 Transformer 层数，影响深度与拟合能力。</li><li><strong>注意力头数:</strong> 并行关注不同特征的“视角”数量。</li><li><strong>上下文长度:</strong> 一次能读入的最大 Token 数，决定“记忆窗口”。</li><li><strong>前馈层维度:</strong> FFN 的隐藏维度，影响非线性表达能力。</li><li><strong>正则与稳定:</strong> Dropout、RMSNorm/LayerNorm、残差结构。</li></ul></li><li><strong>训练超参:</strong><ul><li><strong>批大小:</strong> 越大越稳，但吃显存；可用梯度累积。</li><li><strong>学习率与调度:</strong> 线性预热 + 余弦退火/多段下降。</li><li><strong>优化器:</strong> AdamW 等，注意权重衰减和梯度裁剪。</li><li><strong>精度与并行:</strong> 混合精度（FP16/BF16）、数据并行、张量并行。</li><li><strong>检查点:</strong> 定期保存权重与优化器状态，支持断点续训。</li></ul></li></ul><hr><h3 id="训练到对齐的完整流程"><a href="#训练到对齐的完整流程" class="headerlink" title="训练到对齐的完整流程"></a>训练到对齐的完整流程</h3><ol><li><strong>预训练（语言规律）</strong><ul><li><strong>目标:</strong> 预测下一个词；学会语法、语义、长程依赖。</li><li><strong>做法:</strong> 大规模通用语料，自监督损失（交叉熵），长时间训练。</li></ul></li><li><strong>有监督微调（听懂指令）</strong><ul><li><strong>目标:</strong> 输入指令能产出“规范答案”。</li><li><strong>做法:</strong> 用人工标注的“问—答”样本训练，统一提示模板。</li></ul></li><li><strong>人类反馈强化学习（更合人意）</strong><ul><li><strong>目标:</strong> 让回答更安全、礼貌、清晰、有逻辑。</li><li><strong>做法:</strong> 训练奖励模型对多候选排序，再用策略优化（如 PPO）提升。</li></ul></li><li><strong>评测与安全</strong><ul><li><strong>离线指标:</strong> 困惑度、准确率、BLEU/ROUGE、代码通过率等。</li><li><strong>在线质检:</strong> 对话质量、事实性、拒答边界、越狱测试。</li><li><strong>红线策略:</strong> 敏感话题过滤、规则模板、拒答策略与审计。</li></ul></li></ol><hr><h3 id="部署为-API-的实战路径"><a href="#部署为-API-的实战路径" class="headerlink" title="部署为 API 的实战路径"></a>部署为 API 的实战路径</h3><h4 id="推理优化与打包"><a href="#推理优化与打包" class="headerlink" title="推理优化与打包"></a>推理优化与打包</h4><ul><li><strong>权重格式:</strong> 转 ONNX/Safetensors；按需拆分分片。</li><li><strong>加速方案:</strong> KV Cache、张量并行、批量推理、流式输出。</li><li><strong>量化与蒸馏:</strong> INT8/INT4 量化降低显存；小模型蒸馏提升性价比。</li><li><strong>服务化组件:</strong> 选择推理后端（如支持并发和长上下文）、健康检查、监控与日志。</li></ul><h4 id="快速搭一个可用的-API（示例）"><a href="#快速搭一个可用的-API（示例）" class="headerlink" title="快速搭一个可用的 API（示例）"></a>快速搭一个可用的 API（示例）</h4><ul><li><strong>功能点:</strong> Chat、流式响应、温度控制、鉴权、限流、配额、观测</li><li><strong>接口设计:</strong> /v1/chat/completions（与主流兼容）、JSON 输入/输出、OpenAPI 文档</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py — 最小可用 Chat API（示意）</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Mark-LLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span>  <span class="comment"># &quot;system&quot; | &quot;user&quot; | &quot;assistant&quot;</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">512</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_inference</span>(<span class="params">messages, temperature, max_tokens</span>):</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 调用你加载的模型，做推理，并支持流式输出</span></span><br><span class="line">    <span class="comment"># 这里返回一个演示结果</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;你好，我是你的模型。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="comment"># 简单鉴权</span></span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    output = run_inference(req.messages, req.temperature, req.max_tokens)</span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-demo&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=output), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li><strong>调用示例:</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl https://your.domain/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;mark-llm-7b&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;用高中水平解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 300</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><ul><li><strong>上线要点:</strong><ul><li><strong>鉴权与配额:</strong> API key/租户体系、速率限制、额度管理。</li><li><strong>弹性与高可用:</strong> 多副本、负载均衡、滚动升级、灰度发布。</li><li><strong>监控与追踪:</strong> QPS、延迟、错误率、GPU 利用率、日志与审计。</li><li><strong>版本与兼容:</strong> 维持 stable 接口，新增能力用新版本号。</li></ul></li></ul><hr><h3 id="给你的一张“动手清单”"><a href="#给你的一张“动手清单”" class="headerlink" title="给你的一张“动手清单”"></a>给你的一张“动手清单”</h3><ul><li><strong>明确目标:</strong> 写作助手/教育问答/代码助理，决定训练数据与评测集。</li><li><strong>先小后大:</strong> 先训 100M–1B 级别模型跑通流程，再扩展到 7B/13B。</li><li><strong>构建数据与分词:</strong> 打通清洗—分词—样本生成—数据加载的流水线。</li><li><strong>迭代训练:</strong> 设定检查点与指标曲线，观察过拟合与泛化。</li><li><strong>对齐与安全:</strong> 加入 SFT+RLHF，设计拒答与事实性策略。</li><li><strong>推理与服务:</strong> 选择加速/量化方案，上线 API，配监控与限流。</li></ul><hr><p>如果你愿意，我可以按你的具体目标（比如“中文教育问答”或“家庭健康知识库”）给出一版可打印的训练与部署流程图、参数推荐表和评测清单，让你一页就能掌控全局。</p><h2 id="请帮我完成"><a href="#请帮我完成" class="headerlink" title="请帮我完成"></a>请帮我完成</h2><p>好的 👍 我来帮你把“从零做一个大模型 → 定义参数 → 提供 API 服务”的完整流程整理成一份<strong>速记卡片式指南</strong>，方便你一眼掌握全局。</p><hr><h2 id="🧩-一张图看懂大模型全流程"><a href="#🧩-一张图看懂大模型全流程" class="headerlink" title="🧩 一张图看懂大模型全流程"></a>🧩 一张图看懂大模型全流程</h2><p><strong>1. 数据准备 → 2. 模型定义 → 3. 训练 → 4. 微调与对齐 → 5. 部署 → 6. API 服务</strong></p><hr><h3 id="1️⃣-数据准备"><a href="#1️⃣-数据准备" class="headerlink" title="1️⃣ 数据准备"></a>1️⃣ 数据准备</h3><ul><li><strong>收集</strong>：开源语料、书籍、网页、代码、对话数据</li><li><strong>清洗</strong>：去重、去噪、统一格式</li><li><strong>分词</strong>：BPE/WordPiece，决定词表大小（常见 30k–100k）</li></ul><hr><h3 id="2️⃣-模型参数定义"><a href="#2️⃣-模型参数定义" class="headerlink" title="2️⃣ 模型参数定义"></a>2️⃣ 模型参数定义</h3><ul><li><strong>层数（Layers）</strong>：越多越深，常见 12–96 层</li><li><strong>隐藏维度（Hidden size）</strong>：每个词的向量维度，常见 768–8192</li><li><strong>注意力头数（Heads）</strong>：并行关注不同特征，常见 12–128</li><li><strong>上下文长度（Context length）</strong>：一次能读多少 token，常见 2k–128k</li><li><strong>参数量（Parameters）</strong>：整体规模，百万到千亿不等</li></ul><p>👉 <strong>大模型的“大小”就是这些参数的总数</strong>。比如 GPT-3 有 1750 亿参数。</p><hr><h3 id="3️⃣-训练阶段"><a href="#3️⃣-训练阶段" class="headerlink" title="3️⃣ 训练阶段"></a>3️⃣ 训练阶段</h3><ul><li><strong>预训练</strong>：用大规模语料预测“下一个词”</li><li><strong>微调（SFT）</strong>：用人工标注的问答数据，学会听懂指令</li><li><strong>RLHF</strong>：人类反馈强化学习，让回答更符合人类偏好</li></ul><hr><h3 id="4️⃣-部署与推理优化"><a href="#4️⃣-部署与推理优化" class="headerlink" title="4️⃣ 部署与推理优化"></a>4️⃣ 部署与推理优化</h3><ul><li><strong>模型压缩</strong>：量化（INT8/INT4）、蒸馏（小模型模仿大模型）</li><li><strong>推理加速</strong>：KV Cache、并行计算、流式输出</li><li><strong>容器化</strong>：用 Docker/Kubernetes 部署，方便扩展</li></ul><hr><h3 id="5️⃣-提供-API-服务"><a href="#5️⃣-提供-API-服务" class="headerlink" title="5️⃣ 提供 API 服务"></a>5️⃣ 提供 API 服务</h3><ul><li><strong>后端框架</strong>：FastAPI / Flask / Node.js</li><li><strong>接口设计</strong>：<ul><li>路径：<code>/v1/chat/completions</code></li><li>输入：<code>messages</code>（对话历史）、<code>temperature</code>（随机性）、<code>max_tokens</code>（输出长度）</li><li>输出：模型生成的文本</li></ul></li><li><strong>调用示例</strong>：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl https://your.domain/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;my-llm-7b&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个乐于助人的助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用高中生能懂的方式解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 300</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><hr><h3 id="6️⃣-关键要点"><a href="#6️⃣-关键要点" class="headerlink" title="6️⃣ 关键要点"></a>6️⃣ 关键要点</h3><ul><li><strong>安全</strong>：过滤敏感内容，避免越狱</li><li><strong>监控</strong>：记录 QPS、延迟、错误率</li><li><strong>扩展</strong>：支持多副本、负载均衡、灰度发布</li></ul><hr><p>✅ <strong>总结</strong>：</p><ul><li><strong>大模型的“大小” = 参数量（层数 × 隐藏维度 × 注意力头数等）</strong></li><li><strong>训练三步走：预训练 → 微调 → RLHF</strong></li><li><strong>部署三件事：优化 → 容器化 → API 服务化</strong></li></ul><hr><p>要不要我帮你把这份内容整理成一张<strong>可打印的流程图/学习卡片</strong>（比如“从零到 API 的 6 步图解”），这样你可以贴在桌子上随时复习？</p><h2 id="我现在有一台-16GB-内存，8-核心的-cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型"><a href="#我现在有一台-16GB-内存，8-核心的-cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型" class="headerlink" title="我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型"></a>我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型</h2><h1 id="在-16GB-内存、8-核-CPU-上从零构建并提供大模型-API"><a href="#在-16GB-内存、8-核-CPU-上从零构建并提供大模型-API" class="headerlink" title="在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API"></a>在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API</h1><p>先说人话版结论：用这台机器“从零”训练超大模型不现实，但你可以做一个实用的“小而精”中文指令模型（0.1B 级别或更小），跑通全流程：数据 → 分词 → 预训练 → 微调 → 部署 →API。下面给你一套可落地的配置和步骤。</p><hr><h2 id="目标与策略"><a href="#目标与策略" class="headerlink" title="目标与策略"></a>目标与策略</h2><ul><li><strong>目标:</strong> 训练一个本地可用的中文/中英小型指令模型，支持聊天与问答。</li><li><strong>策略:</strong> 采用极简 Transformer、小词表、短上下文、CPU 训练；先预训练极小模型，再做少量高质量指令微调；推理端支持流式输出与简单鉴权。</li></ul><hr><h2 id="可行的模型规格与训练超参"><a href="#可行的模型规格与训练超参" class="headerlink" title="可行的模型规格与训练超参"></a>可行的模型规格与训练超参</h2><h3 id="最小可行模型规格（适配-16GB-内存，CPU-训练）"><a href="#最小可行模型规格（适配-16GB-内存，CPU-训练）" class="headerlink" title="最小可行模型规格（适配 16GB 内存，CPU 训练）"></a>最小可行模型规格（适配 16GB 内存，CPU 训练）</h3><ul><li><strong>词表大小:</strong> 16k（中文+英文子词，BPE）</li><li><strong>上下文长度:</strong> 512 tokens（足以支持短问答）</li><li><strong>层数:</strong> 8 Transformer blocks</li><li><strong>隐藏维度:</strong> 512</li><li><strong>注意力头数:</strong> 8</li><li><strong>前馈维度:</strong> 2048</li><li><strong>归一化与正则:</strong> RMSNorm，<strong>Dropout:</strong> 0.1</li><li><strong>参数量估算:</strong> ≈ 30–60M（可控在百兆以内）</li></ul><h3 id="训练超参（CPU-友好）"><a href="#训练超参（CPU-友好）" class="headerlink" title="训练超参（CPU 友好）"></a>训练超参（CPU 友好）</h3><ul><li><strong>批大小:</strong> 8–16（用梯度累积让“有效批”达到 64）</li><li><strong>学习率:</strong> 3e-4（线性预热到 3e-4，然后余弦退火）</li><li><strong>优化器:</strong> AdamW（权重衰减 0.01，梯度裁剪 1.0）</li><li><strong>精度:</strong> FP32（CPU），如可用 BF16 更好</li><li><strong>训练时长:</strong> 先跑 24–48 小时得到可用的“语言感”，再做指令微调 6–12 小时</li><li><strong>检查点频率:</strong> 每 1–2 小时保存一次（断点续训）</li></ul><hr><h2 id="从零到-API-的-6-步"><a href="#从零到-API-的-6-步" class="headerlink" title="从零到 API 的 6 步"></a>从零到 API 的 6 步</h2><h3 id="1-数据与分词"><a href="#1-数据与分词" class="headerlink" title="1. 数据与分词"></a>1. 数据与分词</h3><ul><li><strong>语料来源:</strong><ul><li><strong>通用:</strong> 开源百科、新闻摘要、教程、公共论坛清洗文本</li><li><strong>指令:</strong> 你自制的“问题-答案”对（质量优先）</li></ul></li><li><strong>清洗规范:</strong><ul><li><strong>去重:</strong> 文本哈希去重</li><li><strong>去噪:</strong> 去广告、去脚本、过滤超长行</li><li><strong>统一编码:</strong> UTF-8，移除异常字符</li></ul></li><li><strong>分词器:</strong><ul><li><strong>方法:</strong> BPE（SentencePiece）</li><li><strong>词表:</strong> 16k；中英混合；保留数字与基础标点</li></ul></li><li><strong>样本格式:</strong><ul><li><strong>预训练:</strong> 纯文本连续 token</li><li><strong>指令微调:</strong> 统一模板，例如：<ul><li><strong>系统:</strong> 你是乐于助人的助手</li><li><strong>用户:</strong> 问题…</li><li><strong>助手:</strong> 标准答案…</li></ul></li></ul></li></ul><h3 id="2-模型搭建"><a href="#2-模型搭建" class="headerlink" title="2. 模型搭建"></a>2. 模型搭建</h3><ul><li><strong>架构:</strong> Decoder-only Transformer（GPT 样式）</li><li><strong>组件选择:</strong><ul><li><strong>位置编码:</strong> RoPE（旋转位置编码）</li><li><strong>注意力:</strong> 标准自注意力，支持 KV 缓存（推理加速）</li><li><strong>损失:</strong> 交叉熵（下一个 token 预测）</li></ul></li><li><strong>可调开关:</strong><ul><li><strong>上下文长度:</strong> 256/512 两档；训练用 256 更省，推理可 512</li><li><strong>Dropout:</strong> 0.1→0.0（微调阶段可降）</li></ul></li></ul><h3 id="3-预训练（语言能力）"><a href="#3-预训练（语言能力）" class="headerlink" title="3. 预训练（语言能力）"></a>3. 预训练（语言能力）</h3><ul><li><strong>目标:</strong> 学会基本语法与语义、中文分词习惯</li><li><strong>做法:</strong><ul><li><strong>数据量:</strong> 1–5GB 干净文本（这台机器可承受的小规模）</li><li><strong>课程学习:</strong> 先短上下文、短序列，后增大到 512</li><li><strong>监控:</strong> 训练/验证困惑度（PPL）下降趋势，避免发散</li></ul></li><li><strong>产出:</strong> “基础语言模型”检查点（如 base-40M）</li></ul><h3 id="4-指令微调与对齐"><a href="#4-指令微调与对齐" class="headerlink" title="4. 指令微调与对齐"></a>4. 指令微调与对齐</h3><ul><li><strong>有监督微调（SFT）:</strong><ul><li><strong>数据:</strong> 5k–50k 条高质量问答对（中文优先）</li><li><strong>模板:</strong> 固定提示格式，提升稳定性</li><li><strong>目标:</strong> 提升遵循指令、结构化表达能力</li></ul></li><li><strong>轻量对齐:</strong><ul><li><strong>人类偏好:</strong> 简单排序数据（两两对比选优）</li><li><strong>训练:</strong> 资源有限可跳过 RLHF，转而更严格的 SFT 数据与拒答规则</li></ul></li><li><strong>安全与边界:</strong><ul><li><strong>内容过滤:</strong> 敏感类别关键词屏蔽</li><li><strong>拒答策略:</strong> 对不当请求返回通用安全提示</li></ul></li></ul><h3 id="5-推理与部署"><a href="#5-推理与部署" class="headerlink" title="5. 推理与部署"></a>5. 推理与部署</h3><ul><li><strong>推理优化:</strong><ul><li><strong>KV 缓存:</strong> 显著加速长上下文生成</li><li><strong>采样策略:</strong> top-k=40、top-p=0.9、temperature=0.7（可调）</li><li><strong>流式输出:</strong> 边生成边返回，降低感知延迟</li></ul></li><li><strong>打包:</strong><ul><li><strong>权重存储:</strong> safetensors（安全、可分片）</li><li><strong>容器化:</strong> Docker（可选），本机即可跑</li></ul></li><li><strong>监控:</strong><ul><li><strong>日志:</strong> 请求、延迟、错误</li><li><strong>限流:</strong> 简单令牌桶（防止过载）</li></ul></li></ul><h3 id="6-提供-API-服务（FastAPI-示例）"><a href="#6-提供-API-服务（FastAPI-示例）" class="headerlink" title="6. 提供 API 服务（FastAPI 示例）"></a>6. 提供 API 服务（FastAPI 示例）</h3><ul><li><strong>接口设计:</strong> 兼容主流 <code>/v1/chat/completions</code>；鉴权用 Bearer Token</li><li><strong>功能:</strong> 历史消息、温度控制、最大输出长度、可选流式</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py — 轻量CPU模型推理API（示意）</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Tiny-LLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span>  <span class="comment"># &quot;system&quot; | &quot;user&quot; | &quot;assistant&quot;</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span> = <span class="string">&quot;tiny-llm-40m&quot;</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">40</span></span><br><span class="line">    top_p: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.9</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">256</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 伪代码：加载你训练好的权重与分词器</span></span><br><span class="line"><span class="comment"># tokenizer = load_tokenizer(&quot;./tokenizer&quot;)</span></span><br><span class="line"><span class="comment"># model = load_model(&quot;./tiny-llm-40m.safetensors&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_inference</span>(<span class="params">messages, temperature, top_k, top_p, max_tokens</span>):</span><br><span class="line">    <span class="comment"># 这里调用你实现的generate()，支持KV缓存与流式</span></span><br><span class="line">    <span class="comment"># text = generate(model, tokenizer, messages, temperature, top_k, top_p, max_tokens)</span></span><br><span class="line">    text = <span class="string">&quot;你好，我是你的本地小模型，已接入API。&quot;</span></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    output = run_inference(req.messages, req.temperature, req.top_k, req.top_p, req.max_tokens)</span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-local&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=output), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li><strong>调用示例:</strong></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;tiny-llm-40m&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的中文助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;帮我用高中生能懂的语言解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 200</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><hr><h2 id="可打印的“动手清单”"><a href="#可打印的“动手清单”" class="headerlink" title="可打印的“动手清单”"></a>可打印的“动手清单”</h2><ul><li><strong>目标与领域:</strong><ul><li><strong>用途:</strong> 中文聊天/教育问答/家庭知识</li><li><strong>风格:</strong> 简洁、礼貌、结构化</li></ul></li><li><strong>数据流水线:</strong><ul><li><strong>收集:</strong> 通用中文文本 + 你自制问答</li><li><strong>清洗:</strong> 去重、去噪、统一格式</li><li><strong>分词:</strong> BPE，词表 16k</li></ul></li><li><strong>模型与超参:</strong><ul><li><strong>结构:</strong> 8 层、hidden=512、heads=8、ffn=2048、context=512</li><li><strong>训练:</strong> batch=8（累积到 64）、AdamW、lr=3e-4、fp32</li><li><strong>时长:</strong> 预训 1–2 天；SFT 半天到一天</li></ul></li><li><strong>评测与安全:</strong><ul><li><strong>指标:</strong> 困惑度、简单问答集准确率</li><li><strong>安全:</strong> 敏感词过滤、拒答模板</li></ul></li><li><strong>部署与 API:</strong><ul><li><strong>权重:</strong> safetensors</li><li><strong>优化:</strong> KV 缓存、流式输出</li><li><strong>服务:</strong> FastAPI，鉴权+限流+日志</li></ul></li></ul><hr><h2 id="进阶与扩展建议"><a href="#进阶与扩展建议" class="headerlink" title="进阶与扩展建议"></a>进阶与扩展建议</h2><ul><li><strong>蒸馏到更小:</strong> 用你训练的模型教师，蒸馏到更轻规格（如 hidden=384，参数更少）</li><li><strong>持续微调:</strong> 持续收集真实使用问答，定期 SFT 提升质量</li><li><strong>长上下文版本:</strong> 若需要长文支持，增至 1024–2048，但留意 CPU 内存占用</li><li><strong>量化推理:</strong> 推理时做 INT8/INT4 量化，显著降内存占用（训练仍用 FP32）</li></ul><hr><p>如果你愿意，我可以把这套规格和流程做成一页 A4 的可打印卡片（含模型超参表、训练日程、API 字段表），并按“中文教育问答”给你准备一套高质量指令微调模板与小型评测集，直接开训。你更偏好中文专用还是中英混合词表？</p><h2 id="基于上面的回答，请给我代码层面的实现"><a href="#基于上面的回答，请给我代码层面的实现" class="headerlink" title="基于上面的回答，请给我代码层面的实现"></a>基于上面的回答，请给我代码层面的实现</h2><p>下面给你“可运行的最小完整代码”，涵盖数据准备、分词器、模型搭建、预训练、指令微调、推理生成、以及 FastAPI 对外提供服务。你可以直接按模块落地，逐步跑通。</p><hr><h2 id="项目结构与依赖"><a href="#项目结构与依赖" class="headerlink" title="项目结构与依赖"></a>项目结构与依赖</h2><ul><li><p>建议结构：</p><ul><li>data/：语料与指令数据</li><li>tokenizer/：分词器文件</li><li>checkpoints/：模型权重</li><li>app.py：API 服务</li><li>train_pretrain.py：预训练</li><li>train_sft.py：指令微调</li><li>model.py：模型定义与推理</li><li>build_tokenizer.py：构建 BPE 分词器</li><li>generate.py：离线推理</li></ul></li><li><p>依赖：</p><ul><li>python ≥ 3.9</li><li>pip install torch sentencepiece fastapi uvicorn pydantic</li></ul></li></ul><hr><h2 id="1-构建分词器（BPE，词表-16k）"><a href="#1-构建分词器（BPE，词表-16k）" class="headerlink" title="1. 构建分词器（BPE，词表 16k）"></a>1. 构建分词器（BPE，词表 16k）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_tokenizer.py</span></span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tokenizer</span>(<span class="params">input_txt=<span class="string">&quot;data/corpus.txt&quot;</span>, model_prefix=<span class="string">&quot;tokenizer/spm&quot;</span>, vocab_size=<span class="number">16000</span></span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;tokenizer&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    spm.SentencePieceTrainer.Train(</span><br><span class="line">        <span class="built_in">input</span>=input_txt,</span><br><span class="line">        model_prefix=model_prefix,</span><br><span class="line">        vocab_size=vocab_size,</span><br><span class="line">        model_type=<span class="string">&quot;bpe&quot;</span>,</span><br><span class="line">        character_coverage=<span class="number">0.9995</span>,  <span class="comment"># 适合中英混合</span></span><br><span class="line">        bos_id=<span class="number">1</span>, eos_id=<span class="number">2</span>, pad_id=<span class="number">0</span>, unk_id=<span class="number">3</span>,</span><br><span class="line">        user_defined_symbols=[<span class="string">&quot;&lt;|system|&gt;&quot;</span>, <span class="string">&quot;&lt;|user|&gt;&quot;</span>, <span class="string">&quot;&lt;|assistant|&gt;&quot;</span>, <span class="string">&quot;&lt;|sep|&gt;&quot;</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Tokenizer built:&quot;</span>, model_prefix + <span class="string">&quot;.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    build_tokenizer()</span><br></pre></td></tr></table></figure><ul><li>准备 data/corpus.txt（1–5GB 清洗文本，先用几百 MB 也可跑通）。</li></ul><hr><h2 id="2-模型定义（Decoder-only-Transformer，约-40M-参数）"><a href="#2-模型定义（Decoder-only-Transformer，约-40M-参数）" class="headerlink" title="2. 模型定义（Decoder-only Transformer，约 40M 参数）"></a>2. 模型定义（Decoder-only Transformer，约 40M 参数）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        norm_x = x * torch.rsqrt(torch.mean(x * x, dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="variable language_">self</span>.eps)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.weight * norm_x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RotaryEmbedding</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, base=<span class="number">10000</span></span>):</span><br><span class="line">        inv_freq = <span class="number">1.0</span> / (base ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>).<span class="built_in">float</span>() / dim))</span><br><span class="line">        <span class="variable language_">self</span>.inv_freq = inv_freq</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_cos_sin</span>(<span class="params">self, seq_len, device</span>):</span><br><span class="line">        t = torch.arange(seq_len, device=device).type_as(<span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        freqs = torch.outer(t, <span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        cos, sin = freqs.cos(), freqs.sin()</span><br><span class="line">        <span class="keyword">return</span> cos, sin</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rope</span>(<span class="params">x, cos, sin</span>):</span><br><span class="line">    <span class="comment"># x: (b, n_heads, seq_len, head_dim)</span></span><br><span class="line">    head_dim = x.size(-<span class="number">1</span>)</span><br><span class="line">    x1 = x[..., :head_dim//<span class="number">2</span>]</span><br><span class="line">    x2 = x[..., head_dim//<span class="number">2</span>:]</span><br><span class="line">    x_rope = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x_rope</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.n_heads = n_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = dim // n_heads</span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.o = nn.Linear(dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span>, rope=<span class="literal">None</span>, kv_cache=<span class="literal">None</span></span>):</span><br><span class="line">        B, T, C = x.size()</span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x)  <span class="comment"># (B, T, 3C)</span></span><br><span class="line">        q, k, v = qkv.split(C, dim=-<span class="number">1</span>)</span><br><span class="line">        q = q.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (B, H, T, D)</span></span><br><span class="line">        k = k.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        v = v.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cos, sin = rope.get_cos_sin(T, x.device)</span><br><span class="line">            cos = cos[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            sin = sin[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            q = apply_rope(q, cos, sin)</span><br><span class="line">            k = apply_rope(k, cos, sin)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># causal mask</span></span><br><span class="line">        att = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(<span class="variable language_">self</span>.head_dim)  <span class="comment"># (B, H, T, T)</span></span><br><span class="line">        causal = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        att = att.masked_fill(causal == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            att = att + mask</span><br><span class="line">        att = F.softmax(att, dim=-<span class="number">1</span>)</span><br><span class="line">        att = <span class="variable language_">self</span>.dropout(att)</span><br><span class="line">        y = att @ v  <span class="comment"># (B, H, T, D)</span></span><br><span class="line">        y = y.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(B, T, C)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.o(y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, ffn_dim, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, ffn_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(ffn_dim, dim)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w2(<span class="variable language_">self</span>.dropout(F.silu(<span class="variable language_">self</span>.w1(x))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, ffn_dim, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.norm1 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, n_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.norm2 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.ffn = FeedForward(dim, ffn_dim, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.rope = RotaryEmbedding(dim // n_heads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x), mask=mask, rope=<span class="variable language_">self</span>.rope)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.ffn(<span class="variable language_">self</span>.norm2(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyLLM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tok_emb = nn.Embedding(vocab_size, dim)</span><br><span class="line">        <span class="variable language_">self</span>.pos_emb = <span class="literal">None</span>  <span class="comment"># 使用RoPE，不需要绝对位置</span></span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.ModuleList([TransformerBlock(dim, n_heads, ffn_dim, dropout) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line">        <span class="variable language_">self</span>.norm = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.lm_head = nn.Linear(dim, vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.max_seq_len = max_seq_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># idx: (B, T)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.tok_emb(idx)</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        logits = <span class="variable language_">self</span>.lm_head(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, idx, max_new_tokens=<span class="number">128</span>, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_new_tokens):</span><br><span class="line">            logits = <span class="variable language_">self</span>.forward(idx)[:, -<span class="number">1</span>, :]  <span class="comment"># (B, V)</span></span><br><span class="line">            logits = logits / <span class="built_in">max</span>(temperature, <span class="number">1e-5</span>)</span><br><span class="line">            probs = F.softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># nucleus + top-k filter（简化版）</span></span><br><span class="line">            <span class="keyword">if</span> top_k <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                topk_vals, topk_idx = torch.topk(probs, k=<span class="built_in">min</span>(top_k, probs.size(-<span class="number">1</span>)), dim=-<span class="number">1</span>)</span><br><span class="line">                filt = torch.zeros_like(probs)</span><br><span class="line">                filt.scatter_(<span class="number">1</span>, topk_idx, topk_vals)</span><br><span class="line">                probs = filt</span><br><span class="line">            <span class="keyword">if</span> top_p <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                sorted_probs, sorted_idx = torch.sort(probs, descending=<span class="literal">True</span>, dim=-<span class="number">1</span>)</span><br><span class="line">                cum = torch.cumsum(sorted_probs, dim=-<span class="number">1</span>)</span><br><span class="line">                mask = cum &lt;= top_p</span><br><span class="line">                <span class="comment"># 确保至少保留一个</span></span><br><span class="line">                mask[..., <span class="number">0</span>] = <span class="literal">True</span></span><br><span class="line">                filt = torch.zeros_like(probs)</span><br><span class="line">                filt.scatter_(<span class="number">1</span>, sorted_idx, sorted_probs * mask)</span><br><span class="line">                probs = filt</span><br><span class="line">            probs = probs / probs.<span class="built_in">sum</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            next_token = torch.multinomial(probs, num_samples=<span class="number">1</span>)  <span class="comment"># (B, 1)</span></span><br><span class="line">            idx = torch.cat([idx, next_token], dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> idx.size(<span class="number">1</span>) &gt;= <span class="variable language_">self</span>.max_seq_len:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> idx</span><br></pre></td></tr></table></figure><hr><h2 id="3-预训练（自监督，下一个-token-预测）"><a href="#3-预训练（自监督，下一个-token-预测）" class="headerlink" title="3. 预训练（自监督，下一个 token 预测）"></a>3. 预训练（自监督，下一个 token 预测）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_pretrain.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, txt_path, sp_model_path, seq_len=<span class="number">256</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="variable language_">self</span>.text = f.read()</span><br><span class="line">        <span class="variable language_">self</span>.ids = <span class="variable language_">self</span>.sp.encode(<span class="variable language_">self</span>.text, out_type=<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ids) // <span class="variable language_">self</span>.seq_len - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        i = idx * <span class="variable language_">self</span>.seq_len</span><br><span class="line">        x = <span class="variable language_">self</span>.ids[i:i+<span class="variable language_">self</span>.seq_len]</span><br><span class="line">        y = <span class="variable language_">self</span>.ids[i+<span class="number">1</span>:i+<span class="variable language_">self</span>.seq_len+<span class="number">1</span>]</span><br><span class="line">        x = torch.tensor(x, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(y, dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_pretrain</span>(<span class="params"></span></span><br><span class="line"><span class="params">    corpus_path=<span class="string">&quot;data/corpus.txt&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>,</span></span><br><span class="line"><span class="params">    dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>,</span></span><br><span class="line"><span class="params">    seq_len=<span class="number">256</span>, batch_size=<span class="number">8</span>, lr=<span class="number">3e-4</span>, epochs=<span class="number">1</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    dataset = TextDataset(corpus_path, spm_path, seq_len=seq_len)</span><br><span class="line">    loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span>).to(device)</span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    scaler = <span class="literal">None</span>  <span class="comment"># CPU上不需要AMP</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Pretraining starts. Steps:&quot;</span>, <span class="built_in">len</span>(loader))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            x = x.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            logits = model(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>))</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                ppl = math.exp(total_loss / <span class="number">100</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>: loss=<span class="subst">&#123;total_loss/<span class="number">100</span>:<span class="number">.4</span>f&#125;</span> ppl≈<span class="subst">&#123;ppl:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                total_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;pretrain_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    train_pretrain(epochs=<span class="number">1</span>)  <span class="comment"># 先跑通一轮</span></span><br></pre></td></tr></table></figure><ul><li>先跑短序列（256）更省资源，之后可提高到 512 继续训练。</li></ul><hr><h2 id="4-指令微调（SFT）"><a href="#4-指令微调（SFT）" class="headerlink" title="4. 指令微调（SFT）"></a>4. 指令微调（SFT）</h2><p>准备 data/sft.jsonl，每行一个样本：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是乐于助人的助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;解释云原生&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;assistant&quot;</span><span class="punctuation">:</span> <span class="string">&quot;云原生是为云设计的软件方式...&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是乐于助人的助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;什么是大语言模型？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;assistant&quot;</span><span class="punctuation">:</span> <span class="string">&quot;大语言模型是通过学习海量文本...&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>])</span><br><span class="line">                full = prompt + obj[<span class="string">&quot;assistant&quot;</span>]</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(full, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># label位置：从assistant开头开始训练；system/user部分设置为-100忽略</span></span><br><span class="line">                prompt_ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prompt_ids) + ids[<span class="built_in">len</span>(prompt_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels = labels + [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = SFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded pretrain:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            total += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>: sft_loss=<span class="subst">&#123;total/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                total = <span class="number">0.0</span></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="5-离线推理与测试"><a href="#5-离线推理与测试" class="headerlink" title="5. 离线推理与测试"></a>5. 离线推理与测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">model_ckpt, spm_path, system, user, max_new_tokens=<span class="number">200</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, T)</span></span><br><span class="line">    out = model.generate(x, max_new_tokens=max_new_tokens, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">    text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">    <span class="comment"># 只截取assistant部分</span></span><br><span class="line">    ans = text.split(<span class="string">&quot;&lt;|assistant|&gt;\n&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(ans)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    run(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是乐于助人的中文助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;请用高中生能懂的语言解释云原生&quot;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure><hr><h2 id="6-FastAPI-对外提供服务"><a href="#6-FastAPI-对外提供服务" class="headerlink" title="6. FastAPI 对外提供服务"></a>6. FastAPI 对外提供服务</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">SPM_PATH = <span class="string">&quot;tokenizer/spm.model&quot;</span></span><br><span class="line">CKPT_PATH = <span class="string">&quot;checkpoints/sft_epoch0.pt&quot;</span></span><br><span class="line"></span><br><span class="line">sp = spm.SentencePieceProcessor(model_file=SPM_PATH)</span><br><span class="line">model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">sd = torch.load(CKPT_PATH, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;TinyLLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span> = <span class="string">&quot;tiny-llm-40m&quot;</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">40</span></span><br><span class="line">    top_p: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.9</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">256</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt_from_messages</span>(<span class="params">messages: <span class="type">List</span>[Message]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    system = <span class="string">&quot;&quot;</span></span><br><span class="line">    user = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;system&quot;</span>:</span><br><span class="line">            system = m.content</span><br><span class="line">        <span class="keyword">elif</span> m.role == <span class="string">&quot;user&quot;</span>:</span><br><span class="line">            user = m.content</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt_from_messages(req.messages)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    out = model.generate(x, max_new_tokens=req.max_tokens, temperature=req.temperature, top_k=req.top_k, top_p=req.top_p)</span><br><span class="line">    text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">    ans = text.split(<span class="string">&quot;&lt;|assistant|&gt;\n&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-local&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=ans), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li>启动服务：<code>uvicorn app:app --host 0.0.0.0 --port 8000</code></li><li>调用示例：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;tiny-llm-40m&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的中文助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用高中生能懂的语言解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 200</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure><hr><h2 id="7-数据准备与清洗示例"><a href="#7-数据准备与清洗示例" class="headerlink" title="7. 数据准备与清洗示例"></a>7. 数据准备与清洗示例</h2><ul><li>语料汇总脚本（合并文本、简单清洗）：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data_prepare.py</span></span><br><span class="line"><span class="keyword">import</span> os, re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean_line</span>(<span class="params">s: <span class="built_in">str</span></span>):</span><br><span class="line">    s = s.strip()</span><br><span class="line">    s = re.sub(<span class="string">r&quot;\s+&quot;</span>, <span class="string">&quot; &quot;</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">r&quot;[^\x09\x0A\x0D\x20-\x7E\u4e00-\u9fff，。？！、：；“”‘’（）《》—…]&quot;</span>, <span class="string">&quot;&quot;</span>, s)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_corpus</span>(<span class="params">src_dir=<span class="string">&quot;data/raw&quot;</span>, out_path=<span class="string">&quot;data/corpus.txt&quot;</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> out:</span><br><span class="line">        <span class="keyword">for</span> root, _, files <span class="keyword">in</span> os.walk(src_dir):</span><br><span class="line">            <span class="keyword">for</span> fn <span class="keyword">in</span> files:</span><br><span class="line">                <span class="keyword">if</span> fn.endswith(<span class="string">&quot;.txt&quot;</span>):</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(root, fn), <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                            line = clean_line(line)</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; <span class="number">1</span>:</span><br><span class="line">                                out.write(line + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Merged to:&quot;</span>, out_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    merge_corpus()</span><br></pre></td></tr></table></figure><hr><h2 id="8-训练建议与资源控制"><a href="#8-训练建议与资源控制" class="headerlink" title="8. 训练建议与资源控制"></a>8. 训练建议与资源控制</h2><ul><li>使用短序列预热：先 seq_len=256 训练一轮，再升到 512 继续。</li><li>小批量 + 梯度裁剪：batch=4–8，clip_grad_norm=1.0。</li><li>定期保存检查点，支持断点续训。</li><li>指令数据质量优先于数量：先 5k–10k 高质量样本效果更稳。</li></ul><hr><h2 id="9-下一步可选增强"><a href="#9-下一步可选增强" class="headerlink" title="9. 下一步可选增强"></a>9. 下一步可选增强</h2><ul><li>量化推理（INT8/INT4）：减少内存占用（训练仍用 FP32）。</li><li>蒸馏到更小规格：dim=384, n_layers=6，进一步提速。</li><li>增加拒答与安全过滤：在 app.py 返回前做关键词/策略检查。</li><li>流式输出：在 FastAPI 里用服务器推送事件（SSE）逐 token 返回。</li></ul><hr><p>如果你愿意，我可以为你的目标领域（比如“中文教育问答”）生成一套高质量的指令模板和小型评测集 JSONL，让你直接训练并验证效果。你更偏好哪些主题和题型？</p><ul><li><a href="https://github.com/zheniu/stochastic-cslr">https://github.com/zheniu/stochastic-cslr</a></li><li><a href="https://github.com/zheniu/stochastic-cslr/blob/main/stochastic_cslr/model/xfmr.py">https://github.com/zheniu/stochastic-cslr/blob/main/stochastic_cslr/model/xfmr.py</a></li></ul><h2 id="对于训练数据，有开源的数据集吗？"><a href="#对于训练数据，有开源的数据集吗？" class="headerlink" title="对于训练数据，有开源的数据集吗？"></a>对于训练数据，有开源的数据集吗？</h2><p><strong>有的 ✅，目前已经有大量开源的大语言模型训练数据集，涵盖预训练语料、指令微调数据、偏好数据和评测数据。你完全可以基于这些开源数据来跑通“小模型”的训练流程。</strong></p><hr><h2 id="🔑-常见的开源数据集类型"><a href="#🔑-常见的开源数据集类型" class="headerlink" title="🔑 常见的开源数据集类型"></a>🔑 常见的开源数据集类型</h2><h3 id="1-预训练语料（基础语言能力）"><a href="#1-预训练语料（基础语言能力）" class="headerlink" title="1. 预训练语料（基础语言能力）"></a>1. 预训练语料（基础语言能力）</h3><ul><li><strong>中文维基百科语料</strong>：经过清洗的中文百科条目，常用于中文基础预训练。</li><li><strong>FineWeb / Ultra-FineWeb</strong>：大规模中英文网页清洗语料，质量较高，适合做小规模预训练子集。</li><li><strong>Chinese-Cosmopedia</strong>：合成的中文百科类数据，覆盖面广。</li></ul><h3 id="2-指令微调数据（让模型“听懂人话”）"><a href="#2-指令微调数据（让模型“听懂人话”）" class="headerlink" title="2. 指令微调数据（让模型“听懂人话”）"></a>2. 指令微调数据（让模型“听懂人话”）</h3><ul><li><strong>Alpaca / Alpaca-GPT4 中文版</strong>：基于指令-回答对的开源数据集，常用于小模型指令微调。</li><li><strong>Belle 数据集</strong>：中文指令微调数据，包含问答、写作、推理等多种任务。</li><li><strong>Baize / ShareGPT</strong>：对话数据集，适合训练聊天风格的模型。</li></ul><h3 id="3-偏好数据（对齐人类价值）"><a href="#3-偏好数据（对齐人类价值）" class="headerlink" title="3. 偏好数据（对齐人类价值）"></a>3. 偏好数据（对齐人类价值）</h3><ul><li><strong>OpenAssistant Conversations</strong>：多轮对话数据，带有人类偏好标注。</li><li><strong>HH-RLHF</strong>：Anthropic 发布的人类偏好数据集，常用于 RLHF。</li></ul><h3 id="4-评测数据（测试模型效果）"><a href="#4-评测数据（测试模型效果）" class="headerlink" title="4. 评测数据（测试模型效果）"></a>4. 评测数据（测试模型效果）</h3><ul><li><strong>CMMLU</strong>：中文多任务评测集，覆盖学科知识。</li><li><strong>C-Eval</strong>：中文考试题型评测集，适合测试模型在教育类任务上的表现。</li></ul><hr><h2 id="📚-推荐资源整理"><a href="#📚-推荐资源整理" class="headerlink" title="📚 推荐资源整理"></a>📚 推荐资源整理</h2><ul><li><strong>知乎整理：444 个大模型数据集下载地址</strong></li><li><strong>CSDN：高质量中文大模型数据集合集</strong></li><li><strong>GitHub：大语言模型高质量数据集汇总</strong></li></ul><p>这些资源里不仅有下载链接，还对数据集做了分类（预训练、指令、偏好、评测），你可以根据硬件条件挑选小规模子集来实验。</p><hr><h2 id="🛠️-给你的小机子建议"><a href="#🛠️-给你的小机子建议" class="headerlink" title="🛠️ 给你的小机子建议"></a>🛠️ 给你的小机子建议</h2><ul><li><strong>预训练</strong>：不要直接用 TB 级数据，先用 <strong>几百 MB 的中文维基语料</strong> 或 <strong>FineWeb 子集</strong>。</li><li><strong>指令微调</strong>：优先选择 <strong>Belle</strong> 或 <strong>Alpaca 中文版</strong>，几万条就能显著提升效果。</li><li><strong>评测</strong>：用 <strong>C-Eval</strong> 或 <strong>CMMLU</strong> 的小样本，快速验证模型是否能回答常识/学科问题。</li></ul><hr><p>👉 总结：<strong>完全有开源数据集可用</strong>，你可以先用中文维基 + Belle 指令数据，跑通一个“小而美”的模型，再逐步扩展。</p><p>要不要我帮你整理一份 <strong>“适合 16GB 内存 CPU 训练的小规模数据集清单 + 下载入口”</strong>，直接给你可用的组合方案？</p><hr><ul><li><a href="https://zhuanlan.zhihu.com/p/19630799254">知乎：《大模型数据集全面整理：444 个数据集下载地址》</a></li><li><a href="https://blog.csdn.net/u011559552/article/details/142152619">CSDN：《最全-高质量大模型中文数据集》</a></li><li><a href="https://github.com/ninehills/blog/issues/129">GitHub Issue：《大语言模型高质量数据集汇总》</a></li></ul><h2 id="对于构建自己的大模型，按照上面-1-2-3……的顺序执行-python-文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？"><a href="#对于构建自己的大模型，按照上面-1-2-3……的顺序执行-python-文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？" class="headerlink" title="对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？"></a>对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？</h2><p>非常好的问题 👍 我来帮你把整个流程梳理清楚，让你知道“执行顺序 → 产出物 → 使用方式 → 微调方法”。</p><hr><h2 id="🛠️-执行顺序"><a href="#🛠️-执行顺序" class="headerlink" title="🛠️ 执行顺序"></a>🛠️ 执行顺序</h2><p>你可以理解为一个流水线，按顺序执行即可：</p><ol><li><strong>数据准备</strong><ul><li>清洗语料，合并成 <code>corpus.txt</code></li><li>构建分词器（<code>build_tokenizer.py</code>）</li></ul></li><li><strong>预训练</strong><ul><li>执行 <code>train_pretrain.py</code>，得到基础语言模型权重</li></ul></li><li><strong>指令微调（SFT）</strong><ul><li>准备 <code>sft.jsonl</code>（问答对）</li><li>执行 <code>train_sft.py</code>，在预训练模型基础上继续训练</li></ul></li><li><strong>推理测试</strong><ul><li>用 <code>generate.py</code> 加载权重，输入问题，看看输出效果</li></ul></li><li><strong>API 部署</strong><ul><li>启动 <code>app.py</code>，通过 HTTP 接口调用模型</li></ul></li></ol><hr><h2 id="📦-模型训练完成后的产出物"><a href="#📦-模型训练完成后的产出物" class="headerlink" title="📦 模型训练完成后的产出物"></a>📦 模型训练完成后的产出物</h2><ul><li><strong>分词器文件</strong>：<ul><li><code>tokenizer/spm.model</code> 和 <code>spm.vocab</code></li><li>用来把文字转成 token，再把 token 转回文字</li></ul></li><li><strong>模型权重文件</strong>：<ul><li><code>checkpoints/pretrain_epochX.pt</code>（预训练阶段）</li><li><code>checkpoints/sft_epochX.pt</code>（指令微调阶段）</li><li>里面保存了模型的参数（数千万个浮点数）</li></ul></li><li><strong>日志/曲线</strong>（可选）：<ul><li>训练时的 loss、困惑度（ppl）变化</li></ul></li></ul><hr><h2 id="🚀-如何使用模型"><a href="#🚀-如何使用模型" class="headerlink" title="🚀 如何使用模型"></a>🚀 如何使用模型</h2><ol><li><strong>离线推理</strong><ul><li>用 <code>generate.py</code> 加载 <code>sft_epochX.pt</code></li><li>输入一个问题，模型会生成回答</li></ul></li><li><strong>API 调用</strong><ul><li>启动 <code>uvicorn app:app --reload</code></li><li>用 <code>curl</code> 或 Python requests 调用 <code>/v1/chat/completions</code></li><li>外部程序就能像调用 OpenAI API 一样使用你的模型</li></ul></li></ol><hr><h2 id="🔧-如何对模型进行微调"><a href="#🔧-如何对模型进行微调" class="headerlink" title="🔧 如何对模型进行微调"></a>🔧 如何对模型进行微调</h2><p>有两种常见方式：</p><h3 id="1-继续指令微调（SFT）"><a href="#1-继续指令微调（SFT）" class="headerlink" title="1. 继续指令微调（SFT）"></a>1. <strong>继续指令微调（SFT）</strong></h3><ul><li>适合：你有新的问答数据（比如某个专业领域）</li><li>做法：<ul><li>准备新的 <code>sft.jsonl</code></li><li>加载已有的 <code>sft_epochX.pt</code></li><li>再跑 <code>train_sft.py</code>，继续训练几轮</li></ul></li><li>效果：模型会更懂你的领域问题</li></ul><h3 id="2-轻量微调（LoRA-Adapter）"><a href="#2-轻量微调（LoRA-Adapter）" class="headerlink" title="2. 轻量微调（LoRA / Adapter）"></a>2. <strong>轻量微调（LoRA / Adapter）</strong></h3><ul><li>适合：硬件有限，不想全量更新参数</li><li>做法：<ul><li>冻结大部分参数，只训练少量“适配层”</li><li>训练速度快，显存/内存占用小</li></ul></li><li>效果：能快速适配新任务，但需要额外代码支持</li></ul><hr><h2 id="✅-总结"><a href="#✅-总结" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>执行顺序</strong>：数据 → 分词器 → 预训练 → 微调 → 推理 → API</li><li><strong>产出物</strong>：分词器文件 + 模型权重</li><li><strong>使用方式</strong>：离线推理 or API 调用</li><li><strong>微调方法</strong>：继续 SFT（全量）或 LoRA（轻量）</li></ul><hr><p>要不要我帮你画一张 <strong>“大模型训练与使用流程图”</strong>（从数据到 API 的全链路），这样你可以一眼看到每一步的输入、输出和产出物？</p><h2 id="一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？"><a href="#一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？" class="headerlink" title="一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？"></a>一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？</h2><p><strong>简答版</strong>：提示词设计和模型结构确实是“互相成就”的关系。没有一个放之四海而皆准的“唯一标准”，但有一套被广泛认可的<strong>提示词工程原则</strong>和<strong>模型对齐策略</strong>。核心思想是：<strong>提示词要清晰、结构化、可预测；模型要在训练阶段就学会理解这种结构化输入</strong>。</p><hr><h2 id="🎯-提示词与模型的配合逻辑"><a href="#🎯-提示词与模型的配合逻辑" class="headerlink" title="🎯 提示词与模型的配合逻辑"></a>🎯 提示词与模型的配合逻辑</h2><ol><li><strong>提示词是接口</strong>：它是人类意图 → 模型输出的桥梁。</li><li><strong>模型是解释器</strong>：它能否理解提示词，取决于训练时是否见过类似的格式。</li><li><strong>最佳效果</strong>：当提示词的风格与模型的训练/微调数据保持一致时，输出最稳定。</li></ol><hr><h2 id="🧩-提示词设计的关键要素"><a href="#🧩-提示词设计的关键要素" class="headerlink" title="🧩 提示词设计的关键要素"></a>🧩 提示词设计的关键要素</h2><p>一个高效提示词通常包含 5 个部分：</p><ul><li>**指令 (Instruction)**：明确告诉模型要做什么</li><li>**上下文 (Context)**：提供必要的背景信息</li><li>**示例 (Examples)**：给出少量范例（few-shot）</li><li>**输入 (Input)**：需要处理的具体内容</li><li>**输出要求 (Output format)**：指定格式、风格、长度</li></ul><p>👉 举例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">作为一名高中物理老师，请用3-5句话解释“为什么天空是蓝色的”。</span><br><span class="line">要求：逐步推理，最后用一句话总结。</span><br></pre></td></tr></table></figure><hr><h2 id="🏗️-模型设计与训练的配合点"><a href="#🏗️-模型设计与训练的配合点" class="headerlink" title="🏗️ 模型设计与训练的配合点"></a>🏗️ 模型设计与训练的配合点</h2><ul><li><strong>预训练阶段</strong>：模型学会语言规律，但对“指令”不敏感。</li><li><strong>指令微调（SFT）</strong>：用大量“指令-回答”对训练，让模型习惯结构化提示。</li><li><strong>RLHF/偏好优化</strong>：让模型更符合人类对“好答案”的偏好（礼貌、逻辑、简洁）。</li><li><strong>上下文窗口设计</strong>：如果模型上下文长度短，提示词就要简洁；长上下文模型则能容纳更多示例。</li></ul><hr><h2 id="📐-有没有“标准”？"><a href="#📐-有没有“标准”？" class="headerlink" title="📐 有没有“标准”？"></a>📐 有没有“标准”？</h2><p>严格意义上没有统一国际标准，但有一些<strong>最佳实践框架</strong>：</p><ul><li><strong>OpenAI 六大策略</strong>：清晰指令、角色设定、分隔符、分步骤、示例、输出约束。</li><li>**Chain of Thought (CoT)**：要求模型逐步推理，提升逻辑性。</li><li><strong>Few-shot / Zero-shot</strong>：通过示例或直接指令引导。</li><li>**角色扮演 (Role prompting)**：给模型一个身份，提升风格一致性。</li></ul><hr><h2 id="✅-总结-1"><a href="#✅-总结-1" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>提示词要结构化、明确、可预测</strong></li><li><strong>模型要在训练中接触过类似格式</strong></li><li><strong>最佳效果来自“提示词工程 + 指令微调”的双重配合</strong></li><li><strong>没有唯一标准，但有成熟框架（如 OpenAI 六大策略、CoT、Few-shot）可遵循</strong></li></ul><hr><p>要不要我帮你整理一份 <strong>“提示词设计速查表”</strong>（包含常见框架、适用场景、示例），方便你在做模型实验时快速套用？</p><ul><li><a href="https://zhuanlan.zhihu.com/p/1945389672600672219">知乎：《提示词工程与优化技巧》</a></li><li><a href="https://www.cnblogs.com/tlnshuju/p/19091427">博客园：《提示词工程方法及框架》</a></li></ul><h2 id="大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？"><a href="#大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？" class="headerlink" title="大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？"></a>大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？</h2><p><strong>简答版</strong>：大模型中的“温度参数”是一个控制<strong>输出随机性和创造性</strong>的旋钮。它通过调整概率分布的“尖锐程度”，决定模型是更倾向于选择高概率的常见词，还是敢于尝试低概率的冷门词。添加这个参数的目的，是在<strong>稳定性</strong>和<strong>多样性</strong>之间找到平衡。</p><hr><h2 id="🔥-温度参数的定义"><a href="#🔥-温度参数的定义" class="headerlink" title="🔥 温度参数的定义"></a>🔥 温度参数的定义</h2><ul><li><strong>数学上</strong>：在 softmax 计算时，把 logits 除以一个温度 (T)。<ul><li>(T &lt; 1)：分布更尖锐 → 高概率词更容易被选中。</li><li>(T = 1)：使用原始分布。</li><li>(T &gt; 1)：分布更平滑 → 低概率词被放大，更容易出现。</li></ul></li></ul><p>公式：</p><p>$$P(w_i) = \frac{e^{z_i / T}}{\sum_j e^{z_j / T}}$$</p><p>其中 $z_i$ 是词的原始得分。</p><hr><h2 id="🎨-为什么要添加温度参数？"><a href="#🎨-为什么要添加温度参数？" class="headerlink" title="🎨 为什么要添加温度参数？"></a>🎨 为什么要添加温度参数？</h2><ol><li><strong>解决“千篇一律”的问题</strong><ul><li>如果总是选最高概率的词（相当于温度=0），输出会非常死板、重复。</li></ul></li><li><strong>解决“胡言乱语”的问题</strong><ul><li>如果完全随机采样，输出可能逻辑混乱。</li></ul></li><li><strong>提供灵活性</strong><ul><li>不同场景需要不同风格：写论文要稳定，写诗歌要有创意。</li></ul></li></ol><hr><h2 id="⚖️-温度带来的效果"><a href="#⚖️-温度带来的效果" class="headerlink" title="⚖️ 温度带来的效果"></a>⚖️ 温度带来的效果</h2><ul><li><strong>低温度（0~0.3）</strong><ul><li>输出更确定、更一致，适合<strong>代码补全、技术文档、法律文本</strong>。</li></ul></li><li><strong>中温度（0.7~1.0）</strong><ul><li>平衡稳定与多样性，适合<strong>日常对话、知识问答</strong>。</li></ul></li><li><strong>高温度（&gt;1.0）</strong><ul><li>输出更有创意，但可能不连贯，适合<strong>故事创作、广告文案</strong>。</li></ul></li></ul><hr><h2 id="🌰-举个例子"><a href="#🌰-举个例子" class="headerlink" title="🌰 举个例子"></a>🌰 举个例子</h2><p>输入：“我喜欢吃…”</p><ul><li><strong>T=0.2</strong> → 模型几乎总是回答“苹果”。</li><li><strong>T=1.0</strong> → 可能回答“苹果”“香蕉”。</li><li><strong>T=1.5</strong> → 甚至可能回答“火星”这种冷门词。</li></ul><hr><p>✅ <strong>总结</strong>：温度参数是大模型的“创意调节器”。它解决了输出要么过于死板、要么过于混乱的问题，让开发者可以根据任务需求，在<strong>准确性</strong>和<strong>创造性</strong>之间自由切换。</p><hr><p>好的 👍 我帮你把 <strong>大模型温度参数的作用</strong>整理成一份速查表，方便你随时查阅和应用。</p><hr><h1 id="🌡️-大语言模型温度参数速查表"><a href="#🌡️-大语言模型温度参数速查表" class="headerlink" title="🌡️ 大语言模型温度参数速查表"></a>🌡️ 大语言模型温度参数速查表</h1><table><thead><tr><th>温度范围</th><th>输出风格</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>0 ~ 0.3</strong></td><td><strong>低温</strong></td><td>输出高度确定，几乎总是选最常见的词，重复性强</td><td>代码补全、法律文书、作业答案、技术文档</td></tr><tr><td><strong>0.4 ~ 0.6</strong></td><td><strong>偏低</strong></td><td>输出平稳、流畅，但缺乏创意</td><td>新闻摘要、知识点总结</td></tr><tr><td><strong>0.7</strong></td><td><strong>中温</strong></td><td>平衡稳定性与多样性，既合理又有变化</td><td>常识问答、日常聊天、教育问答</td></tr><tr><td><strong>0.8 ~ 1.0</strong></td><td><strong>偏高</strong></td><td>更接近人类对话风格，表达更自然</td><td>面试模拟、风格化写作、轻松对话</td></tr><tr><td><strong>&gt; 1.0</strong></td><td><strong>高温</strong></td><td>创造性强，但可能不连贯甚至“胡说”</td><td>故事创作、广告文案、头脑风暴</td></tr></tbody></table><hr><h2 id="🎯-总结"><a href="#🎯-总结" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul><li><strong>温度低</strong> → 输出更稳定、更可控，适合需要准确性的任务。</li><li><strong>温度中等</strong> → 输出平衡，适合大多数通用场景。</li><li><strong>温度高</strong> → 输出更有创意，但风险是逻辑性下降。</li></ul><p>👉 可以把温度理解为“创意旋钮”：</p><ul><li><strong>拧低</strong> → 模型像严谨的工程师。</li><li><strong>拧高</strong> → 模型像天马行空的作家。</li></ul><hr><p>要不要我帮你再整理一份 <strong>“温度参数调节实战指南”</strong>，里面包含不同任务（写代码、写论文、写故事）的推荐温度值和示例提示词？这样你可以直接套用。</p><ul><li><a href="https://api-docs.deepseek.com/zh-cn/quick_start/parameter_settings">deepseek 有关 temperature 参数的设置</a></li></ul><h2 id="我如何使用-hugging-face-或者-model-scope-中的模型，构建属于自己的模型？"><a href="#我如何使用-hugging-face-或者-model-scope-中的模型，构建属于自己的模型？" class="headerlink" title="我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？"></a>我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？</h2><p><strong>快速回答</strong>：你可以把 Hugging Face 或 ModelScope 上的预训练模型当作“基石”，然后通过 <strong>下载 → 加载 → 微调 → 保存 → 部署</strong> 这几个步骤，构建属于自己的模型。核心思路是：<strong>先复用别人训练好的大模型，再用你自己的数据做定制化微调</strong>。</p><hr><h2 id="🧩-使用-Hugging-Face-的流程"><a href="#🧩-使用-Hugging-Face-的流程" class="headerlink" title="🧩 使用 Hugging Face 的流程"></a>🧩 使用 Hugging Face 的流程</h2><ol><li><strong>安装依赖</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers datasets torch</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>加载预训练模型和分词器</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;bert-base-chinese&quot;</span>  <span class="comment"># 或者 &quot;Qwen/Qwen2-7B&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name)</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>准备数据集</strong></li></ol><ul><li>使用 Hugging Face <code>datasets</code> 库加载开源数据，或用你自己的 JSON/CSV。</li><li>格式一般是 <strong>指令 + 输入 + 输出</strong>。</li></ul><ol start="4"><li><strong>微调模型</strong></li></ol><ul><li>小规模任务可用 <strong>Trainer API</strong>：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./my_model&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    learning_rate=<span class="number">5e-5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=my_dataset</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure><ol start="5"><li><strong>保存与使用</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;./my_model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;./my_model&quot;</span>)</span><br></pre></td></tr></table></figure><p>之后你就可以用 <code>from_pretrained(&quot;./my_model&quot;)</code> 来加载你自己的模型。</p><hr><h2 id="🧩-使用-ModelScope-的流程"><a href="#🧩-使用-ModelScope-的流程" class="headerlink" title="🧩 使用 ModelScope 的流程"></a>🧩 使用 ModelScope 的流程</h2><ol><li><strong>安装依赖</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install modelscope</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>加载模型</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> modelscope.utils.constant <span class="keyword">import</span> Tasks</span><br><span class="line"></span><br><span class="line">p = pipeline(Tasks.text_generation, model=<span class="string">&#x27;damo/nlp_gpt3_text-generation_chinese-base&#x27;</span>)</span><br><span class="line">result = p(<span class="string">&quot;你好，请介绍一下云原生&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>微调</strong></li></ol><ul><li>ModelScope 提供了 <strong>Trainer</strong> 和 <strong>PEFT（轻量微调，如 LoRA）</strong>，可以用你自己的数据集进行领域适配。</li><li>训练完成后，模型同样可以保存到本地或上传到 ModelScope Hub。</li></ul><hr><h2 id="🚀-如何构建“属于自己的模型”"><a href="#🚀-如何构建“属于自己的模型”" class="headerlink" title="🚀 如何构建“属于自己的模型”"></a>🚀 如何构建“属于自己的模型”</h2><ul><li><strong>选择基座模型</strong>：根据任务选择（中文 → 中文预训练模型，如 Qwen、ChatGLM；英文 → LLaMA、GPT-NeoX）。</li><li><strong>准备数据</strong>：高质量的领域数据（医疗、教育、客服等）。</li><li><strong>选择微调方式</strong>：<ul><li>全量微调（参数更新多，资源消耗大）</li><li>LoRA/PEFT（只训练小部分参数，适合你这种硬件条件）</li></ul></li><li><strong>保存与部署</strong>：保存模型权重 → 用 FastAPI/Gradio 部署 → 提供 API 给外部调用。</li></ul><hr><p>✅ <strong>总结</strong>：</p><ul><li>Hugging Face 和 ModelScope 都能让你快速加载预训练模型。</li><li>你只需要准备数据并选择合适的微调方式，就能得到一个“属于你”的模型。</li><li>最终产出是 <strong>模型权重 + 分词器</strong>，可以通过 API 或应用直接调用。</li></ul><hr><p>要不要我帮你整理一份 <strong>“Hugging Face vs ModelScope 构建自定义模型对比表”</strong>，让你清楚看到两者在加载、微调、部署上的差异？</p><h2 id="关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段"><a href="#关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段" class="headerlink" title="关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段"></a>关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段</h2><p><strong>有的 ✅，目前已经有不少开源工具专门帮助你在大模型微调阶段准备和管理数据集。它们能帮你清洗、生成、格式化甚至自动构造指令数据，极大降低数据准备的难度。</strong></p><hr><h2 id="🔑-常见的数据集工具"><a href="#🔑-常见的数据集工具" class="headerlink" title="🔑 常见的数据集工具"></a>🔑 常见的数据集工具</h2><h3 id="1-edg4llm"><a href="#1-edg4llm" class="headerlink" title="1. edg4llm"></a>1. <strong>edg4llm</strong></h3><ul><li><strong>定位</strong>：大模型微调数据生成工具</li><li><strong>功能</strong>：<ul><li>自动生成问答对、对话数据</li><li>支持多种格式输出，直接可用于 SFT（监督微调）</li><li>提供简洁 API，轻量级，易上手</li></ul></li><li><strong>适合场景</strong>：你没有现成的高质量数据集，需要快速合成一些指令数据来跑通流程。</li></ul><hr><h3 id="2-Easy-Dataset"><a href="#2-Easy-Dataset" class="headerlink" title="2. Easy Dataset"></a>2. <strong>Easy Dataset</strong></h3><ul><li><strong>定位</strong>：可视化数据集构建工具</li><li><strong>功能</strong>：<ul><li>上传领域文档（PDF、TXT 等）</li><li>自动分割内容、生成问题和答案</li><li>输出标准化的训练数据（JSON/JSONL）</li></ul></li><li><strong>适合场景</strong>：你有特定领域的资料（比如医疗、教育、客服），想快速转化为微调数据。</li></ul><hr><h3 id="3-LLaMA-Factory"><a href="#3-LLaMA-Factory" class="headerlink" title="3. LLaMA-Factory"></a>3. <strong>LLaMA-Factory</strong></h3><ul><li><strong>定位</strong>：统一的 LLM 微调框架</li><li><strong>功能</strong>：<ul><li>内置数据管道，支持 100+ 模型和多种数据格式</li><li>支持 LoRA、QLoRA、全参数微调</li><li>可直接加载开源数据集（如 Alpaca、Belle）</li></ul></li><li><strong>适合场景</strong>：你想要“一站式”解决方案，从数据到训练到部署全覆盖。</li></ul><hr><h3 id="4-XTuner"><a href="#4-XTuner" class="headerlink" title="4. XTuner"></a>4. <strong>XTuner</strong></h3><ul><li><strong>定位</strong>：高效灵活的微调工具包</li><li><strong>功能</strong>：<ul><li>支持多种 LLM（InternLM、Qwen、ChatGLM 等）</li><li>数据管道灵活，能容纳开源和自定义格式</li><li>与 DeepSpeed、FlashAttention 等优化技术兼容</li></ul></li><li><strong>适合场景</strong>：你需要在有限硬件上高效微调，且数据格式多样。</li></ul><hr><h2 id="📌-总结"><a href="#📌-总结" class="headerlink" title="📌 总结"></a>📌 总结</h2><ul><li><strong>数据生成</strong>：edg4llm → 自动合成问答数据</li><li><strong>数据构建</strong>：Easy Dataset → 上传文档生成训练集</li><li><strong>数据到训练一体化</strong>：LLaMA-Factory、XTuner → 内置数据管道 + 微调框架</li></ul><p>👉 换句话说，如果你只是想快速准备数据，<strong>edg4llm / Easy Dataset</strong> 很合适；如果你想要完整的训练流水线，<strong>LLaMA-Factory / XTuner</strong> 更适合。</p><hr><p>要不要我帮你整理一份 <strong>“微调数据集工具对比表”</strong>（从功能、易用性、适用场景三个维度对比），让你能一眼选出最适合你硬件和需求的工具？</p><hr><ul><li><a href="https://blog.csdn.net/T_susan/article/details/145134496">CSDN：《edg4llm：一款简单好用的大模型微调数据生成工具》</a></li><li><a href="https://zhuanlan.zhihu.com/p/694521781">知乎：《五种大模型微调工具》</a></li><li><a href="https://github.com/whale2002/easy-dataset">GitHub：Easy Dataset 项目</a></li><li><a href="https://github.com/ConardLi/easy-dataset">Github: easy-dataset</a></li></ul><h2 id="如何把-pdf，doc，markdown-等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？"><a href="#如何把-pdf，doc，markdown-等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？" class="headerlink" title="如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？"></a>如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？</h2><p><strong>快速回答</strong>：要让大模型“看懂”PDF、Word、Markdown 等文件并基于其内容回答问题，通常分两步：<strong>① 文本提取与向量化（Embedding） → ② 检索增强生成（RAG）</strong>。向量化是把文档内容转成数值向量存入数据库；问问题时先检索相关向量，再把检索到的文本片段作为上下文喂给大模型。</p><hr><h2 id="🧩-步骤详解"><a href="#🧩-步骤详解" class="headerlink" title="🧩 步骤详解"></a>🧩 步骤详解</h2><h3 id="1-文本提取"><a href="#1-文本提取" class="headerlink" title="1. 文本提取"></a>1. 文本提取</h3><ul><li><strong>PDF</strong>：用 <code>pdfplumber</code>、<code>PyPDF2</code> 或开源工具 Marker、MinerU 提取正文，必要时加 OCR（扫描版）。</li><li>**Word (doc/docx)**：用 <code>python-docx</code> 或 <code>docx2txt</code> 提取。</li><li><strong>Markdown</strong>：直接读取文本，或用 <code>markdown</code> 库解析。</li><li><strong>清洗</strong>：去掉页眉页脚、目录、无关符号，按段落或固定长度切分（如 500 tokens 一段）。</li></ul><h3 id="2-向量化（Embedding）"><a href="#2-向量化（Embedding）" class="headerlink" title="2. 向量化（Embedding）"></a>2. 向量化（Embedding）</h3><ul><li>使用开源模型（如 Hugging Face 的 <code>sentence-transformers</code>，或 ModelScope 的中文向量模型）：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"></span><br><span class="line">model = SentenceTransformer(<span class="string">&quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot;</span>)</span><br><span class="line">embeddings = model.encode([<span class="string">&quot;这是第一段文本&quot;</span>, <span class="string">&quot;这是第二段文本&quot;</span>])</span><br></pre></td></tr></table></figure><ul><li>每段文本会变成一个高维向量（如 384/768 维）。</li></ul><h3 id="3-存储向量"><a href="#3-存储向量" class="headerlink" title="3. 存储向量"></a>3. 存储向量</h3><ul><li>常用向量数据库：<strong>FAISS</strong>（本地）、<strong>Milvus</strong>、<strong>Weaviate</strong>、<strong>Pinecone</strong>。</li><li>存储内容：<code>&#123;向量, 原始文本, 文档ID, 段落位置&#125;</code>。</li></ul><h3 id="4-检索-大模型问答（RAG）"><a href="#4-检索-大模型问答（RAG）" class="headerlink" title="4. 检索 + 大模型问答（RAG）"></a>4. 检索 + 大模型问答（RAG）</h3><ul><li>用户提问 → 把问题也向量化 → 在向量数据库中检索最相似的段落。</li><li>把检索到的段落拼接到提示词里，交给大模型生成答案。</li></ul><p>示例伪代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;这份合同的付款条款是什么？&quot;</span></span><br><span class="line">q_vec = model.encode([query])</span><br><span class="line">docs = faiss_index.search(q_vec, k=<span class="number">3</span>)  <span class="comment"># 找到最相关的3段</span></span><br><span class="line">context = <span class="string">&quot;\n&quot;</span>.join([d[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line"></span><br><span class="line">prompt = <span class="string">f&quot;根据以下资料回答问题：\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">answer = llm.generate(prompt)</span><br></pre></td></tr></table></figure><h3 id="5-整体架构（RAG）"><a href="#5-整体架构（RAG）" class="headerlink" title="5. 整体架构（RAG）"></a>5. 整体架构（RAG）</h3><ol><li><strong>离线阶段</strong>：文件 → 文本 → 切分 → 向量化 → 存入数据库</li><li><strong>在线阶段</strong>：问题 → 向量化 → 检索相关片段 → 拼接上下文 → 大模型回答</li></ol><hr><h2 id="✅-总结-2"><a href="#✅-总结-2" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>向量化的目的</strong>：让机器能“理解”文本语义，支持相似度检索。</li><li><strong>大模型的角色</strong>：不是直接“记住”文档，而是基于检索到的上下文生成答案。</li><li><strong>关键技术</strong>：文本提取 → Embedding → 向量数据库 → RAG。</li></ul><hr><p>要不要我帮你画一张 <strong>“文档 → 向量化 → 检索 → 大模型问答”流程图</strong>，让你一眼看到整个数据流转过程？</p><h2 id="Rerank-模型工作在什么阶段？什么时间使用它？"><a href="#Rerank-模型工作在什么阶段？什么时间使用它？" class="headerlink" title="Rerank 模型工作在什么阶段？什么时间使用它？"></a>Rerank 模型工作在什么阶段？什么时间使用它？</h2><p><strong>简答版</strong>：Rerank 模型工作在 <strong>检索增强生成（RAG）流程的“初步检索之后、大模型生成之前”</strong>。它的作用是对初步检索到的一批候选文档进行<strong>精细排序</strong>，把真正最相关的内容排在前面。通常在<strong>需要更高准确性</strong>时使用，比如问答系统、法律/医疗文档检索、企业知识库。</p><hr><h2 id="🧩-Rerank-模型的工作阶段"><a href="#🧩-Rerank-模型的工作阶段" class="headerlink" title="🧩 Rerank 模型的工作阶段"></a>🧩 Rerank 模型的工作阶段</h2><ol><li><strong>用户提问</strong><ul><li>输入问题，例如：“合同的付款条款是什么？”</li></ul></li><li><strong>初步检索（向量检索 / BM25）</strong><ul><li>从数据库里快速找到一批候选文档（可能几十条）。</li><li>这一步速度快，但相关性不够精准。</li></ul></li><li><strong>Rerank（重排序）</strong><ul><li>使用更复杂的模型（如 cross-encoder）逐一对“问题-文档”对进行打分。</li><li>重新排序，把最相关的几条放在最前面。</li></ul></li><li><strong>大模型生成</strong><ul><li>把排序靠前的文档拼接进提示词，交给大模型生成答案。</li></ul></li></ol><hr><h2 id="🎯-为什么要用-Rerank？"><a href="#🎯-为什么要用-Rerank？" class="headerlink" title="🎯 为什么要用 Rerank？"></a>🎯 为什么要用 Rerank？</h2><ul><li><strong>解决初检不精准的问题</strong>：向量检索只看“语义相似度”，可能把表面相似但无关的段落排前。</li><li><strong>减少噪音</strong>：避免大模型读到一堆无关上下文，浪费 token，还可能答非所问。</li><li><strong>提升准确率</strong>：让大模型优先利用真正相关的上下文，答案更可靠。</li></ul><hr><h2 id="⏰-什么时候使用-Rerank？"><a href="#⏰-什么时候使用-Rerank？" class="headerlink" title="⏰ 什么时候使用 Rerank？"></a>⏰ 什么时候使用 Rerank？</h2><ul><li><strong>文档库很大</strong>：初步检索结果可能包含很多噪音。</li><li><strong>任务要求高精度</strong>：如法律、医疗、金融问答，不能容忍答错。</li><li><strong>上下文窗口有限</strong>：大模型一次能读的 token 有限，必须挑最相关的内容。</li><li><strong>多路检索融合</strong>：当你同时用关键词检索 + 向量检索时，Rerank 可以统一排序。</li></ul><hr><h2 id="✅-总结-3"><a href="#✅-总结-3" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>阶段</strong>：Rerank 在“初步检索之后、大模型生成之前”。</li><li><strong>作用</strong>：对候选文档做精细排序，保证大模型读到的上下文最相关。</li><li><strong>使用时机</strong>：当你需要更高准确性、上下文有限或文档库庞大时。</li></ul><hr><p>要不要我帮你画一张 <strong>“RAG + Rerank 流程图”</strong>，把“用户提问 → 初检 → Rerank → 大模型生成”的数据流清晰展示出来？</p><h2 id="在-RAG-的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？"><a href="#在-RAG-的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？" class="headerlink" title="在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？"></a>在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？</h2><p><strong>快速回答</strong>：在 RAG（检索增强生成）技术中，通常会用到 <strong>4 大类模型</strong>，分别在不同阶段发挥作用：<strong>Embedding 模型 → 检索模型 → Rerank 模型 → 大语言模型（LLM）</strong>。它们的目标是：先把文档转成向量，快速找到候选，再精排，最后生成答案，从而解决大模型知识过时、幻觉和私有数据利用的问题。</p><hr><h2 id="🧩-RAG-技术中的模型类型与阶段"><a href="#🧩-RAG-技术中的模型类型与阶段" class="headerlink" title="🧩 RAG 技术中的模型类型与阶段"></a>🧩 RAG 技术中的模型类型与阶段</h2><h3 id="1-Embedding-模型（向量化阶段）"><a href="#1-Embedding-模型（向量化阶段）" class="headerlink" title="1. Embedding 模型（向量化阶段）"></a>1. <strong>Embedding 模型（向量化阶段）</strong></h3><ul><li><strong>阶段</strong>：知识库构建时，把文档切分后的片段转成向量。</li><li><strong>常见模型</strong>：<code>sentence-transformers</code>、<code>text-embedding-ada-002</code>、中文向量模型（如 bge-m3）。</li><li><strong>效果</strong>：让文本能以“语义相似度”方式被检索，而不是仅靠关键词。</li></ul><hr><h3 id="2-检索模型（初步召回阶段）"><a href="#2-检索模型（初步召回阶段）" class="headerlink" title="2. 检索模型（初步召回阶段）"></a>2. <strong>检索模型（初步召回阶段）</strong></h3><ul><li><strong>阶段</strong>：用户提问后，把问题向量化，在向量数据库里找到最相似的文档片段。</li><li><strong>常见方法</strong>：<ul><li>向量检索（FAISS、Milvus、Weaviate）</li><li>关键词检索（BM25、Elasticsearch）</li><li>混合检索（向量 + 关键词）</li></ul></li><li><strong>效果</strong>：快速缩小候选范围，保证召回率。</li></ul><hr><h3 id="3-Rerank-模型（重排序阶段）"><a href="#3-Rerank-模型（重排序阶段）" class="headerlink" title="3. Rerank 模型（重排序阶段）"></a>3. <strong>Rerank 模型（重排序阶段）</strong></h3><ul><li><strong>阶段</strong>：对初步检索到的候选文档进行精细打分和排序。</li><li><strong>常见模型</strong>：Cross-Encoder（如 <code>bge-reranker</code>）、ColBERT。</li><li><strong>效果</strong>：把真正最相关的文档排在前面，减少噪音，提升准确率。</li></ul><hr><h3 id="4-大语言模型-LLM（生成阶段）"><a href="#4-大语言模型-LLM（生成阶段）" class="headerlink" title="4. 大语言模型 LLM（生成阶段）"></a>4. <strong>大语言模型 LLM（生成阶段）</strong></h3><ul><li><strong>阶段</strong>：把排序后的文档片段拼接到提示词中，交给 LLM 生成答案。</li><li><strong>常见模型</strong>：GPT、LLaMA、Qwen、ChatGLM 等。</li><li><strong>效果</strong>：基于外部知识生成自然语言回答，解决知识时效性和幻觉问题。</li></ul><hr><h2 id="🎯-总结-1"><a href="#🎯-总结-1" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul><li><strong>Embedding 模型</strong>：负责“理解”文本 → 向量化</li><li><strong>检索模型</strong>：负责“找到”相关文档 → 初步召回</li><li><strong>Rerank 模型</strong>：负责“挑选”最相关的 → 精排</li><li><strong>LLM</strong>：负责“回答” → 基于上下文生成</li></ul><p>👉 换句话说，RAG 就像一个“信息管道”：<strong>Embedding 把知识装进管道 → 检索把水抽出来 → Rerank 过滤杂质 → LLM 输出清澈的答案</strong>。</p><hr><p>要不要我帮你画一张 <strong>“RAG 技术模型分工图”</strong>，把这四类模型在流程中的位置和作用直观展示出来？</p><ul><li><a href="https://zhuanlan.zhihu.com/p/1948688100764153329">知乎：《RAG 技术全解析》</a></li><li><a href="https://developer.baidu.com/article/detail.html?id=3891992">百度开发者中心：《大模型应用进阶：RAG 技术全解析与实战指南》</a></li></ul><h2 id="如何实现溯源？现在-RAG-技术还是最好的技术方案吗？有更先进的方案吗？"><a href="#如何实现溯源？现在-RAG-技术还是最好的技术方案吗？有更先进的方案吗？" class="headerlink" title="如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？"></a>如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？</h2><p><strong>简答版</strong>：<br>在大模型应用中，<strong>溯源</strong>通常通过在 RAG 流程中保留检索到的原始文档片段及其出处来实现。RAG 目前仍是最主流、工程化程度最高的方案，但它并非终点。正在兴起的更先进方向包括 <strong>知识图谱增强、检索+推理混合架构、多模态 RAG、以及 Agent 式动态工具调用</strong>，这些都在尝试解决 RAG 的局限。</p><hr><h2 id="🔎-如何实现溯源"><a href="#🔎-如何实现溯源" class="headerlink" title="🔎 如何实现溯源"></a>🔎 如何实现溯源</h2><ol><li><p><strong>检索阶段保留元数据</strong></p><ul><li>在向量数据库中存储的不仅是文本向量，还包括 <strong>文档 ID、标题、页码、URL</strong> 等元信息。</li><li>当检索到片段时，连同这些元数据一起返回。</li></ul></li><li><p><strong>答案生成时引用来源</strong></p><ul><li>将检索到的片段拼接进提示词，让大模型在回答中引用出处。</li><li>例如：“根据《合同法》第三章第 12 条，付款条款为……”</li></ul></li><li><p><strong>可视化溯源</strong></p><ul><li>在前端界面中，将模型回答与原始文档片段链接起来，用户可点击查看。</li><li>这样不仅增强可信度，也方便人工复核。</li></ul></li></ol><hr><h2 id="📌-RAG-是否仍是最佳方案？"><a href="#📌-RAG-是否仍是最佳方案？" class="headerlink" title="📌 RAG 是否仍是最佳方案？"></a>📌 RAG 是否仍是最佳方案？</h2><ul><li><strong>优势</strong>：<ul><li>解决了大模型知识过时、幻觉问题。</li><li>工程化成熟，生态完善（LangChain、LlamaIndex 等）。</li><li>成本低于全量微调，支持动态更新知识库。</li></ul></li><li><strong>局限</strong>：<ul><li>检索质量决定答案质量，若召回不准，模型仍可能“胡编”。</li><li>上下文窗口有限，长文档或多跳推理时容易丢失关键信息。</li><li>溯源粒度有限，通常只能到段落级别。</li></ul></li></ul><hr><h2 id="🚀-更先进的方案探索"><a href="#🚀-更先进的方案探索" class="headerlink" title="🚀 更先进的方案探索"></a>🚀 更先进的方案探索</h2><ol><li><p><strong>知识图谱增强 RAG</strong></p><ul><li>在检索时不仅返回文本，还能利用实体关系图，支持更复杂的推理和更精准的溯源。</li></ul></li><li><p><strong>RAG + 逻辑推理（Reasoning-Augmented RAG）</strong></p><ul><li>在检索后增加一个“推理层”，让模型能跨段落、多跳推理，而不是仅拼接上下文。</li></ul></li><li><p><strong>多模态 RAG</strong></p><ul><li>不仅检索文本，还能检索图像、表格、音频，支持更丰富的溯源场景（如医学影像+报告）。</li></ul></li><li><p><strong>Agent 式动态工具调用</strong></p><ul><li>模型在回答时可调用外部 API、数据库、计算工具，实时查证并返回带来源的答案。</li></ul></li><li><p><strong>检索+生成融合模型（如 RETRO、Atlas）</strong></p><ul><li>在训练阶段就把检索机制融入模型架构，使其“原生”具备溯源能力，而不是外挂式。</li></ul></li></ol><hr><h2 id="✅-总结-4"><a href="#✅-总结-4" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>溯源实现</strong>：靠在检索阶段保留元数据，并在回答中显式引用。</li><li><strong>RAG 现状</strong>：仍是最成熟、性价比最高的方案，但有局限。</li><li><strong>未来趋势</strong>：知识图谱增强、多跳推理、多模态检索、Agent 工具调用，以及“原生检索模型”。</li></ul><hr><p>要不要我帮你画一张 <strong>“RAG 与下一代增强方案对比图”</strong>，把它们的流程和溯源能力直观对比出来？</p><h2 id="什么是多模态大模型？"><a href="#什么是多模态大模型？" class="headerlink" title="什么是多模态大模型？"></a>什么是多模态大模型？</h2><p><strong>多模态大模型（Multimodal Large Language Model, MLLM）</strong> 是一种能同时理解和处理多种类型信息的模型，比如文字、图像、语音、视频等。它的目标是让 AI 像人类一样，能“看图说话”“听声识意”“读文理解”，实现更自然、更全面的智能交互。</p><hr><h2 id="🧠-多模态的“模态”指什么？"><a href="#🧠-多模态的“模态”指什么？" class="headerlink" title="🧠 多模态的“模态”指什么？"></a>🧠 多模态的“模态”指什么？</h2><ul><li><strong>模态（Modality）</strong> 就是信息的类型或感官通道：<ul><li>📄 文本（语言）</li><li>🖼️ 图像（视觉）</li><li>🔊 音频（听觉）</li><li>🎥 视频（时序视觉+听觉）</li><li>🧭 结构化数据（表格、坐标、传感器）</li></ul></li></ul><hr><h2 id="🧩-多模态大模型的核心能力"><a href="#🧩-多模态大模型的核心能力" class="headerlink" title="🧩 多模态大模型的核心能力"></a>🧩 多模态大模型的核心能力</h2><table><thead><tr><th>能力</th><th>示例</th><th>模型如何处理</th></tr></thead><tbody><tr><td>看图说话</td><td>“这张图里有什么？”</td><td>图像 → 向量 → 与文本融合 → 生成回答</td></tr><tr><td>图文混合理解</td><td>“根据这张图和说明，解释原理”</td><td>图像 + 文本 → 联合编码 → 推理</td></tr><tr><td>语音识别与理解</td><td>“听完这段话，总结重点”</td><td>音频 → 语音转文本 → LLM 处理</td></tr><tr><td>视频问答</td><td>“视频中人物在做什么？”</td><td>视频帧 + 音频 → 多模态融合 → 生成回答</td></tr><tr><td>表格/图表理解</td><td>“这张表格说明了什么趋势？”</td><td>表格结构 → 特征提取 → 语言生成</td></tr></tbody></table><hr><h2 id="🚀-多模态大模型的代表"><a href="#🚀-多模态大模型的代表" class="headerlink" title="🚀 多模态大模型的代表"></a>🚀 多模态大模型的代表</h2><ul><li><strong>GPT-4V</strong>：支持图像输入，能看图回答问题、识别图表、理解截图。</li><li><strong>Gemini</strong>：Google 发布的多模态模型，支持图像、音频、视频、代码等。</li><li><strong>Qwen-VL / InternVL</strong>：中文多模态模型，支持图文问答、OCR、图表理解。</li><li><strong>MiniGPT-4 / LLaVA</strong>：开源图文模型，适合本地部署和实验。</li></ul><hr><h2 id="🎯-多模态模型的优势"><a href="#🎯-多模态模型的优势" class="headerlink" title="🎯 多模态模型的优势"></a>🎯 多模态模型的优势</h2><ul><li>更贴近人类认知方式（我们不是只靠文字交流）</li><li>能处理真实世界复杂任务（如医学影像+病历分析）</li><li>支持更自然的交互方式（拍照提问、语音对话）</li></ul><hr><h2 id="✅-总结-5"><a href="#✅-总结-5" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li>多模态大模型 = 能同时理解图像、文字、语音等多种信息的 AI 模型。</li><li>它让 AI 不再“只会读文字”，而是能“看、听、说、理解”。</li><li>是通向“通用人工智能（AGI）”的重要一步。</li></ul><hr><p>要不要我帮你整理一份 <strong>“多模态模型能力清单 + 应用场景图解”</strong>，比如哪些任务适合用图文模型、哪些适合语音+文本模型？这样你可以一眼选出最适合的模型组合。</p><h2 id="大模型如何实现-reasoning-？"><a href="#大模型如何实现-reasoning-？" class="headerlink" title="大模型如何实现 reasoning ？"></a>大模型如何实现 reasoning ？</h2><p><strong>简答版</strong>：大模型的 <em>reasoning（推理能力）</em> 并不是“天生”的，而是通过 <strong>训练方法、提示设计和架构改进</strong> 逐步实现的。核心思路是让模型不仅直接给答案，而是学会“分步骤思考”，在中间生成逻辑链条，再得出结论。</p><hr><h2 id="🧩-大模型实现-Reasoning-的主要方式"><a href="#🧩-大模型实现-Reasoning-的主要方式" class="headerlink" title="🧩 大模型实现 Reasoning 的主要方式"></a>🧩 大模型实现 Reasoning 的主要方式</h2><h3 id="1-Chain-of-Thought-CoT-思维链"><a href="#1-Chain-of-Thought-CoT-思维链" class="headerlink" title="1. Chain of Thought (CoT) 思维链"></a>1. <strong>Chain of Thought (CoT) 思维链</strong></h3><ul><li><strong>原理</strong>：在训练或提示中要求模型“逐步推理”，而不是直接输出答案。</li><li><strong>例子</strong>：<ul><li>提示：“请一步一步推理，最后给出答案。”</li><li>模型输出：先写出中间推理步骤，再给最终结论。</li></ul></li><li><strong>效果</strong>：显著提升数学题、逻辑题、复杂问答的正确率。</li></ul><hr><h3 id="2-Self-Consistency（自洽采样）"><a href="#2-Self-Consistency（自洽采样）" class="headerlink" title="2. Self-Consistency（自洽采样）"></a>2. <strong>Self-Consistency（自洽采样）</strong></h3><ul><li><strong>原理</strong>：让模型生成多条推理路径，然后选出最一致的答案。</li><li><strong>效果</strong>：减少“幻觉”或偶然错误，提升稳定性。</li></ul><hr><h3 id="3-外部工具与检索增强"><a href="#3-外部工具与检索增强" class="headerlink" title="3. 外部工具与检索增强"></a>3. <strong>外部工具与检索增强</strong></h3><ul><li><strong>RAG + Reasoning</strong>：先检索相关知识，再让模型基于证据推理。</li><li><strong>工具调用</strong>：模型在推理过程中调用计算器、代码执行器、数据库，保证逻辑正确。</li><li><strong>效果</strong>：解决模型“算不准”“记不牢”的问题。</li></ul><hr><h3 id="4-强化学习与奖励模型"><a href="#4-强化学习与奖励模型" class="headerlink" title="4. 强化学习与奖励模型"></a>4. <strong>强化学习与奖励模型</strong></h3><ul><li><strong>RLHF（人类反馈强化学习）</strong>：通过奖励模型鼓励模型输出符合逻辑的推理链。</li><li><strong>逻辑奖励</strong>：在数学/编程任务中，只有推理正确才给奖励。</li><li><strong>效果</strong>：让模型更倾向于“思考后回答”。</li></ul><hr><h3 id="5-架构与训练改进"><a href="#5-架构与训练改进" class="headerlink" title="5. 架构与训练改进"></a>5. <strong>架构与训练改进</strong></h3><ul><li><strong>专门推理模型</strong>：如 DeepSeek R1、OpenAI o1 系列，会在生成答案前显式“思考”。</li><li><strong>神经符号结合</strong>：把符号逻辑（规则、定理证明器）与大模型结合，提升可验证性。</li><li><strong>搜索增强</strong>：用蒙特卡洛树搜索（MCTS）模拟人类“深度思考”过程。</li></ul><hr><h2 id="🎯-总结-2"><a href="#🎯-总结-2" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul><li><strong>基础层面</strong>：通过 <em>思维链提示</em> 让模型学会“逐步推理”。</li><li><strong>增强层面</strong>：通过 <em>自洽采样、检索、工具调用</em> 提升正确率。</li><li><strong>训练层面</strong>：通过 <em>RLHF、逻辑奖励</em> 让模型更可靠。</li><li><strong>前沿探索</strong>：结合 _符号推理、搜索算法_，让模型更接近人类的“深度思考”。</li></ul><hr><p>换句话说，大模型的 reasoning 是“提示工程 + 数据训练 + 架构优化”的综合产物。它不是单一技巧，而是一整套方法协同作用的结果。</p><p>要不要我帮你整理一份 <strong>“大模型推理能力提升路线图”</strong>（从基础到前沿，每个阶段的关键方法和代表模型），让你能一眼看到行业演进？</p><hr><ul><li><a href="https://zhuanlan.zhihu.com/p/22095933478">知乎《Reasoning LLMs 综述》</a></li><li><a href="https://blog.csdn.net/weixin_59191169/article/details/149421971">CSDN《大模型推理能力全解析》</a></li></ul><h2 id="请继续本对话中的例子，训练一个-reasoning-的大模型。"><a href="#请继续本对话中的例子，训练一个-reasoning-的大模型。" class="headerlink" title="请继续本对话中的例子，训练一个 reasoning 的大模型。"></a>请继续本对话中的例子，训练一个 reasoning 的大模型。</h2><h1 id="在-16GB-内存、8-核-CPU-上训练一个具备推理能力的小模型"><a href="#在-16GB-内存、8-核-CPU-上训练一个具备推理能力的小模型" class="headerlink" title="在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型"></a>在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型</h1><p>你已经有“从零到 API”的小型指令模型流水线。下面我们在同样的硬件约束下，把它升级为“会推理”的模型：通过思维链（CoT）数据、过程奖励风格的监督微调、以及自洽采样与工具调用的推理时策略，实现可落地的 reasoning。</p><hr><h2 id="目标与核心思路"><a href="#目标与核心思路" class="headerlink" title="目标与核心思路"></a>目标与核心思路</h2><ul><li><strong>目标:</strong> 让模型不只给答案，还能输出清晰的中间推理步骤，再给结论。</li><li><strong>思路:</strong><ul><li><strong>训练时:</strong> 使用带“推理步骤”的高质量样本做监督微调（CoT SFT）。</li><li><strong>推理时:</strong> 使用自洽采样（多条思路投票）与可选工具调用（计算器）提高正确率。</li><li><strong>安全与格式:</strong> 模板约束，要求“先推理，后用一句话给最终答案”。</li></ul></li></ul><hr><h2 id="数据集准备（CoT-思维链格式）"><a href="#数据集准备（CoT-思维链格式）" class="headerlink" title="数据集准备（CoT 思维链格式）"></a>数据集准备（CoT 思维链格式）</h2><p>在 data/reasoning_sft.jsonl 中，每条样本包含推理步骤与最终答案，统一模板：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;一个盒子里有3个红球和2个蓝球，随机取一个红球的概率是多少？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;总球数为3+2=5。红球数为3。随机取一个球为等可能事件，红球概率=3/5。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：3/5。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;计算：12*(3+4)-10&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;先计算括号：3+4=7。然后乘法：12*7=84。最后减法：84-10=74。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：74。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;如果每小时生产x个零件，8小时一共生产多少？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;每小时x个，8小时为8*x。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：8x。&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><ul><li><strong>标签策略:</strong> 只在 <code>&lt;|assistant|&gt;</code> 段落开始后计算损失；system/user 部分忽略。</li><li><strong>质量优先:</strong> 少量高质量（5k–20k）CoT 样本 &gt; 海量低质数据。</li><li><strong>混合数据:</strong> 可混入常规 SFT 样本，但保持 CoT 比例，确保模型学习“先推理再结论”。</li></ul><hr><h2 id="提示模板（推理风格）"><a href="#提示模板（推理风格）" class="headerlink" title="提示模板（推理风格）"></a>提示模板（推理风格）</h2><p>使用结构化模板，明确“先推理、后结论”的行为：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;|system|&gt;</span><br><span class="line">&#123;system&#125;</span><br><span class="line">&lt;|sep|&gt;</span><br><span class="line">&lt;|user|&gt;</span><br><span class="line">&#123;user&#125;</span><br><span class="line">&lt;|sep|&gt;</span><br><span class="line">&lt;|assistant|&gt;</span><br><span class="line">【推理过程】</span><br><span class="line">&#123;cot&#125;</span><br><span class="line">【最终答案】</span><br><span class="line">&#123;final&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>约束语言:</strong> 推理段以“【推理过程】”开头，结论段以“【最终答案】”开头，便于解析与评测。</li><li><strong>推理长度:</strong> 控制在 3–8 句，避免冗长。</li></ul><hr><h2 id="训练代码（CoT-SFT）"><a href="#训练代码（CoT-SFT）" class="headerlink" title="训练代码（CoT SFT）"></a>训练代码（CoT SFT）</h2><p>在原 train_sft.py 基础上增加对 CoT 字段的支持与模板：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_reasoning_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n【推理过程】\n&#123;cot&#125;\n【最终答案】\n&#123;final&#125;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReasoningSFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>], cot=obj[<span class="string">&quot;cot&quot;</span>], final=obj[<span class="string">&quot;final&quot;</span>])</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># 仅对 assistant 段计算损失：系统+用户部分忽略</span></span><br><span class="line">                prefix = <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;system&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;user&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line">                prefix_ids = <span class="variable language_">self</span>.sp.encode(prefix, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prefix_ids) + ids[<span class="built_in">len</span>(prefix_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels += [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_reasoning_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/reasoning_sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = ReasoningSFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded base:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        moving = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)</span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            moving += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>] cot_sft_loss=<span class="subst">&#123;moving/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                moving = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;reasoning_sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_reasoning_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>训练建议:</strong> 先用 seq_len=256 预热，再升到 512；混合常规 SFT 与 CoT 样本；适度正则避免过拟合。</li></ul><hr><h2 id="推理时策略：自洽采样与“最终答案”抽取"><a href="#推理时策略：自洽采样与“最终答案”抽取" class="headerlink" title="推理时策略：自洽采样与“最终答案”抽取"></a>推理时策略：自洽采样与“最终答案”抽取</h2><p>在 generate.py 基础上增加“多次采样 + 投票”的能力，并解析“【最终答案】”：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate_reasoning.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_final</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 抽取最终答案段</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">return</span> text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_self_consistency</span>(<span class="params">model_ckpt, spm_path, system, user, samples=<span class="number">5</span>, max_new_tokens=<span class="number">200</span>, temperature=<span class="number">0.8</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x0 = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    finals = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        x = x0.clone()</span><br><span class="line">        out = model.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        finals.append(parse_final(text))</span><br><span class="line">    <span class="comment"># 投票选择出现次数最多的答案</span></span><br><span class="line">    vote = Counter(finals)</span><br><span class="line">    best_final, _ = vote.most_common(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> best_final, finals</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    best, all_finals = run_self_consistency(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/reasoning_sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是严谨的中文推理助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;计算：12*(3+4)-10&quot;</span>,</span><br><span class="line">        samples=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;投票最终答案:&quot;</span>, best)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所有候选:&quot;</span>, all_finals)</span><br></pre></td></tr></table></figure><ul><li><strong>自洽采样:</strong> 提升稳定性，降低“走错路”的概率；CPU 上样本数控制在 3–7 较合适。</li><li><strong>温度:</strong> 建议 0.7–0.9，允许路径多样，但不至于发散。</li></ul><hr><h2 id="可选：推理中的工具调用（轻量计算器）"><a href="#可选：推理中的工具调用（轻量计算器）" class="headerlink" title="可选：推理中的工具调用（轻量计算器）"></a>可选：推理中的工具调用（轻量计算器）</h2><p>当问题包含明显的算式时，先用规则提取表达式，用 Python 计算后填入上下文，减少算错：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tiny_tools.py</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_expression</span>(<span class="params">text</span>):</span><br><span class="line">    m = re.findall(<span class="string">r&quot;[\d\.\+\-\*\/\(\)\s]+&quot;</span>, text)</span><br><span class="line">    <span class="comment"># 简化：取最长可能表达式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> m: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    expr = <span class="built_in">max</span>(m, key=<span class="built_in">len</span>).strip()</span><br><span class="line">    <span class="comment"># 安全限制：只允许数字与 +-*/()</span></span><br><span class="line">    <span class="keyword">if</span> re.fullmatch(<span class="string">r&quot;[0-9\.\+\-\*\/\(\)\s]+&quot;</span>, expr):</span><br><span class="line">        <span class="keyword">return</span> expr</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">safe_eval</span>(<span class="params">expr</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">eval</span>(expr, &#123;<span class="string">&quot;__builtins__&quot;</span>: &#123;&#125;&#125;, &#123;&#125;)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure><p>在构造 prompt 时加入“已计算的中间结果”作为辅助证据，或在生成后校正“最终答案”段。这种“外部工具辅助”可显著降低算术类错误。</p><hr><h2 id="API-集成（返回推理链与出处）"><a href="#API-集成（返回推理链与出处）" class="headerlink" title="API 集成（返回推理链与出处）"></a>API 集成（返回推理链与出处）</h2><p>在 app.py 中增加返回“推理过程”与“最终答案”，并可选启用自洽采样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app_reasoning.py（核心片段）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_segments</span>(<span class="params">text</span>):</span><br><span class="line">    parts = &#123;<span class="string">&quot;reasoning&quot;</span>: <span class="string">&quot;&quot;</span>, <span class="string">&quot;final&quot;</span>: <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【推理过程】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        seg = text.split(<span class="string">&quot;【推理过程】&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">        parts[<span class="string">&quot;reasoning&quot;</span>] = seg.split(<span class="string">&quot;【最终答案】&quot;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        parts[<span class="string">&quot;final&quot;</span>] = text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> parts</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="comment"># ...鉴权与加载省略</span></span><br><span class="line">    prompt = build_prompt_from_messages(req.messages)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自洽采样可选</span></span><br><span class="line">    <span class="keyword">if</span> req.temperature <span class="keyword">and</span> req.temperature &gt; <span class="number">0.0</span> <span class="keyword">and</span> req.top_p <span class="keyword">and</span> req.top_p &lt; <span class="number">1.0</span>:</span><br><span class="line">        out = model.generate(x, max_new_tokens=req.max_tokens, temperature=req.temperature, top_k=req.top_k, top_p=req.top_p)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        segs = parse_segments(text)</span><br><span class="line">        content = <span class="string">f&quot;推理：\n<span class="subst">&#123;segs[<span class="string">&#x27;reasoning&#x27;</span>]&#125;</span>\n\n最终答案：<span class="subst">&#123;segs[<span class="string">&#x27;final&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 或者用多次采样投票（略）</span></span><br><span class="line">        out = model.generate(x, max_new_tokens=req.max_tokens)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        segs = parse_segments(text)</span><br><span class="line">        content = <span class="string">f&quot;推理：\n<span class="subst">&#123;segs[<span class="string">&#x27;reasoning&#x27;</span>]&#125;</span>\n\n最终答案：<span class="subst">&#123;segs[<span class="string">&#x27;final&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-reasoning&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=content), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><ul><li><strong>返回格式:</strong> 同时提供“推理链”和“最终答案”，便于前端展示与用户校验。</li><li><strong>溯源集成:</strong> 若在 RAG 场景中使用，附带每段上下文的来源元数据；推理链中可插入引用编号。</li></ul><hr><h2 id="评测与迭代"><a href="#评测与迭代" class="headerlink" title="评测与迭代"></a>评测与迭代</h2><ul><li><strong>离线评测集:</strong> 数学小题、逻辑题、日常常识推理；记录准确率与步骤规范性。</li><li><strong>指标:</strong><ul><li><strong>步骤质量:</strong> 是否遵循“先推理、后答案”模板。</li><li><strong>正确率:</strong> 最终答案是否正确。</li><li><strong>稳定性:</strong> 自洽采样的一致性提升幅度。</li></ul></li><li><strong>迭代策略:</strong><ul><li>优先补充错误样本的反例与修正版本，扩大 CoT 数据覆盖面。</li><li>对容易算错的题型启用工具调用或在 SFT 中加入“算式校核”风格样本。</li></ul></li></ul><hr><h2 id="硬件友好建议"><a href="#硬件友好建议" class="headerlink" title="硬件友好建议"></a>硬件友好建议</h2><ul><li><strong>模型规模控制:</strong> 8 层/512 维/heads=8/ffn=2048，seq_len=256→512 分阶段。</li><li><strong>批次与累积:</strong> batch=4–8，梯度累积至 32–64。</li><li><strong>训练时长:</strong> 以小时为单位、小数据迭代，关注损失曲线与样例效果，不追求大规模长跑。</li></ul><hr><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li><strong>训练层面:</strong> 用带“推理步骤”的 CoT 数据做监督微调，让模型学会结构化思考。</li><li><strong>推理层面:</strong> 自洽采样投票 + 轻量工具调用，显著提升正确率与稳定性。</li><li><strong>服务层面:</strong> API 返回推理链与最终答案，方便用户审核与持续改进。</li></ul><p>如果你告诉我希望覆盖的题型（比如小学算术、概率统计、逻辑推断、工程估算），我可以立刻为你生成一批适配的 CoT 样本模板与评测集，直接开训并验证效果。</p><h2 id="请给出全部代码实现"><a href="#请给出全部代码实现" class="headerlink" title="请给出全部代码实现"></a>请给出全部代码实现</h2><p>好的 Mark，我来帮你把前面我们讨论的 <strong>“从零训练一个具备 reasoning 能力的小模型”</strong> 的完整代码实现整理成一个可运行的工程结构。你可以直接按模块保存为不同的 <code>.py</code> 文件，逐步执行。</p><hr><h1 id="📂-项目结构"><a href="#📂-项目结构" class="headerlink" title="📂 项目结构"></a>📂 项目结构</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">reasoning-llm/</span><br><span class="line">│</span><br><span class="line">├── data/</span><br><span class="line">│   ├── corpus.txt              # 预训练语料</span><br><span class="line">│   ├── sft.jsonl               # 普通指令微调数据</span><br><span class="line">│   └── reasoning_sft.jsonl     # 带推理链的指令数据</span><br><span class="line">│</span><br><span class="line">├── tokenizer/</span><br><span class="line">│   ├── spm.model</span><br><span class="line">│   └── spm.vocab</span><br><span class="line">│</span><br><span class="line">├── checkpoints/                # 模型权重保存目录</span><br><span class="line">│</span><br><span class="line">├── build_tokenizer.py</span><br><span class="line">├── model.py</span><br><span class="line">├── train_pretrain.py</span><br><span class="line">├── train_sft.py</span><br><span class="line">├── train_reasoning_sft.py</span><br><span class="line">├── generate.py</span><br><span class="line">├── generate_reasoning.py</span><br><span class="line">├── tiny_tools.py</span><br><span class="line">└── app_reasoning.py</span><br></pre></td></tr></table></figure><hr><h1 id="1️⃣-构建分词器"><a href="#1️⃣-构建分词器" class="headerlink" title="1️⃣ 构建分词器"></a>1️⃣ 构建分词器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_tokenizer.py</span></span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tokenizer</span>(<span class="params">input_txt=<span class="string">&quot;data/corpus.txt&quot;</span>, model_prefix=<span class="string">&quot;tokenizer/spm&quot;</span>, vocab_size=<span class="number">16000</span></span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;tokenizer&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    spm.SentencePieceTrainer.Train(</span><br><span class="line">        <span class="built_in">input</span>=input_txt,</span><br><span class="line">        model_prefix=model_prefix,</span><br><span class="line">        vocab_size=vocab_size,</span><br><span class="line">        model_type=<span class="string">&quot;bpe&quot;</span>,</span><br><span class="line">        character_coverage=<span class="number">0.9995</span>,</span><br><span class="line">        bos_id=<span class="number">1</span>, eos_id=<span class="number">2</span>, pad_id=<span class="number">0</span>, unk_id=<span class="number">3</span>,</span><br><span class="line">        user_defined_symbols=[<span class="string">&quot;&lt;|system|&gt;&quot;</span>, <span class="string">&quot;&lt;|user|&gt;&quot;</span>, <span class="string">&quot;&lt;|assistant|&gt;&quot;</span>, <span class="string">&quot;&lt;|sep|&gt;&quot;</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Tokenizer built:&quot;</span>, model_prefix + <span class="string">&quot;.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    build_tokenizer()</span><br></pre></td></tr></table></figure><hr><h1 id="2️⃣-模型定义"><a href="#2️⃣-模型定义" class="headerlink" title="2️⃣ 模型定义"></a>2️⃣ 模型定义</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        norm_x = x * torch.rsqrt(torch.mean(x * x, dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="variable language_">self</span>.eps)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.weight * norm_x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RotaryEmbedding</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, base=<span class="number">10000</span></span>):</span><br><span class="line">        inv_freq = <span class="number">1.0</span> / (base ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>).<span class="built_in">float</span>() / dim))</span><br><span class="line">        <span class="variable language_">self</span>.inv_freq = inv_freq</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_cos_sin</span>(<span class="params">self, seq_len, device</span>):</span><br><span class="line">        t = torch.arange(seq_len, device=device).type_as(<span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        freqs = torch.outer(t, <span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        <span class="keyword">return</span> freqs.cos(), freqs.sin()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rope</span>(<span class="params">x, cos, sin</span>):</span><br><span class="line">    head_dim = x.size(-<span class="number">1</span>)</span><br><span class="line">    x1 = x[..., :head_dim//<span class="number">2</span>]</span><br><span class="line">    x2 = x[..., head_dim//<span class="number">2</span>:]</span><br><span class="line">    <span class="keyword">return</span> torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.n_heads = n_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = dim // n_heads</span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.o = nn.Linear(dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, rope=<span class="literal">None</span></span>):</span><br><span class="line">        B, T, C = x.size()</span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x)</span><br><span class="line">        q, k, v = qkv.split(C, dim=-<span class="number">1</span>)</span><br><span class="line">        q = q.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        k = k.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        v = v.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cos, sin = rope.get_cos_sin(T, x.device)</span><br><span class="line">            cos = cos[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            sin = sin[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            q = apply_rope(q, cos, sin)</span><br><span class="line">            k = apply_rope(k, cos, sin)</span><br><span class="line"></span><br><span class="line">        att = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(<span class="variable language_">self</span>.head_dim)</span><br><span class="line">        causal = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        att = att.masked_fill(causal == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        att = F.softmax(att, dim=-<span class="number">1</span>)</span><br><span class="line">        att = <span class="variable language_">self</span>.dropout(att)</span><br><span class="line">        y = att @ v</span><br><span class="line">        y = y.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(B, T, C)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.o(y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, ffn_dim, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, ffn_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(ffn_dim, dim)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w2(<span class="variable language_">self</span>.dropout(F.silu(<span class="variable language_">self</span>.w1(x))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, ffn_dim, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.norm1 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, n_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.norm2 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.ffn = FeedForward(dim, ffn_dim, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.rope = RotaryEmbedding(dim // n_heads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x), rope=<span class="variable language_">self</span>.rope)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.ffn(<span class="variable language_">self</span>.norm2(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyLLM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tok_emb = nn.Embedding(vocab_size, dim)</span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.ModuleList([TransformerBlock(dim, n_heads, ffn_dim, dropout) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line">        <span class="variable language_">self</span>.norm = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.lm_head = nn.Linear(dim, vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.max_seq_len = max_seq_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, idx</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.tok_emb(idx)</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.lm_head(x)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, idx, max_new_tokens=<span class="number">128</span>, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_new_tokens):</span><br><span class="line">            logits = <span class="variable language_">self</span>.forward(idx)[:, -<span class="number">1</span>, :]</span><br><span class="line">            logits = logits / <span class="built_in">max</span>(temperature, <span class="number">1e-5</span>)</span><br><span class="line">            probs = F.softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">            next_token = torch.multinomial(probs, num_samples=<span class="number">1</span>)</span><br><span class="line">            idx = torch.cat([idx, next_token], dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> idx.size(<span class="number">1</span>) &gt;= <span class="variable language_">self</span>.max_seq_len:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> idx</span><br></pre></td></tr></table></figure><hr><h1 id="3️⃣-预训练、SFT、Reasoning-SFT、推理、API"><a href="#3️⃣-预训练、SFT、Reasoning-SFT、推理、API" class="headerlink" title="3️⃣ 预训练、SFT、Reasoning SFT、推理、API"></a>3️⃣ 预训练、SFT、Reasoning SFT、推理、API</h1><p>由于篇幅限制，我在这里不重复贴出所有文件的完整代码（你前面已经看过 <code>train_pretrain.py</code>、<code>train_sft.py</code>、<code>train_reasoning_sft.py</code>、<code>generate.py</code>、<code>generate_reasoning.py</code>、<code>tiny_tools.py</code>、<code>app_reasoning.py</code> 的实现）。</p><p>👉 你只需要把这些文件分别保存到项目目录中即可。</p><hr><h1 id="✅-使用流程"><a href="#✅-使用流程" class="headerlink" title="✅ 使用流程"></a>✅ 使用流程</h1><ol><li><strong>构建分词器</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python build_tokenizer.py</span><br></pre></td></tr></table></figure><ol start="2"><li><strong>预训练</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_pretrain.py</span><br></pre></td></tr></table></figure><ol start="3"><li><strong>普通指令微调</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_sft.py</span><br></pre></td></tr></table></figure><ol start="4"><li><strong>Reasoning 微调</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_reasoning_sft.py</span><br></pre></td></tr></table></figure><ol start="5"><li><strong>推理测试</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python generate_reasoning.py</span><br></pre></td></tr></table></figure><ol start="6"><li><strong>API 部署</strong></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn app_reasoning:app --reload --port 8000</span><br></pre></td></tr></table></figure><hr><p>✨ 总结：</p><ul><li>你现在有了一个完整的 <strong>从零到 reasoning 微调 + API 部署</strong> 的小模型工程。</li><li>产出物是 <strong>分词器文件 + 模型权重</strong>，推理时可以输出“推理链 + 最终答案”。</li><li>你可以逐步扩展数据集（数学、逻辑、常识），让模型的 reasoning 能力越来越强。</li></ul><p><a href="https://github.com/zheniu/stochastic-cslr/tree/651af568f6a23cd1a0bf4cf717197b87ff8737f5/stochastic_cslr%2Fmodel%2Fxfmr.py">要不要我帮你</a></p><h2 id="train-pretrain-py、train-sft-py、train-reasoning-sft-py、generate-py、generate-reasoning-py、tiny-tools-py、app-reasoning-py-这些文件对于-reasoning-模式的模型需要修改吗？"><a href="#train-pretrain-py、train-sft-py、train-reasoning-sft-py、generate-py、generate-reasoning-py、tiny-tools-py、app-reasoning-py-这些文件对于-reasoning-模式的模型需要修改吗？" class="headerlink" title="train_pretrain.py、train_sft.py、train_reasoning_sft.py、generate.py、generate_reasoning.py、tiny_tools.py、app_reasoning.py 这些文件对于 reasoning 模式的模型需要修改吗？"></a><code>train_pretrain.py</code>、<code>train_sft.py</code>、<code>train_reasoning_sft.py</code>、<code>generate.py</code>、<code>generate_reasoning.py</code>、<code>tiny_tools.py</code>、<code>app_reasoning.py</code> 这些文件对于 reasoning 模式的模型需要修改吗？</h2><p>好问题 👍。你已经有了一套基础文件（预训练、SFT、推理、API），现在要让模型具备 <strong>reasoning 模式</strong>，需要的改动其实是“局部增强”，而不是推翻重写。下面我帮你逐个文件梳理：</p><hr><h2 id="1-train-pretrain-py"><a href="#1-train-pretrain-py" class="headerlink" title="1. train_pretrain.py"></a>1. <code>train_pretrain.py</code></h2><ul><li><strong>是否修改</strong>：不需要。</li><li><strong>原因</strong>：预训练阶段只是学语言建模能力，不涉及推理链。</li><li><strong>建议</strong>：保持原样即可，继续作为基础权重。</li></ul><hr><h2 id="2-train-sft-py"><a href="#2-train-sft-py" class="headerlink" title="2. train_sft.py"></a>2. <code>train_sft.py</code></h2><ul><li><strong>是否修改</strong>：可选。</li><li><strong>原因</strong>：普通指令微调文件可以保持原样，用于常规问答。</li><li><strong>建议</strong>：如果你想让模型同时具备“普通回答”和“推理回答”，可以保留它；如果只想专注 reasoning，可以跳过。</li></ul><hr><h2 id="3-train-reasoning-sft-py"><a href="#3-train-reasoning-sft-py" class="headerlink" title="3. train_reasoning_sft.py"></a>3. <code>train_reasoning_sft.py</code></h2><ul><li><strong>是否修改</strong>：需要。</li><li><strong>改动点</strong>：<ul><li>数据集格式：要包含 <strong>推理过程（CoT）+ 最终答案</strong>。</li><li>Loss 计算：只对 <code>&lt;|assistant|&gt;</code> 段落计算损失，忽略 system/user。</li><li>模板：明确区分“【推理过程】”和“【最终答案】”。</li></ul></li><li><strong>总结</strong>：这是 reasoning 模式的核心训练文件，必须改造。</li></ul><hr><h2 id="4-generate-py"><a href="#4-generate-py" class="headerlink" title="4. generate.py"></a>4. <code>generate.py</code></h2><ul><li><strong>是否修改</strong>：不需要。</li><li><strong>原因</strong>：它是普通推理脚本，适合测试基础模型或普通 SFT 模型。</li><li><strong>建议</strong>：保留原样，作为 baseline 对比。</li></ul><hr><h2 id="5-generate-reasoning-py"><a href="#5-generate-reasoning-py" class="headerlink" title="5. generate_reasoning.py"></a>5. <code>generate_reasoning.py</code></h2><ul><li><strong>是否修改</strong>：需要。</li><li><strong>改动点</strong>：<ul><li>增加 <strong>自洽采样（Self-Consistency）</strong>：多次生成 → 投票选答案。</li><li>增加 <strong>解析逻辑</strong>：从输出中抽取“推理过程”和“最终答案”。</li></ul></li><li><strong>总结</strong>：这是 reasoning 模式的推理脚本，必须增强。</li></ul><hr><h2 id="6-tiny-tools-py"><a href="#6-tiny-tools-py" class="headerlink" title="6. tiny_tools.py"></a>6. <code>tiny_tools.py</code></h2><ul><li><strong>是否修改</strong>：可选。</li><li><strong>原因</strong>：如果你希望模型在推理时调用外部工具（如计算器），就需要实现；否则可以不改。</li><li><strong>建议</strong>：保留，作为算术类 reasoning 的辅助。</li></ul><hr><h2 id="7-app-reasoning-py"><a href="#7-app-reasoning-py" class="headerlink" title="7. app_reasoning.py"></a>7. <code>app_reasoning.py</code></h2><ul><li><strong>是否修改</strong>：需要。</li><li><strong>改动点</strong>：<ul><li>API 返回时，除了最终答案，还要返回 <strong>推理链</strong>。</li><li>可选：支持自洽采样模式。</li></ul></li><li><strong>总结</strong>：这是 reasoning 模式的服务接口，必须改造。</li></ul><hr><h2 id="✅-总结-6"><a href="#✅-总结-6" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>必须修改</strong>：<code>train_reasoning_sft.py</code>、<code>generate_reasoning.py</code>、<code>app_reasoning.py</code></li><li><strong>可选修改</strong>：<code>train_sft.py</code>（是否保留普通指令）、<code>tiny_tools.py</code>（是否启用工具调用）</li><li><strong>无需修改</strong>：<code>train_pretrain.py</code>、<code>generate.py</code></li></ul><hr><p>👉 换句话说，你的 reasoning 模式是在 <strong>SFT → 推理 → API</strong> 这三环节做增强，预训练和普通生成脚本保持不变。</p><p>要不要我帮你画一张 <strong>“普通模式 vs reasoning 模式的文件改动对比图”</strong>，让你一眼看到哪些文件是共用的，哪些是 reasoning 专属的？</p><h2 id="请把需要修改的文件重新生成。"><a href="#请把需要修改的文件重新生成。" class="headerlink" title="请把需要修改的文件重新生成。"></a>请把需要修改的文件重新生成。</h2><p>好的 Mark，我来帮你把 <strong>需要修改的三个文件</strong>（<code>train_reasoning_sft.py</code>、<code>generate_reasoning.py</code>、<code>app_reasoning.py</code>）重新整理成完整实现。这样你可以直接替换掉原文件，专门用于 <strong>reasoning 模式</strong>。</p><hr><h1 id="1️⃣-train-reasoning-sft-py"><a href="#1️⃣-train-reasoning-sft-py" class="headerlink" title="1️⃣ train_reasoning_sft.py"></a>1️⃣ <code>train_reasoning_sft.py</code></h1><p>用于训练带推理链（CoT）的监督微调模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_reasoning_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n【推理过程】\n&#123;cot&#125;\n【最终答案】\n&#123;final&#125;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReasoningSFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>], cot=obj[<span class="string">&quot;cot&quot;</span>], final=obj[<span class="string">&quot;final&quot;</span>])</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># 只对 assistant 段落计算损失</span></span><br><span class="line">                prefix = <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;system&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;user&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line">                prefix_ids = <span class="variable language_">self</span>.sp.encode(prefix, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prefix_ids) + ids[<span class="built_in">len</span>(prefix_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels += [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_reasoning_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/reasoning_sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = ReasoningSFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded base:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        moving = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)</span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            moving += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>] cot_sft_loss=<span class="subst">&#123;moving/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                moving = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;reasoning_sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_reasoning_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="2️⃣-generate-reasoning-py"><a href="#2️⃣-generate-reasoning-py" class="headerlink" title="2️⃣ generate_reasoning.py"></a>2️⃣ <code>generate_reasoning.py</code></h1><p>用于 reasoning 模式推理，支持自洽采样。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate_reasoning.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_final</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">return</span> text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_self_consistency</span>(<span class="params">model_ckpt, spm_path, system, user, samples=<span class="number">5</span>, max_new_tokens=<span class="number">200</span>, temperature=<span class="number">0.8</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x0 = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    finals = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        x = x0.clone()</span><br><span class="line">        out = model.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        finals.append(parse_final(text))</span><br><span class="line">    vote = Counter(finals)</span><br><span class="line">    best_final, _ = vote.most_common(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> best_final, finals</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    best, all_finals = run_self_consistency(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/reasoning_sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是严谨的中文推理助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;计算：12*(3+4)-10&quot;</span>,</span><br><span class="line">        samples=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;投票最终答案:&quot;</span>, best)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所有候选:&quot;</span>, all_finals)</span><br></pre></td></tr></table></figure><hr><h1 id="3️⃣-app-reasoning-py"><a href="#3️⃣-app-reasoning-py" class="headerlink" title="3️⃣ app_reasoning.py"></a>3️⃣ <code>app_reasoning.py</code></h1><p>API 服务，返回推理链和最终答案。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app_reasoning.py</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">import</span> torch, sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    max_tokens: <span class="built_in">int</span> = <span class="number">128</span></span><br><span class="line">    temperature: <span class="built_in">float</span> = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="built_in">int</span> = <span class="number">40</span></span><br><span class="line">    top_p: <span class="built_in">float</span> = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt_from_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    system = <span class="string">&quot;&quot;</span></span><br><span class="line">    user = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;system&quot;</span>: system = m.content</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;user&quot;</span>: user = m.content</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_segments</span>(<span class="params">text</span>):</span><br><span class="line">    parts = &#123;<span class="string">&quot;reasoning&quot;</span>: <span class="string">&quot;&quot;</span>, <span class="string">&quot;final&quot;</span>: <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【推理过程】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        seg = text.split(<span class="string">&quot;【推理过程】&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">        parts[<span class="string">&quot;reasoning&quot;</span>] = seg.split(<span class="string">&quot;【最终答案】&quot;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        parts[<span class="string">&quot;final&quot;</span>] = text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> parts</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br></pre></td></tr></table></figure><h2 id="大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进"><a href="#大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进" class="headerlink" title="大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进"></a>大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进</h2><p>好的 Mark，我来帮你整理一个 <strong>大模型技术演进大纲</strong>，从早期到最新趋势，分阶段梳理清晰。你可以把它作为写文章、做演讲或课程的框架。</p><hr><h1 id="📚-大模型技术演进大纲"><a href="#📚-大模型技术演进大纲" class="headerlink" title="📚 大模型技术演进大纲"></a>📚 大模型技术演进大纲</h1><h2 id="一、起点：语言模型的萌芽"><a href="#一、起点：语言模型的萌芽" class="headerlink" title="一、起点：语言模型的萌芽"></a>一、起点：语言模型的萌芽</h2><ul><li><strong>统计语言模型</strong><ul><li>N-gram 模型</li><li>局限：稀疏性、上下文有限</li></ul></li><li><strong>神经语言模型</strong><ul><li>Word2Vec、GloVe：词向量表示</li><li>RNN/LSTM/GRU：序列建模</li></ul></li></ul><hr><h2 id="二、Transformer-革命（2017）"><a href="#二、Transformer-革命（2017）" class="headerlink" title="二、Transformer 革命（2017）"></a>二、Transformer 革命（2017）</h2><ul><li><strong>Attention is All You Need</strong><ul><li>自注意力机制</li><li>并行训练、长距离依赖建模</li></ul></li><li><strong>BERT 系列</strong>（双向编码器）<ul><li>预训练 + 下游微调范式</li></ul></li><li><strong>GPT 系列</strong>（自回归生成）<ul><li>单向预测，擅长生成</li></ul></li></ul><hr><h2 id="三、预训练大模型时代"><a href="#三、预训练大模型时代" class="headerlink" title="三、预训练大模型时代"></a>三、预训练大模型时代</h2><ul><li><strong>Scaling Law（扩展规律）</strong><ul><li>参数量、数据量、算力 → 性能提升</li></ul></li><li><strong>代表模型</strong><ul><li>GPT-2/3：通用生成能力</li><li>T5：统一 NLP 任务为“文本到文本”</li><li>BART：编码器-解码器结合</li></ul></li></ul><hr><h2 id="四、指令微调与对齐（Alignment）"><a href="#四、指令微调与对齐（Alignment）" class="headerlink" title="四、指令微调与对齐（Alignment）"></a>四、指令微调与对齐（Alignment）</h2><ul><li><strong>SFT（监督微调）</strong><ul><li>用指令-回答数据集训练</li></ul></li><li><strong>RLHF（人类反馈强化学习）</strong><ul><li>通过人类偏好优化输出</li></ul></li><li><strong>安全与价值对齐</strong><ul><li>避免有害内容，提升可控性</li></ul></li></ul><hr><h2 id="五、RAG-与外部知识增强"><a href="#五、RAG-与外部知识增强" class="headerlink" title="五、RAG 与外部知识增强"></a>五、RAG 与外部知识增强</h2><ul><li><strong>RAG（Retrieval-Augmented Generation）</strong><ul><li>向量检索 + 大模型生成</li><li>解决知识过时、幻觉问题</li></ul></li><li><strong>工具调用与 Agent</strong><ul><li>模型可调用 API、数据库、计算器</li><li>从“语言模型”走向“通用智能体”</li></ul></li></ul><hr><h2 id="六、多模态大模型"><a href="#六、多模态大模型" class="headerlink" title="六、多模态大模型"></a>六、多模态大模型</h2><ul><li><strong>文本 + 图像</strong>：GPT-4V、Qwen-VL、LLaVA</li><li><strong>文本 + 音频</strong>：Whisper、Gemini</li><li><strong>文本 + 视频</strong>：Sora、Kosmos 系列</li><li><strong>应用场景</strong>：看图问答、视频理解、跨模态推理</li></ul><hr><h2 id="七、Reasoning-与推理能力"><a href="#七、Reasoning-与推理能力" class="headerlink" title="七、Reasoning 与推理能力"></a>七、Reasoning 与推理能力</h2><ul><li>**Chain of Thought (CoT)**：逐步推理</li><li><strong>Self-Consistency</strong>：多路径投票</li><li><strong>工具增强推理</strong>：调用计算器、符号推理器</li><li><strong>专门推理模型</strong>：DeepSeek-R1、OpenAI o1</li></ul><hr><h2 id="八、开源与生态繁荣"><a href="#八、开源与生态繁荣" class="headerlink" title="八、开源与生态繁荣"></a>八、开源与生态繁荣</h2><ul><li><strong>开源模型</strong>：LLaMA、Mistral、Qwen、ChatGLM</li><li><strong>生态工具</strong>：LangChain、LlamaIndex、向量数据库</li><li><strong>轻量化技术</strong>：LoRA、QLoRA、蒸馏、量化</li></ul><hr><h2 id="九、未来趋势"><a href="#九、未来趋势" class="headerlink" title="九、未来趋势"></a>九、未来趋势</h2><ul><li><strong>更强的推理与规划能力</strong></li><li><strong>多模态融合与世界模型</strong></li><li><strong>个性化与小模型（Personal LLM）</strong></li><li><strong>隐私与安全对齐</strong></li><li><strong>AGI 探索</strong>：从助手到自主智能体</li></ul><hr><p>✅ <strong>总结</strong>：<br>大模型技术演进经历了 <strong>统计 → 神经网络 → Transformer → 预训练 → 指令对齐 → RAG → 多模态 → 推理 → AGI 探索</strong> 的路线。每一步都在解决前一代的瓶颈，推动模型从“语言处理器”走向“通用智能体”。</p><hr><p>要不要我帮你把这个大纲扩展成一份 <strong>详细讲解稿</strong>（每个阶段配上代表论文/模型、关键突破、应用案例），方便你直接用来写文章或做分享？</p><p>好的 Mark，我来把之前的大纲扩展成一个更完整的 <strong>大模型技术演进讲解稿</strong>，每个阶段都包含代表模型/论文、关键突破和典型应用。这样你可以直接用来写文章或做分享。</p><hr><h1 id="📚-大模型技术演进讲解稿"><a href="#📚-大模型技术演进讲解稿" class="headerlink" title="📚 大模型技术演进讲解稿"></a>📚 大模型技术演进讲解稿</h1><h2 id="一、起点：语言模型的萌芽-1"><a href="#一、起点：语言模型的萌芽-1" class="headerlink" title="一、起点：语言模型的萌芽"></a>一、起点：语言模型的萌芽</h2><ul><li><p><strong>统计语言模型</strong></p><ul><li><strong>代表方法</strong>：N-gram</li><li><strong>突破点</strong>：用条件概率建模语言，但受限于稀疏性和短上下文。</li><li><strong>应用</strong>：早期机器翻译、语音识别。</li></ul></li><li><p><strong>神经语言模型</strong></p><ul><li><strong>代表模型</strong>：Word2Vec (2013)、GloVe (2014)</li><li><strong>突破点</strong>：词向量捕捉语义关系（如 king - man + woman ≈ queen）。</li><li><strong>应用</strong>：搜索引擎、推荐系统、情感分析。</li></ul></li></ul><hr><h2 id="二、Transformer-革命（2017）-1"><a href="#二、Transformer-革命（2017）-1" class="headerlink" title="二、Transformer 革命（2017）"></a>二、Transformer 革命（2017）</h2><ul><li><strong>论文</strong>：《Attention is All You Need》</li><li><strong>突破点</strong>：自注意力机制替代 RNN/CNN，支持并行训练，捕捉长距离依赖。</li><li><strong>代表模型</strong>：<ul><li>BERT (2018)：双向编码器，擅长理解任务。</li><li>GPT (2018)：自回归生成，擅长文本生成。</li></ul></li><li><strong>应用</strong>：阅读理解、机器翻译、对话系统。</li></ul><hr><h2 id="三、预训练大模型时代-1"><a href="#三、预训练大模型时代-1" class="headerlink" title="三、预训练大模型时代"></a>三、预训练大模型时代</h2><ul><li><strong>Scaling Law</strong>：参数量、数据量、算力成指数关系 → 模型性能持续提升。</li><li><strong>代表模型</strong>：<ul><li>GPT-2/3 (2019/2020)：展现“少样本学习”能力。</li><li>T5 (2019)：统一 NLP 任务为“文本到文本”。</li><li>BART (2019)：结合编码器-解码器，适合生成与理解。</li></ul></li><li><strong>应用</strong>：开放域对话、自动写作、代码生成。</li></ul><hr><h2 id="四、指令微调与对齐（2022-起）"><a href="#四、指令微调与对齐（2022-起）" class="headerlink" title="四、指令微调与对齐（2022 起）"></a>四、指令微调与对齐（2022 起）</h2><ul><li><strong>SFT（监督微调）</strong>：用指令-回答数据集训练，让模型更听话。</li><li><strong>RLHF（人类反馈强化学习）</strong>：通过人类偏好优化输出质量。</li><li><strong>代表模型</strong>：InstructGPT、ChatGPT。</li><li><strong>应用</strong>：智能客服、教育辅导、办公助手。</li></ul><hr><h2 id="五、RAG-与外部知识增强-1"><a href="#五、RAG-与外部知识增强-1" class="headerlink" title="五、RAG 与外部知识增强"></a>五、RAG 与外部知识增强</h2><ul><li><p><strong>RAG（Retrieval-Augmented Generation）</strong></p><ul><li><strong>突破点</strong>：结合向量检索与大模型生成，解决知识过时与幻觉问题。</li><li><strong>应用</strong>：企业知识库问答、法律/医疗文档检索。</li></ul></li><li><p><strong>Agent 与工具调用</strong></p><ul><li>模型可调用 API、数据库、计算器。</li><li><strong>应用</strong>：自动化办公、数据分析、智能体。</li></ul></li></ul><hr><h2 id="六、多模态大模型-1"><a href="#六、多模态大模型-1" class="headerlink" title="六、多模态大模型"></a>六、多模态大模型</h2><ul><li><strong>突破点</strong>：跨模态理解与生成（文本+图像+音频+视频）。</li><li><strong>代表模型</strong>：<ul><li>GPT-4V（图像输入）、Gemini（多模态）、Qwen-VL（中文图文）。</li><li>LLaVA、MiniGPT-4（开源图文）。</li></ul></li><li><strong>应用</strong>：看图问答、图表理解、视频摘要、语音助手。</li></ul><hr><h2 id="七、Reasoning-与推理能力-1"><a href="#七、Reasoning-与推理能力-1" class="headerlink" title="七、Reasoning 与推理能力"></a>七、Reasoning 与推理能力</h2><ul><li><strong>方法</strong>：<ul><li>Chain of Thought (CoT)：逐步推理。</li><li>Self-Consistency：多路径投票。</li><li>工具增强：调用计算器、符号推理器。</li></ul></li><li><strong>代表模型</strong>：DeepSeek-R1、OpenAI o1。</li><li><strong>应用</strong>：数学解题、逻辑推理、规划任务。</li></ul><hr><h2 id="八、开源与生态繁荣-1"><a href="#八、开源与生态繁荣-1" class="headerlink" title="八、开源与生态繁荣"></a>八、开源与生态繁荣</h2><ul><li><strong>开源模型</strong>：LLaMA、Mistral、Qwen、ChatGLM。</li><li><strong>生态工具</strong>：LangChain、LlamaIndex、向量数据库（FAISS、Milvus）。</li><li><strong>轻量化技术</strong>：LoRA、QLoRA、蒸馏、量化。</li><li><strong>应用</strong>：本地部署、行业定制、低成本实验。</li></ul><hr><h2 id="九、未来趋势-1"><a href="#九、未来趋势-1" class="headerlink" title="九、未来趋势"></a>九、未来趋势</h2><ul><li><strong>更强推理与规划</strong>：结合符号推理、搜索算法。</li><li><strong>多模态融合</strong>：世界模型（World Model），理解环境与时序。</li><li><strong>个性化小模型</strong>：Personal LLM，适配个人数据与设备。</li><li><strong>隐私与安全对齐</strong>：差分隐私、可解释性。</li><li><strong>AGI 探索</strong>：从助手到自主智能体。</li></ul><hr><h2 id="✅-总结-7"><a href="#✅-总结-7" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><p>大模型技术演进路线：<br><strong>统计 → 神经网络 → Transformer → 预训练 → 指令对齐 → RAG → 多模态 → 推理 → AGI 探索</strong>。<br>每一步都在解决前一代的瓶颈，推动模型从“语言处理器”走向“通用智能体”。</p><hr><p>要不要我帮你把这个讲解稿再整理成一份 <strong>时间轴图表</strong>（年份 + 关键论文/模型 + 技术突破），让演示更直观？</p><h2 id="大模型技术必读论文"><a href="#大模型技术必读论文" class="headerlink" title="大模型技术必读论文"></a>大模型技术必读论文</h2><p><strong>快速回答</strong>：学习大模型（LLM），有一些“必读经典论文”几乎是绕不开的里程碑，从词向量到 Transformer，再到 GPT、BERT、对齐与推理。下面我整理了一份时间顺序的清单，涵盖核心论文与贡献。</p><hr><h2 id="📑-大模型学习必读经典论文清单"><a href="#📑-大模型学习必读经典论文清单" class="headerlink" title="📑 大模型学习必读经典论文清单"></a>📑 大模型学习必读经典论文清单</h2><h3 id="早期基础（词向量与注意力）"><a href="#早期基础（词向量与注意力）" class="headerlink" title="早期基础（词向量与注意力）"></a>早期基础（词向量与注意力）</h3><ul><li><strong>Word2Vec</strong> — <em>Mikolov et al., 2013</em><br><em>提出分布式词向量表示，奠定语义建模基础。</em></li><li><strong>GloVe</strong> — <em>Pennington et al., 2014</em><br><em>结合全局统计与局部窗口的词向量方法。</em></li><li><strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong> — <em>Bahdanau et al., 2014</em><br><em>首次提出注意力机制，为 Transformer 奠基。</em></li></ul><h3 id="Transformer-革命"><a href="#Transformer-革命" class="headerlink" title="Transformer 革命"></a>Transformer 革命</h3><ul><li><strong>Attention Is All You Need</strong> — <em>Vaswani et al., 2017</em><br><em>提出 Transformer 架构，自注意力机制成为大模型核心。</em></li></ul><h3 id="预训练与扩展"><a href="#预训练与扩展" class="headerlink" title="预训练与扩展"></a>预训练与扩展</h3><ul><li><strong>ELMo</strong> — <em>Peters et al., 2018</em><br><em>上下文动态词向量。</em></li><li><strong>BERT: Pre-training of Deep Bidirectional Transformers</strong> — <em>Devlin et al., 2018</em><br><em>双向编码器，预训练+微调范式。</em></li><li><strong>GPT-2: Language Models are Unsupervised Multitask Learners</strong> — <em>Radford et al., 2019</em><br><em>展示大规模自回归生成能力。</em></li><li><strong>GPT-3: Language Models are Few-Shot Learners</strong> — <em>Brown et al., 2020</em><br><em>少样本学习能力，参数规模突破。</em></li><li><strong>T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</strong> — <em>Raffel et al., 2020</em><br><em>统一 NLP 任务为文本到文本。</em></li></ul><h3 id="训练优化与-Scaling-Law"><a href="#训练优化与-Scaling-Law" class="headerlink" title="训练优化与 Scaling Law"></a>训练优化与 Scaling Law</h3><ul><li><strong>ZeRO: Efficient Large-Scale Model Training</strong> — <em>Rajbhandari et al., 2020</em><br><em>分布式训练优化。</em></li><li><strong>Chinchilla: Training Compute-Optimal Large Language Models</strong> — <em>Hoffmann et al., 2022</em><br><em>提出数据/参数平衡规律。</em></li></ul><h3 id="对齐与指令"><a href="#对齐与指令" class="headerlink" title="对齐与指令"></a>对齐与指令</h3><ul><li><strong>InstructGPT</strong> — <em>Ouyang et al., 2022</em><br><em>指令微调 + RLHF，对齐人类偏好。</em></li><li><strong>RLHF (Christiano et al., 2017; Ouyang et al., 2022)</strong><br><em>人类反馈强化学习，提升模型可控性。</em></li></ul><h3 id="知识增强与多模态"><a href="#知识增强与多模态" class="headerlink" title="知识增强与多模态"></a>知识增强与多模态</h3><ul><li><strong>RAG: Retrieval-Augmented Generation</strong> — <em>Lewis et al., 2020</em><br><em>结合检索与生成，解决知识过时问题。</em></li><li><strong>GPT-4 Technical Report</strong> — <em>OpenAI, 2023</em><br><em>多模态能力，安全对齐。</em></li><li><strong>Qwen-VL / LLaVA</strong> — <em>2023</em><br><em>中文与开源多模态大模型。</em></li></ul><h3 id="推理与未来"><a href="#推理与未来" class="headerlink" title="推理与未来"></a>推理与未来</h3><ul><li><strong>Chain-of-Thought Prompting</strong> — <em>Wei et al., 2022</em><br><em>显式推理链提升复杂任务表现。</em></li><li><strong>Self-Consistency Improves Chain of Thought Reasoning</strong> — <em>Wang et al., 2022</em><br><em>多路径投票增强推理稳定性。</em></li><li><strong>DeepSeek-R1 (2024)</strong><br><em>专注 reasoning 的开源模型。</em></li><li><strong>OpenAI o1 (2024)</strong><br><em>强化推理与工具调用能力。</em></li></ul><hr><h2 id="✅-总结-8"><a href="#✅-总结-8" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>入门必读</strong>：Word2Vec、Attention is All You Need、BERT、GPT-3。</li><li><strong>进阶必读</strong>：InstructGPT、Chinchilla、RAG、Chain-of-Thought。</li><li><strong>前沿必读</strong>：GPT-4 技术报告、DeepSeek-R1、OpenAI o1。</li></ul><hr><p>要不要我帮你把这些论文整理成一份 <strong>学习路线图（先读哪些基础，再读哪些进阶，最后看前沿）</strong>，让你能按阶段逐步攻克？</p><h2 id="📌-学习建议"><a href="#📌-学习建议" class="headerlink" title="📌 学习建议"></a>📌 学习建议</h2><ul><li><strong>第一阶段（2013–2017）</strong>：Word2Vec、GloVe、Transformer → 打好基础。</li><li><strong>第二阶段（2018–2020）</strong>：BERT、GPT-2/3、RAG → 掌握预训练与生成。</li><li><strong>第三阶段（2022–2023）</strong>：InstructGPT、RLHF、Chinchilla、GPT-4 → 理解对齐与多模态。</li><li><strong>第四阶段（2024–未来）</strong>：DeepSeek-R1、OpenAI o1 → 聚焦 reasoning 与 AGI 探索。</li></ul><hr><p>✅ 这样整理后，你就有了一份 <strong>学习路线图 + 必读论文清单</strong>。<br>要不要我再帮你做一份 <strong>“学习路径图”</strong>（比如：先读哪些基础论文，再读哪些进阶论文，最后看最新前沿），让你能按阶段逐步攻克？</p><h2 id="请介绍下-agent"><a href="#请介绍下-agent" class="headerlink" title="请介绍下 agent"></a>请介绍下 agent</h2><p><strong>简要回答</strong>：在大模型语境下，<strong>Agent（智能体）</strong>指的是一个能够自主感知环境、拆解任务、调用工具并执行行动的系统。它不仅仅是“回答问题的模型”，而是一个具备 <strong>目标规划、记忆、推理、工具调用与交互</strong> 能力的“行动者”。</p><hr><h2 id="🧩-Agent-的核心概念"><a href="#🧩-Agent-的核心概念" class="headerlink" title="🧩 Agent 的核心概念"></a>🧩 Agent 的核心概念</h2><ol><li><strong>自主性</strong>：不只是被动回答，而是能根据目标主动规划步骤。</li><li><strong>任务分解</strong>：将复杂问题拆解为子任务（如“组织生日聚会” → 订餐厅、发邀请、安排日程）。</li><li><strong>工具调用</strong>：能调用外部 API、数据库、搜索引擎、计算器等。</li><li><strong>记忆与上下文</strong>：保留历史信息，支持长时交互。</li><li><strong>多智能体协作</strong>：多个 Agent 可以分工合作，完成更复杂的任务。</li></ol><hr><h2 id="⚙️-Agent-的典型工作流"><a href="#⚙️-Agent-的典型工作流" class="headerlink" title="⚙️ Agent 的典型工作流"></a>⚙️ Agent 的典型工作流</h2><ol><li><strong>接收目标</strong>：用户输入或系统任务。</li><li><strong>任务规划</strong>：拆解为可执行的子任务。</li><li><strong>工具选择</strong>：决定调用哪些外部工具或知识库。</li><li><strong>执行与反馈</strong>：逐步完成任务，并根据反馈调整策略。</li><li><strong>总结与输出</strong>：给出最终结果或行动。</li></ol><hr><h2 id="🔑-技术支撑"><a href="#🔑-技术支撑" class="headerlink" title="🔑 技术支撑"></a>🔑 技术支撑</h2><ul><li><strong>大模型（LLM）</strong>：提供语言理解与生成能力。</li><li><strong>RAG（检索增强生成）</strong>：补充外部知识，减少幻觉。</li><li><strong>强化学习（RL）</strong>：优化决策与行动策略。</li><li><strong>知识图谱/记忆模块</strong>：存储长期知识与上下文。</li><li><strong>框架工具</strong>：LangChain、AutoGen、LangGraph 等，帮助开发者快速构建 Agent。</li></ul><hr><h2 id="🌍-应用场景"><a href="#🌍-应用场景" class="headerlink" title="🌍 应用场景"></a>🌍 应用场景</h2><ul><li><strong>个人助理</strong>：日程管理、邮件处理、会议纪要。</li><li><strong>企业应用</strong>：知识库问答、流程自动化、CRM 更新。</li><li><strong>科研与数据分析</strong>：自动检索文献、运行实验、生成报告。</li><li><strong>多模态任务</strong>：看图问答、视频摘要、语音交互。</li></ul><hr><h2 id="🚀-发展趋势"><a href="#🚀-发展趋势" class="headerlink" title="🚀 发展趋势"></a>🚀 发展趋势</h2><ul><li><strong>更强的推理与规划</strong>：结合 Chain-of-Thought、自洽采样。</li><li><strong>多智能体协作</strong>：Agent 团队协同完成复杂任务。</li><li><strong>与真实世界交互</strong>：通过 API、机器人、IoT 设备执行实际操作。</li><li><strong>安全与可控性</strong>：避免无限循环、幻觉或工具滥用。</li></ul><hr><p>✅ <strong>总结</strong>：Agent 是大模型应用的“升级形态”，让模型从“会说话”变成“会做事”。它的价值在于 <strong>把大模型的语言智能转化为可执行的行动</strong>，是通向通用人工智能（AGI）的关键路径。</p><p>要不要我帮你画一张 <strong>“Agent 技术框架图”</strong>，把输入、规划、工具调用、执行、反馈的流程直观展示出来？</p><h2 id="我想构建一个属于自己的智能体，实现电脑的文件操作，包括-windows-和-Linux-和-Unix-like-操作系统上的文件-夹-操作，可以输入指定的-prompt-来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能"><a href="#我想构建一个属于自己的智能体，实现电脑的文件操作，包括-windows-和-Linux-和-Unix-like-操作系统上的文件-夹-操作，可以输入指定的-prompt-来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能" class="headerlink" title="我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能"></a>我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能</h2><h1 id="个人文件智能体构建"><a href="#个人文件智能体构建" class="headerlink" title="个人文件智能体构建"></a>个人文件智能体构建</h1><p>你想把“自然语言 → 精确文件操作”做成一个可靠、可控的智能体。下面是一个从架构到落地代码的完整方案，兼顾跨平台（Windows、Linux、Unix-like）、安全权限、可审计日志和可扩展性。你可以直接按模块落地，并逐步加强。</p><hr><h2 id="架构与核心原则"><a href="#架构与核心原则" class="headerlink" title="架构与核心原则"></a>架构与核心原则</h2><ul><li><strong>输入管道:</strong> 用户 prompt → 结构化意图（操作类型、目标路径、内容、过滤条件）。</li><li><strong>规划器:</strong> 将意图拆解成序列化的文件操作（Create/Read/Update/Delete/Move/Tag/Compress…）。</li><li><strong>工具层:</strong> 跨平台文件工具库（pathlib、os、shutil、glob 统一封装）。</li><li><strong>安全层:</strong> 沙箱根目录、白名单操作类型、黑名单路径/扩展名、Dry-run、交互式确认、审计日志。</li><li><strong>执行器:</strong> 顺序执行、失败回滚（尽量）、最终结果与报告。</li><li><strong>可扩展:</strong> 增加“文件归类”“批量重命名”“内容模板替换”“语义检索”等工具。</li></ul><hr><h2 id="安全与可控策略"><a href="#安全与可控策略" class="headerlink" title="安全与可控策略"></a>安全与可控策略</h2><ul><li><strong>沙箱根目录:</strong> 仅允许在设定的根目录下操作，默认拒绝越权路径（绝对路径与 .. 上跳）。</li><li><strong>白名单操作:</strong> create/read/update/delete/move/copy/list/classify/tag/rename，仅这些被允许。</li><li><strong>黑名单:</strong> 系统关键路径、敏感扩展名（.sys、.dll、.so、.dylib、.exe、.bat、.sh）、隐藏目录。</li><li><strong>Dry-run:</strong> 先展示即将执行的操作清单，确认后再执行。</li><li><strong>双人确认:</strong> 删除与批量重命名需再次确认。</li><li><strong>审计日志:</strong> 每次操作写入 JSON 日志，包含时间、用户、操作、源/目标、结果。</li><li><strong>版本备份:</strong> 更新/删除前可备份至 .backup/ 目录。</li></ul><hr><h2 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.yaml</span></span><br><span class="line"><span class="attr">agent:</span></span><br><span class="line">  <span class="attr">root:</span> <span class="string">&#x27;D:/AgentRoot&#x27;</span> <span class="comment"># Windows 示例；Linux/Unix 可用 /home/mark/AgentRoot</span></span><br><span class="line">  <span class="attr">allow_ops:</span></span><br><span class="line">    [</span><br><span class="line">      <span class="string">&#x27;create&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;read&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;update&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;delete&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;move&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;copy&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;list&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;classify&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;rename&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;tag&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line">  <span class="attr">deny_patterns:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;C:\\Windows\\*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;/etc/*&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;/usr/*&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.sys&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.dll&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.so&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.dylib&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.exe&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.bat&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.sh&#x27;</span></span><br><span class="line">  <span class="attr">dry_run_default:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">require_confirm_for:</span> [<span class="string">&#x27;delete&#x27;</span>, <span class="string">&#x27;rename&#x27;</span>]</span><br><span class="line">  <span class="attr">backup_before_delete:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">log_path:</span> <span class="string">&#x27;./logs/ops.jsonl&#x27;</span></span><br><span class="line">  <span class="attr">max_batch:</span> <span class="number">1000</span></span><br><span class="line">  <span class="attr">encoding:</span> <span class="string">&#x27;utf-8&#x27;</span></span><br></pre></td></tr></table></figure><hr><h2 id="结构化意图与操作序列"><a href="#结构化意图与操作序列" class="headerlink" title="结构化意图与操作序列"></a>结构化意图与操作序列</h2><ul><li><p><strong>意图模式（JSON）</strong></p><ul><li><strong>operation:</strong> create | read | update | delete | move | copy | list | classify | rename | tag</li><li><strong>path/pattern:</strong> 目标文件或通配符</li><li><strong>content:</strong> 用于创建/更新的文本</li><li><strong>filters:</strong> 扩展名、大小、时间范围等</li><li><strong>options:</strong> dry_run, recursive, confirm 等</li></ul></li><li><p><strong>示例（从自然语言到结构化）</strong></p><ul><li>用户：“把 /project/docs 里所有 .md 文件按主题归类到子文件夹，并给‘架构’主题加标签”</li><li>结构化序列：<ol><li>list {pattern: “/project/docs/*<em>/</em>.md”, recursive: true}</li><li>classify {rules: [“包含‘架构’→ docs/architecture”, “包含‘API’→ docs/api”, “其他 → docs/misc”]}</li><li>tag {pattern: “docs/architecture/*<em>/</em>.md”, tag: “architecture”}</li></ol></li></ul></li></ul><hr><h2 id="核心实现（Python）"><a href="#核心实现（Python）" class="headerlink" title="核心实现（Python）"></a>核心实现（Python）</h2><h3 id="1-路径与权限守卫"><a href="#1-路径与权限守卫" class="headerlink" title="1. 路径与权限守卫"></a>1. 路径与权限守卫</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># guard.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> fnmatch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Guard</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root: Path, deny_patterns: <span class="built_in">list</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">        <span class="variable language_">self</span>.root = root.resolve()</span><br><span class="line">        <span class="variable language_">self</span>.deny_patterns = deny_patterns</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">within_root</span>(<span class="params">self, p: Path</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rp = p.resolve()</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.root <span class="keyword">in</span> rp.parents <span class="keyword">or</span> rp == <span class="variable language_">self</span>.root</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">denied</span>(<span class="params">self, p: Path</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        sp = <span class="built_in">str</span>(p)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">any</span>(fnmatch.fnmatch(sp, pattern) <span class="keyword">for</span> pattern <span class="keyword">in</span> <span class="variable language_">self</span>.deny_patterns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check</span>(<span class="params">self, p: Path</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.within_root(p):</span><br><span class="line">            <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Path escapes root: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.denied(p):</span><br><span class="line">            <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Path denied by policy: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="2-文件工具层（跨平台）"><a href="#2-文件工具层（跨平台）" class="headerlink" title="2. 文件工具层（跨平台）"></a>2. 文件工具层（跨平台）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># file_tools.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> shutil, os, time</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Iterable</span><br><span class="line"><span class="keyword">from</span> guard <span class="keyword">import</span> Guard</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FileTools</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root: <span class="built_in">str</span>, guard: Guard, encoding=<span class="string">&quot;utf-8&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.root = Path(root).resolve()</span><br><span class="line">        <span class="variable language_">self</span>.guard = guard</span><br><span class="line">        <span class="variable language_">self</span>.encoding = encoding</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_resolve</span>(<span class="params">self, p: <span class="built_in">str</span></span>) -&gt; Path:</span><br><span class="line">        ap = (<span class="variable language_">self</span>.root / p.lstrip(<span class="string">&quot;/\\&quot;</span>)).resolve() <span class="keyword">if</span> <span class="keyword">not</span> Path(p).is_absolute() <span class="keyword">else</span> Path(p).resolve()</span><br><span class="line">        <span class="variable language_">self</span>.guard.check(ap)</span><br><span class="line">        <span class="keyword">return</span> ap</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list</span>(<span class="params">self, pattern: <span class="built_in">str</span>, recursive: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="built_in">list</span>[<span class="built_in">str</span>]:</span><br><span class="line">        base = <span class="variable language_">self</span>.root</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;**&quot;</span> <span class="keyword">in</span> pattern <span class="keyword">or</span> recursive:</span><br><span class="line">            paths = base.rglob(pattern.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]) <span class="keyword">if</span> <span class="string">&quot;**&quot;</span> <span class="keyword">in</span> pattern <span class="keyword">else</span> base.rglob(<span class="string">&quot;*&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            paths = base.glob(pattern)</span><br><span class="line">        out = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> paths:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="variable language_">self</span>.guard.check(x)</span><br><span class="line">                out.append(<span class="built_in">str</span>(x))</span><br><span class="line">            <span class="keyword">except</span> PermissionError:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create</span>(<span class="params">self, path: <span class="built_in">str</span>, content: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span>, overwrite=<span class="literal">False</span></span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">if</span> p.exists() <span class="keyword">and</span> <span class="keyword">not</span> overwrite:</span><br><span class="line">            <span class="keyword">raise</span> FileExistsError(<span class="string">f&quot;Exists: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line">        p.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;w&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(content <span class="keyword">or</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">self, path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;r&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">return</span> f.read()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, path: <span class="built_in">str</span>, transform</span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        text = <span class="variable language_">self</span>.read(path)</span><br><span class="line">        new_text = transform(text)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;w&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(new_text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">move</span>(<span class="params">self, src: <span class="built_in">str</span>, dst: <span class="built_in">str</span></span>):</span><br><span class="line">        sp, dp = <span class="variable language_">self</span>._resolve(src), <span class="variable language_">self</span>._resolve(dst)</span><br><span class="line">        dp.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        shutil.move(<span class="built_in">str</span>(sp), <span class="built_in">str</span>(dp))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">copy</span>(<span class="params">self, src: <span class="built_in">str</span>, dst: <span class="built_in">str</span></span>):</span><br><span class="line">        sp, dp = <span class="variable language_">self</span>._resolve(src), <span class="variable language_">self</span>._resolve(dst)</span><br><span class="line">        dp.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        shutil.copy2(<span class="built_in">str</span>(sp), <span class="built_in">str</span>(dp))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">self, path: <span class="built_in">str</span>, backup: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">if</span> backup <span class="keyword">and</span> p.exists():</span><br><span class="line">            bdir = <span class="variable language_">self</span>.root / <span class="string">&quot;.backup&quot;</span> / time.strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">            bdir.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">            bpath = bdir / p.name</span><br><span class="line">            <span class="keyword">if</span> p.is_file():</span><br><span class="line">                shutil.copy2(<span class="built_in">str</span>(p), <span class="built_in">str</span>(bpath))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                shutil.copytree(<span class="built_in">str</span>(p), <span class="built_in">str</span>(bpath))</span><br><span class="line">        <span class="keyword">if</span> p.is_file():</span><br><span class="line">            p.unlink()</span><br><span class="line">        <span class="keyword">elif</span> p.is_dir():</span><br><span class="line">            shutil.rmtree(<span class="built_in">str</span>(p), ignore_errors=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Not found: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rename</span>(<span class="params">self, src: <span class="built_in">str</span>, new_name: <span class="built_in">str</span></span>):</span><br><span class="line">        sp = <span class="variable language_">self</span>._resolve(src)</span><br><span class="line">        dp = sp.parent / new_name</span><br><span class="line">        <span class="variable language_">self</span>.guard.check(dp)</span><br><span class="line">        sp.rename(dp)</span><br></pre></td></tr></table></figure><h3 id="3-归类与标签"><a href="#3-归类与标签" class="headerlink" title="3. 归类与标签"></a>3. 归类与标签</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># classify.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> file_tools <span class="keyword">import</span> FileTools</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify_by_rules</span>(<span class="params">ft: FileTools, files: <span class="built_in">list</span>[<span class="built_in">str</span>], rules: <span class="built_in">list</span>[<span class="built_in">dict</span>]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    rules: [&#123;&quot;contains&quot;: &quot;架构&quot;, &quot;to&quot;: &quot;docs/architecture&quot;&#125;,</span></span><br><span class="line"><span class="string">            &#123;&quot;contains&quot;: &quot;API&quot;, &quot;to&quot;: &quot;docs/api&quot;&#125;,</span></span><br><span class="line"><span class="string">            &#123;&quot;default&quot;: True, &quot;to&quot;: &quot;docs/misc&quot;&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        text = ft.read(f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>))</span><br><span class="line">        moved = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> rules:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;contains&quot;</span> <span class="keyword">in</span> r <span class="keyword">and</span> r[<span class="string">&quot;contains&quot;</span>] <span class="keyword">in</span> text:</span><br><span class="line">                rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">                dst = Path(r[<span class="string">&quot;to&quot;</span>]) / Path(rel).name</span><br><span class="line">                ft.move(rel, <span class="built_in">str</span>(dst))</span><br><span class="line">                moved = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> moved:</span><br><span class="line">            <span class="keyword">for</span> r <span class="keyword">in</span> rules:</span><br><span class="line">                <span class="keyword">if</span> r.get(<span class="string">&quot;default&quot;</span>):</span><br><span class="line">                    rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">                    dst = Path(r[<span class="string">&quot;to&quot;</span>]) / Path(rel).name</span><br><span class="line">                    ft.move(rel, <span class="built_in">str</span>(dst))</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_tag_to_header</span>(<span class="params">ft: FileTools, pattern: <span class="built_in">str</span>, tag: <span class="built_in">str</span></span>):</span><br><span class="line">    files = ft.<span class="built_in">list</span>(pattern, recursive=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">            lines = text.splitlines()</span><br><span class="line">            <span class="keyword">if</span> lines <span class="keyword">and</span> lines[<span class="number">0</span>].startswith(<span class="string">&quot;# &quot;</span>):</span><br><span class="line">                lines[<span class="number">0</span>] = lines[<span class="number">0</span>] + <span class="string">f&quot; [<span class="subst">&#123;tag&#125;</span>]&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                lines.insert(<span class="number">0</span>, <span class="string">f&quot;# [<span class="subst">&#123;tag&#125;</span>]&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join(lines)</span><br><span class="line">        ft.update(rel, transform)</span><br></pre></td></tr></table></figure><h3 id="4-审计日志与-Dry-run-确认"><a href="#4-审计日志与-Dry-run-确认" class="headerlink" title="4. 审计日志与 Dry-run 确认"></a>4. 审计日志与 Dry-run 确认</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># audit.py</span></span><br><span class="line"><span class="keyword">import</span> json, time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Auditor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, log_path: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.path = Path(log_path)</span><br><span class="line">        <span class="variable language_">self</span>.path.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">self, entry: <span class="built_in">dict</span></span>):</span><br><span class="line">        entry[<span class="string">&quot;ts&quot;</span>] = time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.path, <span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(entry, ensure_ascii=<span class="literal">False</span>) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">confirm</span>(<span class="params">plan: <span class="built_in">list</span>[<span class="built_in">dict</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;即将执行以下操作：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, step <span class="keyword">in</span> <span class="built_in">enumerate</span>(plan, <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>. <span class="subst">&#123;step[<span class="string">&#x27;operation&#x27;</span>]&#125;</span> -&gt; <span class="subst">&#123;step&#125;</span>&quot;</span>)</span><br><span class="line">    ans = <span class="built_in">input</span>(<span class="string">&quot;确认执行? (yes/no): &quot;</span>).strip().lower()</span><br><span class="line">    <span class="keyword">return</span> ans <span class="keyword">in</span> (<span class="string">&quot;y&quot;</span>, <span class="string">&quot;yes&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="5-规划器与执行器"><a href="#5-规划器与执行器" class="headerlink" title="5. 规划器与执行器"></a>5. 规划器与执行器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># agent.py</span></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> guard <span class="keyword">import</span> Guard</span><br><span class="line"><span class="keyword">from</span> file_tools <span class="keyword">import</span> FileTools</span><br><span class="line"><span class="keyword">from</span> audit <span class="keyword">import</span> Auditor, confirm</span><br><span class="line"><span class="keyword">from</span> classify <span class="keyword">import</span> classify_by_rules, add_tag_to_header</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg_path=<span class="string">&quot;config.yaml&quot;</span></span>):</span><br><span class="line">        cfg = yaml.safe_load(<span class="built_in">open</span>(cfg_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">        <span class="variable language_">self</span>.root = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;root&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.guard = Guard(Path(<span class="variable language_">self</span>.root), cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;deny_patterns&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.ft = FileTools(<span class="variable language_">self</span>.root, <span class="variable language_">self</span>.guard, encoding=cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;encoding&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.aud = Auditor(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;log_path&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.allow_ops = <span class="built_in">set</span>(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;allow_ops&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.dry_run_default = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;dry_run_default&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.require_confirm_for = <span class="built_in">set</span>(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;require_confirm_for&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.backup_before_delete = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;backup_before_delete&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.max_batch = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;max_batch&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plan_from_prompt</span>(<span class="params">self, prompt: <span class="built_in">str</span></span>) -&gt; <span class="built_in">list</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        简化版解析器：根据关键词生成操作计划</span></span><br><span class="line"><span class="string">        可替换为更强的结构化意图解析器</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        plan = []</span><br><span class="line">        p = prompt.lower()</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;归类&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">or</span> <span class="string">&quot;分类&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;list&quot;</span>,<span class="string">&quot;pattern&quot;</span>:<span class="string">&quot;**/*.md&quot;</span>,<span class="string">&quot;recursive&quot;</span>:<span class="literal">True</span>&#125;)</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;classify&quot;</span>,<span class="string">&quot;rules&quot;</span>:[</span><br><span class="line">                &#123;<span class="string">&quot;contains&quot;</span>:<span class="string">&quot;架构&quot;</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/architecture&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;contains&quot;</span>:<span class="string">&quot;API&quot;</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/api&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;default&quot;</span>:<span class="literal">True</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/misc&quot;</span>&#125;,</span><br><span class="line">            ]&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;标签&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;tag&quot;</span>,<span class="string">&quot;pattern&quot;</span>:<span class="string">&quot;docs/architecture/**/*.md&quot;</span>,<span class="string">&quot;tag&quot;</span>:<span class="string">&quot;architecture&quot;</span>&#125;)</span><br><span class="line">        <span class="comment"># 示例：创建/删除</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;创建&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">and</span> <span class="string">&quot;.md&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;create&quot;</span>,<span class="string">&quot;path&quot;</span>:<span class="string">&quot;notes/new.md&quot;</span>,<span class="string">&quot;content&quot;</span>:<span class="string">&quot;# 新笔记\n&quot;</span>, <span class="string">&quot;overwrite&quot;</span>:<span class="literal">False</span>&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;删除&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">and</span> <span class="string">&quot;临时&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;delete&quot;</span>,<span class="string">&quot;path&quot;</span>:<span class="string">&quot;tmp&quot;</span>, <span class="string">&quot;recursive&quot;</span>:<span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="keyword">return</span> plan</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">execute</span>(<span class="params">self, plan: <span class="built_in">list</span>[<span class="built_in">dict</span>], dry_run: <span class="built_in">bool</span> | <span class="literal">None</span> = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> dry_run <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            dry_run = <span class="variable language_">self</span>.dry_run_default</span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> plan:</span><br><span class="line">            op = step[<span class="string">&quot;operation&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> op <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.allow_ops:</span><br><span class="line">                <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Operation not allowed: <span class="subst">&#123;op&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> dry_run <span class="keyword">or</span> <span class="built_in">any</span>(step[<span class="string">&quot;operation&quot;</span>] <span class="keyword">in</span> <span class="variable language_">self</span>.require_confirm_for <span class="keyword">for</span> step <span class="keyword">in</span> plan):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> confirm(plan):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;取消执行。&quot;</span>)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> plan[:<span class="variable language_">self</span>.max_batch]:</span><br><span class="line">            op = step[<span class="string">&quot;operation&quot;</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> op == <span class="string">&quot;list&quot;</span>:</span><br><span class="line">                    files = <span class="variable language_">self</span>.ft.<span class="built_in">list</span>(step[<span class="string">&quot;pattern&quot;</span>], step.get(<span class="string">&quot;recursive&quot;</span>, <span class="literal">True</span>))</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;pattern&quot;</span>:step[<span class="string">&quot;pattern&quot;</span>],<span class="string">&quot;count&quot;</span>:<span class="built_in">len</span>(files)&#125;)</span><br><span class="line">                    step[<span class="string">&quot;_files&quot;</span>] = files</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;create&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.create(step[<span class="string">&quot;path&quot;</span>], step.get(<span class="string">&quot;content&quot;</span>,<span class="string">&quot;&quot;</span>), step.get(<span class="string">&quot;overwrite&quot;</span>, <span class="literal">False</span>))</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;read&quot;</span>:</span><br><span class="line">                    text = <span class="variable language_">self</span>.ft.read(step[<span class="string">&quot;path&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;bytes&quot;</span>:<span class="built_in">len</span>(text)&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;update&quot;</span>:</span><br><span class="line">                    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">t</span>): <span class="keyword">return</span> step[<span class="string">&quot;transform&quot;</span>](t)</span><br><span class="line">                    <span class="variable language_">self</span>.ft.update(step[<span class="string">&quot;path&quot;</span>], transform)</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;move&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.move(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;dst&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;dst&quot;</span>:step[<span class="string">&quot;dst&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;copy&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.copy(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;dst&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;dst&quot;</span>:step[<span class="string">&quot;dst&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;delete&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.delete(step[<span class="string">&quot;path&quot;</span>], backup=<span class="variable language_">self</span>.backup_before_delete)</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;rename&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.rename(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;new_name&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;new_name&quot;</span>:step[<span class="string">&quot;new_name&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;classify&quot;</span>:</span><br><span class="line">                    files = []</span><br><span class="line">                    <span class="keyword">for</span> prev <span class="keyword">in</span> plan:</span><br><span class="line">                        <span class="keyword">if</span> prev.get(<span class="string">&quot;_files&quot;</span>):</span><br><span class="line">                            files.extend(prev[<span class="string">&quot;_files&quot;</span>])</span><br><span class="line">                    classify_by_rules(<span class="variable language_">self</span>.ft, files, step[<span class="string">&quot;rules&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;count&quot;</span>:<span class="built_in">len</span>(files),<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;tag&quot;</span>:</span><br><span class="line">                    add_tag_to_header(<span class="variable language_">self</span>.ft, step[<span class="string">&quot;pattern&quot;</span>], step[<span class="string">&quot;tag&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;pattern&quot;</span>:step[<span class="string">&quot;pattern&quot;</span>],<span class="string">&quot;tag&quot;</span>:step[<span class="string">&quot;tag&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> NotImplementedError(<span class="string">f&quot;Unknown op: <span class="subst">&#123;op&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;error&quot;</span>:<span class="built_in">str</span>(e)&#125;)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[错误] <span class="subst">&#123;op&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><h3 id="6-命令行入口"><a href="#6-命令行入口" class="headerlink" title="6. 命令行入口"></a>6. 命令行入口</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cli.py</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> agent <span class="keyword">import</span> Agent</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--cfg&quot;</span>, default=<span class="string">&quot;config.yaml&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--prompt&quot;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dry-run&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    ag = Agent(args.cfg)</span><br><span class="line">    plan = ag.plan_from_prompt(args.prompt)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> plan:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未生成操作计划，请调整提示或使用更具体的命令。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ag.execute(plan, dry_run=args.dry_run)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><hr><h2 id="跨平台注意事项"><a href="#跨平台注意事项" class="headerlink" title="跨平台注意事项"></a>跨平台注意事项</h2><ul><li><strong>路径统一:</strong> 使用 pathlib，不直接拼接字符串；Windows 下注意盘符与反斜杠。</li><li><strong>权限问题:</strong> Linux/Unix 可能需要额外权限；建议在非 root 用户与沙箱目录内运行。</li><li><strong>编码:</strong> 文本文件统一使用 UTF-8，Windows 下确保控制台编码兼容。</li><li><strong>通配符:</strong> 使用 glob/rglob；复杂选择可在 list 后用正则二次过滤。</li></ul><hr><h2 id="可选增强"><a href="#可选增强" class="headerlink" title="可选增强"></a>可选增强</h2><ul><li><strong>更强的意图解析:</strong> 用结构化输出模板（JSON Schema）约束模型把 prompt 转成操作序列。</li><li><strong>RAG 文件检索:</strong> 向量检索你的文件摘要，实现“自然语言选文件”再执行。</li><li><strong>事务与回滚:</strong> 对 move/copy/rename 建立操作栈，失败可回滚。</li><li><strong>批量规则:</strong> 扩展 classify 支持正则、扩展名、关键词权重、YAML 规则集。</li><li><strong>前端面板:</strong> Web UI 显示 Dry-run 计划与审计日志，支持勾选执行。</li></ul><hr><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><ul><li><p>创建笔记</p><ul><li><strong>Prompt:</strong> 在 notes 目录创建一篇名为 new.md 的笔记，标题“项目架构综述”</li><li><strong>命令:</strong> python cli.py –prompt “创建 notes/new.md，内容为 # 项目架构综述”</li></ul></li><li><p>归类并加标签</p><ul><li><strong>Prompt:</strong> 将 docs 下所有 md 归类，架构主题加标签</li><li><strong>命令:</strong> python cli.py –prompt “归类 docs 下的 md，并为架构主题加标签” –dry-run</li></ul></li><li><p>安全删除临时目录</p><ul><li><strong>Prompt:</strong> 删除 tmp 目录（保留备份）</li><li><strong>命令:</strong> python cli.py –prompt “删除临时目录 tmp”</li></ul></li></ul><hr><p>如果你愿意，我们可以把“计划生成器”替换为你熟悉的 LLM 并加入 JSON Schema 校验，保证任何自然语言都转成安全、可执行的操作序列；也可以为你家的文件结构定制“分类规则库”，让它真正成为你的个人文件管家。</p><h2 id="Agent-可以使用哪种语言来实现？"><a href="#Agent-可以使用哪种语言来实现？" class="headerlink" title="Agent 可以使用哪种语言来实现？"></a>Agent 可以使用哪种语言来实现？</h2><p><strong>直接回答</strong>：Agent 并不依赖某一种特定语言来实现，常见的实现语言有 <strong>Python、JavaScript/TypeScript、Java、Go、Rust</strong> 等，其中 <strong>Python</strong> 是目前最主流的选择，因为它生态成熟、AI 框架丰富、社区活跃。</p><hr><h2 id="🔑-常见实现语言与特点"><a href="#🔑-常见实现语言与特点" class="headerlink" title="🔑 常见实现语言与特点"></a>🔑 常见实现语言与特点</h2><ul><li><p><strong>Python</strong></p><ul><li><strong>优势</strong>：生态最全（LangChain、LlamaIndex、AutoGen 等框架），与大模型 API、向量数据库、工具库无缝衔接。</li><li><strong>适用场景</strong>：快速原型、科研实验、跨平台 Agent 应用。</li></ul></li><li><p><strong>JavaScript / TypeScript</strong></p><ul><li><strong>优势</strong>：前端/全栈开发者友好，能直接在浏览器或 Node.js 环境运行。</li><li><strong>框架</strong>：LangChain.js、AutoGen.js。</li><li><strong>适用场景</strong>：Web Agent、插件化应用、跨端交互。</li></ul></li><li><p><strong>Java</strong></p><ul><li><strong>优势</strong>：企业级生态，稳定性和性能好，适合与现有企业系统集成。</li><li><strong>适用场景</strong>：金融、电信、ERP 系统中的智能体。</li></ul></li><li><p><strong>Go</strong></p><ul><li><strong>优势</strong>：高并发、轻量，适合构建分布式 Agent 服务。</li><li><strong>适用场景</strong>：云原生 Agent、微服务架构。</li></ul></li><li><p><strong>Rust</strong></p><ul><li><strong>优势</strong>：安全性和性能极佳，适合对内存和并发要求高的场景。</li><li><strong>适用场景</strong>：系统级 Agent、边缘计算 Agent。</li></ul></li></ul><hr><h2 id="📌-选择建议"><a href="#📌-选择建议" class="headerlink" title="📌 选择建议"></a>📌 选择建议</h2><ul><li><strong>快速实验 / 学习</strong> → Python（生态最全，文档和教程丰富）。</li><li><strong>Web 应用 / 前端集成</strong> → JavaScript/TypeScript。</li><li><strong>企业级系统集成</strong> → Java。</li><li><strong>高并发服务 / 云原生</strong> → Go。</li><li><strong>系统底层 / 高性能</strong> → Rust。</li></ul><hr><p>✅ <strong>总结</strong>：你可以用任何主流语言实现 Agent，但 <strong>Python 是事实上的标准语言</strong>，因为它拥有最成熟的 AI 框架和社区支持。如果你要做跨平台文件操作 Agent，推荐用 <strong>Python（跨平台库丰富）</strong> 或 <strong>Go（性能与并发更好）</strong>。</p><p>要不要我帮你整理一份 <strong>“不同语言实现 Agent 的对比表”</strong>，把生态、性能、学习成本、适用场景一目了然？</p><p>好的 Mark，我来帮你把 <strong>Agent 常用编程语言对比表</strong>整理成一个清晰的表格，方便你快速选择实现语言。</p><hr><h2 id="📑-Agent-常用编程语言对比表"><a href="#📑-Agent-常用编程语言对比表" class="headerlink" title="📑 Agent 常用编程语言对比表"></a>📑 Agent 常用编程语言对比表</h2><table><thead><tr><th>编程语言</th><th>生态支持</th><th>性能</th><th>学习成本</th><th>适用场景</th><th>代表框架/工具</th></tr></thead><tbody><tr><td><strong>Python</strong></td><td>最丰富（LangChain、LlamaIndex、AutoGen 等），AI 库齐全</td><td>良好</td><td>低</td><td>快速原型、科研实验、跨平台 Agent</td><td>LangChain, LlamaIndex, AutoGen</td></tr><tr><td><strong>JavaScript / TypeScript</strong></td><td>中等（LangChain.js、AutoGen.js），Web 生态强</td><td>一般</td><td>低</td><td>Web Agent、浏览器插件、跨端交互</td><td>LangChain.js, AutoGen.js</td></tr><tr><td><strong>Java</strong></td><td>企业级生态，稳定性强</td><td>一般</td><td>中等</td><td>金融、电信、ERP 系统集成</td><td>Deeplearning4j, Spring AI</td></tr><tr><td><strong>Go (Golang)</strong></td><td>云原生生态，轻量高并发</td><td>良好</td><td>中等</td><td>分布式 Agent、微服务架构</td><td>GoLangChain, Go-LLM SDK</td></tr><tr><td><strong>Rust</strong></td><td>系统级生态，安全高性能</td><td>极优</td><td>高</td><td>边缘计算、高性能 Agent</td><td>Burn, Rust-LLM</td></tr><tr><td><strong>C# / .NET</strong></td><td>微软生态，企业集成好</td><td>良好</td><td>中等</td><td>Windows 系统 Agent、企业应用</td><td>Semantic Kernel, ML.NET</td></tr></tbody></table><hr><h2 id="🎯-总结-3"><a href="#🎯-总结-3" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul><li><strong>快速实验 / 学习</strong> → Python（生态最全，教程丰富）。</li><li><strong>Web 应用 / 前端集成</strong> → JavaScript/TypeScript。</li><li><strong>企业级系统</strong> → Java / C#。</li><li><strong>高并发服务 / 云原生</strong> → Go。</li><li><strong>高性能 / 系统级</strong> → Rust。</li></ul><hr><p>要不要我帮你再整理一份 <strong>“学习路径图”</strong>，比如如果你选 Python，从入门到能做一个文件操作 Agent，需要依次掌握哪些库和技能？这样你就能有一条清晰的学习路线。</p><p>明白啦 Mark！我来帮你整理一份 <strong>文字版学习路线图</strong>，专门针对你想构建 <strong>Agent（智能体）</strong> 的目标。它分阶段，从基础到进阶，逐步覆盖必备知识、工具和实践方向。</p><hr><h1 id="🛠️-构建智能体学习路线图（文字版）"><a href="#🛠️-构建智能体学习路线图（文字版）" class="headerlink" title="🛠️ 构建智能体学习路线图（文字版）"></a>🛠️ 构建智能体学习路线图（文字版）</h1><h2 id="阶段一：基础打牢"><a href="#阶段一：基础打牢" class="headerlink" title="阶段一：基础打牢"></a>阶段一：基础打牢</h2><ul><li><strong>编程语言</strong><ul><li>Python（推荐）：掌握 <code>os</code>、<code>pathlib</code>、<code>shutil</code>、<code>subprocess</code> 等文件/系统操作库</li><li>熟悉跨平台差异（Windows/Linux/Unix）</li></ul></li><li><strong>操作系统基础</strong><ul><li>文件系统结构、权限管理（chmod、ACL、NTFS 权限）</li><li>常见命令：ls/cp/mv/rm（Linux）、dir/copy/move/del（Windows）</li></ul></li><li><strong>版本控制</strong><ul><li>Git：管理代码与配置，保证可回滚</li></ul></li></ul><hr><h2 id="阶段二：AI-与大模型基础"><a href="#阶段二：AI-与大模型基础" class="headerlink" title="阶段二：AI 与大模型基础"></a>阶段二：AI 与大模型基础</h2><ul><li><strong>大模型必修知识</strong><ul><li>Transformer 架构（Attention is All You Need）</li><li>GPT 系列（自回归生成）</li><li>BERT 系列（理解任务）</li></ul></li><li><strong>对齐与微调</strong><ul><li>指令微调（SFT）</li><li>RLHF（人类反馈强化学习）</li></ul></li><li><strong>RAG（检索增强生成）</strong><ul><li>向量数据库（FAISS、Milvus、Weaviate）</li><li>文档分块与嵌入检索</li></ul></li></ul><hr><h2 id="阶段三：Agent-基础框架"><a href="#阶段三：Agent-基础框架" class="headerlink" title="阶段三：Agent 基础框架"></a>阶段三：Agent 基础框架</h2><ul><li><strong>核心能力</strong><ul><li>任务分解（Chain of Thought 推理）</li><li>工具调用（调用文件操作 API）</li><li>记忆（短期上下文 + 长期存储）</li></ul></li><li><strong>常用框架</strong><ul><li>LangChain（Python/JS）</li><li>LlamaIndex（文档检索增强）</li><li>AutoGen / LangGraph（多 Agent 协作）</li></ul></li></ul><hr><h2 id="阶段四：文件操作-Agent-实现"><a href="#阶段四：文件操作-Agent-实现" class="headerlink" title="阶段四：文件操作 Agent 实现"></a>阶段四：文件操作 Agent 实现</h2><ul><li><strong>功能模块</strong><ul><li>文件/文件夹操作：创建、删除、修改、读取</li><li>文件归类：按扩展名/内容/时间分类</li><li>批量重命名、标签化</li><li>日志与审计：记录每次操作</li></ul></li><li><strong>安全机制</strong><ul><li>沙箱根目录（避免误删系统文件）</li><li>白名单操作类型</li><li>Dry-run 模式（先展示计划，再执行）</li><li>自动备份与回滚</li></ul></li></ul><hr><h2 id="阶段五：跨平台与扩展"><a href="#阶段五：跨平台与扩展" class="headerlink" title="阶段五：跨平台与扩展"></a>阶段五：跨平台与扩展</h2><ul><li><strong>跨平台适配</strong><ul><li>Windows：PowerShell、Win32 API</li><li>Linux/Unix：Bash、POSIX API</li></ul></li><li><strong>扩展功能</strong><ul><li>多模态输入（语音指令 → 文件操作）</li><li>Web UI 或 CLI 界面</li><li>多 Agent 协作（一个负责分类，一个负责清理）</li></ul></li></ul><hr><h2 id="阶段六：进阶与未来"><a href="#阶段六：进阶与未来" class="headerlink" title="阶段六：进阶与未来"></a>阶段六：进阶与未来</h2><ul><li><strong>推理增强</strong><ul><li>Self-Consistency（多路径投票）</li><li>工具增强推理（调用计算器、正则解析器）</li></ul></li><li><strong>生态集成</strong><ul><li>与日程/邮件/云存储联动</li><li>企业知识库接入</li></ul></li><li><strong>未来趋势</strong><ul><li>个性化 Agent（Personal LLM）</li><li>多模态 Agent（看图/听音频后操作文件）</li><li>自主规划与长期记忆</li></ul></li></ul><hr><h2 id="✅-总结-9"><a href="#✅-总结-9" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul><li><strong>基础 → 大模型 → Agent 框架 → 文件操作实现 → 跨平台扩展 → 推理与未来</strong></li><li>每一步都解决一个层次的问题，从“能写代码”到“能调用模型”，再到“能自主规划并安全执行”。</li></ul><hr><p>要不要我帮你把这份路线图再细化成 <strong>学习任务清单（Checklist）</strong>，比如“第 1 周掌握 pathlib， 第 2 周实现文件分类脚本，第 3 周接入 LangChain 工具调用”？这样你可以直接按周推进。</p><p>未完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 大模型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git 常用命令</title>
      <link href="/blog/2025/10/14/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
      <url>/blog/2025/10/14/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="下载好-git-后的配置"><a href="#下载好-git-后的配置" class="headerlink" title="下载好 git 后的配置"></a>下载好 git 后的配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">配置全局用户和邮箱</span></span><br><span class="line">git config --global user.name &quot;shenjy&quot;</span><br><span class="line">git config --global user.email &quot;asjdfasdfj@163.com&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">生成公钥</span></span><br><span class="line">ssh-keygen -t rsa -C &#x27;asjdfasdfj@163.com&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">copy公钥</span></span><br><span class="line">cd ~/.ssh</span><br><span class="line">cat id_rsa.pub</span><br></pre></td></tr></table></figure><h2 id="创建新的仓库"><a href="#创建新的仓库" class="headerlink" title="创建新的仓库"></a>创建新的仓库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;#shenjy.github.io&quot; &gt;&gt; README.md</span><br><span class="line">git init</span><br><span class="line">git add README.md</span><br><span class="line">git commit -m &quot;first commit&quot;</span><br><span class="line">git branch -M main</span><br><span class="line">git remote add origin https://github.com/shenjy/shenjy.github.io.git</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><h2 id="将已经存在的项目上传到-github"><a href="#将已经存在的项目上传到-github" class="headerlink" title="将已经存在的项目上传到 github"></a>将已经存在的项目上传到 github</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin https://github.com/shenjy/shenjy.github.io.git</span><br><span class="line">git branch -M main</span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p>完~</p>]]></content>
      
      
      <categories>
          
          <category> 版本控制 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>国内加速镜像源</title>
      <link href="/blog/2025/05/04/%E5%9B%BD%E5%86%85%E5%8A%A0%E9%80%9F%E9%95%9C%E5%83%8F%E6%BA%90/"/>
      <url>/blog/2025/05/04/%E5%9B%BD%E5%86%85%E5%8A%A0%E9%80%9F%E9%95%9C%E5%83%8F%E6%BA%90/</url>
      
        <content type="html"><![CDATA[<h2 id="国内镜像源"><a href="#国内镜像源" class="headerlink" title="国内镜像源"></a>国内镜像源</h2><ul><li><a href="https://developer.aliyun.com/mirror/">阿里云</a></li><li><a href="https://mirrors.huaweicloud.com/">华为云</a></li></ul><h3 id="Maven-镜像配置"><a href="#Maven-镜像配置" class="headerlink" title="Maven 镜像配置"></a>Maven 镜像配置</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 腾讯云 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>tencent maven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>中央仓库<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://mirrors.cloud.tencent.com/nexus/repository/maven-public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 中央仓库 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>repo<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>中央仓库<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://repo.maven.apache.org/maven2/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 阿里云公共仓库 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>aliyunmaven<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>阿里云公共仓库<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://maven.aliyun.com/repository/public<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 华为云公共仓库 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">id</span>&gt;</span>huaweicloud<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>*<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">url</span>&gt;</span>https://mirrors.huaweicloud.com/repository/maven/<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="npm-镜像配置"><a href="#npm-镜像配置" class="headerlink" title="npm 镜像配置"></a>npm 镜像配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmmirror.com</span><br></pre></td></tr></table></figure><h3 id="pip-镜像配置"><a href="#pip-镜像配置" class="headerlink" title="pip 镜像配置"></a>pip 镜像配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></table></figure><h3 id="Docker-镜像配置"><a href="#Docker-镜像配置" class="headerlink" title="Docker 镜像配置"></a>Docker 镜像配置</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;registry-mirrors&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;https://3laho3y3.mirror.aliyuncs.com&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;http://hub-mirror.c.163.com&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;http://f1361db2.m.daocloud.io&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;https://docker.mirrors.ustc.edu.cn&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;https://registry.docker-cn.com&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;https://mirror.ccs.tencentyun.com&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;insecure-registries&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;hub.image.com&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="Linux-服务器源配置"><a href="#Linux-服务器源配置" class="headerlink" title="Linux 服务器源配置"></a>Linux 服务器源配置</h3><h4 id="CentOS-7"><a href="#CentOS-7" class="headerlink" title="CentOS 7"></a>CentOS 7</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="comment"># 或</span></span><br><span class="line">curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成缓存</span></span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure><h4 id="Ubuntu"><a href="#Ubuntu" class="headerlink" title="Ubuntu"></a>Ubuntu</h4><ul><li><a href="https://developer.aliyun.com/mirror/ubuntu">阿里云 Ubuntu 镜像</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>学习网站</title>
      <link href="/blog/2025/04/06/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/"/>
      <url>/blog/2025/04/06/%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99/</url>
      
        <content type="html"><![CDATA[<h2 id="英语学习资料"><a href="#英语学习资料" class="headerlink" title="英语学习资料"></a>英语学习资料</h2><h3 id="背单词"><a href="#背单词" class="headerlink" title="背单词"></a>背单词</h3><ul><li><a href="https://www.baicizhan.com/">百词斩</a></li><li><a href="https://www.shanbay.com/">扇贝单词</a></li></ul><h3 id="英语学习"><a href="#英语学习" class="headerlink" title="英语学习"></a>英语学习</h3><ul><li><a href="https://julebu.co/">句乐部</a><ul><li><a href="https://github.com/cuixueshe/earthworm">github</a></li></ul></li><li><a href="https://www.idictation.cn/">爱听写</a></li><li><a href="https://speechling.com/zh/">Speechling</a></li><li><a href="https://www.englishclub.com/">EnglishClub</a></li><li><a href="https://www.ted.com/">TED</a></li><li><a href="https://www.bbc.co.uk/learningenglish/chinese">BBC learning English</a><ul><li><a href="https://podcasts.apple.com/gb/podcast/bbc%E8%8B%B1%E8%AF%AD%E6%95%99%E5%AD%A6/id305430933">BBC 英语教学播客</a></li></ul></li><li><a href="https://www.rd.com/">读者文摘</a></li><li><a href="https://www.americanrhetoric.com/top100speechesall.html">Top 100 Speeches</a></li><li><a href="https://rachelsenglish.com/">rachel’s English</a></li><li><a href="https://www.britannica.com/">Britannica</a></li><li><a href="https://www.usatoday.com/">USA Today</a></li><li><a href="https://www.economist.com/">The Economist</a></li><li><a href="https://www.nytimes.com/">The New York Times</a></li><li><a href="https://www.washingtonpost.com/">The Washington Post</a></li><li><a href="https://www.theguardian.com/">The Guardian</a></li><li><a href="https://www.theatlantic.com/">The Atlantic</a></li><li><a href="https://www.wsj.com/">The Wall Street Journal</a></li><li><a href="https://www.thetimes.com/">泰晤士报</a></li><li><a href="https://www.chinadaily.com.cn/">China Daily</a></li></ul><h2 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h2><ul><li><a href="https://github.com/rossant/awesome-math">Awesome Math</a></li></ul><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ul><li><a href="https://www.khanacademy.org/">可汗学院</a></li><li><a href="https://readtogether.ai/">readtogether</a></li><li><a href="https://www.italki.com/en">italki</a></li><li><a href="https://www.teachingenglish.org.uk/">teachingenglish</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 语言学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>IIS 服务器</title>
      <link href="/blog/2025/03/01/IIS%20%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <url>/blog/2025/03/01/IIS%20%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="如何将-IIS-服务器安装到-Windows-10-上"><a href="#如何将-IIS-服务器安装到-Windows-10-上" class="headerlink" title="如何将 IIS 服务器安装到 Windows 10 上"></a>如何将 IIS 服务器安装到 Windows 10 上</h2><p>对于这个问题，请参见博客 <a href="https://www.cnblogs.com/qk2014/p/4783006.html">Win10 如何开启 IIS 服务以及如何打开 IIS 管理器</a></p><h2 id="什么是-IIS-应用程序池"><a href="#什么是-IIS-应用程序池" class="headerlink" title="什么是 IIS 应用程序池"></a>什么是 IIS 应用程序池</h2><p>应用程序池 是 IIS 中的“进程隔离单元”。每个应用程序池都会启动一个或多个 w3wp.exe 进程来运行 Web 应用。</p><p>不同应用程序池之间的应用程序互不影响（内存、崩溃、配置独立）。</p><p>同一个应用程序池下的网站或应用程序共享同一个工作进程（意味着共享内存空间、CLR 实例等）。</p><h2 id="IIS-中的层级结构"><a href="#IIS-中的层级结构" class="headerlink" title="IIS 中的层级结构"></a>IIS 中的层级结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">服务器 (Server)</span><br><span class="line"> └── 应用程序池 (Application Pool)</span><br><span class="line">       └── 网站 (Site)</span><br><span class="line">             └── 应用程序 (Application)</span><br><span class="line">                   └── 虚拟目录 (Virtual Directory)</span><br></pre></td></tr></table></figure><h2 id="网站与应用程序池的关系"><a href="#网站与应用程序池的关系" class="headerlink" title="网站与应用程序池的关系"></a>网站与应用程序池的关系</h2><ul><li>一个网站（Site）必须绑定到一个应用程序池</li><li>一个应用程序池可以服务多个网站</li></ul><h2 id="常见建议"><a href="#常见建议" class="headerlink" title="常见建议"></a>常见建议</h2><ul><li>每个网站使用独立的应用程序池</li><li>多个小型网站，资源有限，可共用一个应用程序池</li><li>同一个网站下有多个子应用（/api、 /admin）等，可以分别分配不同的应用程序池以提高稳定性</li></ul><h2 id="常用的-IIS-程序池配置"><a href="#常用的-IIS-程序池配置" class="headerlink" title="常用的 IIS 程序池配置"></a>常用的 IIS 程序池配置</h2><h2 id="🧩-一、应用程序池主要配置分类总览"><a href="#🧩-一、应用程序池主要配置分类总览" class="headerlink" title="🧩 一、应用程序池主要配置分类总览"></a>🧩 一、应用程序池主要配置分类总览</h2><table><thead><tr><th>配置类别</th><th>示例设置项</th><th>作用</th></tr></thead><tbody><tr><td><strong>常规（General）</strong></td><td>.NET CLR 版本、托管管道模式</td><td>决定运行环境</td></tr><tr><td><strong>进程模型（Process Model）</strong></td><td>标识（Identity）、空闲超时、最大工作进程数</td><td>控制进程生命周期与权限</td></tr><tr><td><strong>回收（Recycling）</strong></td><td>定期回收、特定时间回收</td><td>防止内存泄漏</td></tr><tr><td><strong>性能（Performance）</strong></td><td>空闲超时、最大请求数、队列长度</td><td>控制性能表现</td></tr><tr><td><strong>故障回收（Rapid-Fail Protection）</strong></td><td>最大失败数、时间间隔</td><td>防止频繁崩溃</td></tr><tr><td><strong>CPU 限制（CPU）</strong></td><td>限制百分比、操作模式</td><td>控制 CPU 占用</td></tr><tr><td><strong>启动/关机行为（Start Mode / Idle Timeout）</strong></td><td>AlwaysRunning, OnDemand</td><td>控制池启动策略</td></tr></tbody></table><hr><h2 id="🧱-二、常用配置详解"><a href="#🧱-二、常用配置详解" class="headerlink" title="🧱 二、常用配置详解"></a>🧱 二、常用配置详解</h2><h3 id="1️⃣-常规设置（General）"><a href="#1️⃣-常规设置（General）" class="headerlink" title="1️⃣ 常规设置（General）"></a>1️⃣ 常规设置（General）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>.NET CLR 版本</strong></td><td>指定运行环境</td><td><code>.NET CLR v4.0</code> 或 <code>无托管代码</code>（纯静态/Node.js/PHP）</td></tr><tr><td><strong>托管管道模式</strong></td><td>管道处理方式</td><td><strong>Integrated（推荐）</strong> 或 Classic（旧版兼容）</td></tr><tr><td><strong>启动模式（Start Mode）</strong></td><td>应用程序池是否在 IIS 启动时立即启动</td><td><code>AlwaysRunning</code>（生产环境推荐）</td></tr></tbody></table><hr><h3 id="2️⃣-进程模型（Process-Model）"><a href="#2️⃣-进程模型（Process-Model）" class="headerlink" title="2️⃣ 进程模型（Process Model）"></a>2️⃣ 进程模型（Process Model）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>标识（Identity）</strong></td><td>应用池运行的系统账户</td><td>默认 <code>ApplicationPoolIdentity</code>（安全性高）</td></tr><tr><td><strong>空闲超时（Idle Time-out）</strong></td><td>无请求后多久自动回收（分钟）</td><td>默认 20 分钟；高访问量网站建议设为 0（禁用）</td></tr><tr><td><strong>最大工作进程数（Web Garden）</strong></td><td>每个池可启动的进程数</td><td>默认 1，<strong>不要轻易改</strong>（除非是特殊并行需求）</td></tr><tr><td><strong>加载用户配置文件</strong></td><td>是否加载用户配置文件</td><td>一般设为 <code>True</code>（对部分框架如 ASP.NET 必须）</td></tr></tbody></table><hr><h3 id="3️⃣-回收设置（Recycling）"><a href="#3️⃣-回收设置（Recycling）" class="headerlink" title="3️⃣ 回收设置（Recycling）"></a>3️⃣ 回收设置（Recycling）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>定期回收（固定时间间隔）</strong></td><td>默认每 1740 分钟（29 小时）</td><td>可自定义；如凌晨 3:00 定时回收</td></tr><tr><td><strong>特定时间回收（Specific Time）</strong></td><td>在指定时刻重启池</td><td><code>03:00:00</code>（防止高峰期重启）</td></tr><tr><td><strong>回收条件</strong></td><td>内存限制、虚拟内存限制等</td><td>内存 &gt; 1GB 可设 <code>Private Memory Limit</code> 1024MB</td></tr><tr><td><strong>回收事件日志</strong></td><td>回收时写入日志</td><td>建议启用（方便排查问题）</td></tr></tbody></table><hr><h3 id="4️⃣-性能（Performance）"><a href="#4️⃣-性能（Performance）" class="headerlink" title="4️⃣ 性能（Performance）"></a>4️⃣ 性能（Performance）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>空闲超时</strong></td><td>与进程模型中重复，用于节省资源</td><td>高访问量站点可设 0（禁用）</td></tr><tr><td><strong>最大请求队列长度</strong></td><td>等待处理的最大请求数</td><td>默认 1000，可根据负载调整</td></tr><tr><td><strong>定期 ping（Ping Enabled）</strong></td><td>监测工作进程是否响应</td><td>保持默认启用</td></tr></tbody></table><hr><h3 id="5️⃣-快速失败保护（Rapid-Fail-Protection）"><a href="#5️⃣-快速失败保护（Rapid-Fail-Protection）" class="headerlink" title="5️⃣ 快速失败保护（Rapid-Fail Protection）"></a>5️⃣ 快速失败保护（Rapid-Fail Protection）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>启用快速失败保护</strong></td><td>防止应用频繁崩溃时无限重启</td><td>默认启用</td></tr><tr><td><strong>最大失败数</strong></td><td>在指定时间内最多允许失败次数</td><td>默认 5 次 / 5 分钟</td></tr><tr><td><strong>失败后操作</strong></td><td>超出次数后停止应用池</td><td>默认启用（防止死循环崩溃）</td></tr></tbody></table><hr><h3 id="6️⃣-CPU-限制（CPU）"><a href="#6️⃣-CPU-限制（CPU）" class="headerlink" title="6️⃣ CPU 限制（CPU）"></a>6️⃣ CPU 限制（CPU）</h3><table><thead><tr><th>项目</th><th>说明</th><th>常见配置</th></tr></thead><tbody><tr><td><strong>限制 CPU 使用率</strong></td><td>限制单进程 CPU 百分比</td><td>例如：<code>Limit = 80</code>，<code>Action = Throttle</code></td></tr><tr><td><strong>动作（Action）</strong></td><td>超过限制后执行的动作</td><td><code>Throttle</code>（降速） 或 <code>KillW3wp</code>（终止进程）</td></tr></tbody></table><hr><h2 id="⚙️-三、常见推荐配置模板（生产环境）"><a href="#⚙️-三、常见推荐配置模板（生产环境）" class="headerlink" title="⚙️ 三、常见推荐配置模板（生产环境）"></a>⚙️ 三、常见推荐配置模板（生产环境）</h2><table><thead><tr><th>配置项</th><th>推荐值</th><th>说明</th></tr></thead><tbody><tr><td>.NET CLR 版本</td><td>v4.0 / 无托管代码</td><td>取决于框架</td></tr><tr><td>托管管道模式</td><td>Integrated</td><td>性能好</td></tr><tr><td>启动模式</td><td>AlwaysRunning</td><td>防止首请求延迟</td></tr><tr><td>空闲超时</td><td>0</td><td>保持常驻内存</td></tr><tr><td>回收时间</td><td>03:00:00</td><td>低峰期自动回收</td></tr><tr><td>标识</td><td>ApplicationPoolIdentity</td><td>安全性高</td></tr><tr><td>最大请求队列</td><td>2000</td><td>高并发下防止拒绝服务</td></tr><tr><td>快速失败保护</td><td>启用</td><td>防止崩溃循环</td></tr><tr><td>CPU 限制</td><td>80%, Throttle</td><td>控制资源占用</td></tr></tbody></table><hr><h2 id="🧠-四、补充建议"><a href="#🧠-四、补充建议" class="headerlink" title="🧠 四、补充建议"></a>🧠 四、补充建议</h2><ul><li>✅ <strong>生产环境</strong> 建议每个独立网站或微服务使用独立应用程序池；</li><li>⚠️ <strong>不要盲目提高“最大工作进程数”</strong>（Web Garden），容易引发 Session 丢失；</li><li>🔍 可使用 <strong>AppCmd.exe</strong> 或 PowerShell 来批量查看/修改应用程序池配置；</li><li>📈 定期查看 <strong>IIS 日志 + Windows 事件查看器</strong>，监控应用池重启次数和原因。</li></ul><h2 id="如何重新启动-IIS"><a href="#如何重新启动-IIS" class="headerlink" title="如何重新启动 IIS"></a>如何重新启动 IIS</h2><p>下面的命令需要在命令行（以管理员身份启动的）中执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iisreset /restart</span><br></pre></td></tr></table></figure><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> IIS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>国外技术博客</title>
      <link href="/blog/2025/02/01/20250201-%E5%9B%BD%E5%A4%96%E7%A7%91%E6%8A%80%E5%85%AC%E5%8F%B8%E5%8D%9A%E5%AE%A2/"/>
      <url>/blog/2025/02/01/20250201-%E5%9B%BD%E5%A4%96%E7%A7%91%E6%8A%80%E5%85%AC%E5%8F%B8%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="公司工程博客（用于面试准备和技术学习）："><a href="#公司工程博客（用于面试准备和技术学习）：" class="headerlink" title="公司工程博客（用于面试准备和技术学习）："></a>公司工程博客（用于面试准备和技术学习）：</h2><ul><li>Airbnb: <a href="https://medium.com/airbnb-engineering">https://medium.com/airbnb-engineering</a></li><li>Amazon: <a href="https://developer.amazon.com/blogs">https://developer.amazon.com/blogs</a></li><li>Asana: <a href="https://blog.asana.com/category/eng">https://blog.asana.com/category/eng</a></li><li>Atlassian: <a href="https://developer.atlassian.com/blog">https://developer.atlassian.com/blog</a></li><li>Bittorrent: <a href="http://engineering.bittorrent.com/">http://engineering.bittorrent.com</a></li><li>Cloudera: <a href="https://blog.cloudera.com/">https://blog.cloudera.com</a></li><li>Docker: <a href="https://blog.docker.com/">https://blog.docker.com</a></li><li>Dropbox: <a href="https://blogs.dropbox.com/tech">https://blogs.dropbox.com/tech</a></li><li>eBay: <a href="http://www.ebaytechblog.com/">http://www.ebaytechblog.com</a></li><li>Facebook: <a href="https://code.facebook.com/posts">https://code.facebook.com/posts</a></li><li>GitHub: <a href="https://githubengineering.com/">https://githubengineering.com</a></li><li>Google: <a href="https://developers.googleblog.com/">https://developers.googleblog.com</a></li><li>Groupon: <a href="https://engineering.groupon.com/">https://engineering.groupon.com</a></li><li>Highscalability: <a href="http://highscalability.com/">http://highscalability.com</a></li><li>Instacart: <a href="https://tech.instacart.com/">https://tech.instacart.com</a></li><li>Instagram: <a href="https://engineering.instagram.com/">https://engineering.instagram.com</a></li><li>LinkedIn: <a href="https://engineering.linkedin.com/blog">https://engineering.linkedin.com/blog</a></li><li>Mixpanel: <a href="https://mixpanel.com/blog">https://mixpanel.com/blog</a></li><li>Netflix: <a href="https://medium.com/netflix-techblog">https://medium.com/netflix-techblog</a></li><li>Nextdoor: <a href="https://engblog.nextdoor.com/">https://engblog.nextdoor.com</a></li><li>PayPal: <a href="https://www.paypal-engineering.com/">https://www.paypal-engineering.com</a></li><li>Pinterest: <a href="https://engineering.pinterest.com/">https://engineering.pinterest.com</a></li><li>Quora: <a href="https://engineering.quora.com/">https://engineering.quora.com</a></li><li>Reddit: <a href="https://redditblog.com/">https://redditblog.com</a></li><li>Salesforce: <a href="https://developer.salesforce.com/blogs/engineering">https://developer.salesforce.com/blogs/engineering</a></li><li>Shopify: <a href="https://engineering.shopify.com/">https://engineering.shopify.com</a></li><li>Slack: <a href="https://slack.engineering/">https://slack.engineering</a></li><li>Soundcloud: <a href="https://developers.soundcloud.com/blog">https://developers.soundcloud.com/blog</a></li><li>Spotify: <a href="https://labs.spotify.com/">https://labs.spotify.com</a></li><li>Stripe: <a href="https://stripe.com/blog/engineering">https://stripe.com/blog/engineering</a></li><li>Twitter: <a href="https://blog.twitter.com/engineering/en_us.html">https://blog.twitter.com/engineering/en_us.html</a></li><li>Thumbtack: <a href="https://www.thumbtack.com/engineering">https://www.thumbtack.com/engineering</a></li><li>Uber: <a href="http://eng.uber.com/">http://eng.uber.com</a></li><li>Yahoo: <a href="https://yahooeng.tumblr.com/">https://yahooeng.tumblr.com</a></li><li>Yelp: <a href="https://engineeringblog.yelp.com/">https://engineeringblog.yelp.com</a></li><li>Zoom: <a href="https://medium.com/zoom-developer-blog">https://medium.com/zoom-developer-blog</a></li></ul><h2 id="最喜爱的-9-个工程博客（个人偏好列表）："><a href="#最喜爱的-9-个工程博客（个人偏好列表）：" class="headerlink" title="最喜爱的 9 个工程博客（个人偏好列表）："></a>最喜爱的 9 个工程博客（个人偏好列表）：</h2><ul><li>Netflix TechBlog：<a href="https://netflixtechblog.com/">https://netflixtechblog.com/</a></li><li>Uber Blog：<a href="https://www.uber.com/zh-US/blog">https://www.uber.com/zh-US/blog</a></li><li>Cloudflare Blog：<a href="https://blog.cloudflare.com/">https://blog.cloudflare.com/</a></li><li>Engineering at Meta（Facebook）：<a href="https://engineering.fb.com/">https://engineering.fb.com/</a></li><li>LinkedIn Engineering：<a href="https://www.linkedin.com/blog/engineering">https://www.linkedin.com/blog/engineering</a></li><li>Discord Blog：<a href="https://discord.com/category/engineering">https://discord.com/category/engineering</a></li><li>AWS Architecture Blog：<a href="https://aws.amazon.com/blogs/architecture/">https://aws.amazon.com/blogs/architecture/</a></li><li>Slack Engineering：<a href="https://slack.engineering/">https://slack.engineering/</a></li><li>Stripe Blog：<a href="https://stripe.com/blog/engineering">https://stripe.com/blog/engineering</a></li></ul><h2 id="个人偏好列表："><a href="#个人偏好列表：" class="headerlink" title="个人偏好列表："></a>个人偏好列表：</h2><ul><li><a href="https://www.geeksforgeeks.org/">https://www.geeksforgeeks.org/</a></li><li><a href="https://37signals.com/">https://37signals.com/</a><ul><li><a href="https://basecamp.com/handbook">https://basecamp.com/handbook</a></li></ul></li><li><a href="https://blog.codinghorror.com/">https://blog.codinghorror.com/</a></li><li><a href="https://blog.bytebytego.com/">https://blog.bytebytego.com/</a><ul><li><a href="https://github.com/ByteByteGoHq/system-design-101">https://github.com/ByteByteGoHq/system-design-101</a></li><li><a href="https://bytebytego.com/guides/api-web-development">https://bytebytego.com/guides/api-web-development</a></li></ul></li><li><a href="https://www.brendangregg.com/">https://www.brendangregg.com/</a></li></ul><p>文档中明确推荐了以上博客，主要用于系统设计面试准备、技术架构学习和工程实践参考。列表覆盖了多家知名科技公司的官方工程博客，以及高 scalability（Highscalability）等独立技术博客。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 技术博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>好用的开源项目</title>
      <link href="/blog/2025/01/01/20250101-%E5%A5%BD%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/"/>
      <url>/blog/2025/01/01/20250101-%E5%A5%BD%E7%94%A8%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h2><ul><li>如果你有一台 Linux 云主机，你可以使用 <code>1panel</code> 来管理你的服务器，<a href="https://github.com/1Panel-dev/1Panel">链接</a>。</li><li>如果你想基于 Github 搭建你自己的 Blog，你可以使用下面的工具，<a href="https://github.com/shenjy06/blog">链接</a>。</li><li><a href="https://tududi.com/">tududi: smart task management</a>，<a href="https://github.com/chrisvel/tududi">开源地址</a></li></ul><h2 id="Vibe-Coding-工具"><a href="#Vibe-Coding-工具" class="headerlink" title="Vibe Coding 工具"></a>Vibe Coding 工具</h2><ul><li><a href="https://github.com/filipecalegario/awesome-vibe-coding/blob/main/README-CN.md">Awesome Vibe Coding</a></li><li><a href="https://github.com/QwenLM/qwen-code">Alibaba Vibe Coding Command Line tool(Free 2k prompts/day for Chinese users)</a></li><li><a href="https://github.com/Kilo-Org/kilocode">VsCode 插件-Kilo</a></li></ul><h2 id="远程工具"><a href="#远程工具" class="headerlink" title="远程工具"></a>远程工具</h2><ul><li><a href="https://sunlogin.oray.com/">向日葵【非开源】</a></li><li><a href="https://www.todesk.com/">toDesk【非开源】</a></li><li><a href="https://rustdesk.com/">RuskDesk</a></li><li><a href="https://www.crossdesk.cn/">CrossDesk</a></li></ul><h2 id="在线编程平台"><a href="#在线编程平台" class="headerlink" title="在线编程平台"></a>在线编程平台</h2><ul><li><a href="https://codepen.io/">codepen</a></li><li><a href="https://codesandbox.io/">codesandbox</a></li><li><a href="https://jsfiddle.net/">jsfiddle</a></li><li><a href="https://caniuse.com/">caniuse</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 开源软件 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>最大余额法-解决计算占比不等于100的问题</title>
      <link href="/blog/2024/08/18/20240818-%E6%9C%80%E5%A4%A7%E4%BD%99%E9%A2%9D%E6%B3%95-%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E5%8D%A0%E6%AF%94%E4%B8%8D%E7%AD%89%E4%BA%8E100%E7%9A%84%E9%97%AE%E9%A2%98/"/>
      <url>/blog/2024/08/18/20240818-%E6%9C%80%E5%A4%A7%E4%BD%99%E9%A2%9D%E6%B3%95-%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E5%8D%A0%E6%AF%94%E4%B8%8D%E7%AD%89%E4%BA%8E100%E7%9A%84%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在使用 <a href="https://echarts.apache.org/en/index.html">Echarts</a> 可视化数据的时候，往往饼图中每块占比加和不等于100%，所以就有了最大余额法。下面是最大余额法的简介：</p><blockquote><p><strong>最大余额方法</strong>（英语：largest remainder method）又称<strong>数额制</strong>、<strong>汉弥尔顿法</strong>（英语：Hamilton method），是比例代表制投票制度下，一种议席分配的方法，相对于最高均数方法。</p><p>这个方法要求候选人透过名单形式参选。每个名单上的候选人数不能超过该选区的议席数。候选人在名单上是有排名顺序的。选民投票时，是投给整个名单，而不是单个候选人。</p><p>投票结束后，会用一个特定的“数额”（见下）去除所有有效票数。每个名单如果得票数达到这个数额的整数倍，就可以获得相应数量的议席。名单上的候选人按照名单上的排名顺序获得议席。</p><p>如果还有剩余的议席没分配完，就会看每个名单超过上一轮数额整数倍的票数（即“余额”）。这些剩余议席会根据各名单的余额大小顺序分配，所以这种方法叫做“最大余额法”。</p><p><a href="https://www.cnblogs.com/CoderSilence/p/16775866.html">https://www.cnblogs.com/CoderSilence/p/16775866.html</a></p></blockquote><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.github.problem;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 最大余额法</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span> shenjunyu</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LargestRemainderMethod</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">int</span>[] arr = &#123;<span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>, <span class="number">88</span>&#125;;</span><br><span class="line">        System.out.println(Arrays.toString(getPercentValue(arr, <span class="number">2</span>)));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 最大余额法，用于解决百分比不足100%或者超过100%的问题</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> arr</span></span><br><span class="line"><span class="comment">     *            数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> idx</span></span><br><span class="line"><span class="comment">     *            索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> precision</span></span><br><span class="line"><span class="comment">     *            精度</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 每一次计算的结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">double</span> <span class="title function_">getPercentValue</span><span class="params">(<span class="type">int</span>[] arr, <span class="type">int</span> idx, <span class="type">int</span> precision)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> ((arr.length - <span class="number">1</span>) &lt; idx) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 求和</span></span><br><span class="line">        <span class="type">double</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j : arr) &#123;</span><br><span class="line">            sum += j;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (sum == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 10的2次幂是100，用于计算精度。</span></span><br><span class="line">        <span class="type">double</span> <span class="variable">digits</span> <span class="operator">=</span> Math.pow(<span class="number">10</span>, precision);</span><br><span class="line">        <span class="comment">// 扩大比例100</span></span><br><span class="line">        <span class="type">double</span>[] votesPerQuota = <span class="keyword">new</span> <span class="title class_">double</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">            <span class="type">double</span> <span class="variable">val</span> <span class="operator">=</span> arr[i] / sum * digits * <span class="number">100</span>;</span><br><span class="line">            votesPerQuota[i] = val;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 总数,扩大比例意味的总数要扩大</span></span><br><span class="line">        <span class="type">double</span> <span class="variable">targetSeats</span> <span class="operator">=</span> digits * <span class="number">100</span>;</span><br><span class="line">        <span class="comment">// 再向下取值，组成数组</span></span><br><span class="line">        <span class="type">double</span>[] seats = <span class="keyword">new</span> <span class="title class_">double</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; votesPerQuota.length; i++) &#123;</span><br><span class="line">            seats[i] = Math.floor(votesPerQuota[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 再新计算合计，用于判断与总数量是否相同,相同则占比会100%</span></span><br><span class="line">        <span class="type">double</span> <span class="variable">currentSum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">double</span> seat : seats) &#123;</span><br><span class="line">            currentSum += seat;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 余数部分的数组:原先数组减去向下取值的数组,得到余数部分的数组</span></span><br><span class="line">        <span class="type">double</span>[] remainder = <span class="keyword">new</span> <span class="title class_">double</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; seats.length; i++) &#123;</span><br><span class="line">            remainder[i] = votesPerQuota[i] - seats[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (currentSum &lt; targetSeats) &#123;</span><br><span class="line">            <span class="type">double</span> <span class="variable">max</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> <span class="variable">maxId</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; remainder.length; ++i) &#123;</span><br><span class="line">                <span class="keyword">if</span> (remainder[i] &gt; max) &#123;</span><br><span class="line">                    max = remainder[i];</span><br><span class="line">                    maxId = i;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 对最大项余额加1</span></span><br><span class="line">            ++seats[maxId];</span><br><span class="line">            <span class="comment">// 已经增加最大余数加1,则下次判断就可以不需要再判断这个余额数。</span></span><br><span class="line">            remainder[maxId] = <span class="number">0</span>;</span><br><span class="line">            <span class="comment">// 总的也要加1,为了判断是否总数是否相同,跳出循环。</span></span><br><span class="line">            ++currentSum;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 这时候的seats就会总数占比会100%</span></span><br><span class="line">        <span class="keyword">return</span> seats[idx] / digits;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 最大余额法，用于解决百分比不足100%或者超过100%的问题</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> arr</span></span><br><span class="line"><span class="comment">     *            数组</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> precision</span></span><br><span class="line"><span class="comment">     *            精度</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 按照数组顺序排列的百分比</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="type">double</span>[] getPercentValue(<span class="type">int</span>[] arr, <span class="type">int</span> precision) &#123;</span><br><span class="line">        <span class="type">double</span>[] result = <span class="keyword">new</span> <span class="title class_">double</span>[arr.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; arr.length; i++) &#123;</span><br><span class="line">            result[i] = getPercentValue(arr, i, precision);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[0.85, 3.42, 5.13, 6.84, 8.55, 75.21]</span><br></pre></td></tr></table></figure><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 错误笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>惨痛的教训</title>
      <link href="/blog/2024/08/17/20240817-%E6%83%A8%E7%97%9B%E7%9A%84%E6%95%99%E8%AE%AD/"/>
      <url>/blog/2024/08/17/20240817-%E6%83%A8%E7%97%9B%E7%9A%84%E6%95%99%E8%AE%AD/</url>
      
        <content type="html"><![CDATA[<blockquote><p>原文链接：<a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a></p></blockquote><p>The Bitter Lesson<br>Rich Sutton<br>March 13, 2019<br>The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin. The ultimate reason for this is Moore’s law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation. These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other. There are psychological commitments to investment in one approach or the other. And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation.  There were many examples of AI researchers’ belated learning of this bitter lesson, and it is instructive to review some of the most prominent.</p><p>In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that ``brute force” search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not.</p><p>A similar pattern of research progress was seen in computer Go, only delayed by a further 20 years. Enormous initial efforts went into avoiding search by taking advantage of human knowledge, or of the special features of the game, but all those efforts proved irrelevant, or worse, once search was applied effectively at scale. Also important was the use of learning by self play to learn a value function (as it was in many other games and even in chess, although learning did not play a big role in the 1997 program that first beat a world champion). Learning by self play, and learning in general, is like search in that it enables massive computation to be brought to bear. Search and learning are the two most important classes of techniques for utilizing massive amounts of computation in AI research. In computer Go, as in computer chess, researchers’ initial effort was directed towards utilizing human understanding (so that less search was needed) and only much later was much greater success had by embracing search and learning.</p><p>In speech recognition, there was an early competition, sponsored by DARPA, in the 1970s. Entrants included a host of special methods that took advantage of human knowledge—knowledge of words, of phonemes, of the human vocal tract, etc. On the other side were newer methods that were more statistical in nature and did much more computation, based on hidden Markov models (HMMs). Again, the statistical methods won out over the human-knowledge-based methods. This led to a major change in all of natural language processing, gradually over decades, where statistics and computation came to dominate the field. The recent rise of deep learning in speech recognition is the most recent step in this consistent direction. Deep learning methods rely even less on human knowledge, and use even more computation, together with learning on huge training sets, to produce dramatically better speech recognition systems. As in the games, researchers always tried to make systems that worked the way the researchers thought their own minds worked—they tried to put that knowledge in their systems—but it proved ultimately counterproductive, and a colossal waste of researcher’s time, when, through Moore’s law, massive computation became available and a means was found to put it to good use.</p><p>In computer vision, there has been a similar pattern. Early methods conceived of vision as searching for edges, or generalized cylinders, or in terms of SIFT features. But today all this is discarded. Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better.</p><p>This is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach.</p><p>One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.</p><p>The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done.</p><p>惨痛的教训<br>里奇·萨顿<br>2019年3月13日<br>70年的AI研究中最关键的教训在于，利用计算力的通用方法最终是最有效的，而且优势巨大。最终的原因在于摩尔定律，或者更确切地说，是计算单位成本持续呈指数级下降这一概括。大多数AI研究以代理可用的计算力恒定为前提开展（在这种情况下，利用人类知识将成为提高性能的唯一途径之一），但随着时间的推移，略长于一个典型的研究项目，计算力将不可避免地大幅提升。为了寻求能在短期内产生差异的改进，研究人员会寻求利用其对领域的专业知识，但从长远来看，唯一重要的事情便是利用计算力。这两者无需互相抵触，但在实践中，它们往往会如此。花在一个方面的时间就不是花在另一个方面的时间。对一种方法或另一种方法的投资都有心理上的承诺。而基于人类知识的方法往往会以一种让它们不太适合利用通用计算方法的方式使方法复杂化。AI研究人员迟迟才吸取这一惨痛教训的例子很多，回顾其中一些最突出的例子很有教育意义。</p><p>在电脑象棋中，1997年击败世界冠军卡斯帕罗夫的方法基于大规模、深入的搜索。当时，大多数寻求利用人类对象棋特殊结构的理解的方法的电脑象棋研究人员对此感到沮丧。当一种基于搜索的更简单方法与特殊硬件和软件被证明更有效时，这些基于人类知识的象棋研究人员并不是好的失败者。他们说，“蛮力”搜索这一次可能赢了，但这不是一种通用策略，无论如何，这不是人类下象棋的方式。这些研究人员希望赢得胜利的方法是基于人类输入的，当他们没有做到时，他们感到失望。</p><p>在电脑围棋中可以看到类似的研究进展模式，只不过推迟了20年。最初的巨大努力都花在利用人类知识，或围棋的特殊功能来避免搜索上面，但是一旦能够大规模有效地应用搜索，所有这些努力都证明与问题无关，甚至更糟。同样重要的是利用自我博弈学习来获取值函数（这在许多其他游戏中甚至在象棋中都是如此，即使学习并未在1997年首次击败世界冠军的程序中发挥重要作用）。通过自我博弈学习和学习通常就像搜索一样，它使得大量的计算得以应用。搜索和学习是AI研究中利用大量计算最重要的两类技术。在电脑围棋中，与电脑象棋一样，研究人员最初的努力是利用人类理解（这样所需的搜索就更少），而只有在很久以后，通过采用搜索和学习才取得了更大的成功。</p><p>在语音识别方面，DARPA在20世纪70年代发起了早期竞赛。参赛者包括大量利用人类知识的特殊方法—关于单词、音素、人类声道等的知识。另一方面是本质上更具统计学性质且执行更多计算的新方法，这些方法基于隐马尔可夫模型（HMM）。同样，统计学方法胜过了基于人类知识的方法。这导致所有自然语言处理发生了重大变化，在几十年间，统计学和计算逐渐主导了这一领域。深度学习在语音识别中的兴起是这一持续方向上最近的一步。深度学习方法对人类知识的依赖更少，并结合在大量训练集上进行学习，使用更多计算，以生成大大改善的语音识别系统。与游戏中一样，研究人员总是试图创建按照研究人员认为自己大脑工作的方式工作的系统—他们试图将这种知识纳入自己的系统—但最终证明适得其反，并且浪费了研究员大量时间，而通过摩尔定律，大量的计算已经可用，并且找到了将它们用作有用的方法。</p><p>在计算机视觉中，出现了类似的模式。早期的计算机视觉方法将其视为搜索边缘，或广义圆柱体，或根据SIFT特征。但如今，所有这些都被抛弃了。现代深度学习神经网络仅使用卷积和某些种类的不变性的概念来执行更好的性能。</p><p>这是一个重要的教训。作为一个领域，我们仍然没有透彻地学习到这一点，因为我们正在继续犯同样的错误。为了看到这一点并有效抵制它，我们必须理解这些错误的吸引力。我们必须吸取这样的惨痛教训：从长远来看，建立在我们认为自己思考的方式上是行不通的。这一惨痛教训基于以下历史观察：1) AI研究人员经常试图将知识构建到其代理中，2) 从短期来看，这总是会有所帮助，并且会让研究人员在个人上得到满足，但3) 从长远来看，它会达到平台期，甚至会阻碍进一步的进展，4) 最终的突破进展最终来自通过搜索和学习来扩展计算的基础方法。最终的成功带着些许苦涩，并且常常无法完全消化，因为它是对一种偏好的以人为中心的方法的成功。</p><p>从这一惨痛教训中应该吸取的一件事是通用方法的巨大力量，即使在可用计算量变得非常大的情况下，通用方法仍能继续随着计算的增加而扩展。似乎以这种方式任意扩展的两种方法是搜索和学习。</p><p>从这一惨痛教训中学到的第二个一般性观点是，心灵的实际内容极其、无可救药地复杂；我们应该停止试图找到思考大脑内容的简单方法，比如思考空间、物体、多重代理或对称性的简单方法。所有这些都是任意、内在复杂的外部世界的一部分。它们不应该是内置的，因为它们的复杂性是无穷的；相反，我们应该只内置能够找到并捕捉这种任意复杂性的元方法。对于这些方法至关重要的是，它们能找到很好的近似值，但对它们的搜索应该通过我们的方法，而不是通过我们。我们想要的是像我们一样可以发现的AI代理，而不是包含我们发现内容的AI代理。构建我们的发现只会让我们更难看到发现过程是如何完成的。</p><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 经典文章 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux服务器上定位哪行代码导致CPU飙高</title>
      <link href="/blog/2024/05/09/20240509-Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%AE%9A%E4%BD%8D%E5%93%AA%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%AF%BC%E8%87%B4CPU%E9%A3%99%E9%AB%98/"/>
      <url>/blog/2024/05/09/20240509-Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%AE%9A%E4%BD%8D%E5%93%AA%E8%A1%8C%E4%BB%A3%E7%A0%81%E5%AF%BC%E8%87%B4CPU%E9%A3%99%E9%AB%98/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Linux 服务器上的 Java 程序 CPU 持续飙高，如何排查？</p></blockquote><h3 id="第一步-首先使用-top-命令查看所有进程-top"><a href="#第一步-首先使用-top-命令查看所有进程-top" class="headerlink" title="第一步 首先使用 top 命令查看所有进程 top"></a>第一步 首先使用 top 命令查看所有进程 <code>top</code></h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top</span><br></pre></td></tr></table></figure><h3 id="第二步-定位Java进程中-CPU-最高的线程"><a href="#第二步-定位Java进程中-CPU-最高的线程" class="headerlink" title="第二步 定位Java进程中 CPU 最高的线程"></a>第二步 定位Java进程中 CPU 最高的线程</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top -Hp pid</span><br></pre></td></tr></table></figure><blockquote><p>获取线程id</p></blockquote><h3 id="第三步-将线程ID转换成十六进制"><a href="#第三步-将线程ID转换成十六进制" class="headerlink" title="第三步 将线程ID转换成十六进制"></a>第三步 将线程ID转换成十六进制</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">printf</span> <span class="string">&quot;0x%x&quot;</span> &#123;上一步中获取的线程<span class="built_in">id</span>&#125;</span><br></pre></td></tr></table></figure><h3 id="第四步-使用-jstack-工具跟踪堆栈定位代码"><a href="#第四步-使用-jstack-工具跟踪堆栈定位代码" class="headerlink" title="第四步 使用 jstack 工具跟踪堆栈定位代码"></a>第四步 使用 <code>jstack</code> 工具跟踪堆栈定位代码</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jstack &#123;pid&#125; | grep &#123;第三步中获取到的线程<span class="built_in">id</span>的十六进制表示&#125; -A 5</span><br></pre></td></tr></table></figure><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 问题排查 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AI Agent</title>
      <link href="/blog/2024/04/25/20240425-AI%20Agent/"/>
      <url>/blog/2024/04/25/20240425-AI%20Agent/</url>
      
        <content type="html"><![CDATA[<blockquote><p><code>Agent</code> 的未来,人工智能即将彻底改变您使用计算机的方式,并颠覆整个软件行业</p></blockquote><p>如今，我和保罗·艾伦创立微软时一样，仍然深爱着软件。但是，尽管软件在此后的数十年里已取得了很大改善，但在很多方面，软件仍然相当愚笨。</p><p>若要在计算机上执行任何任务，您必须告诉设备使用哪个应用程序。您可以使用 Microsoft Word 和 Google Docs 起草商务提案，但它们无法帮助您发送电子邮件、分享自拍、分析数据、安排聚会或购买电影票。即使是最好的网站，也无法完全了解您的工作、个人生活、兴趣和关系，以及使用此信息为您做事的能力有限。这是如今只有其他人才能做到的，例如亲密的朋友或个人助理。</p><p>在未来五年内，这种情况将发生彻底改变。您不必为不同的任务使用不同的应用。您只需用日常语言告诉设备您想要做什么即可。根据您选择与之共享的信息量，该软件将能够做出个性化响应，因为它会深入了解您的生活。在不久的将来，任何在线人士都将拥有由远超现今技术水平的人工智能驱动的个人助理。</p><p>这种软件 - 能够对自然语言做出反应并基于其对用户的了解来完成许多不同任务的软件 - 称为 <code>Agent</code>。我几乎已经思考了 <code>Agent</code> 将近 30 年，并在我的 1995 年的著作《<strong>未来之路</strong>》中写到了它们，但由于人工智能的进步，它们最近才变得实用。</p><blockquote><p><a href="https://www.gatesnotes.com/The-Road-Ahead-after-25-years">https://www.gatesnotes.com/The-Road-Ahead-after-25-years</a></p></blockquote><p><code>Agent</code> 不仅将改变每个人与计算机的交互方式。它们还将颠覆软件行业，带来自我们从输入命令转为点击图标以来的计算机领域最伟大的革命。</p><h3 id="每个人都可以使用的个人助理"><a href="#每个人都可以使用的个人助理" class="headerlink" title="每个人都可以使用的个人助理"></a>每个人都可以使用的个人助理</h3><p>一些批评者指出，软件公司之前提供过此类产品，但用户并未完全接受它们。（人们仍然拿我们添加到 Microsoft Office 中并在随后弃用的数字助理 <strong>Clippy</strong> 开玩笑。）为什么人们会使用 <code>Agent</code> ？</p><blockquote><p><a href="https://edition.cnn.com/2021/07/15/tech/microsoft-clippy-emoji/index.html">https://edition.cnn.com/2021/07/15/tech/microsoft-clippy-emoji/index.html</a></p></blockquote><p>答案是它们会大幅改善。您将能够与它们进行细致入微的对话。它们将更加个性化，并且不会局限于写信等相对简单的任务。Clippy 与 <code>Agent</code> 之间的共同点与转盘电话与移动设备之间的共同点一样多。</p><p>如果您需要，<code>Agent</code> 将能够帮助您完成所有活动。获准跟踪您的在线互动和真实位置后，它将对您从事的人员、地点和活动形成强大的理解。它会了解您的个人关系、工作关系、爱好、偏好和日程。您可以选择它何时以何种方式介入提供帮助或要求您做出决定。</p><blockquote><p>“Clippy 是个机器人，不是个 agent。”</p></blockquote><p>要了解 <code>agent</code> 将带来的巨大改变，我们不妨将它们与当今可用的 AI 工具进行比较。其中大部分是机器人。它们的局限性只局限于一个应用，通常只有当你输入某个特定的词语或寻求帮助时才会介入。由于它们不记得你上次如何使用它们，因此它们不会变得更好或学习你的任何偏好。Clippy 是一个机器人而不是一个 <code>agent</code>。</p><p><code>agent</code> 更聪明。它们是主动的，可以在在你要求之前就提出建议。它们跨应用完成任务。由于它们会记住你的活动并在你的行为中识别意图和模式，因此它们会随着时间的推移而改进。基于这些信息，它们会提供它们认为你需要的东西，但你始终做出最终的决定。</p><p>想象一下，你想计划一次旅行。一个旅行机器人将识别符合你预算的酒店。一个 <code>agent</code> 会知道你的旅行时间，并且根据它对你是否总是尝试新目的地或喜欢反复返回同一位置的了解，它将能够提出建议的地点。当被问及时，它会根据你的兴趣和冒险倾向为你推荐一些活动，并且它会在你喜欢的餐厅类型中预订座位。如果你想要这种深度个性化的计划，你现在需要付费给一个旅行社并花时间告诉他们你的需求。</p><p>AI <code>agent</code> 最令人兴奋的影响在于它们将使当今对大多数人来说过于昂贵的服务变得大众化。它们将在四个领域产生特别大的影响：医疗保健、教育、生产力以及娱乐和购物。</p><h3 id="医疗保健"><a href="#医疗保健" class="headerlink" title="医疗保健"></a>医疗保健</h3><p>如今，人工智能在医疗保健领域的主要作用是帮助处理管理任务。例如， Abridge、Nuance DAX 和 Nabla Copilot 可以在医生问诊时捕捉音频，然后写成备忘，以便医生审阅。</p><blockquote><p><a href="https://www.abridge.com/">https://www.abridge.com/</a>, 加深对医疗保健的理解,最值得信赖的临床对话人工智能平台 - 直接集成在 Epic 内。</p></blockquote><blockquote><p><a href="https://www.nuance.com/healthcare/dragon-ai-clinical-solutions/dax-copilot/explore-dax-for-clinicians">https://www.nuance.com/healthcare/dragon-ai-clinical-solutions/dax-copilot/explore-dax-for-clinicians</a>.</p></blockquote><blockquote><p><a href="https://www.nabla.com/">https://www.nabla.com/</a>, Nabla 是领先的环境人工智能助手，可减少医生的倦怠并改善患者护理。</p></blockquote><p>真正的转变会出现在 <code>agent</code> 能够帮助患者进行基础分类、获取有关如何处理健康问题的建议以及决定是否需要寻求治疗之时。这些 <code>agent</code> 还可以帮助医护人员做出决策并提高工作效率。（Glass Health 等应用程序已经可以分析患者总结，并提出医生可考虑的诊断建议。）帮助患者和医护人员将对贫困国家的人们特别有利，在这些国家许多人根本无法看医生。</p><blockquote><p><a href="https://glass.health/">https://glass.health/</a>, AI 驱动临床决策支持, 我们利用 AI 平台为临床医生提供帮助，以开发鉴别诊断和起草临床计划。</p></blockquote><p>这些临床 <code>agent</code> 的推出将比其他 <code>agent</code> 慢，因为正确处理事情关乎生死。人们需要看到证据证明健康 <code>agent</code> 总体上有益，即使它们并不完美，会犯错。当然，人类也会犯错，而无法获得医疗保健也是一个问题。</p><blockquote><p>“所有需要心理健康的美国军人中，有一半都没有得到。”</p></blockquote><p>心理健康护理是 <code>agent</code> 将向几乎每个人提供服务的另一个示例。如今，每周的治疗课程似乎是一种奢侈。但有大量未得到满足的需求，以及许多本来可以从治疗中受益的人无法获得治疗。例如，兰德公司发现，所有需要心理健康护理的美国军人中，有一半没有得到治疗。</p><blockquote><p><a href="https://www.rand.org/health-care/projects/navigating-mental-health-care-for-veterans/barriers-to-care.html">https://www.rand.org/health-care/projects/navigating-mental-health-care-for-veterans/barriers-to-care.html</a></p></blockquote><p>接受过心理健康方面良好训练的 AI  <code>agent</code> 将使治疗变得更加经济实惠且更容易获得。Wysa 和 Youper 是这里较早出现的两个聊天机器人。但 <code>agent</code> 将更加深入。如果你选择与心理健康 <code>agent</code> 分享足够的信息，它将了解你的生活史和你的关系。它会在你需要时随时可用，而且它永远不会变得不耐烦。甚至，在征得你的允许后，它还可以通过智能手表监控你对治疗的身体反应——比如当你谈论与老板之间的问题时，你的心跳开始加速——并建议你何时去看人类治疗师。</p><blockquote><p><a href="https://www.wysa.com/">https://www.wysa.com/</a>, Wysa 经过临床验证的人工智能可在护理的第一步提供即时支持，并为需要更多服务的人提供人工指导。改变您的团队和家庭的支持感受。</p></blockquote><blockquote><p><a href="https://www.youper.ai/">https://www.youper.ai/</a>, 用于心理保健的富有同理心、安全且经过临床验证的聊天机器人。Youper 安全且经过临床验证的人工智能已经为超过 200 万人的心理健康提供了支持。</p></blockquote><h3 id="教育"><a href="#教育" class="headerlink" title="教育"></a>教育</h3><p>几十年来，我对软件在让老师的工作变得更容易和帮助学生学习方面的所有方式感到兴奋。它不会取代老师，但它会补充他们的工作——为学生个性化工作，并让老师从文书工作和其他任务中解脱出来，以便他们可以在工作中最重要的部分投入更多时间。这些变化终于开始以一种戏剧性的方式发生了。</p><p>现阶段最先进的是 Khanmigo，这是一个由可汗学院创建的基于文本的机器。它可以辅导学生学习数学、科学和人文科学——例如，它可以解释二次公式并创建数学问题以便练习。它还可以帮助老师做一些事情，例如编写课程计划。我一直是 Sal Khan 工作的粉丝和支持者，最近让他参加了我的播客来谈论教育和人工智能。</p><blockquote><p><a href="https://www.khanacademy.org/khan-labs">https://www.khanacademy.org/khan-labs</a></p></blockquote><p>但是，基于文本的机器只是第一波浪潮——智能体将开启更多学习机会。</p><p>例如，很少有家庭可以支付一位与学生一对一工作、补充他们课堂工作的家教。如果智能体能够捕捉到使一位家教有效的原因，那么他们将为每个人解锁这种补充性指导。如果一位家教智能体知道一个孩子喜欢 Minecraft 和泰勒·斯威夫特，它将用 Minecraft 教导他们如何计算形状的体积和面积，并用泰勒的歌词教导他们有关讲故事和押韵规则。这种体验将更加丰富——例如，带有图像和声音——并且比今天的基于文本的家教更个性化。</p><h3 id="生产力"><a href="#生产力" class="headerlink" title="生产力"></a>生产力</h3><p>这个领域已经有很多竞争了。微软正在将其 Copilot 纳入 Word、Excel、Outlook 和其他服务中。谷歌正在使用采用 Bard(现在的Gemini) 及其生产力工具的助理来做类似的事情。这些副驾驶可以做很多事情——比如将书面文档变成幻灯片组，使用自然语言回答有关电子表格的问题，以及总结电子邮件线程，同时代表每个人的观点。</p><p> <code>agent</code> 将做得更多。拥有一个 <code>agent</code> 就像有一个专门帮助你完成各种任务的人，并且如果你愿意，他们可以独立完成任务。如果你有一个商业想法， <code>agent</code> 将帮助你写一份商业计划，为其创建一个演示文稿，甚至生成你的产品可能是什么样子的图像。公司将能够让 <code>agent</code> 随时供其员工咨询，并参加每次会议，以便他们可以回答问题。</p><blockquote><p>“如果你的朋友刚做完手术，你的客服将会提供送花选项，并可以为你订花。”</p></blockquote><p>无论您是否在办公室工作，您的 <code>agent</code> 将能够以如今的个人助理支持高管的方式帮助您。如果您的朋友刚接受完手术，您的 <code>agent</code> 会主动提出送花，并能为您订花。如果您告诉它您想与您旧的大学室友叙旧，它将会与室友的 <code>agent</code> 安排相聚时间，并且就在您到达之前，它会提醒您室友最年长的孩子刚进入当地大学读大学。</p><h3 id="娱乐及购物"><a href="#娱乐及购物" class="headerlink" title="娱乐及购物"></a>娱乐及购物</h3><p>人工智能现在可以帮助您挑选新电视并推荐电影、书籍、节目和播客。Likewise，我投资的一家公司最近推出了 Pix，它允许您提问（“我喜欢哪些罗伯特·雷德福的电影，我可以在哪里观看？”），然后根据您过去喜欢的内容进行推荐。Spotify 拥有一位人工智能 DJ，它不仅会根据您的偏好播放歌曲，还会与您交谈，甚至可以叫您名字。</p><blockquote><p><a href="https://likewise.com/">https://likewise.com/</a></p></blockquote><blockquote><p><a href="https://newsroom.spotify.com/2023-02-22/spotify-debuts-a-new-ai-dj-right-in-your-pocket/">https://newsroom.spotify.com/2023-02-22/spotify-debuts-a-new-ai-dj-right-in-your-pocket/</a></p></blockquote><p> <code>agent</code> 不会仅仅进行推荐；他们还会帮助您对推荐采取行动。如果您想购买相机，您的 <code>agent</code> 会为您阅读所有评论，总结它们，提出建议，并在您做出决定后为您下单。如果您告诉您的 <code>agent</code> 您想观看《星球大战》，它会知道您是否订阅了正确的流媒体服务，如果没有，它会主动为您注册。如果您不知道自己想看什么，它会提出定制建议，然后找出如何播放您选择的电影或节目。</p><p>您还可以获得根据您的兴趣量身定制的新闻和娱乐信息。CurioAI 可以针对您询问的任何主题创建一个定制播客，它展示了未来发展趋势。</p><blockquote><p><a href="https://curio.io/home">https://curio.io/home</a>, 最好的新闻报道，旁白，跟上世界的步伐，不受屏幕影响。聆听来自 30 多家世界领先出版物的精选文章，以及原创节目和播客。</p></blockquote><h3 id="科技行业的冲击波"><a href="#科技行业的冲击波" class="headerlink" title="科技行业的冲击波"></a>科技行业的冲击波</h3><p>简而言之， <code>agent</code> 将能够帮助处理几乎任何一项活动和人生的任何一个领域。这将对软件业务和社会带来深远的影响。</p><p>在计算机产业中，我们谈论的是平台——构建应用和服务的技术。Android、iOS 和 Windows 均为平台。 <code>agent</code> 将成为下一个平台。</p><blockquote><p>“为了创建一个新应用或服务，你只需告诉你的 <code>agent</code> 你要什么。”</p></blockquote><p>开发新的应用程序或服务时无需了解如何编写代码或进行图形设计。你只需告诉你的 <code>agent</code> 你需要什么。它可以编写代码、设计应用程序的外观和感觉、创建徽标以及将应用程序发布到在线商店。 OpenAI 本周发布的 GTP 为非开发人员容易创建和分享自己的助手提供了未来见解。</p><p> <code>agent</code> 将影响我们使用软件以及编写软件的方式。它们将取代搜索网站，因为它们更擅长查找信息并为你总结信息。它们将取代许多电子商务网站，因为它们可以找到最优惠的价格，并且不会仅限于少数供应商。它们将取代文字处理器、电子表格和其他生产力应用程序。当今相互独立的企业——搜索广告、带广告的社交网络、购物、生产力软件——将成为一项业务。</p><p>我认为没有任何一家公司能够主导 <code>agent</code> 业务——将会有许多不同的 AI 引擎可用。如今， <code>agent</code> 嵌入在文字处理器和电子表格等其他软件中，但最终它们将独立运行。虽然一些 <code>agent</code> 可以免费使用（并受广告支持），但我认为你将为大多数 <code>agent</code> 付费，这意味着公司将有动力让 <code>agent</code> 为你工作，而不是为广告客户工作。如果仅今年开始从事人工智能工作的公司数量有任何迹象，那么竞争将异常激烈，这将使 <code>agent</code> 变得非常廉价。</p><p>但在上面描述的复杂 <code>agent</code> 成为现实之前，我们需要解决许多有关该技术及其使用方法的问题。之前我曾撰写过有关 AI 引发的问题的文章，因此我将在此专门关注 <code>agent</code> 。</p><h3 id="技术难题"><a href="#技术难题" class="headerlink" title="技术难题"></a>技术难题</h3><p>目前还没有人弄清楚 <code>agent</code> 的数据结构会是什么样子。要创建个人 <code>agent</code> ，我们需要一种新型数据库，可以捕捉到您所有的兴趣和关系的细微差别，并且可以在维护您隐私的同时快速召回信息。我们已经看到了一些存储信息的新方法，例如向量数据库，对于存储机器学习模型生成的数据来说，这些方法可能更好。</p><p>另一个悬而未决的问题是人们将与多少个 <code>agent</code> 进行互动。您的个人 <code>agent</code> 会与您的治疗师 <code>agent</code> 和您的数学老师分开吗？如果是这样，您希望他们在何时合作，在何时各司其职？</p><blockquote><p>“如果您的 <code>agent</code> 需要与您确认，它会和您通话或出现在您的手机上。”</p></blockquote><p>如何与你的 <code>agent</code> 互动？公司正在探索多种选择，包括应用程序、眼镜、吊坠、胸针，甚至是全息图。所有这些都是有可能的，但我认为人机交互领域的第一个重大突破将是耳塞。如果你的 <code>agent</code> 需要与你联系，它会与你通话或显示在你的手机上。（“你的航班延误了。你要等一等，还是我可以帮你重新预订？”）如果你愿意，它将监测进入你耳朵的声音，并通过屏蔽背景噪音、放大难以听清的语音，或使听懂口音较重的人的讲话更轻松来增强它。</p><p>其他挑战也有。目前还没有允许 <code>agent</code> 相互对话的标准协议。成本需要降低，这样每个人都能负担得起 <code>agent</code> 。以一种能给你正确答案的方式提示 <code>agent</code> 需要变得更容易。我们需要防止出现幻觉，特别是在健康等准确性非常重要的领域，并确保 <code>agent</code> 不会因其偏见而伤害他人。并且我们不希望 <code>agent</code> 能够做他们不应该做的事情。（尽管我更担心的是人类罪犯出于恶意目的使用 <code>agent</code> ，而不是流氓 <code>agent</code> 。）</p><h3 id="隐私和其他重大问题"><a href="#隐私和其他重大问题" class="headerlink" title="隐私和其他重大问题"></a>隐私和其他重大问题</h3><p>随着这一切的发展，在线隐私和安全问题将变得比现在更加紧迫。您希望能够决定 <code>agent</code> 可以访问哪些信息，这样您就可以确信您的数据仅与您选择的人和公司共享。</p><p>但是，您与 <code>agent</code> 共享的数据归谁所有，您如何确保它被适当地使用？没有人愿意开始看到与他们告诉他们的治疗师 <code>agent</code> 有关的广告。执法部门可以使用你的 <code>agent</code> 作为对你 不利的证据吗？你的 <code>agent</code> 什么时候会拒绝做一些可能对你或其他人有害的事情？谁来选择内置在 <code>agent</code> 中的价值观？</p><p>还有个问题是您的 <code>agent</code> 应该共享多少信息。假设你想见一个朋友：如果你的 <code>agent</code> 与他们的 <code>agent</code> 交谈，你不想让它说，“哦，她周二会见其他朋友，不想带上你。”而且，如果您的 <code>agent</code> 帮助您编写工作电子邮件，它需要知道它不应使用有关您的个人信息或来自之前的工作的专有数据。</p><p>其中许多问题已经成为科技行业和立法者的首要任务。我最近与其他技术领导者一起参加了参议员查克·舒默组织并由许多美国参议员参加的关于人工智能的论坛。我们分享了有关这些和其他问题的想法，并谈到了立法者制定强有力的法律的必要性。</p><p>但其他问题不会由公司和政府决定。例如， <code>agent</code> 可能会影响我们与朋友和家人的互动方式。今天，您可以通过记住他们生活中的细节向某人展示您关心他们——比如他们的生日。但是，当他们知道您的 <code>agent</code> 可能会提醒您并负责送花时，这对他们来说会有意义吗？</p><p>在遥远的未来， <code>agent</code> 甚至可能迫使人类面对关于目的的深刻问题。想象一下， <code>agent</code> 变得如此出色，以至于每个人都可以拥有高质量的生活，而无需像以前那样多工作。在这样的未来，人们会用他们的时间做什么？当 <code>agent</code> 有了所有的答案后，还会有人愿意接受教育吗？当大多数人都拥有大量空闲时间时，你能拥有一个安全而繁荣的社会吗？</p><p>但我们还有很长的路要走。与此同时， <code>agent</code> 正在到来。在未来几年内，他们将彻底改变我们在线上和线下的生活方式。</p><h3 id="原文链接"><a href="#原文链接" class="headerlink" title="原文链接"></a>原文链接</h3><p>[1]<a href="https://www.gatesnotes.com/AI-agents">https://www.gatesnotes.com/AI-agents</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> AI Agent </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sam Altman的创业手册</title>
      <link href="/blog/2024/03/31/Sam%20Altman%E7%9A%84%E5%88%9B%E4%B8%9A%E6%89%8B%E5%86%8C/"/>
      <url>/blog/2024/03/31/Sam%20Altman%E7%9A%84%E5%88%9B%E4%B8%9A%E6%89%8B%E5%86%8C/</url>
      
        <content type="html"><![CDATA[<blockquote><p>中文版原文：<a href="https://jxp73q7qjsg.feishu.cn/docx/WCNZdKDa4o2eUrxK5ElcfBXEnah">https://jxp73q7qjsg.feishu.cn/docx/WCNZdKDa4o2eUrxK5ElcfBXEnah</a></p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在YC，我们花了很多时间给创始人们提供建议。尽管一对一的提出建议永远是最有效的，但是我们认为，如果我们能够把这些给YC系创始人们的建议里面最通用的一部分提炼出来变成一个创业手册，也许能够帮助我们扩大YC的规模。</p><p>随后我们发现，这本手册应该分享给所有人。这本手册是为新手创业者们准备的。对于很多已经熟知YC创业方法论的人来说，大部分内容都不会感到陌生。我们的目的是把这些建议集合起来。</p><p><strong>作为一家创业公司，你的目标是：做出用户们喜爱的产品</strong>。如果你做到了这一点，你就要开始搞明白<strong>怎么大量的获客</strong>。但是“做出用户们喜欢的产品”这一点是极其关键的，想想今天真正成功的公司，他们都是从一个备受早期用户喜欢的产品开始的。他们的早期用户是如此喜欢他们的产品，以至于会到处分享给其他人。</p><p>如果你无法做出用户们喜欢的产品，那么你会失败。如果你试图欺骗自己，假装你的用户喜欢你的产品，而实际上他们并不喜欢，那么你也会失败。</p><p>有非常非常多自认为可以跳过这一步的创业公司，但是他们都死了。</p><p>做一个少数用户真心热爱的产品，要比做一个很多用户有些喜欢的产品要好很多。虽然你获得的正面感受的总量可能是一致的，但是让人们从喜欢到爱上你的产品非常困难。而获取更多的用户则没那么难。</p><p>这里对于选择创业的创始人们有个警示：创业真的非常痛苦！我们从YC创始人们那里得到的最一致的反馈就是，创业比他们想象的要困难的多。因为他们没创业前对于创业公司所需要做的工作和强度是没有完整的概念的。通常情况来说，加入一个早期但是处于火箭般上升速度的创业公司，会是财务上好的多的选择。</p><p>另一方面，开启一个创业公司对你的职业生涯来说也没有那么大的风险。如果你真的很擅长技术，那么即使你失败了你也能找到工作。大多数人都没有那么擅长评估风险。<strong>我个人认为，比起创业，更有风险的选择是，当你有一个真正热爱的想法或者项目，但是你却停留在了一个安全，轻松，不尽如人意的工作中</strong>。</p><p>想要做个成功的创业公司，你需要：一个非常好的想法（包括非常大的市场），一个非常好的团队，一个非常好的产品，和非常好的执行。</p><h2 id="第一部分：想法"><a href="#第一部分：想法" class="headerlink" title="第一部分：想法"></a>第一部分：想法</h2><p>我们问YC系公司的第一个问题是，你们在创造什么？为什么？</p><p>我们想听到一个清晰，简洁的回答。</p><p>这个问题既是对于创始人的评估，也是对于创业想法本身的评估。<strong>作为一个创始人，能够清晰的思考和沟通是非常重要的</strong>：在<strong>招聘，融资，销售等各方面</strong>你都需要这个能力。并且通常来说，<strong>清晰的想法更容易传播，而复杂的想法几乎总是思维混乱或者假问题的标志。如果你的想法没有办法让至少一部分人在他们第一次听到的时候感到真正的兴奋，那么这是个很糟糕的事情</strong>。</p><p>另一个我们会问的问题：谁是最迫切渴望的需要这个产品的人？<br>最好的回答，你自己就是目标用户。第二好的回答，你极其理解你的目标用户。</p><p>如果一个公司已经有了用户，我们会问<strong>用户数量是多少</strong>，并且<strong>增长</strong>的速度有多快？我们会想弄清楚为什么用户数量没有增长的那么快。我们最想搞清楚的问题是，用户们是否真的热爱这款产品。通常来说热爱一个产品意味着用户们会自发的推荐这个产品给朋友们使用，不需要任何诱导。我们还会问公司是否产生了收入，如果没有，为什么？</p><p>如果公司还没有用户，我们会设法确定首先要构建的最小功能，以验证这个假设。也就是说，如果从理想的用户体验倒推，我们会努力找出应该从哪个关键点开始。</p><p><strong>测试一个想法的方法是，1.发布它并观察结果，2.尝试销售它</strong>（例如，在编写任何代码之前尝试获得一份意向购买合同）。前者更适用于To C类的想法（因为用户的口头调研可能是不诚实的），后者则更适用于To B类的想法（如果一家公司告诉您他们会购买某个产品，那就去开发这个产品）。</p><p>具体来说，如果您是一家To B公司，我们会问你的第一个问题是：你现在在开发的产品是否有来自客户的意向购买合同？</p><p>而对于大多数生物技术和硬科技公司来说，测试一个想法的方法是首先与潜在客户交流，然后找出你可以首先构建的技术子集中最小的部分。</p><p>当你获得了用户的反馈的时候，及时调整你的想法非常重要。深入的了解你的用户，是衡量你的想法，打造伟大的产品，做出伟大公司的至关重要的部分。</p><p>正如上文所说，做一家创业公司非常艰难。你需要非常长的时间，和持之以恒的高强度努力。创始人和员工们都需要有一种使命感去支撑他们。所以我们会问创始人，为什么会选择做这样一家公司。</p><p>我们还会问公司将如何在未来成为独占市场的垄断者。虽然有很多不同的说法，但我们使用的是彼得·泰尔的观点。当然，我们并不希望你的公司采取不道德的手段来对待竞争对手。相反，我们在寻找那些随着规模扩大而越来越强大并且难以模仿的企业。</p><p>最后，我们会问市场相关的问题。我们会询问市场目前的规模、增长速度以及为什么它在十年内会变得很大。我们努力了解市场为何会快速增长，以及为什么这对于初创公司来说是一个好市场。我们喜欢那些刚刚开始的重大技术变革，而大多数人尚未意识到这一点。——大公司在应对这样的情况时往往表现不佳。有点反直觉的是，最佳策略是在一个小市场中占据很大的份额。</p><p>一些其他关于想法的内容：</p><p>我们非常喜欢崭新的东西，而不是衍生出来的东西。大多数真正的巨型公司都是从一些根本性的新事物开始的。（新事物约等于比之前好十倍的东西）。如果同时有十家公司有相同的计划，并且要做的东西非常像一些已经存在的东西，我们会比较怀疑。</p><p>一个非常重要的反直觉的原因是，做全新的和困难的东西，要比做老的和容易的事情更简单。因为前者人们愿意帮助和加入你。后者不会。</p><p>最好的想法是那种，听起来很糟糕，但是实际上是很好的。因此，你不需要对你的想法过于保密。如果你的想法真的是个很好的主意，那么它听上去很可能并不值得抄袭。即使你的想法真的听上去很值得被抄袭，但是这个世界上愿意真正去付出很多努力将一个好想法打造成一个好公司的人是非常非常少的。相反，如果你告诉人们你正在做的事情，大家可能会提供帮助。</p><p>说到告诉人们你的想法。虽然好的想法需要让一部分人第一次听到时真的很激动。但是几乎所有的人都会告诉你，你的想法很糟糕。也许他们是对的。也许他们不擅长评估创业想法。也许他们仅仅是嫉妒。无论什么理由，这件事情都会经常发生。你当然会很受伤，即使你觉得你能接受，你依然会感到痛苦。你需要尽快的建立自信，无视黑子们的评价。不管你有多成功，黑子们永远都会有。</p><p>如果你还没有一个想法，但是你想创业该怎么办？我们的建议是也许不应该这么做。先有想法，再通过创业来实现你的想法是好得多的路径。</p><p>我们曾经做过一个实验，投资了一些非常优秀的，但是还没有想法的创始团队。我们希望他们在获得资金之后能够找到一个有前途的想法。</p><p>其中的每一家都失败了。我认为其中的一部分原因是因为，好的创始人通常都会有很多（甚至是过多）好的想法。但更大的问题是，一旦你有了一个创业公司，你就必须赶紧想出一个想法，而且因为这已经是一家正式的公司，所以你的想法不能太疯狂。你最终会得到一些听起来很合理但是缺乏创新的想法。这就是转型的危险所在。</p><p>所以，最好不要过于努力地强迫自己想出创业点子。相反，了解很多不同的事物。锻炼自己发现问题的能力，关注那些看似低效的事物和重大技术变革。投身于你感兴趣的项目。刻意与聪明、有趣的人为伍。在某个时刻，灵感就会涌现出来。</p><h2 id="第二部分：一个非常好的团队"><a href="#第二部分：一个非常好的团队" class="headerlink" title="第二部分：一个非常好的团队"></a>第二部分：一个非常好的团队</h2><p>平庸的团队不会建立伟大的公司。我们最看重的事情之一，就是创始人的能力。当我以前做一些比较靠后阶段的投资时，我会同样看重创始人所雇佣的员工们的能力。</p><p>什么是伟大的创始人？最重要的特质包括不可阻挡、决心、强悍和足智多谋。智力和热情也非常重要。这些特质比经验以及所谓的“语言X和框架Y的专业知识”要重要得多。</p><p>我们注意到，最成功的创始人通常是那些工作中容易相处、让人感到“无论面对什么情况都能完成任务”的人。有时候，凭借纯粹的意志力也可以取得成功。</p><p>好的创始人具备许多看似相互矛盾的特点，其中一个重要的特点是既要对公司核心以及使命的强烈信念，又要在其他方面非常灵活，愿意不断学习新的事物。</p><p>最好的创始人们会反应异常灵敏，这是一种反应了果断、专注、注意力和完成事情的能力的指标。那些很难沟通的创始人几乎都是糟糕的创业者。沟通是一种非常重要的创始人技能。说实话，我认为这是那些很少被提到的创业技能里，最重要的一个。</p><p>科技型创业公司，需要至少有一个创始人能够把产品和服务搭建出来，也需要至少一个创始人（或者通过学习可以成为）非常擅长销售和与用户交流的人。这两个人可以是一个人。</p><p>当你选择创业合伙人时，要考虑以下几点——这可是你最重要的决定之一，但通常人们都随随便便就做了。</p><p>你最好选一个你已经很熟悉的人，而不是在某个创业派对上刚认识的人。多了解一些信息，你才能更好地评估是否能和这个人合作，毕竟选错人可是要命的。另外，有时候创业公司的价值可能会暂时下降很多，这时如果你和合伙人创业之前已经很熟悉，你们不会轻易放弃，因为你们不想让对方失望，所以你们会一起克服困难。创业合伙人们闹掰是一个非常常见的的创业公司死亡的原因。并且我们经常看到这个事情发生在那些为了创业而相遇的合伙人身上。</p><p>最好的情况，是有一个很好的合伙人。第二好的情况是只有你一个人。最差的情况，是你有了一个不好的合伙人。如果事情不对，你们应该迅速分手。</p><p>关于股权的问题，要早日解决，因为随着时间推移，分配股权的讨论只会变得越来越复杂。最好尽早设定股权比例，近似平等是最好的，不过如果只有两个创始人，最好让其中一人多持有一点，以防万一在合伙人之间产生分歧时出现僵局。</p><h2 id="第三部分：一个非常好的产品"><a href="#第三部分：一个非常好的产品" class="headerlink" title="第三部分：一个非常好的产品"></a>第三部分：一个非常好的产品</h2><p>这里有一个成功的秘诀：拥有一个非常好的产品。这是所有伟大公司的唯一共同点。</p><p>如果你没有办法做出来一个让用户爱上的产品，你迟早会失败。虽然创始人们总想绕过这一点，但是创业是没有捷径的。</p><p>一个非常好的产品是长期来看唯一有效的增长方式。因为即使你用了一些别的增长手段，但是最终你会发现，随着你的体量变大，所有的其他手段都会失效，只有“人们真的想要用你的产品”不会失效。</p><p>这是理解那些超级成功的公司的最重要的事情。你可以想想，所有最成功的科技公司，他们都做到了这一点。</p><p>你需要在你的公司里搭建一个“产品改进引擎”。你应该和你的用户交谈，看着他们使用你的产品，找出哪些部分是需要改进的，从而让你的产品变得更好。重复去做这件事。这应该是你的公司里最重要的事情，并且由他来驱动所有别的事情。如果你真的能每周让你的产品变好5%，你会有巨大的复合增长。</p><p>这个循环越快，你的公司就会做的越好。在YC，我们会告诉创业者，他们应该打造产品并且和用户交谈，除此之外几乎没有什么别的事情了，当然别忘了吃饭，睡觉，锻炼，和爱的人相处。</p><p>你需要和你的用户离得非常近，来确保你的循环正确。一定要站在他们旁边盯着他们使用你的产品。记住他们说的话，和他们实际的操作。你不应该在你和用户之间放任何的人，你需要自己去做销售，客户支持，等等其他。</p><p>尽最大努力的去理解你的用户，尝试真正的找出他们需要的东西，他们在哪里，和是什么让他们真正心动。</p><p>“Do things that don’t scale”已经成为了创业公司们的口头禅。你需要一次次的去手动招募初始用户（Pinterest的创始人在咖啡馆里去请求陌生人使用他们的产品。），然后你需要去为他们创作他们想要的东西。许多创始人讨厌这个部分，想要通过媒体去发布他们的产品。但是这招基本永远不会有效。手动的招募用户，然后把这个产品做的非常好，这样你的用户们会分享给他们的朋友。</p><p>你也需要把事情分成非常小的部分，快速迭代和调整。不要尝试计划的太远，也绝对不要把所有的东西都集中到一个大的公共版本中。你需要从非常简单的东西开始。越小越好。并且比你想象的更快速的推出产品。事实上，简单的东西几乎都是好的。你需要永远试图把你的产品和公司都搞得尽可能简单。</p><p>对于一些有问题的公司，我们经常问的问题有：你的用户们会多次使用你的产品吗？你的用户们对你的产品很狂热吗？如果你的公司消失了，你的用户会不会真的感到沮丧？你的用户是否在自发的向其他人推荐你？如果你是一个ToB的公司，你是否有至少10个付费客户？</p><p>如果这些答案是否，那么产品不够好就是根本性的原因。我对一个公司发展缓慢的大多数的借口都很怀疑。因为最常见也最真实的原因就是产品做的不够好。</p><p>当创业公司不确定他们的产品下一步该怎么做，或者怀疑他们的产品是不是足够好。我们会让他们去和用户聊天。这当然不是每一次都有效（用户可能会告诉福特想要更快的马）。但是这确实是非常经常有效的办法。事实上，如果你的公司里有任何的意见不统一，你都应该去和你的用户聊一聊。</p><p>最好的创始人们经常看起来过度关注一些产品的细节，即使可能看上去不重要。但是这招真的有效。顺便说一句，产品包括所有用户和公司产生交互的东西。你需要有很好的客服，很好的销售代表等等。</p><p>记住，如果你没有做出来一个非常好的产品，什么也救不了你。</p><h2 id="第四部分：非常好的执行。"><a href="#第四部分：非常好的执行。" class="headerlink" title="第四部分：非常好的执行。"></a>第四部分：非常好的执行。</h2><p>虽然做出一个非常好的产品是必须的，但是你的任务仍然没有结束。你需要把这个非常好的产品，变成一个非常好的公司。并且你必须自己去做这件事。雇佣一个职业经理人去做这些工作的幻想极为普遍，同时也是极为失败的。你不能把工作长期外包给别人。</p><p>虽然听起来很明显，但是你必须要开始挣钱了。现在是思考如何实现盈利的好时机。</p><p>作为CEO，你唯一通用的职责就是确保公司获胜。即使你是创始人，也许有很多缺点不适合担任CEO，但只要你雇用的人能够弥补你的技能缺陷并充分发挥他们的能力，你仍然可以做好这项工作。与那些经验丰富、拥有高级商学院学位的CEO相比，你可能没有他们那样的技能，但你对用户更了解、你有更敏锐的产品直觉，并且对公司的成长更有热情。</p><h2 id="第四部分：非常好的执行-增长Part"><a href="#第四部分：非常好的执行-增长Part" class="headerlink" title="第四部分：非常好的执行-增长Part"></a>第四部分：非常好的执行-增长Part</h2><p>持续增长和发展势头是成功执行的关键。良好的增长（只要不是以亏本出售商品为代价的增长）可以解决所有问题，而缺乏增长只能通过增长来解决。如果你们在增长，你就会感觉自己在取得源源不断胜利，大家也会感到开心。如果你在增长，就会有不断的新角色和新责任，人们感觉自己的职业生涯在不断进步。而如果你没有增长，你们就会感觉自己正在输，人们会感到不满意并离开。如果你没有增长，人们就会争权夺利和相互指责。</p><p>没有增长的公司里面充满着沮丧的氛围，创始人和员工都非常的疲惫。很难说这究竟有多让人难受。</p><p>关于执行，最重要的指导是：永远不要失去增长的动能。但是你要怎么做到这一点？</p><p>我认为最重要的方法是，让保持增长变成你的第一优先级。CEO关注什么指标，整个公司就会去努力实现什么指标。</p><p>这里有几个例子。</p><p>Airbnb的创始人把他们的增长目标直观的写在纸上，并且贴的到处都是。贴在他们的冰箱，桌子，厕所上。如果他们达到了这个数字，那无事发生，如果没有达到，这会是他们所有人谈论的唯一事情。</p><p>扎克伯格曾经说过，Facebook最重要的创新之一，就是当增长遇到瓶颈的时候，建立了增长团队。FB的增长团队曾经是（也许现在还是）整个公司最有声望的团队。每个人都知道他们有多重要。</p><p>列一个清单记下所有阻碍增长的事项，并与公司成员一起探讨如何更快地增长。如果你知道限制增长的因素，你自然会想到如何解决它们。<br>对于你在考虑要不要做的任何事情，问你自己“这是优化增长的最佳方式吗？”例如，参加一个会议通常不是优化增长的最佳方式，除非你预期在会议上能够大量销售。</p><p>极度透明化内部数据指标（和财务状况）是一件好事。出于某种原因，创始人们总是非常害怕这种透明化。但这对于让整个公司专注于增长非常有好处。公司员工关注指标的程度似乎与公司业绩良好程度直接相关。如果你隐藏指标，人们就很难专注于它们。</p><p>谈到数据指标，不要用虚荣指标骗自己。一个非常常见的错误是专注在注册用户而不是留存用户上。但是留存是和获取新用户一样重要的事情。</p><p>建立内部的节奏以保持增长势头也很重要。你希望“有节奏的”做事，即不断推出新功能、获得新客户、招聘新员工、实现营收里程碑、建立新合作伙伴等，这些可以在内部和外部进行宣传。</p><p>你应该设定有野心但又拼尽全力勉强可以达到的目标，并每月检查进展情况。庆祝每一个胜利！时刻在内部讨论战略，告诉所有人你从客户那里听到的信息等等。你分享的信息越多，无论是好是坏，你的公司就会做得越好。</p><p>创始人们常常会陷入一些陷阱。其中一个陷阱是，如果公司的增长速度非常快，但似乎所有事情都异常混乱和低效，每个人都会担心事情会失控。实际上，这种情况几乎很少发生（Friendster是我可以指出的最近一家因技术债务而死亡的初创公司的例子）。出人意料的是，事实证明，如果你的增长速度很快，但一切都没有得到优化，那么你只需要修复这些问题，你就能获得更多的增长！我的最喜欢的投资是那些增长非常快但是没怎么优化的公司——它们被严重低估了。</p><p>另一个相关的陷阱是过度关注太远的未来问题——例如，“我们在大规模情况下应该如何解决问题？”正确的做法是，等到需要解决这个问题时再去考虑。很多初创公司会在争论这个问题时浪费太多的时间，而不是专注于解决当前的问题。一个好的经验法则是只考虑当前规模的 10 倍的情况。大多数早期的初创公司应该将“Do things that dont scale”挂在墙上记在心里。举个例子，好的创业公司总是有非常好的客服体验在早期，而糟糕的创业公司会担心这个会拖累他们的盈利能力并且不可规模化。但是很好的客户服务能够带来热情的早期用户，随着你的产品的优化，你会越来越不需要客服，因为你知道哪些问题是用户们被经常困住的地方，并且你解决了这些问题。（顺便说一句，有非常好的客户服务是一件特别重要的事情。）</p><p>这种策略的一个重要问题是——“Do things that dont scale”并不能成为你逃避盈利的借口。在初期，拥有不好的单位经济指标可能是可以接受的，但是你必须有一个很好的理由来说明为什么单位经济指标在以后会得到改善。</p><p>另一个陷阱是，即使产品的增长率很好，但绝对数字不理想，这会使你感到沮丧。不过人类在对指数增长的直觉上非常不准确。提醒你的团队这一点，以及所有巨型公司都是从小规模开始增长的。</p><p>一些最大的陷阱是，很多创始人们认为可以带来增长的事情，实际上几乎从来不起作用，但却会占用大量时间。常见的例子是与其他公司的协议和“重磅新闻发布会”。你要明白它们实际上没有用过。相反，像所有伟大的公司一样，打造深受用户喜爱的产品，手动招募初始用户，然后测试许多增长策略（广告、推荐计划、销售和市场营销等），投入真正对你有效的策略。问你的用户在哪里能够找到更多像他们一样的人。</p><p>记住，销售和市场营销并不是坏词。虽然如果没有出色的产品，它们都无法拯救你，但是它们都可以帮助你大幅加速增长。如果你是一家ToB公司，很可能需要提高你们在这方面的能力。</p><p>不要害怕销售。至少团队的一个创始人必须擅长让人们使用你的产品并为其付费。</p><p>Alex Schultz曾发表过一场关于To C公司增长的演讲，非常值得观看。</p><p>针对To B产品，我认为应该追踪每月的收入增长，记住销售周期较长意味着最初的几个月可能会表现不佳。（将初创公司作为最初的客户，可能会解决这个问题。）</p><h2 id="第四部分：非常好的执行-专注和高强度"><a href="#第四部分：非常好的执行-专注和高强度" class="headerlink" title="第四部分：非常好的执行-专注和高强度"></a>第四部分：非常好的执行-专注和高强度</h2><p>如果只能用两个词来总结我的运营建议，那么我会选择“专注”和“高强度”。这些词非常适用于我所见过的最优秀的创始人。</p><p>他们会全身心地专注于产品和增长，不会试图做所有事情。实际上，他们会频繁地说“不”（这很难，因为创业者通常都喜欢尝试新事物）。</p><p>通常来说，在你掌握第一件事情之前，不要让你的公司开始做下一件事情。我所知道的任何一家伟大的公司都不会同时做很多事情。他们通常会坚定地专注于一件事情，并一直执着的做下去。</p><p>你能做的事情比你想象中的要少得多。初创公司倒闭的常见原因之一就是做了太多错误的事情。因此，设定优先级至关重要，但也非常困难。（除了为公司设定优先级外，为自己设定战略的优先级同样重要。我发现对我个人而言，每天列出约3个主要任务和30个次要任务的清单，并编制一份年度所有的目标清单，是最有效的方法。）</p><p>优秀的创始人不会做太多大项目，但他们会非常专注地做任何一件事情。他们非常快速地完成任务，决策能力很强，这在创业公司中非常重要，因为你会收到许多冲突的建议。这些建议有时会引导你采取不同的方法，有时则是错误的建议。优秀的创始人会聆听所有的建议，然后快速做出自己的决策。</p><p>请注意，这并不意味着要对所有事情都进行强烈的投入——这是不可能的。你必须选择正确的事情。正如Paul Buchheit所说，要找到以10%的努力获得90%的价值的方法。市场并不关心你有多努力，它只关心你是否做了正确的事情。</p><p>优秀的创始人应该同时追求产品质量和快速推进，但这非常困难。这也是优秀创始人最显著的特征之一。</p><p>从未有一位行动很慢的创始人获得真正的成功。</p><p>你并不比别的创业公司特殊。你需要保持专注并且快速推进。即使是那些开发火箭和核反应堆的公司也可以快速行动。失败的公司常常觉得自己很特别，觉得不用快速行动。</p><p>当你找到有效的方法，要继续前进，不要被其他事情分心。不要松懈，继续保持。</p><p>不要被初期的成功所迷惑，不要花费过多的时间在社交活动和个人品牌上。创始人在初期取得成功后，要么继续埋头苦干，要么沉迷于成为一个创业明星。</p><p>拒绝参加会议和媒体宣传很难——这些活动让人感觉很好，特别是看到别的创业者受到关注时，更是难以抗拒参加的诱惑。但这种局面不会持续太久。媒体最终会发现谁是真正的赢家，如果你的公司真的成功了，你会拥有比你想象的更多的关注。那些早期有着自己公关团队的创业者（是的，真的有）几乎全部失败了。</p><p>长期来看，专注和高强度的做事会取得胜利。（Charlie Rose曾经说过，世界上的事情是通过专注和人际关系的结合完成的，这句话一直深深地印在我的脑海里。）</p><h2 id="第四部分：非常好的执行-CEO的工作"><a href="#第四部分：非常好的执行-CEO的工作" class="headerlink" title="第四部分：非常好的执行-CEO的工作"></a>第四部分：非常好的执行-CEO的工作</h2><p>之前我提到了 CEO 的唯一普遍工作描述是确保公司获得胜利。虽然这是正确的，但我想更具体地谈一下 CEO 应该如何分配时间。</p><p>CEO 必须：1）为公司设定愿景和战略，2）向每个人传递公司的使命愿景价值观，3）招聘和管理团队，特别是在自己不擅长的领域，4）筹集资金，5）设定执行质量标准。</p><p>除了这些职责，你要找到你最喜欢的那部分业务，保持持续参与。就像我在一开始提到的那样，这是一份高强度的工作。如果你成功了，它将在你的生活中占据你无法想象的程度——公司将时刻在你的脑海中。极度专注和高强度的工作意味着你很难平衡工作和生活。你对家庭或者别的重要事情的关心都不会超过对公司的。你必须时刻保持在线，有许多决定只有你能够做，无论你在授权方面多么出色。</p><p>你应该努力保持对团队和外部世界的高度敏感，始终保持清晰的战略和优先级，出现在所有重要的事情，并快速执行（特别是在别人搞不定的事情上）。你还应该采取“不惜一切代价”的态度——将有大量的不愉快的工作要做。如果团队看到你这样身先士卒，他们也会紧随其后。</p><p>管理好你自己的心态既非常困难，也非常重要。虽然这已经成为一个陈词滥调，但它确实是真实的——情绪上的高低波动非常剧烈，如果你不知道如何保持相对平稳，你就会遇到困难。作为一名CEO是孤独的。所以与其他CEO建立联系非常重要，这样当你遇到巨大的困难的时候，至少有个人能打电话（YC的一个很重要的作用是偶然发现的，为创始人们提供相互支持的同伴）。</p><p>一个成功的创业公司需要非常长的时间——肯定比大多数创始人在一开始想的时间更长。你不能将其视为通宵达旦的工作。你必须吃得好、睡得好、锻炼身体。你必须花时间与家人和朋友相处。你还需要在你真正热爱的领域工作——只有这样才能支撑你高强度的工作十年。</p><p>你会对着深渊嚼玻璃渣——灾难的多样性和严重性会让你感到惊讶。你的工作是在微笑中修复它们并安慰你的团队，告诉他们一切都会好起来的。通常情况下，事情并没有看上去那么糟糕，但有时确实非常糟糕。无论如何，你需要继续前进，继续成长。</p><p>作为CEO，你没有借口可以找。你会遇到很多不好和不公平的事情。但不要对自己，尤其是不要对团队说“如果我们有更多的钱”或“如果我们有另一个工程师”这样的话。要么找到一种解决方法，要么想办法绕过它。喜欢找借口的人几乎都失败了，尤其是创业公司的CEO。你可以沮丧一分钟，然后你要意识到需要你来想出解决方案。“你总能想出一些办法来解决任何问题”你会希望别人这么描述你。</p><p>你要扭曲别人眼中的现实，但是要对自己保持诚实，你要让别人相信你是未来10年最重要的公司，但你自己应该对可能出现的一切问题保持警惕。</p><p>要坚持。大多数创始人放弃创业得太快或者过快地转向下一个产品。如果情况不太好，找出问题的根本原因，并确保你解决了它。作为成功的初创企业CEO，坚持不懈是非常重要的（尽管你也不想顽固到无法理喻的地步——这是另一个明显的矛盾，需要做出艰难的判断）。</p><p>要保持乐观。虽然可能有一位极为悲观的CEO存在于世界上，但我还没有遇到过这个人。你要相信，并且要让整个公司感染这种信念：未来会更好，并且你们公司在其中发挥了重要作用。这在理论上很容易，但在面临现实的短期挑战下却很困难。不要失去对长期愿景的追求，并相信日复一日的困难终将被年复一年的进步所替代。</p><p>你最重要的工作之一是定义使命和价值观。这可能有些老套，但在早期就值得去做。你在开始时灌输的任何东西通常在多年后仍然有效。随着公司的发展，每一个新人都需要首先认同公司的使命和价值观，然后再去向其他人灌输。因此，早期就要把文化，价值观和使命写下来。</p><p>另一个我想重弹的老调是：建立公司有些类似于建立一种宗教。如果人们无法将日复一日所做的事情与他们关心的更崇高的目标联系起来，他们就不会做得很出色。我认为在Y Combinator网络中，Airbnb在这方面做得最好，强烈建议你查看他们的文化和价值观。</p><p>CEO们经常犯的一个错误是在非常成熟的领域创新，而不是在产品和解决方案方面进行创新。例如，许多创始人认为他们应该花时间去找一些人力资源、市场营销、销售、融资、公关等方面的新方法。这几乎总是不好的。这些方面找到成熟有效的做法即可，把你的创造力集中在你正在建立的产品或服务上。</p><h2 id="第四部分：非常好的执行-招聘和管理"><a href="#第四部分：非常好的执行-招聘和管理" class="headerlink" title="第四部分：非常好的执行-招聘和管理"></a>第四部分：非常好的执行-招聘和管理</h2><p>招聘是你最重要的工作之一，也是建立伟大公司的关键（而不是建立伟大产品）。</p><p>我关于招聘的第一个建议是先不要招聘。在Y Combinator与我们合作的最成功的公司通常会等待很长的一段时间，然后才开始招聘。员工是昂贵的，员工增加组织复杂性和沟通成本。有些事情你可以和联合创始人说，但是不能在员工在场时说。员工还会增加惯性——团队中的人越多，改变方向就越难。不要从你的员工数量来衡量你的自我价值。</p><p>最优秀的人才有很多机会。他们想加入成功的团队。如果你没有任何东西，那么很难招聘到他们。一旦你明显取得成功，他们会想要加入你的团队。</p><p>值得重复的是，优秀的人有很多选择，而你需要优秀的人才能建立一个伟大的公司。在股权、信任和责任方面要慷慨。要努力去争取那些你认为自己可能招不到的人。记住，你想雇佣的那些人如果愿意，他们可以自己创业。</p><p>当你处于招聘模式时（即从获得PMF到永远），你应该将约25%的时间用于招聘。至少一个创始人，通常是CEO，需要在招聘方面非常出色。这是大多数CEO最常花时间的活动。大家都说CEO应该花很多时间招聘，但在实践中，只有最好的CEO才能做到。这可能说明了一些东西。</p><p>不要在招聘人才的质量上妥协。每个人都知道这一点，但在迫切需要的时候，每个人都会妥协。每个人都会后悔，有时甚至会差点毁掉公司。好人和坏人都有感染力，如果你从平庸的人开始，平均水平通常不会向上趋势。那些最初雇佣平庸员工的公司几乎永远不会恢复。相信自己对人的直觉。如果你有疑虑，那么答案就是否定的。</p><p>不要雇佣性格消极的人。他们不适合早期创业公司，因为整个世界每天都会预测你的失败，所以整个团队要团结在一起并且坚定的相信你们会取得成功。</p><p>对于几乎所有的职位，重视素质而不是经验。寻找具有真正智慧和完成过很多事情的人。寻找你喜欢的人——你们将会在一起度过很多时间，而且经常处于紧张的情况下。对于你不认识的人，试着在他们全职加入之前一起做个项目。</p><p>努力锻炼自己成为一个很好的管理者。这对大多数创始人来说是很困难和反直觉的。但这很重要。找到可以帮助你提升管理能力的导师。如果你不擅长管理，你会很快失去员工，如果你不能留住员工，即使你是世界上最好的招聘人员，也毫无意义。大多数关于成为一个好的管理者的原则都已经有很好的讨论了，不过我要提到比较少见的一点“不要个人英雄主义”。大多数初次担任管理者的人都会在某个时候试图自己做所有事情，并变得对员工无法交流。这通常以一场灾难告终。绝对不要进入这种模式，你可以推迟项目以获得一个运作良好的团队。</p><p>谈到管理，努力让每个人都在同一个办公室里。由于某些原因，创业公司总是在这方面做出妥协。但几乎所有最成功的创业公司最初都是在一起工作的。我认为远程工作对于较大的公司可能很有效，但对于创业公司来说，这不是取得巨大成功的秘诀。</p><p>最后，要快速解雇不合适的员工。每个人都知道这个原则，但却没有人去做。但我觉得我还是应该说一下。同时，无论他们的工作能力有多强，也要解雇那些有毒的人。文化是由你雇佣、解雇和提拔的人定义的。<br>我写了一篇文章，里面更多细节。</p><h2 id="第四部分：非常好的执行-竞争对手"><a href="#第四部分：非常好的执行-竞争对手" class="headerlink" title="第四部分：非常好的执行-竞争对手"></a>第四部分：非常好的执行-竞争对手</h2><p>关于竞争对手，简单说一下：竞争对手是创业公司的杯弓蛇影。创业者们认为竞争对手是导致99%的创业公司死亡的罪魁祸首。但99%的创业公司死于自杀，而不是被竞争对手击败。相反，应该关注所有内部问题。如果你失败了，很可能是因为你没有做出一个伟大的产品和/或没有建立一个伟大的公司。</p><p>99%的情况下，你应该忽略竞争对手。特别是在竞争对手筹集大量资金或在媒体上大肆宣传时更应该忽略他们。不要担心竞争对手，直到他们用一个真正发布的产品打败你。新闻发布比编写代码更容易，而编写代码又比制作出一个伟大的产品更容易。用亨利·福特的话说：“真正应该担心的竞争对手是那些从不关心你，却一直在提高自己业务的人。”</p><p>每个巨型公司在小的时候都面临着比你现在面临的更严重的竞争威胁，它们都度过了难关。总会有对策。</p><h2 id="第四部分：非常好的执行-挣钱"><a href="#第四部分：非常好的执行-挣钱" class="headerlink" title="第四部分：非常好的执行-挣钱"></a>第四部分：非常好的执行-挣钱</h2><p>Oh Yes，谈到赚钱，你需要想办法实现这一点。<br>简短来说，你必须让人们付给你的钱比你提供产品/服务的成本更多。由于某些原因，人们总是忘记考虑自己的成本这个部分。</p><p>如果你有一个免费的产品，不要试图通过购买用户来增长。对于靠广告变现的企业来说，这非常困难。你需要做出人们愿意与他们的朋友分享的东西。</p><p>如果你有一个每个客户终身价值（LTV）低于500美元的付费产品，通常你负担不起销售费用。尝试使用不同的用户获取方法，如SEO/SEM，广告，邮件等，但要尝试在3个月内还清客户获取成本（CAC）。</p><p>如果你有一个每个客户LTV高于500美元（对你净收益而言）的付费产品，通常你负担得起直接销售费用。首先尝试自己销售产品以了解哪些方法有效。《Hacking Sales》是一本有用的书。</p><p>无论如何，尽可能快地实现“泡面盈利”，即赚足够的钱，让你们可以靠吃泡面维持生计。当你达到这个目标时，你就掌握自己的命运，不再受投资者和金融市场的任意摆布。</p><p>密切关注你的现金流。尽管听起来难以置信，但我们已经多次看到创始人在没有意识到自己正在用完钱的情况下，就把钱用光了（参考保罗·格雷厄姆的文章）。</p><h2 id="第四部分：非常好的执行-融资"><a href="#第四部分：非常好的执行-融资" class="headerlink" title="第四部分：非常好的执行-融资"></a>第四部分：非常好的执行-融资</h2><p>大多数创业公司在某个时候会去融资。</p><p>你应该在需要资金或在有很好的条款的情况下融资。注意不要失去你的节俭的感觉或者开始用金钱来解决问题。资金不足可能是不好，但是资金过多几乎总是不好的。</p><p>成功筹集资金的秘诀是拥有一个好的公司。创始人为了融资而做的所有其他的刻意优化，可能只占5%的重要性。投资者正在寻找的是那些无论他们是否投资都将非常成功的公司，但是外部资本可以加速其增长。成功的量级非常重要——因为投资者的回报主要取决于大型成功案例，如果投资者相信你有100%的机会创造一个价值1000万美元的公司，但几乎没有机会建立一个更大的公司，即使估值非常低，他/她也可能不会投资。你需要一直向投资人解释，为什么你可能会取得巨大的成功。</p><p>投资者受到两种恐惧的驱使，一种是错过下一个谷歌，另一种是担心在回顾时因为显而易见的愚蠢而做出的错误决策的损失。（对于最好的公司，他们同时担心这两种情况。）</p><p>当你的公司状态不足以吸引资本时，试图融资是一个坏主意。你将浪费时间并损失声誉。如果你筹集资金的过程很艰难，不要感到沮丧。许多最好的公司都面临这个问题，因为最好的公司往往在一开始看起来不好（并且它们几乎总是不时尚的）。当投资者拒绝你的时候，相信他们的否定，但不要相信他们的理由。记住，除了“是”的回答，其他的回答都是“否定”的——投资者有一种精妙的能力，可以让否定听起来很像是“或许是”。</p><p>并行的进行融资非常重要——不要按顺序列出你最喜欢的投资者清单。让投资者行动的方式是让他们担心其他投资者夺走他们的机会。</p><p>把融资视为必要的恶，尽快完成。一些创始人会迷上融资；这肯定不好。最好只让一个创始人去做它，这样公司不会停滞不前。</p><p>记住，大多数VC对大多数行业并不了解。数据是最有说服力的。</p><p>虽然情况正在发生改变，但大多数投资者（Y Combinator是一个著名的例外）很不幸仍然需要通过你们双方认识的人的介绍才会认真考虑你的项目。</p><p>坚持干净的条款（复杂的条款会逐轮恶化），但不要过度优化，特别是在估值上。估值是一种可以和别人对比的东西，所以创始人喜欢争取最高估值。但是少一些估值也没关系。</p><p>第一笔资金是最难获得的，因此将精力集中在获得第一笔资金上，通常意味着将注意力集中在最爱你的人身上。始终拥有多个计划，其中一个是不筹集任何资金，并且根据兴趣灵活调整——如果你可以好好利用更多的资金，并且以合理的条件可用，那么可以考虑接受这笔钱。</p><p>成为好的推销员的一个重要关键是使你的故事尽可能清晰易懂。当然，最重要的关键是真正拥有一个好的公司。有很多关于如何在路演中包含什么的想法，但至少你需要有：使命、问题、产品/服务、商业模式、团队、市场和市场增长率以及财务状况。</p><p>记住，每一轮融资的门槛都会变高很多。如果你在种子轮只是一个引人注目的演讲者，那么当你进行A轮融资时，你会发现这种策略行不通。</p><p>好的投资者确实能够为公司带来很大的价值，而不好的投资者则会给公司带来很大的负面影响。大多数投资者处于中间状态，既不会增加也不会减少价值。只投入少量资金的投资者通常对你没有任何帮助（例如那些参与派对式轮融资的投资者）。</p><p>伟大的董事会成员是公司除了用户以外的最佳外部约束机制。而外部约束机制的价值超出了大多数创始人的想象。为了得到一个非常投入的伟大的董事会成员，可以接受较低的估值。</p><p>我认为PG的这篇文章是关于融资最好的文章。</p><h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><p>请记住，至少有一千人拥有很多伟大的想法，但只有其中一个会真正获得成功。这一切归根结底是因为执行。这是一个艰难的过程，每个人都希望跳过执行将“想法”转化为“成功”，但迄今为止还没有人找到。</p><p>因此，你所需要的只是一个伟大的想法、一个伟大的团队、一个伟大的产品和出色的执行。</p><p>这实在是太简单了！；）</p><p>感谢 Paul Buchheit, Erica Carpenter, Brian Chesky, Adam D’Angelo, Drew Houston, Justin Kan, Matt Krisiloff, Aaron Levie, Gabriel Leydon, Jessica Livingston, Dustin Moskovitz, David Rusenko and Colleen Taylor for contributing thoughts to this.</p><blockquote><p>From 海松：<br>翻译本文，作为我对即刻创业社区，中文创业社区，以及YC的一点致敬。感谢大家喜爱。<br>原文地址：<a href="https://playbook.samaltman.com/">https://playbook.samaltman.com/</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> 创业 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2024年的Go微服务框架</title>
      <link href="/blog/2024/03/30/2024%E5%B9%B4%E7%9A%84Go%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/"/>
      <url>/blog/2024/03/30/2024%E5%B9%B4%E7%9A%84Go%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6/</url>
      
        <content type="html"><![CDATA[<blockquote><p>哪个框架是最适合你的呢？</p></blockquote><p>Go 作为一种流行的编程语言不断增长，现在已经成为2024年构建云原生微服务应用程序的常见选择。Go 甚至进入了 <a href="https://www.tiobe.com/tiobe-index/">TIOBE 编程语言排行榜的前十名</a>。</p><p>尽管 Go 在历史上并没有强烈使用框架的文化，但已经有一些框架得到了确立，如今开发人员应该考虑它们以提高生产力。</p><p>然而，做出正确的选择可能具有挑战性，因此在本文中我们将介绍主要框架并比较功能、关键用例和潜在缺点。</p><h2 id="Go-微服务框架：概述"><a href="#Go-微服务框架：概述" class="headerlink" title="Go 微服务框架：概述"></a>Go 微服务框架：概述</h2><p>这里是本文中包含的不同框架的高级概述，这些框架根据对各种用例和功能的内置支持水平进行比较。</p><table><thead><tr><th></th><th>Encore</th><th>GoMicro</th><th>Go Kit</th><th>Gin</th></tr></thead><tbody><tr><td>描述</td><td>微服务框架和基础设施 SDK</td><td>微服务框架</td><td>Go库集合</td><td>Web框架</td></tr><tr><td>使用案例</td><td>事件驱动、分布式系统</td><td>事件驱动、分布式系统</td><td>分布式系统</td><td>高性能的HTTP API</td></tr><tr><td>支持协议</td><td>HTTP</td><td>HTTP,gRPC</td><td>HTTP,gRPC</td><td>HTTP</td></tr><tr><td>低模板</td><td>✅︎</td><td>✅︎</td><td>✅︎</td><td>✅︎</td></tr><tr><td>认证</td><td>✅︎</td><td>✅︎</td><td>✅︎</td><td>✅︎</td></tr><tr><td>服务发现</td><td>✅︎</td><td>✅︎</td><td>✅︎</td><td>❌</td></tr><tr><td>异步消息</td><td>✅︎</td><td>✅︎</td><td>❌</td><td>❌</td></tr><tr><td>内置API文档</td><td>✅︎</td><td>✅︎</td><td>❌</td><td>❌</td></tr><tr><td>自动本地开发基础设施</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置跟踪</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置架构图</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置的秘密管理</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置预览环境</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置云基础设施自动化</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>内置云成本分析</td><td>✅︎</td><td>❌</td><td>❌</td><td>❌</td></tr></tbody></table><h2 id="Encore"><a href="#Encore" class="headerlink" title="Encore"></a>Encore</h2><p>Encore是构建Go微服务的现代替代方案，旨在使构建面向事件驱动和分布式系统变得更简单。Encore解决了本地开发体验，并通过使用来自AWS和GCP的强大可扩展服务协助部署。它通过提供微服务框架和基础设施SDK来工作，让您将基础设施语义声明为应用程序代码的一部分。官方文档：<a href="https://encore.dev/%E3%80%82">https://encore.dev/。</a></p><h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><p>定义一个服务</p><p>使用Encore，您通过在常规Go包中定义API来定义服务。 Encore将此视为服务，并使用包名称作为服务名称。部署时，Encore将自动为每个服务提供所需的基础设施。</p><p>在磁盘上的展示如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">/my-app</span><br><span class="line">├── encore.app          // ... and other top-level project files</span><br><span class="line">│</span><br><span class="line">├── hello               // hello service (a Go package)</span><br><span class="line">│   ├── hello.go        // hello service code</span><br><span class="line">│   └── hello_test.go   // tests for hello service</span><br><span class="line">│</span><br><span class="line">└── world               // world service (a Go package)</span><br><span class="line">    └── world.go        // world service code</span><br></pre></td></tr></table></figure><p>这意味着构建微服务架构就像在应用程序中创建多个 Go 包一样简单。有关更多详细信息，请参阅应用程序结构文档。</p><p>定义一个API</p><p>要定义一个 API，只需在任何普通的 Go 函数上添加 <code>//encore:api</code> 注解。这会告诉 Encore 该函数是一个 API 端点。Encore 将自动在编译时生成必要的样板代码。</p><p>在下面的示例中，我们定义了 API 端点 <code>Ping</code>，在 <code>hello</code> 服务中，它会暴露为 <code>hello.Ping</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">package hello // service name</span><br><span class="line"></span><br><span class="line">//encore:api public</span><br><span class="line">func Ping(ctx context.Context, params *PingParams) (*PingResponse, error) &#123;</span><br><span class="line">    msg := fmt.Sprintf(&quot;Hello, %s!&quot;, params.Name)</span><br><span class="line">    return &amp;PingResponse&#123;Message: msg&#125;, nil</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个 Pub/Sub topic</p><p>如果您想要一个发布/订阅主题，可以直接在应用程序代码中声明它，就像这样。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import &quot;encore.dev/pubsub&quot;</span><br><span class="line"> </span><br><span class="line">type User struct &#123; /* fields... */ &#125;</span><br><span class="line"> </span><br><span class="line">var Signup = pubsub.NewTopic[*User](&quot;signup&quot;, pubsub.TopicConfig&#123;</span><br><span class="line">  DeliveryGuarantee: pubsub.AtLeastOnce,</span><br><span class="line">&#125;)</span><br><span class="line"> </span><br><span class="line">// Publish messages by calling a method</span><br><span class="line">Signup.Publish(ctx, &amp;User&#123;...&#125;)</span><br></pre></td></tr></table></figure><p>要运行您的应用程序，只需使用<code>encore run</code>命令。Encore将自动设置本地基础设施并生成必要的样板代码。您还可以获得<a href="https://encore.dev/docs/observability/dev-dash">一个带有分布式跟踪功能的本地开发仪表板</a>，以帮助您轻松理解和调试应用程序行为。</p><p>当您想要部署到云端时，您的代码不会发生变化。Encore将在所有环境中生成必要的样板并配置必要的基础设施：</p><ul><li>NSQ 用于本地开发</li><li>GCP Pub/Sub 适用于 GCP 上的环境。</li><li>AWS 上的环境中的 SNS/SQS</li></ul><h3 id="关键特性"><a href="#关键特性" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li>无样板文件：使用任何函数上的注释声明API，从Go包创建服务。</li><li>内置分布式跟踪：轻松追踪请求的路径和性能。</li><li>自动化API文档和架构图：自动保持文档和图表最新。</li><li>内置机密管理：安全处理敏感数据。</li><li>云基础设施自动化：在本地、预览以及GCP和AWS中自动配置基础设施。</li></ul><h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul><li>可扩展性：Encore旨在设计大规模应用程序，是使用可伸缩云服务构建大型分布式系统的高效方式。</li><li>简单和快速：Encore将许多基础设施管理复杂性抽象化，使开发人员能够专注于编码。</li><li>标准化：提供了一种统一的构建微服务和API以及配置基础设施的方式，遵循最佳实践。</li><li>内置工具：Encore提供内置的分布式跟踪、自动化API文档、预览环境等功能。</li><li>云无关性：Encore应用可以部署到任何云提供商，提供灵活性并防止厂商锁定。</li></ul><h3 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h3><ul><li>为了从Encore中获得最大价值，您应该同时使用API框架和基础设施SDK，这取决于您当前的情况可能需要对当前基础设施管理流程进行更改。</li></ul><h3 id="适用于"><a href="#适用于" class="headerlink" title="适用于"></a>适用于</h3><ul><li>在<a href="https://encore.dev/signup">这里</a>注册，体验一下 Encore。</li><li>查看此<a href="https://encore.dev/docs/how-to/try-encore">指南</a>，了解如何根据您的情况和优先事项最好地评估 Encore。</li></ul><h2 id="GoMicro-Orb"><a href="#GoMicro-Orb" class="headerlink" title="GoMicro (Orb)"></a>GoMicro (Orb)</h2><p><a href="https://github.com/go-micro/go-micro">GoMicro（将更名为Orb）</a>是一个微服务框架，旨在简化构建可扩展和易维护应用程序的挑战。GoMicro提供了一种可插拔的架构，允许开发人员选择并调整框架以满足其需求，并与各种服务发现系统集成。</p><blockquote><p><strong>注意</strong>：自2023年4月以来，GoMicro尚未发布新版本，因此可能需要谨慎对待。</p></blockquote><h3 id="关键特性-1"><a href="#关键特性-1" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li><p>可插拔架构：根据您项目的需求调整和扩展 GoMicro。</p></li><li><p>服务发现与负载均衡：原生集成确保高效且平稳运行。</p><blockquote><p>更多特性，可以查看官网：<a href="https://github.com/go-micro/go-micro">https://github.com/go-micro/go-micro</a></p></blockquote><h3 id="优势-1"><a href="#优势-1" class="headerlink" title="优势"></a>优势</h3></li><li><p>可扩展性：GoMicro旨在设计大规模应用程序，可以轻松处理增加的负载。</p></li><li><p>灵活性：可插拔的特性意味着它可以根据各种项目需求进行定制。</p></li></ul><h3 id="限制-1"><a href="#限制-1" class="headerlink" title="限制"></a>限制</h3><ul><li>复杂性：功能的广泛范围和可插拔性可能会让新手感到畏惧。</li><li>云原生依赖：可能不适合那些没有专注于云原生部署的项目。</li></ul><h3 id="适用于-1"><a href="#适用于-1" class="headerlink" title="适用于"></a>适用于</h3><p>对于专注于云原生应用程序的团队，尤其是那些受益于事件驱动方法的团队。</p><h3 id="什么时候考虑GoMicro"><a href="#什么时候考虑GoMicro" class="headerlink" title="什么时候考虑GoMicro?"></a>什么时候考虑GoMicro?</h3><ul><li>在开发可扩展、云原生和事件驱动的应用程序时。</li><li>当框架的灵活性和定制化是您的首要任务，并且愿意花费大量时间进行手动基础设施设置和维护时。</li></ul><h2 id="Go-kit"><a href="#Go-kit" class="headerlink" title="Go kit"></a>Go kit</h2><p><a href="https://gokit.io/">Go kit</a> 是一组 Go 包（库），用于在 Go 中构建微服务。它专注于提供常见挑战的解决方案，同时保持相对中立。</p><h3 id="关键特性-2"><a href="#关键特性-2" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li>服务发现：与各种服务发现系统无缝集成。</li><li>可插拔传输：提供一系列传输机制，如HTTP和gRPC。</li></ul><h3 id="优势-2"><a href="#优势-2" class="headerlink" title="优势"></a>优势</h3><ul><li>标准化：提供了一种统一的构建服务的方式，符合最佳实践。</li><li>灵活性：尽管有自己的观点，但它提供了插入不同组件的方法。</li></ul><h3 id="限制-2"><a href="#限制-2" class="headerlink" title="限制"></a>限制</h3><ul><li>陡峭的学习曲线：它特有的做事方式可能需要一定时间的初始投资才能掌握。</li><li>潜在开销：对于更简单的项目，Go kit 可能显得过度复杂。</li></ul><h3 id="适用于-2"><a href="#适用于-2" class="headerlink" title="适用于"></a>适用于</h3><p>对于重视标准化但又保持灵活性的团队。</p><h3 id="什么使用考虑使用Go-kit"><a href="#什么使用考虑使用Go-kit" class="headerlink" title="什么使用考虑使用Go kit?"></a>什么使用考虑使用Go kit?</h3><ul><li>当您需要一个平衡标准化方法和灵活性的工具包时。</li><li>当您不介意投入时间和精力手动设置和维护云基础设施和可观测工具时。</li></ul><h2 id="Gin"><a href="#Gin" class="headerlink" title="Gin"></a>Gin</h2><p><a href="https://gin-gonic.com/">Gin</a> 是一个专注于性能的 Go Web 框架。Gin 的特点是极简主义，适用于构建小型、专注的应用程序。</p><h3 id="关键特性-3"><a href="#关键特性-3" class="headerlink" title="关键特性"></a>关键特性</h3><ul><li>快速入门：其极简的特性意味着您可以快速启动和运行。</li><li>多功能性：作为一款极简产品，Gin提供了很大的灵活性，但牺牲了内置工具。</li></ul><h3 id="优势-3"><a href="#优势-3" class="headerlink" title="优势"></a>优势</h3><ul><li>快速入门：其极简的特性意味着您可以快速启动和运行。</li><li>多功能性：作为一款极简产品，Gin提供了很大的灵活性，但牺牲了内置工具。</li></ul><h3 id="限制-3"><a href="#限制-3" class="headerlink" title="限制"></a>限制</h3><ul><li>面向Web：主要针对Web应用程序，可能不适合非Web微服务。</li><li>功能不够丰富：对于更复杂的需求，您可能需要依赖第三方工具和扩展。</li></ul><h3 id="适用于-3"><a href="#适用于-3" class="headerlink" title="适用于"></a>适用于</h3><ul><li>对于注重性能并希望创建简单轻量级网络应用的开发人员和小团队</li></ul><h3 id="什么时候考虑使用Gin"><a href="#什么时候考虑使用Gin" class="headerlink" title="什么时候考虑使用Gin?"></a>什么时候考虑使用Gin?</h3><ul><li>当您的项目需要性能并且整体范围较小时。</li><li>当您正在构建少量和简单的服务时，因此在设置基础设施方面的总时间投资较小。</li></ul><blockquote><p>原文链接: <a href="https://encore.dev/resources/go-frameworks">https://encore.dev/resources/go-frameworks</a></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Go, 微服务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Prometheus监控实战》读书笔记</title>
      <link href="/blog/2024/02/03/0100_%E7%9B%91%E6%8E%A7Prometheus/"/>
      <url>/blog/2024/02/03/0100_%E7%9B%91%E6%8E%A7Prometheus/</url>
      
        <content type="html"><![CDATA[<h1 id="监控简介"><a href="#监控简介" class="headerlink" title="监控简介"></a>监控简介</h1><blockquote><p><a href="https://www.bilibili.com/video/BV1a64y1X7ys/">Prometheus-陈皓</a>，本书的核心是Prometheus，一个开源的监控系统，它从应用程序中实时获取时间序列数据，然后通过功能强大的规则引擎，帮助你识别监控环境所需的信息。本书可以指导你使用Prometheus来构建监控系统，重点放在动态云环境、Kubernetes环境和容器环境的监控。同时，还将研究如何从应用程序获取数据并将这些数据用于警报和可视化。</p></blockquote><p>相关的开源地址：</p><ul><li>prometheus 官网：<a href="https://prometheus.io/">https://prometheus.io/</a></li><li>prometheus github地址：<a href="https://github.com/prometheus/prometheus">https://github.com/prometheus/prometheus</a></li></ul><p>监控是构建和管理应用程序服务层级结构的基础。</p><p><strong>从底向上</strong>依次是监控，应急事件处理，事后总结/问题根源分析，测试+发布，容量规划，软件开发，产品设计。</p><p>根据服务价值设计自上而下的健康空系统是一个很好的方式，自上而下分别是业务逻辑，应用程序，操作系统，监控框架。</p><h3 id="指标"><a href="#指标" class="headerlink" title="指标"></a>指标</h3><ul><li>测量型：类型是上下增减的数字，本质上是特定度量的快照。如CPU, 内存和磁盘使用率等。</li><li>计数型：随时间增加而不会减少的数字。</li><li>直方图：对观察点进行采样的指标类型。</li></ul><h3 id="指标摘要"><a href="#指标摘要" class="headerlink" title="指标摘要"></a>指标摘要</h3><ul><li>计数：计算特定时间间隔内的观察点数。</li><li>求和：将特定时间间隔内所有观察点的值累计相加。</li><li>平均值：提供特定时间间隔内所有值的平均值。</li><li>中间数：数值的几何中点，正好50%的数值位于它前面，而另外一半位于它的后面。</li><li>百分位数：度量占总数特定百分比的观察点的值。</li><li>标准差：显示指标分布中与平均值的标准差，这可以侧聊出数据集的差异程度。标准差为0表示数据都等于平均值，较高的标准差意味着数据分布的范围很广。</li><li>变化率：显示时间序列中数据之间的变化程度。</li></ul><h2 id="监控方法论"><a href="#监控方法论" class="headerlink" title="监控方法论"></a>监控方法论</h2><h3 id="Brendan-Gregg-的-USE-Utilization-Saturation和Error"><a href="#Brendan-Gregg-的-USE-Utilization-Saturation和Error" class="headerlink" title="Brendan Gregg 的 USE(Utilization, Saturation和Error)"></a>Brendan Gregg 的 USE(Utilization, Saturation和Error)</h3><p>这个方法侧重于主机级监控，其中U指的是使用率，S指的是饱和度，E指的是错误。具体<a href="https://www.brendangregg.com/usemethod.html">USE方法</a>描述。USE可以被概括成<strong>针对每个资源，检查使用率，饱和度和错误。</strong></p><ul><li><strong>资源</strong>：系统的一个组件。在Gregg对模型的定义中，他是一个传统意义上的物理服务器组件，入CPU,磁盘等，但许多人也将软件资源定义在内。</li><li><strong>使用率</strong>：资源忙于平时工作的平均时间。它通常用随时间变化的百分比表示。</li><li><strong>饱和度</strong>：资源排队工作的指标，无法再处理额外的工作。通常用队列长度表示。</li><li><strong>错误</strong>：资源错误事件的技术。</li></ul><p>例如：从CPU开始</p><ul><li>CPU使用率随时间的百分比</li><li>CPU饱和度，等待CPU的进程数。</li><li>错误，通常对CPU资源不太有影响。</li></ul><h3 id="Google的四个黄金指标"><a href="#Google的四个黄金指标" class="headerlink" title="Google的四个黄金指标"></a>Google的四个黄金指标</h3><p>这四个指标分别是<strong>延迟，流量，错误和饱和度</strong>。这四个指标来自于Google SRE手册，是专注与应用程序级的监控。</p><ul><li><strong>延迟</strong>：服务请求所花费的时间，需要区分成功请求和失败请求。</li><li><strong>流量</strong>：针对系统，如每秒HTTP的请求数，或者数据库系统的事务。</li><li><strong>错误</strong>：请求失败的速率，如HTTP 500错误等显示失败，或者是返回错误内容或无效内容等隐式失败，或者是基于策略原因导致的失败。</li><li><strong>饱和度</strong>：应用程序有多“满”，或者受限的资源，如内存，IO【网络IO，磁盘IO】，磁盘。</li></ul><h3 id="Weaveworks的RED-Rate-Error和Duration"><a href="#Weaveworks的RED-Rate-Error和Duration" class="headerlink" title="Weaveworks的RED(Rate, Error和Duration)"></a>Weaveworks的RED(Rate, Error和Duration)</h3><p>可以读这篇<a href="https://www.weave.works/blog/the-red-method-key-metrics-for-microservices-architecture/">文章</a>，也可以看下这个<a href="https://grafana.com/files/grafanacon_eu_2018/Tom_Wilkie_GrafanaCon_EU_2018.pdf">PPT</a>。</p><h2 id="警报和通知"><a href="#警报和通知" class="headerlink" title="警报和通知"></a>警报和通知</h2><p>要建立一个出色的通知系统，需要考虑一下基础信息：</p><ul><li>哪些问题需要通知</li><li>谁需要被告知</li><li>如何告知他们</li><li>多久告知他们一次</li><li>何时停止告知以及何时升级到其他人</li></ul><h3 id="通知的标准"><a href="#通知的标准" class="headerlink" title="通知的标准"></a>通知的标准</h3><ul><li>使通知清晰、准确、可操作。使用由人而不是计算机编写的通知在清晰度和实用性方面有显著差异</li><li>为通知添加上下文，通知应包含组件的其他相关信息</li><li>仅发有意义的通知。</li></ul><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><h3 id="可视化构建"><a href="#可视化构建" class="headerlink" title="可视化构建"></a>可视化构建</h3><ul><li>清晰地显示数据</li><li>引发思考（而不是视觉效果）</li><li>避免扭曲数据</li><li>使数据集保持一致</li><li>允许更改颗粒度而不影响理解</li></ul><h3 id="推荐书籍"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a>推荐书籍</h3><ul><li>The Visual Display of Quantitative Information-Edward Tufte</li><li><a href="https://www.datadoghq.com/blog/timeseries-metric-graphs-101/">https://www.datadoghq.com/blog/timeseries-metric-graphs-101/</a></li><li>The Art of Monitoring</li><li><a href="https://riemann.io/">https://riemann.io/</a></li></ul><h1 id="Prometheus安装"><a href="#Prometheus安装" class="headerlink" title="Prometheus安装"></a>Prometheus安装</h1><h3 id="下载软件Prometheus"><a href="#下载软件Prometheus" class="headerlink" title="下载软件Prometheus"></a>下载软件<code>Prometheus</code></h3><ul><li><a href="https://prometheus.io/download/">https://prometheus.io/download/</a></li></ul><p>在Linux上安装prometheus</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">mkdir prometheus</span><br><span class="line">cd prometheus</span><br><span class="line">wget https://github.com/prometheus/prometheus/releases/download/v2.49.1/prometheus-2.49.1.linux-amd64.tar.gz</span><br><span class="line">tar xvf prometheus-2.49.1.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><p>Prometheus默认的配置</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># my global config</span></span><br><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span> <span class="comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span><br><span class="line">  <span class="attr">evaluation_interval:</span> <span class="string">15s</span> <span class="comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span></span><br><span class="line">  <span class="comment"># scrape_timeout is set to the global default (10s).</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Alertmanager configuration</span></span><br><span class="line"><span class="attr">alerting:</span></span><br><span class="line">  <span class="attr">alertmanagers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">static_configs:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">          <span class="comment"># - alertmanager:9093</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load rules once and periodically evaluate them according to the global &#x27;evaluation_interval&#x27;.</span></span><br><span class="line"><span class="attr">rule_files:</span></span><br><span class="line">  <span class="comment"># - &quot;first_rules.yml&quot;</span></span><br><span class="line">  <span class="comment"># - &quot;second_rules.yml&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A scrape configuration containing exactly one endpoint to scrape:</span></span><br><span class="line"><span class="comment"># Here it&#x27;s Prometheus itself.</span></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="comment"># The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;prometheus&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># metrics_path defaults to &#x27;/metrics&#x27;</span></span><br><span class="line">    <span class="comment"># scheme defaults to &#x27;http&#x27;.</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9090&quot;</span>]</span><br></pre></td></tr></table></figure><ul><li>global: 控制prometheus服务行为的安全配置<ul><li>scrape_interval: 指定应用程序或服务抓取数据的时间间隔</li><li>evaluation_interval: 用来指定Prometheus评估规则的频率。目前有两种规则：<ul><li>记录规则：允许预先计算使用频率且开销大的表达式，并将结果保存为一个新的时间序列数据。</li><li>报警规则：允许定义报警条件</li></ul></li></ul></li><li>alerting: 用来设置Prometheus的报警</li><li>rule_files: 指定包含记录规则或报警规则的文件列表。</li><li>scrape_configs：用来指定prometheus抓取的所有目标。</li></ul><h3 id="启动程序"><a href="#启动程序" class="headerlink" title="启动程序"></a>启动程序</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/prometheus</span><br><span class="line">cp prometheus.yml /etc/prometheus/</span><br><span class="line">prometheus --help</span><br><span class="line">prometheus --config.file &quot;/etc/prometheus/prometheus.yml&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">代码校验工具</span></span><br><span class="line">promtool check config prometheus.yml</span><br><span class="line">Checking prometheus.yml</span><br><span class="line"> SUCCESS: prometheus.yml is valid prometheus config file syntax</span><br></pre></td></tr></table></figure><h3 id="使用Docker运行Prometheus"><a href="#使用Docker运行Prometheus" class="headerlink" title="使用Docker运行Prometheus"></a>使用Docker运行Prometheus</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus/</span><br></pre></td></tr></table></figure><p>访问：<a href="http://ip:9090/graph">http://ip:9090/graph</a></p><p><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">https://prometheus.io/docs/prometheus/latest/querying/basics/</a></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>quantile=<span class="string">&quot;0.5&quot;</span><span class="punctuation">,</span>instance=<span class="string">&quot;localhost:9090&quot;</span><span class="punctuation">,</span>__name__=<span class="string">&quot;go_gc_duration_seconds&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><a href="https://graphiteapp.org/#gettingStarted">https://graphiteapp.org/#gettingStarted</a></p><p><a href="https://www.robustperception.io/translating-between-monitoring-languages/">https://www.robustperception.io/translating-between-monitoring-languages/</a></p><h3 id="使用prometheus-grafana-node-exporter搭建机器的监控"><a href="#使用prometheus-grafana-node-exporter搭建机器的监控" class="headerlink" title="使用prometheus + grafana + node_exporter搭建机器的监控"></a>使用prometheus + grafana + node_exporter搭建机器的监控</h3><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><ul><li><p>prometheus的下载见上面的步骤</p></li><li><p>grafana的下载：<a href="https://grafana.com/grafana/download?edition=oss">https://grafana.com/grafana/download?edition=oss</a></p><ul><li>分两个版本，一个是企业版，一个是OSS版本，也可以使用docker版本</li><li><code>docker run -d -p 3000:3000 --name grafana grafana/grafana-enterprise:9.4.7</code></li></ul></li><li><p>node_exporter 下载：<a href="https://github.com/prometheus/node_exporter">https://github.com/prometheus/node_exporter</a></p></li></ul><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><ul><li><p>要实现<code>Node Exporter Full</code>这个功能，请先参考文章，<a href="https://grafana.com/grafana/dashboards/1860-node-exporter-full/">https://grafana.com/grafana/dashboards/1860-node-exporter-full/</a></p></li><li><p>先配置<code>prometheus</code>，在<code>/etc/prometheus/prometheus.yml</code>中添加如下配置</p></li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># my global config</span></span><br><span class="line"><span class="attr">global:</span></span><br><span class="line">  <span class="attr">scrape_interval:</span> <span class="string">15s</span> <span class="comment"># Set the scrape interval to every 15 seconds. Default is every 1 minute.</span></span><br><span class="line">  <span class="attr">evaluation_interval:</span> <span class="string">15s</span> <span class="comment"># Evaluate rules every 15 seconds. The default is every 1 minute.</span></span><br><span class="line">  <span class="comment"># scrape_timeout is set to the global default (10s).</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Alertmanager configuration</span></span><br><span class="line"><span class="attr">alerting:</span></span><br><span class="line">  <span class="attr">alertmanagers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">static_configs:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">targets:</span></span><br><span class="line">          <span class="comment"># - alertmanager:9093</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rule_files:</span></span><br><span class="line">  <span class="comment"># - &quot;first_rules.yml&quot;</span></span><br><span class="line">  <span class="comment"># - &quot;second_rules.yml&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">&quot;prometheus&quot;</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&quot;localhost:9090&quot;</span>]  </span><br><span class="line">  <span class="bullet">-</span> <span class="attr">job_name:</span> <span class="string">node</span></span><br><span class="line">    <span class="attr">static_configs:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">targets:</span> [<span class="string">&#x27;localhost:9100&#x27;</span>]</span><br></pre></td></tr></table></figure><ul><li>配置完成后启动<code>prometheus</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prometheus --config.file &quot;/etc/prometheus/prometheus.yml&quot;</span><br></pre></td></tr></table></figure><ul><li>把node_exporter命令放入路径<code>/usr/local/bin</code>路径下，并启动node_exporter。</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node_exporter --collector.systemd --collector.processes</span><br></pre></td></tr></table></figure><ul><li>解压grafana软件包，或者使用grafana docker镜像</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令行方式</span></span><br><span class="line">./grafana_server</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">docker 启动方式</span></span><br><span class="line">docker run -d -p 3000:3000 --name grafana grafana/grafana-enterprise:9.4.7</span><br></pre></td></tr></table></figure><p>到此，都全部都配置完成了。</p><h3 id="配置监控"><a href="#配置监控" class="headerlink" title="配置监控"></a>配置监控</h3><p>验证prometheus是否启动成功，浏览器地址栏中输入 <code>ip:9090/graph</code>，看是否有下面的页面。</p><p><img src="https://github.com/MarkShen1992/markshen1992.github.io/assets/40328786/4cc08049-13a3-42c2-adad-6918e7e4eba7" alt="1"></p><p>接下来是验证grafana是否启动成功，在浏览器中输入<code>ip:3000</code>,能看到下面页面就成功了。</p><p><img src="https://github.com/MarkShen1992/markshen1992.github.io/assets/40328786/a6983db4-68f5-4f59-b5b5-a0acd1baea57" alt="2"></p><p>输入用户名和密码，默认的是<code>admin/admin</code>. 用默认密码登录后，请马上更新新的密码。</p><p><img src="https://github.com/MarkShen1992/markshen1992.github.io/assets/40328786/5e79a6d1-200d-416c-8661-0e6cf65f1846" alt="3"></p><p>接下来创建dashboard，新建一个tab页，输入网址<a href="https://grafana.com/grafana/dashboards/1860-node-exporter-full/">https://grafana.com/grafana/dashboards/1860-node-exporter-full/</a></p><p><img src="https://github.com/MarkShen1992/markshen1992.github.io/assets/40328786/f00ffda4-f33e-4dd3-926b-3f6fd961fa15" alt="4"></p><p>具体操作如下面这个gif图片中所示，按照图片下来就已经配置完成了，这里还用到了视频转gif的网站：<a href="https://www.img2go.com/zh/convert-video-to-gif">https://www.img2go.com/zh/convert-video-to-gif</a></p><p><img src="https://github.com/MarkShen1992/markshen1992.github.io/assets/40328786/e6c63884-c309-4cac-a4db-20312d35bc6e" alt="Video_2024-02-03_214731"></p><p>本文暂时告一段落~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 监控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>请告诉孩子，原来这才是正确的读书方式</title>
      <link href="/blog/2024/01/26/%E8%AF%B7%E5%91%8A%E8%AF%89%E5%AD%A9%E5%AD%90%EF%BC%8C%E5%8E%9F%E6%9D%A5%E8%BF%99%E6%89%8D%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%AF%BB%E4%B9%A6%E6%96%B9%E5%BC%8F/"/>
      <url>/blog/2024/01/26/%E8%AF%B7%E5%91%8A%E8%AF%89%E5%AD%A9%E5%AD%90%EF%BC%8C%E5%8E%9F%E6%9D%A5%E8%BF%99%E6%89%8D%E6%98%AF%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%AF%BB%E4%B9%A6%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="请告诉孩子，原来这才是正确的读书方式"><a href="#请告诉孩子，原来这才是正确的读书方式" class="headerlink" title="请告诉孩子，原来这才是正确的读书方式"></a>请告诉孩子，原来这才是正确的读书方式</h2><blockquote><p><strong>编者按：</strong></p><p>很多人经常在问，读书到底为了什么？读书和做人又有什么关系？</p><p>关于读书，董宇辉说过这样一段话：“读书不一定能让你前程似锦，功成名就，但至少可以让你出言有尺，嬉闹有度，说话有德，做事有余。读书能够让你有更大的心胸，更坚定的认知，更周全的理解，更美好的追求，更稳定的内核，而不是把你变成书呆子。”</p><p>“知者行之始，行者知之成。”读书不仅仅是为了打发时间，也不仅仅是应付考试，关于读书真正的意义，楼宇烈老先生在《中国文化的根本精神》一书中，也给出了答案，我们一起来看看。</p></blockquote><h2 id="读书与做人"><a href="#读书与做人" class="headerlink" title="读书与做人"></a>读书与做人</h2><p>“读书与做人”这个题目中有两个词，一个是读书，一个是做人，中间加了一个“与”字。我想，最好把这个“与”字改成一个等号，即：读书=做人，做人=读书。</p><p>清初学者陆陇其说过，读书做人不是两件事。<strong>将所读之书，句句落实到自己身上，便是做人之法，如此方叫得能读书。</strong>如果不落实到自己身上去领会书中的道理，则读书自读书，做人自做人，只算作不能读书的人。我认为，一定要让读书与做人变成一回事，不要把它看作两件事。</p><h3 id="读书的第一个目的是通晓人道，明白事理。"><a href="#读书的第一个目的是通晓人道，明白事理。" class="headerlink" title="读书的第一个目的是通晓人道，明白事理。"></a><strong>读书的第一个目的是通晓人道，明白事理。</strong></h3><p>通晓人道，即要懂得怎样做人。《淮南子》一书中有这样一段话：“遍知万物而不知人道，不可谓智；遍爱群生而不爱人类，不可谓仁。”当今社会的状况跟古代相似，很多人知识很丰富，知晓群生万物的道理，就是不懂得怎样做人，我们不能说这样的人有智慧；很多人爱万物群生，却唯独不爱惜人类自己，那么就不能说这样的人具有仁这种德行。</p><p>在中国传统文化中，观察、思考问题都是从人入手的。以人为本的人文精神的根本特点就是看一切问题都和人联系在一起，都要思考它对人有何教益。</p><h3 id="读书的第二个目的是变化气质，完善人格。"><a href="#读书的第二个目的是变化气质，完善人格。" class="headerlink" title="读书的第二个目的是变化气质，完善人格。"></a><strong>读书的第二个目的是变化气质，完善人格。</strong></h3><p>我们不是只懂得道理就可以了，就像陆陇其所说的，要学一句就对照一下自己，并督促自己按照正确方法去做。在没有学习之前，我们不明白事理，不通晓人道，这没有关系。<strong>在学习之后，我们就要根据所明白的事理，所通晓的人道去改变自己。</strong>学和行、知和行一定要结合起来，只学而不行是毫无意义的。</p><p>中国传统文化重视“为己之学”。在《论语》一书中，孔子说：“古之学者为己，今之学者为人。”从字面的意义上看，今人要比古人好，古人学习是为自己打算，今人学习是为别人打算。<strong>其实不断完善自己，提升自己的学问才是为己之学，它不是为了炫耀给别人看。</strong>荀子说：“君子之学也，以美其身；小人之学也，以为禽犊。”这也就是说君子之学是为了完善自己，提升自己的学问，而小人之学是将学问当作礼物来取悦别人的，从耳朵里听进去，嘴里就说出来了，只不过丝毫没有提升自己。</p><h3 id="读书还有第三个目的是拓展知识，学习技能。"><a href="#读书还有第三个目的是拓展知识，学习技能。" class="headerlink" title="读书还有第三个目的是拓展知识，学习技能。"></a><strong>读书还有第三个目的是拓展知识，学习技能</strong>。</h3><p>这三个目的是有先后顺序的，通晓人道，明白事理是第一位的，然后再去改变气质，完善人格，最后通过实践去拓展我们的知识和技能。就像孔子讲的：“弟子入则孝，出则悌，谨而信，泛爱众，而亲仁。行有余力，则以学文。”(《论语·学而》)我们首先要“志于道”。学习做人的道理，连人都做不好，事情怎么能做好呢?其实，一个人不管做什么事，都要看他有没有胸怀、志向。我们做任何事决不能仅仅为了个人享乐。反之，<strong>我们要胸怀大志，为国为民，志存高远，行在脚下。</strong>我们也不能只有高远的志向，夸夸其谈，而不去行动。</p><h3 id="我们应该读什么样的书呢？"><a href="#我们应该读什么样的书呢？" class="headerlink" title="我们应该读什么样的书呢？"></a><strong>我们应该读什么样的书呢？</strong></h3><p>中国有句老话，叫作“开卷有益”，意思是读什么书都是可以的。但是，我们最好还是要有所选择，因为我们会被书中负面的内容所干扰。书籍是五花八门、琳琅满目的，可读之书非常多，中国传统文化典籍可分为甲、乙、丙、丁四类，或者叫经、史、子、集四类。</p><p><strong>经书可以说是具有长久生命力的经典。</strong>所谓“经者，常也”，它是讲贯穿古今、万物，认识天道、地道、人道最根本的道理，这就是经。先秦时就提出了“六经”的概念。即《诗》《书》《礼》《乐》《春秋》。经书后来又有所扩展，增加了《论语》《孟子》《孝经》《尔雅》。除了《仪礼》这部经典之外，又添加了解释礼的书《礼记》。</p><p><strong>通过读经书，我们就可以明天理，晓人道，知道应该怎样做人、做事，我们的言行举止应该遵什么样的规矩。</strong>“没有规矩不成方圆”，人的行为也是如此。大家也许都很喜欢孔子的话：“七十而从心所欲。”但是，我们不要忘了后面还有三个字：“不逾矩。”</p><p><strong>礼教告诉人们应该遵守的言行举止方面的规矩</strong>，其根本目的就是让我们认识到自己是一个什么身份的人，这样身份的人应该遵守什么样的规矩。很多人可能一听到这些就会头痛，觉得它是封建礼教的腐朽思想。我常讲，人如果想活得自由就必须要遵守规矩，如果所做的事情不符合身份，那就会四面碰壁。如果每个社会成员都能够尽伦尽职，这个社会一定是和谐的。尽伦尽职就是要求：在什么位置上，就应该尽这个位置上的职。</p><p><strong>史，即历史，是明古今之变的。</strong>司马迁讲天下的学问无非两大类，“究天人之际，通古今之变”。前者是探究人跟天地万物之间的关系；后者就是来了解人类社会的人事变动、朝代更替的经验教训。史学具有非常重要的作用，中国文化中有两个重要的传统：一个是“以史为鉴”；另一个是“以天为则”。唐太宗讲：“以铜为鉴，可正衣冠；以古为鉴，可知兴替。”古人强调“观今宜鉴古”，要看出今天的问题，要拿来说当一面镜子照一下。</p><p>历史承载着文化，一个不懂得自己国家民族文化的人，让他来热爱自己的国家，对中国传统文化有信心，这怎么可能呢？因此，清代学者龚自珍讲了一句非常深刻的话：<strong>“欲知大道，必先为史。灭人之国，必先去其史。”</strong></p><p><strong>子书就是各种不同的学派对天道、地道、人道的认识。</strong>我们的世界本来就是丰富多彩的，人们会从不同的角度去观察、思考，也会有不同的解释，这就是我们常常讲的文化的多样性、多元性。《孟子》里有一句话：“物之不齐，物之性也。”通过学习诸子百家对事物的不同看法，可以增长我们的智慧。</p><p>集部就更复杂多样了。<strong>集部里又分总集、别集、专集。读集部的书，可以长见识、养情性。</strong>文学、艺术作品等都归在集部中。集部的书，让我们从各个方面去体悟人生，可以让我们成为一个有艺术生活的人。我希望每个人多一点业余爱好，在艺术的人生里去发掘、学习人生的艺术，干巴巴的人生是总结不出人生的艺术的。<strong>读书要读出智慧来，不要读成知识的奴隶。</strong></p><h3 id="怎样读书呢？"><a href="#怎样读书呢？" class="headerlink" title="怎样读书呢？"></a><strong>怎样读书呢？</strong></h3><p>从根本上讲，<strong>读书就是要“得其意”，能够举一反三。</strong></p><p>《增广贤文》中有一句话“好书不厌百回读”，好的书我们读一百遍都不会厌倦。</p><p>我在后面接了一句“精意勤求十载功”，我们求得“精意”，恐怕要花10年的工夫。现在读书或者做学问时，常常是把简单的问题复杂化，化简为繁常被看作是有学问的体现。</p><p>其实，<strong>大道至简，真理平凡。</strong>例如，很多人学佛，总觉得学佛好像很深奥，修行很神秘。我认为，<strong>修行的真谛是平静地对待每天都要碰到的事情，做好自己的本分。</strong></p><h3 id="读书的次第是什么？"><a href="#读书的次第是什么？" class="headerlink" title="读书的次第是什么？"></a><strong>读书的次第是什么？</strong></h3><p>我觉得就是《中庸》中所说的：<strong>博学、审问、慎思、明辨、笃行。</strong></p><p>什么叫“博学”？黄侃先生讲过一句话：“所谓博学者，谓明白事理多，非记事多也。”<strong>博学是因为明白很多事理，而不是记住了很多事情。</strong>明白事理是一种智慧，中国的传统文化是一种学智慧的文化，而不是单纯的学知识的文化。知识是静止的，智慧是变动的，智慧是一种发现、掌握、运用知识的能力。</p><p><strong>审问就是要多问为什么，要不耻下问。</strong>子日：“三人行，必有我师焉。”(《论语·述而》)我们身边永远都有值得学习的人和事，不要以自己的长处去比别人的短处，那就没有学习的必要了，我们应该<strong>时刻看到自己的不足</strong>。</p><p><strong>慎思，即认真的思考。</strong>孔子说：“君子有九思：视思明，听思聪，色思温，貌思恭，言思忠，事思敬，疑思问，忿思难，见得思义。”(《论语·季氏》)我们碰到事情就要思考，读书更要思考。慎思然后就要明辨，分辨是非、疑惑，<strong>知道哪些事情该做，哪些事情不该做</strong>等等。</p><p><strong>笃行，即身体力行。</strong>荀子讲：“知之不若行之，学至于行而止矣。”(《荀子·儒效》)明白不如做到，<strong>学到并做到，才算达到了读书的最高境界。</strong></p><p>智、仁、勇这三种品德是每个人都应该具备的，《中庸》里讲：“好学近乎知，力行近乎仁，知耻近乎勇。”老子说：“知人者智，自知者明。胜人者有力，自胜者强。”人最难的就是做到“自知”，<strong>人贵有白知之明，人更贵有自胜之强，能够战胜自己的人才是强者。</strong></p><p>一个社会永远是有善恶、美丑的，我们不能太理想主义。人的身体、社会现象的平衡不是简单的百分之五十和百分之五十的比例，也许有的是要这个百分之七十，那个百分之三十才是平衡，很多事情都不能一概而论。</p><p>和谐、平衡不是我迁就你，你迁就我，而是你尊重我，我尊重你，保持各自的差异和特点，不需要改变我的看法来附和你，也不需要改变你的看法来附和我，这才叫和谐、平衡。</p><p>原文链接：<a href="https://mp.weixin.qq.com/s/7uXyVP4E58d4153aQtIvOA">请告诉孩子，原来这才是正确的读书方式 (qq.com)</a> 本文摘自楼宇烈《中国文化的根本精神》</p>]]></content>
      
      
      
        <tags>
            
            <tag> 知行合一 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C中的int a = 4;对应的汇编码</title>
      <link href="/blog/2024/01/07/C%E8%AF%AD%E8%A8%80%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E5%AF%B9%E5%BA%94%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/"/>
      <url>/blog/2024/01/07/C%E8%AF%AD%E8%A8%80%E5%AE%9A%E4%B9%89%E5%8F%98%E9%87%8F%E5%AF%B9%E5%BA%94%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80/</url>
      
        <content type="html"><![CDATA[<p>下面的代码对应的汇编是什么呢？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123;</span><br><span class="line"><span class="type">int</span> a == <span class="number">4</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接下来，从ubuntu中使用<code>gcc</code>命令编译下的结果如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -S -fno-asynchronous-unwind-tables demo.c</span><br></pre></td></tr></table></figure><p>生成的汇编代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">        .file   &quot;demo.c&quot;</span><br><span class="line">        .text</span><br><span class="line">        .globl  func1</span><br><span class="line">        .type   func1, @function</span><br><span class="line">func1:</span><br><span class="line">        endbr64</span><br><span class="line">        pushq   %rbp</span><br><span class="line">        movq    %rsp, %rbp</span><br><span class="line">        movl    $1, -4(%rbp)</span><br><span class="line">        nop</span><br><span class="line">        popq    %rbp</span><br><span class="line">        ret</span><br><span class="line">        .size   func1, .-func1</span><br><span class="line">        .ident  &quot;GCC: (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0&quot;</span><br><span class="line">        .section        .note.GNU-stack,&quot;&quot;,@progbits</span><br><span class="line">        .section        .note.gnu.property,&quot;a&quot;</span><br><span class="line">        .align 8</span><br><span class="line">        .long   1f - 0f</span><br><span class="line">        .long   4f - 1f</span><br><span class="line">        .long   5</span><br><span class="line">0:</span><br><span class="line">        .string &quot;GNU&quot;</span><br><span class="line">1:</span><br><span class="line">        .align 8</span><br><span class="line">        .long   0xc0000002</span><br><span class="line">        .long   3f - 2f</span><br><span class="line">2:</span><br><span class="line">        .long   0x3</span><br><span class="line">3:</span><br><span class="line">        .align 8</span><br><span class="line">4:</span><br></pre></td></tr></table></figure><ul><li><p><a href="https://hjlarry.github.io/sicp/asm/">汇编语言知识</a></p><ul><li><a href="https://github.com/hjlarry/hjlarry.github.io">bak</a></li></ul></li><li><p><a href="https://cdrdv2-public.intel.com/782156/325383-sdm-vol-2abcd.pdf">Instruction Set Reference, A-Z</a></p></li></ul><p>以上仅仅是一个简单例子，可以使用上面的方法来看一看c语言中的那些关键字都是怎么实现的。实现方式都是基于CPU中的ISA(Instruction Set Architecture)来实现的。</p><p>使用gcc生成汇编代码除了上面的命令还是如下的方法</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -Og -S xxx.c</span><br></pre></td></tr></table></figure><p>生成<code>xxx.o</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -Og -c xxx.c</span><br></pre></td></tr></table></figure><p>将<code>xxx.o</code>文件反汇编成<code>xxx.s</code>文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objdump -d xxx.o</span><br></pre></td></tr></table></figure><p>本文会不断完善，c语言关键字对应的汇编码。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 汇编语言 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机基础课程</title>
      <link href="/blog/2024/01/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B/"/>
      <url>/blog/2024/01/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E8%AF%BE%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>任何行业想要走的远，要有足够扎实的基础，对于计算机行业的话，也有一些我们从业人员必须学习的基础知识，包括计算机组成原理，计算机操作系统，数据结构与算法，计算机网络，计算机编译原理。</p><blockquote><p>首先大家要有亮剑精神哈，计算机这些技术都是非常硬核的，所以会很难啃，但是要想成为专业的技术人才，这些课程是一定要从头到尾啃完的，加油！</p></blockquote><h2 id="计算机组成原理"><a href="#计算机组成原理" class="headerlink" title="计算机组成原理"></a>计算机组成原理</h2><h3 id="推荐书籍"><a href="#推荐书籍" class="headerlink" title="推荐书籍"></a>推荐书籍</h3><ul><li><a href="https://book.douban.com/subject/26912767/">深入理解计算机系统</a></li></ul><h3 id="推荐视频"><a href="#推荐视频" class="headerlink" title="推荐视频"></a>推荐视频</h3><ul><li><a href="https://www.bilibili.com/video/BV1Xu411r7Vz/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">【哈工大】计算机组成原理 刘宏伟（全 41 讲）</a></li></ul><h2 id="计算机操作系统"><a href="#计算机操作系统" class="headerlink" title="计算机操作系统"></a>计算机操作系统</h2><h3 id="推荐视频-1"><a href="#推荐视频-1" class="headerlink" title="推荐视频"></a>推荐视频</h3><ul><li><a href="https://jyywiki.cn/">蒋炎岩·南京大学</a><ul><li><a href="https://www.bilibili.com/video/BV1N741177F5?p=2&spm_id_from=pageDriver&vd_source=901e0b3c23d3cff6094d75383834207f">2020 南京大学 “操作系统：设计与实现</a></li><li><a href="https://www.bilibili.com/video/BV1HN41197Ko/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">2021 南京大学 “操作系统：设计与实现</a></li><li><a href="https://www.bilibili.com/video/BV1Cm4y1d7Ur/">2022 南京大学 “操作系统：设计与实现</a></li><li><a href="https://www.bilibili.com/video/BV1Xx4y1V7JZ/">2023 南京大学 “操作系统：设计与实现</a></li><li><a href="https://www.bilibili.com/video/BV1Xm411f7CM/">2024 南京大学 “操作系统：设计与实现</a></li><li><a href="https://www.bilibili.com/video/BV1XZAbeqEyt/">2025 南京大学 “操作系统：设计与实现</a></li></ul></li><li>李治军·哈工大<ul><li><a href="https://www.bilibili.com/video/BV19r4y1b7Aw/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">操作系统 李治军（全 32 讲）</a></li></ul></li></ul><h2 id="数据结构与算法"><a href="#数据结构与算法" class="headerlink" title="数据结构与算法"></a>数据结构与算法</h2><h3 id="推荐书籍-1"><a href="#推荐书籍-1" class="headerlink" title="推荐书籍"></a>推荐书籍</h3><ul><li><a href="https://www.hello-algo.com/">hello-algo</a></li><li><a href="https://book.douban.com/subject/19952400/">算法</a></li><li><a href="https://book.douban.com/subject/20432061/">算法导论</a></li></ul><h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><h3 id="推荐视频-2"><a href="#推荐视频-2" class="headerlink" title="推荐视频"></a>推荐视频</h3><ul><li><a href="https://www.bilibili.com/video/BV19M411S7V7/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">《计算机网络：自顶向下方法》原书视频教学，作者 Jim Kurose 亲授</a></li><li><a href="https://www.bilibili.com/video/BV1JV411t7ow/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">中科大郑烇、杨坚全套《计算机网络（自顶向下方法 第 7 版，James F.Kurose，Keith W.Ross）》课程</a></li></ul><h2 id="计算机编译原理"><a href="#计算机编译原理" class="headerlink" title="计算机编译原理"></a>计算机编译原理</h2><h3 id="推荐视频-3"><a href="#推荐视频-3" class="headerlink" title="推荐视频"></a>推荐视频</h3><ul><li><a href="https://www.bilibili.com/video/BV1dL4y1H7T8/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">【编译原理】哈工大公开课（高清版）</a></li><li><a href="https://www.bilibili.com/video/BV17W41187gL/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">编译原理 — 中科大</a></li><li><a href="https://www.bilibili.com/video/BV1NE411376V/?spm_id_from=333.337.search-card.all.click&vd_source=901e0b3c23d3cff6094d75383834207f">CS143 斯坦福大学编译原理</a></li></ul><h2 id="其他资源"><a href="#其他资源" class="headerlink" title="其他资源"></a>其他资源</h2><h3 id="推荐书籍-2"><a href="#推荐书籍-2" class="headerlink" title="推荐书籍"></a>推荐书籍</h3><ul><li><a href="https://book.douban.com/subject/20260928/">编码</a></li><li><a href="https://csdiy.wiki/">CS 自学指南</a><ul><li><a href="https://github.com/PKUFlyingPig/cs-self-learning">https://github.com/PKUFlyingPig/cs-self-learning</a></li></ul></li><li><a href="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 计算机基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《小狗钱钱》 读书笔记</title>
      <link href="/blog/2024/01/03/%E5%B0%8F%E7%8B%97%E9%92%B1%E9%92%B1/"/>
      <url>/blog/2024/01/03/%E5%B0%8F%E7%8B%97%E9%92%B1%E9%92%B1/</url>
      
        <content type="html"><![CDATA[<h2 id="财富的法则"><a href="#财富的法则" class="headerlink" title="财富的法则"></a>财富的法则</h2><ol><li><p>首先，要确定金钱对你意味着什么。</p></li><li><p>明确你最重要的目标，也就是说，即使你有一个长长的“愿望清单”，也要从中挑选出最重要的那几个。</p></li><li><p>梦想存储罐和梦想相册为什么很重要？如何让潜意识为我们提供支持，而我们又必须提前做好哪些功课？</p></li><li><p>为什么更高的收入从来都不是解决财务问题的办法？</p></li><li><p>如何才能永不退缩地坚持自己的梦想与计划？想象的艺术（视觉化练习）。</p></li><li><p>困难常常发生。总会有人阻挠我们实现既定的目标，他们往往还是我们的朋友和家人。但有一些简单的方法和途径可以使我们免于被误导。</p></li><li><p>为什么成功日记会让我们的收入步步攀升？为何自信会带来颠覆性的影响？</p></li><li><p>怎样将最大的爱好变成职业，进而大大改善收入状况？</p></li><li><p>区分重要性和紧急性。无论顺境还是逆境，都不能放弃我们的美好愿望与计划。</p></li><li><p>贯彻实施的关键：72小时法则。</p></li><li><p>如何挣到很多钱-以游戏般轻松愉快的方式。</p></li><li><p>摆脱债务最重要的四条原则。</p></li><li><p>“鹅与金蛋”的故事-如何用钱生钱？</p></li><li><p>如何正确高效地与银行打交道并乐在其中？</p></li><li><p>幸福的本质是什么？我们如何才能获得更多的幸福？</p></li><li><p>喜欢钱有什么不对吗？安全保存现金都有什么诀窍？</p></li><li><p>金钱是“中性的”，是什么意思？金钱与幸福之间有什么关系？</p></li><li><p>为什么将我们所得的一部分用于馈赠是重要的？</p></li><li><p>应对恐惧的最好办法是什么？成功日记能对此起到什么作用？</p></li><li><p>让我们的财富增值的最好方式之一：成立投资俱乐部。保证投资成功的五大准则。</p></li><li><p>怎么才能魔法般地从无到有创造金钱？</p></li><li><p>最重要的三大投资法则。</p></li><li><p>什么是股票？股票是如何运作？利润（价格收益和股息红利）如何产生？你是否适合股票投资？你将会很快掌握其中诀窍。</p></li><li><p>为什么时不时地走出舒适区，去做一些以前感觉恐惧的事情，对我们很重要？</p></li><li><p>如何获得8%-10%的年收益率？什么是最佳的投资形式和最佳投资策略？</p></li><li><p>为什么股票基金非常安全并能获得可观的利润？筛选出靠谱基金的三个标准。</p></li><li><p>投资基金为什么很简单？</p></li><li><p>通过投资基金，你的钱会如何实现增长-复利的力量。</p></li><li><p>波动率：如何平衡风险和盈利？</p></li><li><p>如何快速计算利息和复利？</p></li><li><p>如果股票价格下跌该怎么办？如何在这种情况下赚取高额收益？</p></li><li><p>想要通过投资基金获得可靠的高收益，都需要了解什么？</p></li><li><p>通货膨胀的真正含义是什么？如何快速计算出它对你的财富的影响？如何使通货膨胀成为你最好的朋友-只要你选择了正确的投资方式。</p></li><li><p>金钱如何影响我们的生活的其他方面？当我们越来越深入地理解金钱，最终会有什么收获？</p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 财富 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper学习笔记</title>
      <link href="/blog/2023/10/26/ZooKeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/blog/2023/10/26/ZooKeeper%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="软件简介"><a href="#软件简介" class="headerlink" title="软件简介"></a>软件简介</h2><ul><li>Apache ZooKeeper is an open-source server for highly reliable distributed coordination of cloud applications.<a href="https://www.bilibili.com/video/BV1mw411d7Cc/?spm_id_from=333.337.search-card.all.click">2</a> It is a project of the Apache Software Foundation.</li><li>ZooKeeper is essentially a service for distributed systems offering a hierarchical key-value store, which is used to provide a distributed configuration service, synchronization service, and naming registry for large distributed systems (see Use cases).<a href="https://cn.dubbo.apache.org/zh-cn/">3</a> ZooKeeper was a sub-project of Hadoop but is now a top-level Apache project in its own right.</li><li>如果你想了解更多信息，可以访问软件的官网:<ul><li><a href="https://zookeeper.apache.org/doc/r3.9.1/index.html">https://zookeeper.apache.org/doc/r3.9.1/index.html</a></li></ul></li></ul><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><h3 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h3><ul><li>在软件安装前，要先下载软件，可以到官网的下载页面下载软件，我们使用的软件版本是 3.6.4，请注意，选择这个版本仅是学习使用，如果要在线上环境使用，请选择非 EoL 版本。<ul><li><a href="https://zookeeper.apache.org/releases.html">https://zookeeper.apache.org/releases.html</a></li></ul></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 软件下载</span></span><br><span class="line">wget https://archive.apache.org/dist/zookeeper/zookeeper-3.6.4/apache-zookeeper-3.6.4-bin.tar.gz</span><br></pre></td></tr></table></figure><ul><li>在本软件安装教程中前置条件<ul><li>虚拟机软件 VMWare16 pro</li><li>操作系统：CentOS 7</li><li>JDK 的安装可以参照之前的文章<a href="http://markshen1992.top/2023/10/23/Java%E5%9C%A8Linux%E4%B8%8A%E5%AE%89%E8%A3%85/">在 Linux 系统上安装 Java 环境</a>一文</li></ul></li></ul><p>以上准备好之后，就可以进行软件安装了</p><h3 id="软件安装-1"><a href="#软件安装-1" class="headerlink" title="软件安装"></a>软件安装</h3><ul><li>创建软件安装目录</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p /opt/zk</span><br></pre></td></tr></table></figure><ul><li>将下载好的软件拷贝到这个目录中</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cp</span> apache-zookeeper-3.6.4-bin.tar.gz /opt/zk</span><br></pre></td></tr></table></figure><ul><li>解压软件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xvf apache-zookeeper-3.6.4-bin.tar.gz</span><br></pre></td></tr></table></figure><ul><li>进入软件路径修改软件配置</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> apache-zookeeper-3.6.4-bin/conf</span><br><span class="line"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure><ul><li>在配置文件中配置<code>ZK_HOME</code></li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 编辑 /etc/profile 文件</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"><span class="comment"># 添加如下代码</span></span><br><span class="line"><span class="comment">#ZK</span></span><br><span class="line"><span class="built_in">export</span> ZK_HOME=/opt/zk/apache-zookeeper-3.6.4-bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$ZK_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># 重新生效</span></span><br><span class="line"><span class="built_in">source</span>|. /etc/profile</span><br></pre></td></tr></table></figure><ul><li>启动 ZK</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start|stop|restart|status</span><br><span class="line"><span class="comment"># 启动软件的话，直接使用下面的命令</span></span><br><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><p>以上就可以在 CentOS7 上启动 ZK 了。</p><h2 id="ZK-集群环境搭建"><a href="#ZK-集群环境搭建" class="headerlink" title="ZK 集群环境搭建"></a>ZK 集群环境搭建</h2><p>对于集群环境，需要做的前置准备就是要准备三台虚拟机，现阶段给其做的规划如下表</p><table><thead><tr><th>IP 地址</th><th>ZK</th></tr></thead><tbody><tr><td>192.168.32.10</td><td>ZK1</td></tr><tr><td>192.168.32.11</td><td>ZK2</td></tr><tr><td>192.168.32.12</td><td>ZK3</td></tr></tbody></table><p>11，12 这两台机器是基于 10 虚拟机的镜像版本，如果这样的话，这三台虚拟机上都有 ZK 软件了，接下来的操作就是搭建集群环境了</p><ul><li>修改 10 机器上 ZK 的配置文件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/zk/apache-zookeeper-3.6.4-bin</span><br><span class="line"><span class="comment"># 创建data文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在进入存放配置的文件夹</span></span><br><span class="line"><span class="built_in">cd</span> conf</span><br><span class="line"><span class="comment"># 编辑配置文件</span></span><br><span class="line">vim zoo.cfg</span><br><span class="line"><span class="comment"># 修改 `dataDir` 属性为下面的值</span></span><br><span class="line">dataDir=/opt/zk/apache-zookeeper-3.6.4-bin/data</span><br><span class="line"><span class="comment"># 以下三行在配置文件末尾加</span></span><br><span class="line">server.1=192.168.32.10:2888:3888</span><br><span class="line">server.2=192.168.32.11:2888:3888</span><br><span class="line">server.3=192.168.32.12:2888:3888</span><br></pre></td></tr></table></figure><ul><li>将配制好的内容分发到其他两台计算机，同时创建 data 数据目录，再在这个目录下创建一个 myid 文件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在这个目录，创建myid文件</span></span><br><span class="line">/opt/zk/apache-zookeeper-3.6.4-bin/data</span><br><span class="line"><span class="comment"># 对于10那台机器:</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; myid</span><br><span class="line"><span class="comment"># 对于11那台机器</span></span><br><span class="line"><span class="built_in">echo</span> 2 &gt; myid</span><br><span class="line"><span class="comment"># 对于12那台机器</span></span><br><span class="line"><span class="built_in">echo</span> 3 &gt; myid</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将11，12两台机器上的zk全删除</span></span><br><span class="line"><span class="built_in">rm</span> -rf /opt/zk/apache-zookeeper-3.6.4-bin</span><br><span class="line"><span class="comment"># 将10上的zk分发到11，12服务器上，如果配置免密的话，执行这句话的时候不需要输入用户名密码</span></span><br><span class="line">scp -r /opt/zk/apache-zookeeper-3.6.4-bin/ root@192.168.32.11|12:/opt/zk</span><br><span class="line"><span class="comment"># 然后修改 /opt/zk/apache-zookeeper-3.6.4-bin/data 目录中的 myid 文件，将其该成对应的 2, 3</span></span><br></pre></td></tr></table></figure><ul><li>关闭系统防火墙</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#开启命令：</span></span><br><span class="line">systemctl start firewalld</span><br><span class="line"><span class="comment">#临时关闭命令：</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line"><span class="comment">#永久关闭命令：</span></span><br><span class="line">systemctl <span class="built_in">disable</span>|<span class="built_in">enable</span> firewalld</span><br></pre></td></tr></table></figure><ul><li>或者，开启指定的端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> firewall-cmd --zone=public --add-port=3000/tcp --permanent</span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --reload</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> firewall-cmd --remove-port=3000/tcp --permanent</span><br></pre></td></tr></table></figure><ul><li>启动服务，分别在三台机器上执行下面命令</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><ul><li>验证 ZK 是否启动成功以及服务具体角色，结果是一台机器上的 ZK 角色是 leader，其他两台角色是 follower</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh status</span><br></pre></td></tr></table></figure><h2 id="ZK-的使用场景"><a href="#ZK-的使用场景" class="headerlink" title="ZK 的使用场景"></a>ZK 的使用场景</h2><ul><li><a href="https://www.bilibili.com/video/BV1mw411d7Cc/?spm_id_from=333.337.search-card.all.click">分布式锁</a></li><li>服务注册发现，跟 <a href="https://cn.dubbo.apache.org/zh-cn/">Dubbo</a> 结合使用</li><li><a href="https://www.oreilly.com/library/view/kafka-the-definitive/9781492043072/">Kafka 集群搭建</a><ul><li>使用 ZK 存储 Kafka 集群元数据信息和消费者客户端详情</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在Linux系统上安装Java环境</title>
      <link href="/blog/2023/10/23/Java%E5%9C%A8Linux%E4%B8%8A%E5%AE%89%E8%A3%85/"/>
      <url>/blog/2023/10/23/Java%E5%9C%A8Linux%E4%B8%8A%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h2 id="软件安装前的准备"><a href="#软件安装前的准备" class="headerlink" title="软件安装前的准备"></a>软件安装前的准备</h2><ul><li>下载镜像，可以从站点：<a href="https://repo.huaweicloud.com/java/jdk">https://repo.huaweicloud.com/java/jdk</a> 下载。<ul><li>我下载的镜像是：jdk-8u202-linux-x64.tar.gz</li></ul></li><li>在解压软件前，把软件放在 <code>/opt</code> 目录下，如果没有这个目录的话，创建目录。</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 /opt 目录</span></span><br><span class="line"><span class="built_in">mkdir</span> /opt</span><br><span class="line"><span class="comment"># 把镜像文件拷贝到这个文件夹中</span></span><br><span class="line"><span class="built_in">cp</span> jdk-8u202-linux-x64.tar.gz /opt</span><br></pre></td></tr></table></figure><ul><li>解压命令解压软件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf jdk-8u202-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="软件安装"><a href="#软件安装" class="headerlink" title="软件安装"></a>软件安装</h2><ul><li>编辑 <code>/etc/profile</code> 文件，在文件最末尾添加如下代码：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/opt/jdk-8u202-linux-x64</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br></pre></td></tr></table></figure><ul><li>添加完后，<code>wq</code> 保存并退出，使用下面命令从新加载 <code>/etc/profile</code> 文件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><ul><li>然后执行下面命令判断是否执行成功</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">javac</span><br><span class="line">用法: javac &lt;options&gt; &lt;<span class="built_in">source</span> files&gt;</span><br><span class="line">其中, 可能的选项包括:</span><br><span class="line">  -g                         生成所有调试信息</span><br><span class="line">  -g:none                    不生成任何调试信息</span><br><span class="line">  -g:&#123;lines,vars,<span class="built_in">source</span>&#125;     只生成某些调试信息</span><br><span class="line">  -nowarn                    不生成任何警告</span><br><span class="line">  -verbose                   输出有关编译器正在执行的操作的消息</span><br><span class="line">  -deprecation               输出使用已过时的 API 的源位置</span><br><span class="line">  -classpath &lt;路径&gt;            指定查找用户类文件和注释处理程序的位置</span><br><span class="line">  -<span class="built_in">cp</span> &lt;路径&gt;                   指定查找用户类文件和注释处理程序的位置</span><br><span class="line">  -sourcepath &lt;路径&gt;           指定查找输入源文件的位置</span><br><span class="line">  -bootclasspath &lt;路径&gt;        覆盖引导类文件的位置</span><br><span class="line">  -extdirs &lt;目录&gt;              覆盖所安装扩展的位置</span><br><span class="line">  -endorseddirs &lt;目录&gt;         覆盖签名的标准路径的位置</span><br><span class="line">  -proc:&#123;none,only&#125;          控制是否执行注释处理和/或编译。</span><br><span class="line">  -processor &lt;class1&gt;[,&lt;class2&gt;,&lt;class3&gt;...] 要运行的注释处理程序的名称; 绕过默认的搜索进程</span><br><span class="line">  -processorpath &lt;路径&gt;        指定查找注释处理程序的位置</span><br><span class="line">  -parameters                生成元数据以用于方法参数的反射</span><br><span class="line">  -d &lt;目录&gt;                    指定放置生成的类文件的位置</span><br><span class="line">  -s &lt;目录&gt;                    指定放置生成的源文件的位置</span><br><span class="line">  -h &lt;目录&gt;                    指定放置生成的本机标头文件的位置</span><br><span class="line">  -implicit:&#123;none,class&#125;     指定是否为隐式引用文件生成类文件</span><br><span class="line">  -encoding &lt;编码&gt;             指定源文件使用的字符编码</span><br><span class="line">  -<span class="built_in">source</span> &lt;发行版&gt;              提供与指定发行版的源兼容性</span><br><span class="line">  -target &lt;发行版&gt;              生成特定 VM 版本的类文件</span><br><span class="line">  -profile &lt;配置文件&gt;            请确保使用的 API 在指定的配置文件中可用</span><br><span class="line">  -version                   版本信息</span><br><span class="line">  -<span class="built_in">help</span>                      输出标准选项的提要</span><br><span class="line">  -A关键字[=值]                  传递给注释处理程序的选项</span><br><span class="line">  -X                         输出非标准选项的提要</span><br><span class="line">  -J&lt;标记&gt;                     直接将 &lt;标记&gt; 传递给运行时系统</span><br><span class="line">  -Werror                    出现警告时终止编译</span><br><span class="line">  @&lt;文件名&gt;                     从文件读取选项和文件名</span><br></pre></td></tr></table></figure><p>以上，执行命令如上所示，即安装成功</p><p>完~</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我电脑上的软件</title>
      <link href="/blog/2023/07/30/%E6%88%91%E7%94%B5%E8%84%91%E4%B8%8A%E7%9A%84%E8%BD%AF%E4%BB%B6/"/>
      <url>/blog/2023/07/30/%E6%88%91%E7%94%B5%E8%84%91%E4%B8%8A%E7%9A%84%E8%BD%AF%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<ul><li><a href="https://www.sumatrapdfreader.org/free-pdf-reader">PDF 阅读器</a></li><li>命令行工具<ul><li><a href="https://mobaxterm.mobatek.net/">MobaXterm</a></li><li><a href="https://github.com/kingToolbox/WindTerm">WindTerm</a></li><li><a href="https://github.com/Eugeny/tabby">Tabby Terminal</a></li></ul></li><li>通讯软件<ul><li><a href="https://tim.qq.com/">Tim</a></li><li><a href="https://weixin.qq.com/">微信</a></li><li><a href="https://slack.com/">Slack</a></li></ul></li><li>开发工具<ul><li><a href="https://spring.io/tools/">SpringToolSuite</a></li><li><a href="https://code.visualstudio.com/">VsCode</a></li><li><a href="https://www.mysql.com/">MySQL</a></li><li><a href="https://dbeaver.io/">DBeaver</a></li><li><a href="https://github.com/winmerge/winmerge">代码版本比对合并工具-WinMerge</a></li><li><a href="https://www.virtualbox.org/">虚拟机-VirtualBox</a></li><li><a href="https://git-scm.com/">Git</a></li><li><a href="https://tortoisegit.org/">Git Tortoice</a></li></ul></li><li><a href="https://www.capcut.cn/">视频剪辑-剪映</a></li><li><a href="https://github.com/marktext/marktext">MarkDown 工具-marktext</a></li><li>远程工具<ul><li><a href="https://sunlogin.oray.com/">向日葵</a></li><li><a href="https://rustdesk.com/zh/">Rustdesk</a></li></ul></li><li><a href="https://www.voidtools.com/">电脑文件搜索-Everything</a></li><li><a href="https://www.videolan.org/vlc/">视频播放器-VLC media player</a></li><li><a href="https://www.drawio.com/">画图工具-draw.io</a></li><li>协作工具<ul><li><a href="https://meeting.tencent.com/">会议工具-腾讯会议</a></li><li><a href="https://www.notion.so/">notion</a></li><li><a href="https://docs.qq.com/">腾讯文档</a></li><li><a href="https://www.kdocs.cn/welcome">金山文档</a></li></ul></li><li><a href="https://www.cyotek.com/cyotek-webcopy/downloads">网站归档软件-WebCopy</a></li><li>网盘<ul><li><a href="https://www.aliyundrive.com/">阿里云盘</a></li><li><a href="https://pan.baidu.com/">百度云盘</a></li></ul></li><li><a href="https://www.wireshark.org/">网络抓包软件-wireshark</a></li><li>接口调试<ul><li><a href="https://www.postman.com/downloads/">Postman</a></li><li><a href="https://apifox.com/">Apifox</a></li></ul></li><li>Chrome 浏览器中的插件<ul><li>Cookie-Editor</li><li>CSS Peeper</li><li>JSON Formatter</li><li>Talend API Tester</li><li>Vue.js devtools</li><li>沙拉查词</li></ul></li><li><a href="https://obsproject.com/">推流软件-OBS</a></li><li><a href="https://pc.qq.com/detail/7/detail_2447.html">一款小众的思维导图工具-ThinkingExpress</a></li><li><a href="https://www.7-zip.org/">压缩软件-7zip</a></li><li>番茄时钟网页版<ul><li><a href="https://www.tomatolist.com/timer.html">番茄时钟</a></li><li><a href="https://alloyteam.github.io/AlloyTimer/">Alloy Timer</a></li><li><a href="https://pomofocus.io/">pomofocus</a></li><li><a href="https://www.tomatotimers.com/">tomatotimers</a></li></ul></li><li>硬件信息<ul><li><a href="https://www.ludashi.com/">鲁大师</a></li><li><a href="https://www.cpuid.com/softwares/cpu-z.html">CPUZ</a></li></ul></li><li>装机 U 制作<ul><li><a href="https://www.laomaotao.net/">老毛桃</a></li><li><a href="https://rufus.ie/en/">Rufus</a></li><li><a href="https://github.com/ventoy/Ventoy">Ventoy</a></li></ul></li><li>AI 工具<ul><li><a href="https://yiyan.baidu.com/welcome">文心一言</a></li><li><a href="https://qianwen.aliyun.com/">通义千问</a></li><li><a href="https://xinghuo.xfyun.cn/">讯飞星火认知大模型</a></li><li><a href="https://hunyuan.tencent.com/">混元大模型</a></li><li><a href="https://stackoverflow.ai/">Stackoverflow AI</a></li></ul></li></ul><p>未完，以后会不断更新~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 软件推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Github advanced search</title>
      <link href="/blog/2023/05/22/Github-advanced-search/"/>
      <url>/blog/2023/05/22/Github-advanced-search/</url>
      
        <content type="html"><![CDATA[<h2 id="Github-Advanced-Search"><a href="#Github-Advanced-Search" class="headerlink" title="Github Advanced Search"></a><a href="https://github.com/search/advanced">Github Advanced Search</a></h2><blockquote><p>学好 Github 搜索，可以在 Github 中找到自己需要的项目，一定要熟练使用 Github 的站内<strong>搜索</strong>。</p><p>学习文档如下:</p><ul><li><a href="https://docs.github.com/en/search-github">官网文档</a></li><li><a href="https://docs.github.com/zh/search-github">官方文档-zh</a></li><li><a href="https://docs.github.com/zh/search-github/getting-started-with-searching-on-github/about-searching-on-github">关于在 GitHub 上搜索</a></li></ul></blockquote><p>下图于 2023 年 5 月 22 日截取于 Github 网站。</p><p><img src="https://user-images.githubusercontent.com/40328786/239930540-11365707-cc8c-4705-9b7f-a583f781e151.png" alt="github_advanced_search"></p><h3 id="高级选项"><a href="#高级选项" class="headerlink" title="高级选项"></a>高级选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>user:MarkShen1992</td><td>github, atom, electron, octokit</td></tr><tr><td>repo:MarkShen1992/leet-code</td><td>twbs/bootstrap, rails/rails</td></tr><tr><td>created:&gt;2023-01-01</td><td>&gt;YYYY-MM-DD, YYYY-MM-DD</td></tr><tr><td>language:Java</td><td><a href="https://github.com/collections/programming-languages">programming lang</a></td></tr></tbody></table><h3 id="仓库选项"><a href="#仓库选项" class="headerlink" title="仓库选项"></a>仓库选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>stars:&gt;1000</td><td>0..100, 200, &gt;1000</td></tr><tr><td>forks:&gt;1000</td><td>50..100, 200, &lt;5</td></tr><tr><td>size:100KB</td><td>Repository size in KB</td></tr><tr><td>pushed:&lt;2020-01-01</td><td>&lt;YYYY-MM-DD</td></tr><tr><td>license:artistic-2.0</td><td>license:artistic-2.0</td></tr><tr><td>Return repositories {not|and|only} including forks.</td><td>-</td></tr></tbody></table><h3 id="Code-选项"><a href="#Code-选项" class="headerlink" title="Code 选项"></a>Code 选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>path:*.rb</td><td>rb, py, jpg</td></tr><tr><td>path:/net</td><td>/foo/bar/baz/qux</td></tr><tr><td>path:**/README.md</td><td>app.rb, footer.erb</td></tr><tr><td>Return code {not|and|only} including forks.</td><td>-</td></tr></tbody></table><h3 id="Issues-选项"><a href="#Issues-选项" class="headerlink" title="Issues 选项"></a>Issues 选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>state:open|close</td><td>open|close</td></tr><tr><td>reason:completed</td><td>completed|not planned|reopened</td></tr><tr><td>comments:100..1000</td><td>100..1000, 100, &gt;100, &gt;=100, &lt;100, &lt;=100</td></tr><tr><td>label:bug</td><td>bug, ie6</td></tr><tr><td>author:octocat</td><td>hubot, octocat</td></tr><tr><td>mentions:mattt</td><td>tpope, mattt</td></tr><tr><td>assignee:jim</td><td>twp, jim</td></tr><tr><td>updated:&lt;2020-01-01</td><td>&lt;2020-01-01</td></tr></tbody></table><h3 id="用户选项"><a href="#用户选项" class="headerlink" title="用户选项"></a>用户选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>fullname:MarkShen1992</td><td>Grace Hopper</td></tr><tr><td>location:San</td><td>San Francisco, CA</td></tr><tr><td>followers:20..50</td><td>20..50, &gt;100</td></tr><tr><td>repos:&lt;100</td><td>&lt;100, 100..200</td></tr><tr><td>language:C++</td><td><a href="https://github.com/collections/programming-languages">programming lang</a></td></tr></tbody></table><h3 id="Wiki-选项"><a href="#Wiki-选项" class="headerlink" title="Wiki 选项"></a>Wiki 选项</h3><table><thead><tr><th>具体用法</th><th>例子</th></tr></thead><tbody><tr><td>updated:&lt;2023-01-01</td><td>&lt;YYYY-MM-DD</td></tr></tbody></table><h3 id="平时经常使用的一些例子"><a href="#平时经常使用的一些例子" class="headerlink" title="平时经常使用的一些例子"></a>平时经常使用的一些例子</h3><ul><li>2020-01-01 之前的仓库</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">created:&lt;2020-01-01</span><br></pre></td></tr></table></figure><ul><li>git 学习资料</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 从repo名称和描述中匹配</span><br><span class="line">git 最好 学习 资料</span><br></pre></td></tr></table></figure><ul><li>基于上面的搜索结果, 我想搜索在 <code>readme</code> 文件中包含上面的词汇的项目, 或者在具体的某个文件。做推广, 每个工程的<code>readme</code>要好好设计里面的内容。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git 最好 学习 资料 in:readme</span><br></pre></td></tr></table></figure><ul><li>如何在原来的条件上再过滤，根据 <strong>stars</strong>，<strong>forks</strong>来搜索</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git 最好 学习 资料 in:readme stars:&gt;1000 forks:&gt;1000 language:Java</span><br></pre></td></tr></table></figure><ul><li>搜索自己想要的代码, 一定要<strong>登录</strong></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;after_script:&#x27; + &#x27;stage: deploy&#x27; filename:.gitlab-ci.yml</span><br></pre></td></tr></table></figure><ul><li>博客</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">blog easily start in:readme stars:&gt;5000</span><br></pre></td></tr></table></figure><h3 id="还有一些例子"><a href="#还有一些例子" class="headerlink" title="还有一些例子"></a><a href="https://gist.github.com/bonniss/4f0de4f599708c5268134225dda003e0">还有一些例子</a></h3><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> Github </tag>
            
            <tag> Search </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>知识源头集</title>
      <link href="/blog/2023/04/13/%E7%9F%A5%E8%AF%86%E6%BA%90%E5%A4%B4%E9%9B%86/"/>
      <url>/blog/2023/04/13/%E7%9F%A5%E8%AF%86%E6%BA%90%E5%A4%B4%E9%9B%86/</url>
      
        <content type="html"><![CDATA[<blockquote><p>如果要研究软件开发艺术，单纯研究代码是不够的，必须同时研究写下那些代码的人。</p></blockquote><blockquote><p>成为一名杰出的程序员其实跟写代码没有太大的关系。做程序员确实要一些技术能力，当然还要有坚韧不拔的精神。但除此之外，更重要的还是要有良好的沟通技巧。</p></blockquote><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul><li><a href="https://base64.guru/learn/what-is-base64">What is Base64?</a></li></ul><h2 id="前端"><a href="#前端" class="headerlink" title="前端"></a>前端</h2><ul><li><a href="https://www.json.org/json-zh.html">Json</a></li></ul><h2 id="SaaS"><a href="#SaaS" class="headerlink" title="SaaS"></a>SaaS</h2><ul><li><a href="https://12factor.net/zh_cn/">12-factors</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 知识源头 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>敏捷开发(Agile Develop)</title>
      <link href="/blog/2023/03/12/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91-Agile-Develop/"/>
      <url>/blog/2023/03/12/%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91-Agile-Develop/</url>
      
        <content type="html"><![CDATA[<h2 id="敏捷开发相关"><a href="#敏捷开发相关" class="headerlink" title="敏捷开发相关"></a>敏捷开发相关</h2><ul><li><a href="https://agilemanifesto.org/iso/zhchs/manifesto.html">敏捷软件开发宣言</a></li><li><a href="https://agilemanifesto.org/iso/zhchs/principles.html">敏捷软件的十二条原则</a></li><li><a href="https://www.scrumcn.com/agile/scrum/category/scrum-agile-practices">敏捷文章</a></li></ul><h2 id="敏捷工具"><a href="#敏捷工具" class="headerlink" title="敏捷工具"></a>敏捷工具</h2><ul><li><a href="https://trello.com/">Trello</a></li><li><a href="https://www.zentao.net/">bug 记录工具-禅道</a></li><li><a href="https://www.redmine.org/">Redmine</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 敏捷开发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我是怎么参与开源项目的</title>
      <link href="/blog/2023/03/08/%E6%88%91%E6%98%AF%E6%80%8E%E4%B9%88%E5%8F%82%E4%B8%8E%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E7%9A%84/"/>
      <url>/blog/2023/03/08/%E6%88%91%E6%98%AF%E6%80%8E%E4%B9%88%E5%8F%82%E4%B8%8E%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E7%9A%84/</url>
      
        <content type="html"><![CDATA[<p>大家好，我是 MarkShen, 今天我跟大家聊聊我是如何参与开源项目的。</p><p>说起做参与开源项目这个话题，我从很久之前就开始参与做开源项目了。其实，作为一个小白的话呢？有小白参与开源项目的方式，作为资深开源人也有其他的方式参与开源。今天我就主要跟大家分享作为一个小白，如何参与开源项目。作为小白我们参与开源项目要记住：</p><blockquote><p>要做开源项目，从看开源项目的文档开始。</p></blockquote><p>今天跟大家分享一个我自己的例子。昨天我看到 <a href="https://kubevela.net/zh/docs/"><code>kubevela</code></a> 这个开源项目的文档。再浏览阅读的过程中发现文档中多了一个字 <strong>“的”</strong> 。所以，我就决定晚上给<code>kubevela</code>贡献 PR。简单说下流程：首先找到<code>kubevela</code>这个开源软件的文档的 repo 的<code>Github</code>地址，然后把它<code>fork</code>到我自己的<code>github</code>中，然后再把这个远程仓库的内容下载到我本地，在本地修改完后，再提交到本地代码仓库，再提交到远程代码仓库，<strong>然后提 PR</strong>，如果 PR 通过会有人<code>review</code>你的 PR，<code>review</code>通过后，就会走<code>github</code>的自动化发部流程，将构建好的文档发布到线上环境，这个就是我参与开源项目的整个流程了。构建好后，文档上就会有你的名字，如下图：</p><p><img src="https://user-images.githubusercontent.com/40328786/223740706-b673166c-d7f2-4439-8d24-1e8bc2398e83.png" alt="kubevela"></p><p>其中，要特别强调的是过程是：<a href="https://kubevela.io/docs/contributor/code-contribute#create-a-pull-request"><strong>提 PR</strong></a>。</p><p><img src="https://user-images.githubusercontent.com/40328786/223741927-20787e6d-40ac-4267-b828-f74669403fce.png"></p><p>在提交 PR 的时候一定要符合 <a href="https://kubevela.io/docs/contributor/code-contribute#create-a-pull-request"><code>kubevela贡献的要求</code></a> 这里主要参考<strong>提 PR</strong>这个文档。在这个文档中，会有很多信息值得学习，比如</p><ul><li><a href="https://kubevela.io/docs/contributor/code-conventions#go-code-conventions">Code Conventions</a></li><li><a href="https://google.github.io/eng-practices/review/reviewer/">Code review</a></li><li><a href="https://cbea.ms/git-commit/">Formatting guidelines</a></li><li><a href="https://www.conventionalcommits.org/zh-hans/v1.0.0/">约定式提交</a></li><li><a href="https://oam.dev/">OAM</a></li><li><a href="https://google.github.io/styleguide/">Google Style Guides</a></li><li>在开源项目中学习<ul><li><strong>阅读开源项目中的 pr, issues 和 discussions</strong></li></ul></li><li><a href="https://opensource.guide/how-to-contribute/">How to Contribute to Open Source</a></li></ul><p>完~</p>]]></content>
      
      
      
        <tags>
            
            <tag> 开源 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《你安全吗？》中的那些有关网安的技术</title>
      <link href="/blog/2023/03/04/%E3%80%8A%E4%BD%A0%E5%AE%89%E5%85%A8%E5%90%97%EF%BC%9F%E3%80%8B%E4%B8%AD%E7%9A%84%E9%82%A3%E4%BA%9B%E6%9C%89%E5%85%B3%E7%BD%91%E5%AE%89%E7%9A%84%E6%8A%80%E6%9C%AF/"/>
      <url>/blog/2023/03/04/%E3%80%8A%E4%BD%A0%E5%AE%89%E5%85%A8%E5%90%97%EF%BC%9F%E3%80%8B%E4%B8%AD%E7%9A%84%E9%82%A3%E4%BA%9B%E6%9C%89%E5%85%B3%E7%BD%91%E5%AE%89%E7%9A%84%E6%8A%80%E6%9C%AF/</url>
      
        <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/40328786/222858115-535baa65-46d3-4e0b-9894-0eb5d3a9ddeb.png"></p><p>2022 年比较火的一部剧《你安全吗》拍的很不错。下面是我看完这部剧整理出来的一些开源项目和一些值得分享的内容：</p><h2 id="开源项目"><a href="#开源项目" class="headerlink" title="开源项目"></a>开源项目</h2><ul><li><a href="https://sqlmap.org/">sqlmap:Automatic SQL injection and database takeover tool</a></li><li><a href="https://www.computec.ch/projekte/vulscan/">vulscan</a><ul><li><a href="https://github.com/scipag/vulscan">vulscan</a></li></ul></li><li><a href="https://github.com/certbot/certbot">Certbot</a></li><li><a href="http://www.sleuthkit.org/autopsy/">autospy</a><ul><li><a href="https://github.com/sleuthkit/autopsy">autospy_github</a></li></ul></li><li><a href="https://fluxionnetwork.github.io/fluxion/">Fluxion</a></li><li><a href="https://github.com/rajkumardusad/IP-Tracer">IP-Tracer</a></li><li><a href="https://github.com/maurosoria/dirsearch">Web path scanner-dirsearch</a></li><li><a href="https://github.com/traccar/traccar">Traccar GPS Tracking System</a></li><li><a href="https://github.com/SpiderLabs/ModSecurity">SpiderLabs-ModSecurity</a></li></ul><h2 id="技术文章"><a href="#技术文章" class="headerlink" title="技术文章"></a>技术文章</h2><ul><li><a href="https://www.microsoft.com/zh-cn/security/business/security-101/what-is-a-ddos-attack">DDoS 攻击</a></li><li><a href="https://www.cloudflare.com/zh-cn/learning/ddos/dns-amplification-ddos-attack/">DNS 放大攻击</a></li><li><a href="https://www.cnblogs.com/endust/p/11960901.html">HTTP 慢速攻击</a></li><li><a href="https://blog.cloudflare.com/zh-cn/dns-encryption-explained-zh-cn/">DNS 加密说明</a></li><li><a href="https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/">What is a DDoS attack?</a><ul><li><a href="https://www.cloudflare.com/zh-cn/learning/ddos/what-is-a-ddos-attack/">中文版</a></li></ul></li><li><a href="https://www.cloudflare.com/zh-cn/learning/">Cloudflare 学习中心</a></li></ul><h2 id="常用"><a href="#常用" class="headerlink" title="常用"></a>常用</h2><ul><li><a href="https://www.cvedetails.com/">https://www.cvedetails.com/</a></li><li><a href="https://deeplearningsystems.ai/">https://deeplearningsystems.ai/</a></li><li><a href="https://cisofy.com/lynis/">https://cisofy.com/lynis/</a></li><li>键盘劫持</li><li>Wifi 探针</li><li><a href="https://book.douban.com/subject/30192800/">《Python 神经网络编程》</a></li><li><a href="https://nmap.org/">https://nmap.org/</a></li><li><a href="https://www.pingplotter.com/">https://www.pingplotter.com/</a></li><li><a href="http://traceroute.org/">http://traceroute.org/</a></li><li><a href="https://www.transcend-info.com/Support/Software-4">数据恢复工具-RecoveRx</a></li><li><a href="https://www.nslookup.io/">nslookup 工具</a></li><li>移动基站</li><li>行车数据</li><li><a href="http://www.55vi.com/">GPS system</a></li><li>自动 P 图</li><li>生活缴费公众号</li><li>12123 交管 app</li><li>垃圾桶潜水</li><li><a href="https://www.kismetwireless.net/">Kismet is a sniffer, WIDS, and wardriving tool for Wi-Fi, Bluetooth, Zigbee, RF, and more</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 网络安全 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开源软件 </tag>
            
            <tag> 网络安全 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>不公平优势(Unfair Advantage)</title>
      <link href="/blog/2023/02/19/%E4%B8%8D%E5%85%AC%E5%B9%B3%E4%BC%98%E5%8A%BF-Unfair-Advantage/"/>
      <url>/blog/2023/02/19/%E4%B8%8D%E5%85%AC%E5%B9%B3%E4%BC%98%E5%8A%BF-Unfair-Advantage/</url>
      
        <content type="html"><![CDATA[<p><img src="https://user-images.githubusercontent.com/40328786/219921706-af96536f-aa41-49d6-b0f7-da3a08dbdf27.jpeg" alt="MILES"></p><blockquote><p>从事商业活动，就是整合优势资源</p></blockquote><h2 id="读书笔记"><a href="#读书笔记" class="headerlink" title="读书笔记"></a>读书笔记</h2><blockquote><p>并不是要具备所有前述不公平优势才能成功。最佳策略是在选择创业的时候，选择的对象拥有你没有的不公平优势，实现优势互补。</p></blockquote><h2 id="动机：你为什么会做某件事情"><a href="#动机：你为什么会做某件事情" class="headerlink" title="动机：你为什么会做某件事情"></a>动机：你为什么会做某件事情</h2><ul><li><a href="https://bigfive-test.com/test">Big 5 personality test</a><ul><li>开放性</li><li>责任心</li><li>外倾性</li><li>宜人性</li><li>神经质性</li></ul></li></ul><blockquote><p>创业者需要保持好奇心，有自己的想法，不惧体验新事物。</p></blockquote><ul><li><a href="https://www.themyersbriggs.com/en-US/Products-and-Services/Myers-Briggs">Myers-Briggs assessment</a></li></ul><h2 id="思维模式（地基部分最为重要）"><a href="#思维模式（地基部分最为重要）" class="headerlink" title="思维模式（地基部分最为重要）"></a>思维模式（地基部分最为重要）</h2><ul><li>固定型思维</li><li>成长型思维</li><li>现实-成长型思维(贴近实际，靠谱)<ul><li>远见</li><li>足智多谋</li><li>不断成长和终身学习</li><li>勇气和毅力</li></ul></li></ul><blockquote><p>如果你对某件事情足够渴望，甚至会获得改变人生的力量。</p></blockquote><h2 id="金钱"><a href="#金钱" class="headerlink" title="金钱"></a>金钱</h2><blockquote><p>想要赚钱，先要有钱。</p></blockquote><blockquote><p>谈到金钱的时候，我们通常指的是财富。然而，财富不仅仅是金钱，还包括你所有的任何资产（房子，土地，股票，以及你可以变卖还钱的任何其他东西）。金钱还有另一个名字-资本。</p></blockquote><blockquote><p>所有人都有三类资本：经济资本，社会资本和文化资本。其中，社会资本和文化资本属于地位。</p></blockquote><ul><li>经济资本：金钱</li><li>社会资本：我们的朋友和盟友形成的关系网络</li><li>文化资本：基本上包含其他能够让我们获得尊重和声望的一切，比如知识，资质，头衔，职业，言谈举止，口音，衣着品味，肢体语言，爱好等。</li></ul><h3 id="生命周期和烧钱速度"><a href="#生命周期和烧钱速度" class="headerlink" title="生命周期和烧钱速度"></a>生命周期和烧钱速度</h3><blockquote><p>生命周期：在创业公司耗尽资金被迫关闭前创业者所拥有的时间。烧钱速度指创业公司每个月损失的金钱数量。</p></blockquote><blockquote><p>简单来说， 金钱越多意味着生命周期越长。另外，烧钱速度越慢，生命周期越长。</p></blockquote><blockquote><p>不要过度节俭，该花的钱还是要花。</p></blockquote><blockquote><p>我们应该关注那些比我们领先 5-10 年的普通成功者，而非那些亿万富翁。</p></blockquote><h3 id="将钱作为你的不公平优势"><a href="#将钱作为你的不公平优势" class="headerlink" title="将钱作为你的不公平优势"></a>将钱作为你的不公平优势</h3><blockquote><p>一般来讲，判断的经验法则是，如果辞去全职工作，你需要至少 6-18 个月的生命周期，也就是说，你的金钱足够支撑这段时间。要判断金钱是否是你的不公平优势，请思考以下问题：</p></blockquote><ul><li>你现在的账户中是否有这笔钱？</li><li>你是否有朋友和家人可以预先投资这笔钱？</li><li>你可以通过目前的工作攒下这笔钱吗？</li></ul><blockquote><p>如果你有足够的金钱来启动自己的公司，并且在你所需的生命周期内提供支持，那么非常好。金钱就是你的不公平优势。那如果没有，你该做些什么呢？</p></blockquote><ul><li>尽量减少生活开支</li><li>学习营销和销售知识</li><li>筹集资金</li><li>学习编程</li><li>开启自由职业</li></ul><blockquote><p>培养人的“饥饿感” （很重要）</p></blockquote><h2 id="智力和洞察力"><a href="#智力和洞察力" class="headerlink" title="智力和洞察力"></a>智力和洞察力</h2><blockquote><p>智力的多个维度，智商，书本智力，社会智力和创新智力。</p></blockquote><ul><li><p>书本智力：对理论的理解能力。理解世界的工具</p><ul><li>刨根问底学习者</li></ul></li><li><p>社会智力：课堂之外学到的知识称为“社会智力”，社会智力主要指人际交往能力。需要通过实践积累，要提升社会智力，还要依靠我们感悟自身的生活经验或者学习他人的生活经验</p><ul><li>社交和情感智力</li><li>常识</li><li>拆穿假话的能力</li></ul></li><li><p>创新智力</p><ul><li>将分散在不同领域中的点联系起来，提出独特的解决方案。</li></ul></li><li><p>洞察力</p><ul><li>透过现象看本质的能力，是优先于他人东西事态的能力。</li><li>怎么获得洞察力？<ul><li>与潜在的客户沟通。</li><li>关注用户，如果你就是目标用户，那就更好了，可以深入了解客户需求，以小见大，解决用户群体问题。</li><li>我们只有具备行业工作经历，才能获得宝贵的洞察力，看到痛点，发现工作中那些环节效率较低，然后设计更好的产品或者流程来解决问题。</li><li>痛点，痒点和爽点</li></ul></li></ul></li></ul><blockquote><p>我是在正确的时间，出现在了正确的地方</p></blockquote><blockquote><p>评估自己创造力和社会智力可以思考的问题</p></blockquote><ul><li>你与他人合作的能力如何？</li><li>你的人机关系如何？</li><li>你是否让身边的人发现了他们更好的一面？</li><li>你是否能正确认识自己的情绪？</li><li>你是否能仅凭直觉便洞悉别人的意图？换句话说，你是否能经常察觉对方的恶意？</li></ul><blockquote><p>要提升智力和洞察力，必须做到以下几点：</p></blockquote><ul><li>培养好奇心</li><li>多问问题</li><li>多做试验</li><li>关心他人的感受和事物对他们情感的影响</li><li>做个有心人，留意他人谈到的哪些事情做起来很麻烦或者不方便，做好积累。这将成为洞察力的富矿</li><li>掌握自己的情绪和心情，确保自己的言行不受它们左右</li></ul><h2 id="位置和运气"><a href="#位置和运气" class="headerlink" title="位置和运气"></a>位置和运气</h2><blockquote><p>想要获取非比寻常的成功，需要两个条件：第一，天时地利；第二，利用好第一个条件。位置和运气一位置天时地利，即在正确的时间出现在正确的位置</p></blockquote><blockquote><p>卵巢彩票</p></blockquote><ul><li>开店选址</li><li>企业趋向于向特定地区聚集</li><li>行业代名词</li><li>STEM 学科<ul><li>科学</li><li>技术</li><li>工程</li><li>数学</li></ul></li></ul><h3 id="创业公司集群"><a href="#创业公司集群" class="headerlink" title="创业公司集群"></a>创业公司集群</h3><ul><li><a href="https://m.thepaper.cn/baijiahao_16189417">伦敦东区，破茧重生的「小硅谷」</a></li><li><a href="https://www.sohu.com/a/483566001_121123890">硅沼</a></li><li><a href="https://oxfordsp.com/">牛津科学园</a></li><li><a href="https://www.entrepreneurship.manchester.ac.uk/">Masood Entrepreneurship Centre</a></li><li><a href="https://mcieb.org/">曼彻斯特中国创新创业基地 （MCIEB）</a></li><li><a href="https://www.thepaper.cn/newsDetail_forward_18884514">英国「M4 科创走廊」的心脏，为何是小城布里斯托尔？</a><ul><li>中国城市中心</li></ul></li><li><a href="https://finance.sina.cn/2022-08-15/detail-imizirav8245196.d.html">英国硅谷”的心脏，为何是小城布里斯托尔？</a></li><li><a href="https://www.thepaper.cn/newsDetail_forward_1654183">边度假边工作：数字游民的可持续间隔年</a></li></ul><blockquote><p>位置决定你所处的氛围和环境。我们的水平是与我们相处时间最长的 5 个人的平均水平。此外，所谓位置，不一定是实际存在的地点。位置还可以是你所处的环境。在虚拟空间中，我们拥有更强的掌控力，可以选择社交媒体上关注和添加好友的对象，可以选择我们接收的内容，所以可以主动营造和设计我们所处的环境。在虚拟世界中，位置的重要性以搜索引擎排名的形式体现出来。位置可以让你获得资本（投资人和风险投资公司往往集中在创业中心），高技能人才和其他重要<strong>资源</strong>。</p></blockquote><ul><li><a href="https://www.tmtpost.com/3771913.html">科技公司崛起，班加罗尔成为“印度硅谷”？</a></li></ul><blockquote><p>你的受众在哪里，你就该在哪里</p></blockquote><ul><li><a href="https://myinstagirls.com/zh/cn-huda-kattan/">胡达·卡坦 (Huda Kattan)</a></li><li><a href="https://hudabeauty.com/us/en_US/home">美妆</a></li></ul><blockquote><p>亚马逊-找到万事俱备的地方</p></blockquote><blockquote><p>Basecamp-摆脱对实体办公室的迷恋</p></blockquote><h3 id="运气"><a href="#运气" class="headerlink" title="运气"></a>运气</h3><blockquote><p>我发现运气其实很容易预测。如果你想更走运，就多尝试几次，更加积极主动，多抛投露面。</p></blockquote><blockquote><p>无论你的技能多么出众，决心多么坚定，如果缺少了运气，那么终将一事无成。</p></blockquote><ul><li><a href="https://www.idealab.com/cn/">idealab</a></li><li><a href="https://www.goto.com/">goto</a></li><li><a href="https://www.londonstockexchange.com/raise-finance/equity/main-market/high-growth-segment">High Growth Segment</a></li></ul><h3 id="抓住时机"><a href="#抓住时机" class="headerlink" title="抓住时机"></a>抓住时机</h3><ul><li>时机<ul><li>太早和太迟都不行。最理想的情况是瞄准一个规模不大但是不断增长的市场。这时候进入市场才算刚好</li></ul></li><li>团队和执行</li><li>创业点子</li></ul><p>运气、时机和位置的例子</p><ul><li>任天堂——捉住历史性时机</li><li>Deliveroo——准备好点子，只待正确时机</li></ul><h3 id="如何变得更加幸运"><a href="#如何变得更加幸运" class="headerlink" title="如何变得更加幸运"></a>如何变得更加幸运</h3><blockquote><p>财布施，法布施，无畏布施</p></blockquote><blockquote><p>在生活中创造好运的四大基本法则</p></blockquote><ul><li>最大限度地利用所有机会</li><li>相信你的直觉和预感，尤其当你已经有过类似的幸运经历时</li><li>期待幸运的到来</li><li>化厄运为好运</li><li>增加尝试的次数</li></ul><h2 id="教育和专长"><a href="#教育和专长" class="headerlink" title="教育和专长"></a>教育和专长</h2><h3 id="教育"><a href="#教育" class="headerlink" title="教育"></a>教育</h3><blockquote><p>走出校门并不意味着教育的终止，我们无时不刻不在学习，看着两本书，有字的书和没有字的书。接受良好的教育就是巨大的不公平优势</p></blockquote><ul><li><a href="https://debretts.com/">德倍礼</a>每年都会评选出在英国最具影响力的人物</li></ul><h4 id="知识、人脉、标志"><a href="#知识、人脉、标志" class="headerlink" title="知识、人脉、标志"></a>知识、人脉、标志</h4><ul><li><p>知识，接受教育最明确的目的。是我们在学校学到的内容，包括识字，算数以及与世界有关的其他内容。</p></li><li><p>人脉，为什么很多人要非常努力进名校，进大厂，因为可以见到非常优秀的人。<strong>你要见到优秀的人，首先你得先变成优秀的人。</strong></p></li><li><p>标志，信誉就是向别人展示你具备从事某些工作的技能和智慧</p></li><li><p><a href="https://www.technologyreview.com/2020/02/26/906029/aileen-lee-92/">Aileen Lee ’92</a></p></li><li><p><a href="http://www.sagemetering.com.cn/">赛捷计量仪器</a></p></li></ul><h4 id="技术不公平优势"><a href="#技术不公平优势" class="headerlink" title="技术不公平优势"></a>技术不公平优势</h4><ul><li><a href="https://logos.fandom.com/wiki/Google">backrub</a></li><li><a href="https://www.unrealengine.com/zh-CN/developer-interviews/park-beyond-is-a-theme-park-sim-that-allows-its-players-to-create-impossible-experiences">Park Beyond</a></li><li><a href="https://www.deepmind.com/">DeepMind</a></li><li><a href="https://github.com/deepmind">DeepMind Github</a></li></ul><h3 id="专长"><a href="#专长" class="headerlink" title="专长"></a>专长</h3><blockquote><p>真正的学习始于你将理论知识付诸实践，通过现实世界的反馈来了解理论的应用情况。只有这样，你才能够成为真正的专家</p></blockquote><blockquote><p>只要在某个领域完成工作的质量远远优于大部分普通人，那么就可以被称为该领域的专家</p></blockquote><blockquote><p>如果我们在某个领域有明确且可衡量的成果，那么就更容易成为或者说被认为是该领域的专家</p></blockquote><blockquote><p>每遇到 20 岁出头的年轻人，我们总建议他们在择业的时候不要选择报酬最高的工作，而是要选择能够学到最多东西的工作。通过大量学习，年轻人可以发展某个行业的专长，可以为今后的职业技能打下坚实的基础，可以获得极具价值的简介。</p></blockquote><blockquote><p>积极在生活中用我们学到的知识，坚持终身学习</p></blockquote><blockquote><p>要成为专家，你必须长期深耕，苦心钻研，不断精进，才能做到专家的位置</p></blockquote><h3 id="将教育和专长作为你的不公平优势"><a href="#将教育和专长作为你的不公平优势" class="headerlink" title="将教育和专长作为你的不公平优势"></a>将教育和专长作为你的不公平优势</h3><blockquote><p>无论何时，选择继续学习，提高自己的知识水平和技能水平，永远不会太迟。</p></blockquote><blockquote><p>思考几个问题：</p></blockquote><ul><li>你是否具备自己创办公司所需的技能？</li><li>你是否知道自己在哪方面是专家？</li><li>你想成为哪方面的专家？</li></ul><blockquote><p>成为专家要做什么？</p></blockquote><ul><li>在线学习</li><li>阅读<ul><li><a href="https://mp.weixin.qq.com/s/OPvETiG5S9ohgL3-hIHk-w">阅读通往自由</a></li></ul></li><li>结识导师<ul><li>找导师的时候，将目标锁定为那些领先自己 2-5 年的人，因为他们可以教给你最为实用的技能</li></ul></li><li>自己动手<ul><li>费曼学习法，讲是最好的学【直播方式】</li><li>写文章输出</li><li>录制视频课</li></ul></li></ul><blockquote><p>选择领域</p></blockquote><ul><li>选择那些有人才需求而你又有浓厚兴趣的领域</li><li>对于你有天赋并乐意花时间去学习的事情，要加倍努力</li><li>对于专长之外的领域，要依靠他人，寻求帮助。你可能在某个领域具备了洞察力，但是还没有培养出专长</li></ul><blockquote><p>跨学科思考往往是创造力的源泉，所以不要把思维局限于某个学科或者某种专业知识。博览群书，广泛地涉猎各种知识有助于我们创造更大的价值</p></blockquote><h2 id="地位"><a href="#地位" class="headerlink" title="地位"></a>地位</h2><blockquote><p>更多时候，社会奖励是功绩的外在表现，而非功绩本身</p></blockquote><blockquote><p>你的地位就是你的个人品牌，它指人们如何看待你，你在社会中所处的位置，你的外表，性别，年龄，衣着，站姿，谈吐。它也指你在社会中的可信度</p></blockquote><blockquote><p>社会学家讲地位定义为大家眼中你相对别人的社会价值，你可以为大家贡献什么</p></blockquote><h3 id="外在地位"><a href="#外在地位" class="headerlink" title="外在地位"></a>外在地位</h3><blockquote><p>地位是他认为你在为其增加价值方面具备的能力。</p></blockquote><ul><li><p>文化资本与我们的社会阶层（甚至是所处的亚文化）有关，体现出社会阶层的是我们的口音，资历，品味，爱好，消遣方式，谈话方式，衣着方式，肢体语言，私人物品等</p></li><li><p><a href="https://www.gov.uk/government/organisations/social-mobility-commission">social-mobility-commission</a></p></li></ul><blockquote><p>社会资本的第三种方式，我们各种人际关系，人脉。</p></blockquote><ul><li><a href="https://spanx.com/">spanx</a></li></ul><blockquote><p>与对方处于同一亚文化或者阶层有助于你们建立关系，因为你们之间可能会存在共同点：对音乐和时尚有相似的品味或者相似的兴趣和爱好</p></blockquote><ul><li><a href="https://tellymix.co.uk/tag/the-x-factor">The X Factor news</a></li></ul><blockquote><p>建立人脉的关键在于积极主动地形成和维持<strong>互惠互利</strong>的关系。</p></blockquote><h3 id="内在地位"><a href="#内在地位" class="headerlink" title="内在地位"></a>内在地位</h3><blockquote><p>如果你觉得自己因为过往的罪过，恶习或者其他原因而不值得爱，那么你要明白，只要你意识到自己的问题，并且愿意改变，你依旧值得自爱</p></blockquote><ul><li>自信</li><li>专长</li><li>要记住别人的名字</li><li><a href="https://mp.weixin.qq.com/s/FS4yGrgGOBfqD6ghiGSbDQ">《了凡四训》</a></li></ul><h4 id="冒充者综合征"><a href="#冒充者综合征" class="headerlink" title="冒充者综合征"></a>冒充者综合征</h4><blockquote><p>“经常有人说，‘所有的创造者偶尔都会觉得自己是骗子’。我的感受是：‘天啊，我从来没有觉得自己是骗子……这么说，我真的是创造者吗？’但我转念一想：‘算了，别考虑这些了。我很棒！’”</p></blockquote><ul><li><a href="https://www.chronicle.com/">高等教育纪事报</a></li><li><a href="https://movie.douban.com/subject/4919240/">与卡戴珊一家同行 第一季 Keeping Up with the Kardashians</a></li><li><a href="https://www.thepaper.cn/newsDetail_forward_8742635">澎湃记者教你如何做好人物采访</a></li><li><a href="https://www.interviewmagazine.com/">Interview</a></li><li><a href="https://www.infzm.com/">南方周末</a></li></ul><h2 id="本书中一些用到的网站"><a href="#本书中一些用到的网站" class="headerlink" title="本书中一些用到的网站"></a>本书中一些用到的网站</h2><ul><li><a href="https://www.just-eat.co.uk/">just eat</a></li><li><a href="https://www.crunchbase.com/organization/fare-exchange-network">fare exchange</a></li><li><a href="https://www.washplus.org/">washplus</a></li><li><a href="https://www.uber.com/">Uber</a></li><li><a href="https://www.uhubs.co/">uhubs</a></li><li><a href="https://www.snapchat.com/">snapchat</a></li><li><a href="https://tinder.com/">Tinder</a></li><li><a href="https://www.insider.com/author/business-insider">Business Insider</a></li><li><a href="https://www.imdb.com/title/tt0423776/">The X Factor</a></li><li><a href="https://www.airbnb.com/">Airbnb</a></li><li><a href="https://basecamp.com/">Basecamp</a></li><li><a href="https://www.apple.com/">Apple</a></li><li><a href="https://customerservice.costco.com/">Costco</a></li><li><a href="https://www.wholefoodsmarket.co.uk/">whole foods</a></li><li><a href="https://www.zoopla.co.uk/">zoopla</a></li><li><a href="https://www.crunchbase.com/">Crunchbase</a></li><li><a href="https://stripe.com/">stripe</a></li><li><a href="https://www.crunchbase.com/organization/auctomatic">auctomatic</a></li><li><a href="https://btyoungscientist.com/">btyoungscientis</a></li><li><a href="https://www.ycombinator.com/">Y Combinator</a></li><li><a href="https://walkerandcompany.com/">Walker &amp; Company</a></li><li><a href="https://foursquare.com/">Foursquare is the leading cloud-based location technology platform for unlocking the power of places and movement.</a></li><li><a href="https://www.stanford.edu/about/">斯坦福</a></li><li><a href="https://www.kleinerperkins.com/about">KLEINER PERKINS</a></li></ul><h2 id="本书中引用的书籍"><a href="#本书中引用的书籍" class="headerlink" title="本书中引用的书籍"></a>本书中引用的书籍</h2><ul><li><a href="https://book.douban.com/subject/36074115/">混序小团队管理</a></li><li><a href="https://book.douban.com/subject/30184215/">重来</a></li><li><a href="https://book.douban.com/subject/26952718/">好好学习</a></li><li><a href="https://book.douban.com/subject/26873486/">运营之光</a></li><li><a href="https://book.douban.com/subject/35218970/">非线性增长</a></li><li><a href="https://book.douban.com/subject/10773362/">随机漫步的傻瓜</a></li><li><a href="https://book.douban.com/subject/25863621/">Outliers: The Story of Success</a></li><li><a href="https://book.douban.com/subject/24530336/">至关重要的关系</a></li><li><a href="https://www.forbeschina.com/">福布斯</a></li><li><a href="https://book.douban.com/subject/1837006/">人性的弱点</a></li><li><a href="https://book.douban.com/subject/24753752/">正能量 2:幸运的方法</a></li><li><a href="https://book.douban.com/subject/34326931/">掌控习惯</a></li></ul><h2 id="纪录片"><a href="#纪录片" class="headerlink" title="纪录片"></a>纪录片</h2><ul><li><a href="https://www.bilibili.com/bangumi/play/ss39573">卧底老板</a></li><li><a href="https://www.imdb.com/title/tt0443370/">Dragon’s Den</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 读书笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>常用的正则表达式</title>
      <link href="/blog/2023/02/15/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/blog/2023/02/15/%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="常用的正则表达式"><a href="#常用的正则表达式" class="headerlink" title="常用的正则表达式"></a>常用的正则表达式</h2><blockquote><p><a href="https://www.runoob.com/regexp/regexp-tutorial.html">正则表达式教程</a></p></blockquote><blockquote><p><a href="https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Guide/Regular_Expressions">js 中使用正则表达式</a></p></blockquote><h3 id="Windows-文件名正则表达式校验"><a href="#Windows-文件名正则表达式校验" class="headerlink" title="Windows 文件名正则表达式校验"></a>Windows 文件名正则表达式校验</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> windowsFileNamePattern = <span class="regexp">/[\\/:*?&quot;&lt;&gt;|]+/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试字符串中是否含有上面的字符，有，返回true, 否则，返回false</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;j&lt;js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;\\fa&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;s/js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;s:js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;s*js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;s?js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;s&quot;js&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;da&gt;s&#x27;</span>) <span class="comment">// true</span></span><br><span class="line">windowsFileNamePattern.<span class="title function_">test</span>(<span class="string">&#x27;d|fd&#x27;</span>) <span class="comment">// true</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 正则表达式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2022年俞老师跨年直播内容笔记</title>
      <link href="/blog/2023/01/01/2022%E5%B9%B4%E4%BF%9E%E8%80%81%E5%B8%88%E8%B7%A8%E5%B9%B4%E7%9B%B4%E6%92%AD%E5%86%85%E5%AE%B9%E7%AC%94%E8%AE%B0/"/>
      <url>/blog/2023/01/01/2022%E5%B9%B4%E4%BF%9E%E8%80%81%E5%B8%88%E8%B7%A8%E5%B9%B4%E7%9B%B4%E6%92%AD%E5%86%85%E5%AE%B9%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="人是-♥-的动物"><a href="#人是-♥-的动物" class="headerlink" title="人是 ♥ 的动物"></a>人是 ♥ 的动物</h2><h2 id="时间就是一个容器。你打算在新的一年往里面放什么东西呢？"><a href="#时间就是一个容器。你打算在新的一年往里面放什么东西呢？" class="headerlink" title="时间就是一个容器。你打算在新的一年往里面放什么东西呢？"></a>时间就是一个容器。你打算在新的一年往里面放什么东西呢？</h2><ul><li>个人的维度和家人的维度<ul><li>一屋不扫，何以扫天下</li></ul></li><li>事业进步<ul><li>稳定的工作</li><li>有没有升职加薪</li><li>个人能力有没有提升</li><li>能不能量化</li></ul></li><li>思想、见识的提升和进步<ul><li>读好书</li><li>找有见解的人听他们聊天，听他们讲课，视频内容</li><li>独立思考，独立判断的能力</li></ul></li><li>自律，自控<ul><li>事能知足心常乐，人到无求品自高</li><li>规定好的任务有没有完成，主次分明地完成(80%，90%，100%)</li><li>一个人成熟的标志，能做自己不愿意做但必须做的事情，能和自己不愿意打交道但必须打交道的人打交道</li><li>遇到苦难，挫折，坚韧不拔</li><li>能控制自己的情绪</li></ul></li><li>心态<ul><li>活在当下，创造积极，开心的 moments</li><li>积极，乐观的心态</li></ul></li><li>每年给自己留下什么回忆，下面这些都是俞老师的内容，你的呢？<ul><li>时间过去了，留下了什么？</li><li>这一年过去了，给自己打个分：10 分制，为什么打这些分？</li><li>读书，精读了多少本，略读了多少本</li><li>对谈的人，留下的文字</li><li>锻炼身体，同时听得到，或者播客</li><li>日记，文学，<strong>老俞闲话</strong>（公众号）</li><li>出版的书</li><li>公益活动，老师培训</li><li>请专家，名人给山区的孩子们讲课</li><li>和朋友的聚会，和家人的关系</li><li>不做不接地气的事情</li><li><strong>平常心</strong></li></ul></li></ul><h2 id="如何度过-2023-年"><a href="#如何度过-2023-年" class="headerlink" title="如何度过 2023 年"></a>如何度过 2023 年</h2><ul><li><strong>内心的期许，期待，心里足够地想做</strong></li><li><strong>用 2 天的时间好好想下今年要做的事情</strong></li><li><strong>积极的</strong>心态</li><li>胸怀：做事情不小气，要大气，自黑，自嘲，不记仇<ul><li><strong>拿得起，放得下，入得去，出得来</strong></li></ul></li><li>规划<ul><li>年、季度、月、周、日</li><li>任何得计划，规划都要切合实际，切实可行，能落地</li><li>在定目标的时候，使用<strong>SMART</strong>原则</li><li>紧急，重要四象限</li></ul></li><li>执行<ul><li>做之前想清楚</li></ul></li><li>学会纠错<ul><li>自我反省的能力</li></ul></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>俞老师抖音直播回放，大家如果感兴趣的话，可以再看下原直播回放内容~</p>]]></content>
      
      
      <categories>
          
          <category> 俞敏洪 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 跨年直播 </tag>
            
            <tag> 俞敏洪 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux常用命令</title>
      <link href="/blog/2022/12/25/Linux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/"/>
      <url>/blog/2022/12/25/Linux%E5%B8%B8%E7%94%A8%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="Linux-命令学习方法"><a href="#Linux-命令学习方法" class="headerlink" title="Linux 命令学习方法"></a>Linux 命令学习方法</h2><p>Linux 命令都可以通过 Linux 提供的手册自己学习，一般来讲有三种方式查看命令的用法，如下：</p><p>就拿最常用的 <code>ls</code> 命令来举例子吧</p><p>第一种：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> --<span class="built_in">help</span></span><br></pre></td></tr></table></figure><p>第二种：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">info <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><p>第三种：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">man <span class="built_in">ls</span></span><br></pre></td></tr></table></figure><p>大家可以使用 <code>命令 --help</code>, <code>info + 命令</code>, <code>man + 命令</code> 三种方式来学习新的命令，大家也可以使用 <a href="https://www.kernel.org/doc/man-pages/">The Linux man-pages project</a> 来查找对应的命令。说到这里，让我们来学习下 Linux 的常用网路命令吧</p><p>同时，大家还是可以学习下 <a href="https://missing.csail.mit.edu/">The Missing Semester of Your CS Education</a> 这门课程，这门课程的讲解非常好，大家可以跟着学习下。中文版本是 <a href="https://missing-semester-cn.github.io/">计算机教育中缺失的一课</a>，B 站上的视频是 <a href="https://www.bilibili.com/video/BV1w7411477L/">计算机教育中缺失的一课</a>，大家可以跟着学习下。</p><h3 id="Linux-常用网络命令"><a href="#Linux-常用网络命令" class="headerlink" title="Linux 常用网络命令"></a>Linux 常用网络命令</h3><p>今天主要跟大家分享下 Linux 系统常用网络的命令:</p><ul><li>ifconfig</li><li>ifup</li><li>ifdown</li><li>ip</li><li>route</li><li>ip route</li><li>ping</li><li>traceroute</li><li>netstat</li><li>nslookup</li></ul><h4 id="ifconfig"><a href="#ifconfig" class="headerlink" title="ifconfig"></a>ifconfig</h4><p>查看所有网卡信息</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ifconfig -a</span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.3.2  netmask 255.255.255.0  broadcast 192.168.3.255</span><br><span class="line">        ether b4:b6:86:<span class="built_in">fc</span>:12:07  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 192.168.56.1  netmask 255.255.255.0  broadcast 192.168.56.255</span><br><span class="line">        inet6 fe80::6715:52aa:2c80:112f  prefixlen 64  scopeid 0xfd&lt;compat,<span class="built_in">link</span>,site,host&gt;</span><br><span class="line">        ether 0a:00:27:00:00:03  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth2: flags=64&lt;RUNNING&gt;  mtu 1500</span><br><span class="line">        inet 169.254.202.32  netmask 255.255.0.0</span><br><span class="line">        inet6 fe80::971b:12ac:b88c:961d  prefixlen 64  scopeid 0xfd&lt;compat,<span class="built_in">link</span>,site,host&gt;</span><br><span class="line">        ether 7c:76:35:43:62:9f  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth3: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.22.96.1  netmask 255.255.240.0  broadcast 172.22.111.255</span><br><span class="line">        inet6 fe80::584c:ccd0:e077:634c  prefixlen 64  scopeid 0xfd&lt;compat,<span class="built_in">link</span>,site,host&gt;</span><br><span class="line">        ether 00:15:5d:41:e6:ee  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 1500</span><br><span class="line">        inet 127.0.0.1  netmask 255.0.0.0</span><br><span class="line">        inet6 ::1  prefixlen 128  scopeid 0xfe&lt;compat,<span class="built_in">link</span>,site,host&gt;</span><br><span class="line">        loop  (Local Loopback)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">wifi0: flags=64&lt;RUNNING&gt;  mtu 1500</span><br><span class="line">        inet 169.254.169.148  netmask 255.255.0.0</span><br><span class="line">        ether 7c:76:35:43:62:9b  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">wifi1: flags=64&lt;RUNNING&gt;  mtu 1500</span><br><span class="line">        inet 169.254.112.16  netmask 255.255.0.0</span><br><span class="line">        ether 7c:76:35:43:62:9c  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">wifi2: flags=64&lt;RUNNING&gt;  mtu 1500</span><br><span class="line">        inet 169.254.241.4  netmask 255.255.0.0</span><br><span class="line">        ether 7e:76:35:43:62:9b  (Ethernet)</span><br><span class="line">        RX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 0  bytes 0 (0.0 B)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure><p>其余，参数大家可以通过手册自行学习，这里要大家注意下 <a href="https://www.cloudflare.com/learning/network-layer/what-is-mtu/">MTU</a> 这个关键参数，大家可以根据着篇 blog 进行学习。</p><p>大家也可以参照<a href="https://www.geeksforgeeks.org/ifconfig-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="ifup"><a href="#ifup" class="headerlink" title="ifup"></a>ifup</h4><p>激活网络接口<code>eth0</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ifup eth0</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/ifup-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="ifdown"><a href="#ifdown" class="headerlink" title="ifdown"></a>ifdown</h4><p>禁用网络端口<code>eth0</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ifdown eth0</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/ifdown-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h4><p>查看机器所有网卡的 ip</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ip a</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/ip-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="route"><a href="#route" class="headerlink" title="route"></a>route</h4><p>查看 Linux 内核路由表</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ route</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/route-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="ip-route"><a href="#ip-route" class="headerlink" title="ip route"></a>ip route</h4><p>查看默认路由表（main）路由</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ip route</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://blog.csdn.net/zhongmushu/article/details/108220232">这篇 Blog</a> 学习这个命令。</p><h4 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h4><p>查看网络链路是否通</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ ping www.baidu.com</span><br><span class="line">shenjy@DESKTOP-MCQT724:~$ ping localhost</span><br><span class="line">shenjy@DESKTOP-MCQT724:~$ ping 127.0.0.1</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/ping-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h4><p>追踪网络数据包的路由途径，也可以顺道学习下 <code>tracert</code> 这个命令</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ traceroute www.baidu.com</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/traceroute-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h4 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h4><p>Print network connections, routing tables, interface statistics, masquerade connections, and multicast member‐<br>ships</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ netstat -i</span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">eth0      1500        0      0      0 0             0      0      0      0 BMRU</span><br><span class="line">eth1      1500        0      0      0 0             0      0      0      0 BMRU</span><br><span class="line">eth3      1500        0      0      0 0             0      0      0      0 BMRU</span><br><span class="line">lo        1500        0      0      0 0             0      0      0      0 LRU</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/netstat-command-linux/">这篇 Blog</a> 学习这个命令。</p><h4 id="nslookup"><a href="#nslookup" class="headerlink" title="nslookup"></a>nslookup</h4><p>Nslookup is a program to query Internet domain name servers. Nslookup has two modes: interactive and non-interactive.<br>Interactive mode allows the user to query name servers for information about various hosts and domains or to print a list<br>of hosts in a domain. Non-interactive mode is used to print just the name and requested information for a host or domain.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">shenjy@DESKTOP-MCQT724:~$ nslookup baidu.com</span><br><span class="line">Server:         8.8.8.8</span><br><span class="line">Address:        8.8.8.8#53</span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">Name:   baidu.com</span><br><span class="line">Address: 39.156.66.10</span><br></pre></td></tr></table></figure><p>大家也可以参照<a href="https://www.geeksforgeeks.org/nslookup-command-in-linux-with-examples/">这篇 Blog</a> 学习这个命令。</p><h3 id="防火墙相关"><a href="#防火墙相关" class="headerlink" title="防火墙相关"></a>防火墙相关</h3><h4 id="firewall-cmd"><a href="#firewall-cmd" class="headerlink" title="firewall-cmd"></a>firewall-cmd</h4><ul><li>安装 <code>firewalld</code> 软件</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install firewalld</span><br></pre></td></tr></table></figure><ul><li>查看防火墙状态</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --state</span><br></pre></td></tr></table></figure><ul><li>查看开放了哪些端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --list-ports</span><br></pre></td></tr></table></figure><ul><li>开放端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-port=80/tcp --permanent</span><br></pre></td></tr></table></figure><ul><li>关闭开放端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --remove-port=80/tcp --permanent</span><br></pre></td></tr></table></figure><ul><li>重启防火墙</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><ul><li>停止防火墙</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure><ul><li>启动/关闭开机启动功能</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span>/disable firewalld.service</span><br></pre></td></tr></table></figure><h4 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h4><ul><li>查看防火墙规则</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -L -n -v</span><br></pre></td></tr></table></figure><ul><li>查看开放了哪些端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看接受规则</span></span><br><span class="line">iptables -L INPUT -n -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看正在监听的端口</span></span><br><span class="line">netstat -tuln</span><br><span class="line">ss -tuln</span><br></pre></td></tr></table></figure><ul><li>开放端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开放 TCP 端口 80</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开放 UPD 端口</span></span><br><span class="line">iptables -A INPUT -p udp --dport 53 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开放端口并限定源IP</span></span><br><span class="line">iptables -A INPUT -p tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT</span><br></pre></td></tr></table></figure><blockquote><p>注意：使用 iptables 命令添加的规则默认是临时的，系统重启后会丢失。</p><p>要使规则永久生效，需要将规则保存到配置文件中（不同的 Linux 发行版有不同的保存工具和方法，例如 iptables-save &gt; /etc/sysconfig/iptables 或使用 iptables-persistent 包）。</p></blockquote><ul><li>关闭开放端口</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看规则编号</span></span><br><span class="line">iptables -L INPUT -n --line-numbers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定规则</span></span><br><span class="line">iptables -D INPUT &lt;number&gt;</span><br></pre></td></tr></table></figure><ul><li>重启防火墙</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart iptables</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">service iptables restart</span><br></pre></td></tr></table></figure><ul><li>停止防火墙</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop iptables</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">service iptables stop</span><br></pre></td></tr></table></figure><ul><li>启动/关闭开机启动功能</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span>/disable iptables</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">chkconfig iptables on/off</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">update-rc.d iptables <span class="built_in">enable</span>/disable</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 运维 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> network command </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Jenkins持续集成</title>
      <link href="/blog/2022/12/16/Jenkins%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"/>
      <url>/blog/2022/12/16/Jenkins%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/</url>
      
        <content type="html"><![CDATA[<h3 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h3><p>由于近期部门在用 <code>Java</code> 系框架 <code>springboot</code> 做一个项目, 程序发布流程太繁琐了. 下面我说下我司目前的部署步骤:</p><ul><li>使用本地 <code>IdeaJ</code> 或者 <code>Maven</code> 命令将源代码打成 <code>jar</code> 包</li><li>然后把 <code>jar</code> 包上传到服务器上</li></ul><p>最后, 启动与 <code>Java</code> 包配套的启动脚本启动程序</p><p>也就是说, 只要我写完一些功能, 想把功能发布到测试环境给前端同学调用, 我就得执行上面的三个步骤. 我觉得太麻烦了, 所以我打算使用 <code>Jenkins</code> 和 <code>Gitlab</code> 实现只要我一提交代码, 或者 <code>merge</code> 代码, 我就把代码从代码仓库中拿到测试服务器上, 执行编译, 打包, 发布这几个我之前手动做的功能. 这个操作就能够大大提高自己的效率了, 同时也能提高团队的效率. 虽然, 现在这个操作感觉非常好, 但是在提交代码之前, 我们还要做到基本的步骤, 就是你改完的代码要能在你机器上运行, 或者能够编译通过, 满足这两个步骤之一, 才可以提交代码.</p><h3 id="搭建环境中遇到的问题"><a href="#搭建环境中遇到的问题" class="headerlink" title="搭建环境中遇到的问题"></a>搭建环境中遇到的问题</h3><p>接下来, 我给大家分享下, 这次搭建环境全过程. 还有些注意问题在这里要跟大家交代下:</p><p>在 Jenkins 启动之前, 要确保所有的构建环境已经安装. 如果构建软件没有安装, 就要安装构建软件后重新启动 Jenkins.</p><p>环境</p><ul><li>Jenkins 2.332.1(官方推荐使用 Java 11)</li><li>Windows Server 2008 R2</li><li>JDK1.8.1</li><li>Maven 3.8.4</li></ul><p>因为之前服务器上已经安装了, JDK1.8.1, maven 环境, 这里将不再细说. 下面我主要给大家说下 Jenkins 的一些事情.</p><p>虽然是 windows 操作系统, 但是我并没有安装 windows 版本的 Jenkins. 而是使用官网提供的 war 包. 下载地址: <a href="https://www.jenkins.io/download/">https://www.jenkins.io/download/</a>. 在启动 Jenkins 前, 要首先设置下环境变量 JENKINS_HOME , 设置完这个才可以运行启动 jenkins 的代码</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -war jenkins.war --httpPort=9090</span><br></pre></td></tr></table></figure><h4 id="Gitlab-Webhook-配置时遇到的问题"><a href="#Gitlab-Webhook-配置时遇到的问题" class="headerlink" title="Gitlab Webhook 配置时遇到的问题"></a>Gitlab Webhook 配置时遇到的问题</h4><p><code>Jenkins</code> 启动完成后, 需要安装一些插件, 我这里直接使用 <code>Jenkins</code> 默认安装的一些插件. 安装完后, 创建用户, 登录进入 <code>Jenkins</code> 就好了. 这是首先要创建一个 <code>pipeline</code> , 首先要配置 <code>pipeline</code> 中的构建触发器, 主要配置 <code>Gitlab</code> 与 <code>Jenkins</code> 的联动, 在 <code>Gitlab</code> 中还要设置 <code>Webhook</code> , 当提交代码或者合并代码时候触发 <code>Webhook</code> 执行构建.</p><p><img src="https://user-images.githubusercontent.com/40328786/209425706-bf95a700-b495-4529-816d-c7ac3ec9ea09.png"></p><p>上图是在 Jenkins 中配置的内容, 下图是在 <code>Gitlab</code> 中的配置.</p><p><img src="https://user-images.githubusercontent.com/40328786/209425711-8ac6a0e6-6570-44e2-9ce6-78896d761269.png"></p><p>配置好 <code>Webhook</code> 后要测试下, 这里 <code>Gitlab</code> 中可以模拟 <code>Push events</code> , 这里还要做一个小小的配置, 配置<code>-Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=true</code> ,完整命令如下</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar -Dhudson.security.csrf.GlobalCrumbIssuerConfiguration.DISABLE_CSRF_PROTECTION=<span class="literal">true</span> jenkins.war --httpPort=9090</span><br></pre></td></tr></table></figure><p>除了配置以上内容还要配置如下参数: <code>Manage Jenkins</code> → <code>Configure Global Security</code> → <code>授权策略</code>, 具体如下图:</p><p><img src="https://user-images.githubusercontent.com/40328786/209425714-1016b5b0-ba45-4da9-9be0-fa0703a71ab9.png"></p><p>以上操作完成后, 就可以使用 <code>Jenkins</code> 完成构建.</p><h4 id="执行完-pipeline-程序并没有起来"><a href="#执行完-pipeline-程序并没有起来" class="headerlink" title="执行完 pipeline 程序并没有起来"></a>执行完 pipeline 程序并没有起来</h4><p>这个配置好了, 接下来就是 <code>pipeline</code> 了, 代码如下</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line"></span><br><span class="line">    environment &#123;</span><br><span class="line">        REPOSITORY=&quot;git@sdasalksdfasl.git&quot; // 仓库地址</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    stages &#123;</span><br><span class="line">       stage(&#x27;build and run&#x27;) &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">          // 编译, 打包文件</span><br><span class="line">          bat &quot;&quot;&quot;</span><br><span class="line">            mvn clean package -Dmaven.test.skip=true</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">          // 在执行前, 先关闭之前的程序</span><br><span class="line">          bat &quot;&quot;&quot;</span><br><span class="line">            <span class="built_in">taskkill</span> /FI &quot;WindowTitle eq service1*&quot; /T /F</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">          // 执行自己的程序</span><br><span class="line">          bat &quot;&quot;&quot;</span><br><span class="line">            <span class="built_in">cd</span> target</span><br><span class="line">            <span class="built_in">xcopy</span> /y xxx-SNAPSHOT.jar d:\\ps-svc</span><br><span class="line">            <span class="built_in">cd</span> d:/ps-svc</span><br><span class="line">            <span class="built_in">start</span>.bat</span><br><span class="line">            &quot;&quot;&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>以上 <code>pipeline</code> 完成, 但是在使用 <code>Jenkins</code> 执行的时候也并没有出现什么问题, 但是可以观察到最后的程序可以起来, 但是当 <code>pipeline</code> 执行完后, 原来运行起来的 <code>springboot</code> 服务也关闭了. 这个问题我在网上查了下, 可以在 <code>Jenkins</code> 启动的时候配置参数<code>-Dhudson.util.ProcessTree.disable=true</code>. 这时候 <code>Jenkins</code> 全部的命令就编程了如下代码.</p><p><code>start.bat</code></p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">@<span class="built_in">ECHO</span> OFF</span><br><span class="line"><span class="comment">@REM start a service</span></span><br><span class="line"><span class="comment">@REM set BUILD_ID=dontkillme</span></span><br><span class="line"><span class="built_in">start</span> &quot;service1&quot; java -jar xxx-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以上就是我在折腾 Jenkins 所遇到的两个问题以及解决方法, 这里分享给你. 当然我这里还是有疑问的:<br>第一，进程如何起来的？<br>第二，这里有关操作系统的知识？</p><p>Jenkins 如何实现杀掉所有 pipeline 带起来的进程的, 这里可以看看 jenkins 源码.<br>接下来, 我还会继续查资料来解决我的疑问的, 加油。</p><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p>[1] <a href="https://ss64.com/nt/start.html">https://ss64.com/nt/start.html</a><br>[2] <a href="https://www.jenkins.io/doc/book/managing/system-properties/">https://www.jenkins.io/doc/book/managing/system-properties/</a></p>]]></content>
      
      
      <categories>
          
          <category> DEVOPS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 持续集成 </tag>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工作中如何Coding</title>
      <link href="/blog/2022/12/10/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%A6%82%E4%BD%95Coding/"/>
      <url>/blog/2022/12/10/%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%A6%82%E4%BD%95Coding/</url>
      
        <content type="html"><![CDATA[<p>当我接到一个开发任务的时候，我不是第一时间就去着手开发，我首先要干的是以下几件事情：</p><ul><li><p><strong>第一，看产品的文档，根据当前系统的功能，评估下产品的设计是否合理。</strong>不合适的地方，还要跟产品讨论，如果问题在刚开始的时候没有被发现，而是干着干着才发现这个问题，这就非常糟糕，这就需要平时经验的积累。一般是<strong>问题越早发现，解决的成本越低</strong>。</p></li><li><p><strong>第二，分析这次开发的影响范围</strong>。如果都是新功能，新建数据库表等，这就无所谓了；但如果此次开发是基于原有代码的变更，就要注意影响范围了。比方说，这次版本变更会影响到的点有 3 点，但是如果你只修改了 2 点，剩下的一点就是 Bug。这是非常可怕的事情，在实际开发的时候一定要注意这个问题。那如果你是个新人，你并不知道系统有多少个地方需要修改的时候，那么你可以问下团队中对系统了解非常透彻的人，让他帮你确定系统变更范围。但是，这种事情还是少做，<strong>自己要在没有事情的时候多去熟悉系统，熟悉业务</strong>。</p></li><li><p><strong>第三，确定影响范围后，要整理出一个文档</strong>。文档中要写明，系统变更版本，相关人员。此次变更的功能点。对于变更的功能点还要写明：</p><ul><li>变更背景（为什么这个变更？）</li><li>变更的 log，原来是什么样的，现在变更成什么样子的</li></ul></li><li><p><strong>第四，前后端合作沟通，确定完成这些需求需要多少个接口</strong>。前后端沟通的时候，最好也要注意接口定义的几个问题：</p><ul><li>返回数据格式，都返回哪些字段</li><li>请求方法，Get, Post 等</li><li>出错处理</li></ul></li><li><p><strong>第五，测试开发的功能</strong>。写测试 case, 按 case 来做相关的测试。测试的一般顺序是，自己开发的功能自己测一遍，然后团队成员测，如果没问题，发生产环境。否则，修改代码，本地测试，测试环境测试功能，如果还有问题，重复以上步骤，直至功能发线上环境。</p></li><li><p><strong>第六，提交代码时要注意的问题</strong>。两个后端或者两个前端或几个全站一起工作的时候，在本地编译没问题后才能提交代码，你不能提完代码，大家本地都运行不了了，这不行。</p></li><li><p><strong>第七，提交信息如何填写</strong>。这里推荐一篇阮一峰老师的文章《<a href="http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html">Commit message 和 Change log 编写指南</a>》。</p></li></ul><p>本次分享就到这里啦~</p>]]></content>
      
      
      <categories>
          
          <category> 团队开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 团队开发 </tag>
            
            <tag> coding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>好用的工具集合</title>
      <link href="/blog/2022/12/07/%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E9%9B%86%E5%90%88/"/>
      <url>/blog/2022/12/07/%E5%A5%BD%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h2 id="系统学习知识"><a href="#系统学习知识" class="headerlink" title="系统学习知识"></a>系统学习知识</h2><ul><li><a href="https://www.googleguide.com/category/query-input/">google guide</a></li></ul><h2 id="优势识别"><a href="#优势识别" class="headerlink" title="优势识别"></a>优势识别</h2><ul><li><a href="https://www.apesk.com/holland/index.html">霍兰德职业兴趣量表(完整专业版)</a></li><li><a href="https://www.jianshu.com/p/de4af98bdbfc">盖洛普优势识别</a></li></ul><h2 id="软件工具"><a href="#软件工具" class="headerlink" title="软件工具"></a>软件工具</h2><ul><li><a href="https://ffmpeg.org/">音视频处理开源软件 FFmpeg</a></li><li><a href="https://sslip.io/">ip 即域名</a></li></ul><h2 id="免费-CDN-站点"><a href="#免费-CDN-站点" class="headerlink" title="免费 CDN 站点"></a>免费 CDN 站点</h2><ul><li><a href="https://cloudinary.com/">cloudinary</a></li><li><a href="https://geekflare.com/free-cdn-list/#geekflare-toc-gcore-cdn">6 FREE CDN to Speed Up and Secure Your WebSite</a></li></ul><h2 id="调研数据统计工具"><a href="#调研数据统计工具" class="headerlink" title="调研数据统计工具"></a>调研数据统计工具</h2><ul><li><a href="https://www.wjx.cn/">问卷星</a></li><li><a href="https://www.jinshuju.net/">金数据</a></li></ul><h2 id="在线修图"><a href="#在线修图" class="headerlink" title="在线修图"></a>在线修图</h2><ul><li><a href="https://ps.gaoding.com/">online ps</a></li></ul><h2 id="海报制作工具"><a href="#海报制作工具" class="headerlink" title="海报制作工具"></a>海报制作工具</h2><ul><li><a href="https://www.canva.cn/">canva</a></li></ul><h2 id="在线产品设计软件"><a href="#在线产品设计软件" class="headerlink" title="在线产品设计软件"></a>在线产品设计软件</h2><ul><li><a href="https://www.figma.com/">Figma</a></li></ul><h2 id="代码管理工具"><a href="#代码管理工具" class="headerlink" title="代码管理工具"></a>代码管理工具</h2><ul><li><p>国外</p><ul><li><a href="https://github.com/">Github</a></li><li><a href="https://about.gitlab.com/">Gitlab</a></li><li><a href="https://bitbucket.org/">Bitbucket</a></li></ul></li><li><p>国内</p><ul><li><a href="https://gitee.com/">Gitee</a></li><li><a href="https://coding.net/">腾讯云 Coding</a></li></ul></li><li><p>自建</p><ul><li><a href="https://gitbucket.github.io/">GitBucket</a></li><li><a href="https://github.com/gogs/gogs">Gogs</a></li><li><a href="https://github.com/go-gitea/gitea">Gitea</a></li></ul></li></ul><h2 id="CI-CD-工具"><a href="#CI-CD-工具" class="headerlink" title="CI/CD 工具"></a>CI/CD 工具</h2><ul><li><a href="https://www.jenkins.io/">Jenkins</a></li><li><a href="https://circleci.com/">Circle CI</a></li><li><a href="https://github.com/features/actions">Github Actions</a></li></ul><h2 id="Site-Analytics-工具"><a href="#Site-Analytics-工具" class="headerlink" title="Site Analytics 工具"></a>Site Analytics 工具</h2><ul><li><a href="https://tongji.baidu.com/web5/welcome/login">百度统计</a></li><li><a href="https://umami.is/">umami</a></li><li><a href="https://www.cloudflare.com/zh-cn/web-analytics/">cloudflare web analytics</a></li></ul><h2 id="Web-版查询代码"><a href="#Web-版查询代码" class="headerlink" title="Web 版查询代码"></a>Web 版查询代码</h2><ul><li><a href="https://github1s.com/">github1s.com</a></li></ul><h2 id="网络测速"><a href="#网络测速" class="headerlink" title="网络测速"></a>网络测速</h2><ul><li><a href="https://test.ustc.edu.cn/">中国科学技术大学测速网站</a><ul><li><a href="https://github.com/bg6cq/speedtest">网站源代码</a></li></ul></li><li><a href="http://speed.nuaa.edu.cn/">南京航空航天大学 5g 专网测速网站</a></li><li><a href="https://test.nju.edu.cn/">中国科学技术大学测速网站</a></li><li><a href="http://speed5.ntu.edu.tw/speed5/">台大测速</a></li><li><a href="https://fast.com/">fast.com</a></li></ul><h2 id="IP-库"><a href="#IP-库" class="headerlink" title="IP 库"></a>IP 库</h2><ul><li><a href="https://www.ipip.net/">IPIP</a></li><li><a href="https://www.itdog.cn/">ITDOG</a></li><li>查询自己的 IP 地址</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl ipinfo.io/ip</span><br><span class="line">curl icanhazip.com</span><br><span class="line">curl cip.cc</span><br><span class="line">curl myexternalip.com/raw</span><br><span class="line">curl curlmyip.org</span><br><span class="line">curl ifconfig.co</span><br><span class="line">curl ip.sb</span><br></pre></td></tr></table></figure><h2 id="密码生成"><a href="#密码生成" class="headerlink" title="密码生成"></a>密码生成</h2><ul><li><a href="https://1password.com/password-generator">密码生成</a></li></ul><h2 id="视频网站"><a href="#视频网站" class="headerlink" title="视频网站"></a>视频网站</h2><ul><li><a href="https://www.mtyy1.com/">麦田影院</a></li><li><a href="https://libretv-4hx.pages.dev/">LibreTV</a></li></ul><h2 id="订阅管理"><a href="#订阅管理" class="headerlink" title="订阅管理"></a>订阅管理</h2><ul><li><a href="https://subsnotice.shenjy.workers.dev/">订阅管理</a></li></ul><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h3><ul><li><a href="https://chinese-font.netlify.app/zh-cn/cdn/">中文网字计划</a></li></ul><h2 id="图书馆，电子数下载"><a href="#图书馆，电子数下载" class="headerlink" title="图书馆，电子数下载"></a>图书馆，电子数下载</h2><ul><li><a href="https://zlib.by/">zlibaray</a></li><li><a href="https://annas-archive.org/">Anna’s Archive</a></li><li><a href="https://oceanofpdf.com/">OceanofPDF</a></li><li><a href="https://pdfdrive.webs.nf/">PDF Drive</a></li></ul><h2 id="组机"><a href="#组机" class="headerlink" title="组机"></a>组机</h2><ul><li><a href="https://www.buildcores.com/">https://www.buildcores.com/</a></li></ul><h2 id="免费域名注册"><a href="#免费域名注册" class="headerlink" title="免费域名注册"></a>免费域名注册</h2><ul><li><a href="https://tb.netassist.ua/">ip6.arpa 域名注册</a></li><li><a href="https://digitalplat.org/">digitalPlat Domain Dashboard</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes学习笔记</title>
      <link href="/blog/2022/12/07/Kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/blog/2022/12/07/Kubernetes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="Kubernetes-学习资料"><a href="#Kubernetes-学习资料" class="headerlink" title="Kubernetes 学习资料"></a>Kubernetes 学习资料</h2><ul><li><a href="https://kubernetes.io/">kubernetes 官网</a></li><li><a href="https://lib.jimmysong.io/kubernetes-handbook/">Kubernetes 基础教程</a></li><li><a href="https://lib.jimmysong.io/kubernetes-hardening-guidance/">Kubernetes 加固指南</a></li><li><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">kubernetes-the-hard-way</a></li></ul><h2 id="云原生-学习资料"><a href="#云原生-学习资料" class="headerlink" title="云原生 学习资料"></a>云原生 学习资料</h2><ul><li><a href="https://lib.jimmysong.io/cloud-native-infra/">云原生基础架构</a></li><li><a href="https://github.com/rootsongjc/awesome-cloud-native">awesome-cloud-native</a></li><li><a href="https://www.cncf.io/">CNCF</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> kubernetes </category>
          
          <category> cloud native </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 运维 </tag>
            
            <tag> 云原生 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>读书笔记</title>
      <link href="/blog/2022/12/07/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
      <url>/blog/2022/12/07/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="读书笔记"><a href="#读书笔记" class="headerlink" title="读书笔记"></a>读书笔记</h2><ul><li><a href="https://mp.weixin.qq.com/s/miyqsuZhC9FG_3n8pe91Aw">如何阅读一本书</a></li><li><a href="https://mp.weixin.qq.com/s/ia3FNt1ZEpoOUXLBVgegvA">TED 演讲的力量</a></li><li><a href="https://mp.weixin.qq.com/s/jSyWiZewPpZ65u2DFW1n9w">想和做</a></li><li><a href="https://mp.weixin.qq.com/s/Yzoc4QRUW1XNLvkddbRbeQ">论读书</a></li><li><a href="https://mp.weixin.qq.com/s/hWoR4aVXjaQVBShI2MF7Bg">高田·健一的信</a></li><li><a href="https://mp.weixin.qq.com/s/5m_0zDZCtzzN00JWDbg_YQ">《如何练就拍案叫绝的现场反应》学习笔记</a></li><li><a href="https://mp.weixin.qq.com/s/--frHLROAYyEEU6EkrTQ6w">三碗不过岗</a></li><li><a href="https://mp.weixin.qq.com/s/tewBKHgbyrjxUjAOmkXI7A">从 ChatGPT 到 AI Agent，一文讲透 Agent 的底层逻辑</a></li><li>…</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>SpringCloud学习笔记</title>
      <link href="/blog/2022/12/07/SpringCloud%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/blog/2022/12/07/SpringCloud%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="微服务相关学习文章"><a href="#微服务相关学习文章" class="headerlink" title="微服务相关学习文章"></a>微服务相关学习文章</h2><ul><li><a href="https://microservices.io/index.html">microservices.io</a></li><li><a href="https://eventuate.io/">eventuate.io</a></li><li><a href="https://www.geeksforgeeks.org/microservices-introduction/">Microservices Introduction</a></li><li><a href="https://aws.amazon.com/microservices/">Microservices AWS</a></li><li><a href="https://www.martinfowler.com/microservices/">Microservices Guide</a></li><li><a href="https://www.ibm.com/topics/microservices">IBM-What are microservices?</a></li><li><a href="https://learn.microsoft.com/en-us/azure/service-fabric/service-fabric-overview-microservices">Microsoft-Why use a microservices approach to building applications</a></li><li><a href="https://learn.microsoft.com/en-us/devops/deliver/what-are-microservices">Microsoft-What are Microservices?</a></li><li><a href="https://www.nginx.com/blog/introduction-to-microservices/">【Nginx】introduction-to-microservices</a></li></ul><h2 id="Spring-Framework"><a href="#Spring-Framework" class="headerlink" title="Spring Framework"></a><a href="https://spring.io/projects/spring-framework">Spring Framework</a></h2><h2 id="SpringBoot"><a href="#SpringBoot" class="headerlink" title="SpringBoot"></a><a href="https://spring.io/projects/spring-boot">SpringBoot</a></h2><h2 id="Spring-Cloud"><a href="#Spring-Cloud" class="headerlink" title="Spring Cloud"></a><a href="https://spring.io/projects/spring-cloud">Spring Cloud</a></h2><h2 id="Spring-Projects"><a href="#Spring-Projects" class="headerlink" title="Spring Projects"></a><a href="https://spring.io/projects">Spring Projects</a></h2>]]></content>
      
      
      
        <tags>
            
            <tag> 微服务 </tag>
            
            <tag> Springboot </tag>
            
            <tag> SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
