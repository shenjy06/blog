<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="请用高中生可以理解的方式介绍下大语言模型一句话理解：大语言模型（LLM）就是一个“超级会聊天、会写作的人工智能大脑”，它通过学习海量的文字，学会了如何像人一样理解和生成语言。  🧠 什么是大语言模型？ “大”：指的是它学过的内容非常多，参数（就像大脑里的“神经元连接”）可能有上亿甚至上千亿个。 “语言”：它的主要能力是处理文字，比如理解问题、写文章、翻译语言、写代码。 “模型”：就是一个经过训练">
<meta property="og:type" content="article">
<meta property="og:title" content="构建自己的大模型">
<meta property="og:url" content="https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/index.html">
<meta property="og:site_name" content="Mark&#39;s Blog">
<meta property="og:description" content="请用高中生可以理解的方式介绍下大语言模型一句话理解：大语言模型（LLM）就是一个“超级会聊天、会写作的人工智能大脑”，它通过学习海量的文字，学会了如何像人一样理解和生成语言。  🧠 什么是大语言模型？ “大”：指的是它学过的内容非常多，参数（就像大脑里的“神经元连接”）可能有上亿甚至上千亿个。 “语言”：它的主要能力是处理文字，比如理解问题、写文章、翻译语言、写代码。 “模型”：就是一个经过训练">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-10-20T18:28:42.000Z">
<meta property="article:modified_time" content="2026-01-18T00:02:59.263Z">
<meta property="article:author" content="Mark Shen">
<meta property="article:tag" content="大模型">
<meta name="twitter:card" content="summary">
    
    
      
        
          <link rel="shortcut icon" href="/blog/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/blog/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>构建自己的大模型</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/blog/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
      <link rel="alternate" href="/blog/true" title="Mark&#39;s Blog" type="application/atom+xml" />
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.2"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="目录"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="目录"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="顶部" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/blog/">首页</a></li><!--
     --><!--
       --><li><a href="/blog/about/">关于</a></li><!--
     --><!--
       --><li><a href="/blog/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/blog/categories/">分类</a></li><!--
     --><!--
       --><li><a href="/blog/search/">搜索</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/shenjy06">项目</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="上一篇" href="/blog/2025/10/24/%E9%80%9A%E8%BF%87api%E8%B0%83%E7%94%A8ai%E6%8E%A5%E5%8F%A3/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="下一篇" href="/blog/2025/10/14/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="返回顶部" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="分享文章" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&text=构建自己的大模型"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&is_video=false&description=构建自己的大模型"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=构建自己的大模型&body=Check out this article: https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&name=构建自己的大模型&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&t=构建自己的大模型"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%94%A8%E9%AB%98%E4%B8%AD%E7%94%9F%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BB%8B%E7%BB%8D%E4%B8%8B%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">请用高中生可以理解的方式介绍下大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A0-%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">🧠 什么是大语言模型？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%9A-%E5%AE%83%E6%98%AF%E6%80%8E%E4%B9%88%E5%AD%A6%E4%BC%9A%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">📚 它是怎么学会的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%8D%94-%E6%89%93%E4%B8%AA%E6%AF%94%E6%96%B9"><span class="toc-number">1.3.</span> <span class="toc-text">🍔 打个比方</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%9A%80-%E5%AE%83%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">🚀 它能做什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%9A%A1-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E2%80%9C%E5%A4%A7%E2%80%9D%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">⚡ 为什么叫“大”？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">大语言模型如何训练？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A9-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E5%88%86%E8%A7%A3"><span class="toc-number">2.1.</span> <span class="toc-text">🧩 训练流程分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%9A%99%EF%B8%8F-%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9"><span class="toc-number">2.2.</span> <span class="toc-text">⚙️ 技术要点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%96-%E6%89%93%E4%B8%AA%E7%94%9F%E6%B4%BB%E6%AF%94%E6%96%B9"><span class="toc-number">2.3.</span> <span class="toc-text">📖 打个生活比方</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BB%8E%E9%9B%B6%E5%81%9A%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%91%A2%EF%BC%9F%E6%88%91%E4%BB%AC%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%91%A2%EF%BC%9F%E5%81%9A%E5%A5%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87-api-%E7%9A%84%E6%96%B9%E5%BC%8F%E6%8F%90%E4%BE%9B%E7%BB%99%E5%A4%96%E9%83%A8%E7%A8%8B%E5%BA%8F%E4%BD%BF%E7%94%A8%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">从零构建大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%AF%E7%BA%BF%E6%A6%82%E8%A7%88"><span class="toc-number">0.1.</span> <span class="toc-text">路线概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E5%87%86%E5%A4%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%BA%BF"><span class="toc-number">0.2.</span> <span class="toc-text">基础准备与数据管线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E2%80%9D%E7%9A%84%E5%85%B3%E9%94%AE%E5%8F%82%E6%95%B0"><span class="toc-number">0.3.</span> <span class="toc-text">定义“大模型”的关键参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%88%B0%E5%AF%B9%E9%BD%90%E7%9A%84%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B"><span class="toc-number">0.4.</span> <span class="toc-text">训练到对齐的完整流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E4%B8%BA-API-%E7%9A%84%E5%AE%9E%E6%88%98%E8%B7%AF%E5%BE%84"><span class="toc-number">0.5.</span> <span class="toc-text">部署为 API 的实战路径</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E4%B8%8E%E6%89%93%E5%8C%85"><span class="toc-number">0.5.1.</span> <span class="toc-text">推理优化与打包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E6%90%AD%E4%B8%80%E4%B8%AA%E5%8F%AF%E7%94%A8%E7%9A%84-API%EF%BC%88%E7%A4%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">0.5.2.</span> <span class="toc-text">快速搭一个可用的 API（示例）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%99%E4%BD%A0%E7%9A%84%E4%B8%80%E5%BC%A0%E2%80%9C%E5%8A%A8%E6%89%8B%E6%B8%85%E5%8D%95%E2%80%9D"><span class="toc-number">0.6.</span> <span class="toc-text">给你的一张“动手清单”</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E5%B8%AE%E6%88%91%E5%AE%8C%E6%88%90"><span class="toc-number">1.</span> <span class="toc-text">请帮我完成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%9C%8B%E6%87%82%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">🧩 一张图看懂大模型全流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">2.1.</span> <span class="toc-text">1️⃣ 数据准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-number">2.2.</span> <span class="toc-text">2️⃣ 模型参数定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5"><span class="toc-number">2.3.</span> <span class="toc-text">3️⃣ 训练阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%EF%B8%8F%E2%83%A3-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96"><span class="toc-number">2.4.</span> <span class="toc-text">4️⃣ 部署与推理优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%EF%B8%8F%E2%83%A3-%E6%8F%90%E4%BE%9B-API-%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.5.</span> <span class="toc-text">5️⃣ 提供 API 服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%EF%B8%8F%E2%83%A3-%E5%85%B3%E9%94%AE%E8%A6%81%E7%82%B9"><span class="toc-number">2.6.</span> <span class="toc-text">6️⃣ 关键要点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9C%89%E4%B8%80%E5%8F%B0-16GB-%E5%86%85%E5%AD%98%EF%BC%8C8-%E6%A0%B8%E5%BF%83%E7%9A%84-cpu%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%88%91%E6%83%B3%E5%9F%BA%E4%BA%8E%E8%BF%99%E6%A0%B7%E7%9A%84%E7%A1%AC%E4%BB%B6%E6%9D%A1%E4%BB%B6%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%9D%EF%BC%8C%E8%AF%B7%E5%B8%AE%E6%88%91%E6%8C%89%E4%B8%8A%E9%9D%A2%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%8C%E5%9F%BA%E4%BA%8E%E6%88%91%E6%89%8B%E4%B8%8A%E7%9A%84%E7%A1%AC%E4%BB%B6%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8-16GB-%E5%86%85%E5%AD%98%E3%80%818-%E6%A0%B8-CPU-%E4%B8%8A%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%B9%B6%E6%8F%90%E4%BE%9B%E5%A4%A7%E6%A8%A1%E5%9E%8B-API"><span class="toc-number"></span> <span class="toc-text">在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E4%B8%8E%E7%AD%96%E7%95%A5"><span class="toc-number">1.</span> <span class="toc-text">目标与策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A1%8C%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%A7%84%E6%A0%BC%E4%B8%8E%E8%AE%AD%E7%BB%83%E8%B6%85%E5%8F%82"><span class="toc-number">2.</span> <span class="toc-text">可行的模型规格与训练超参</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E5%8F%AF%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%A7%84%E6%A0%BC%EF%BC%88%E9%80%82%E9%85%8D-16GB-%E5%86%85%E5%AD%98%EF%BC%8CCPU-%E8%AE%AD%E7%BB%83%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">最小可行模型规格（适配 16GB 内存，CPU 训练）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%B6%85%E5%8F%82%EF%BC%88CPU-%E5%8F%8B%E5%A5%BD%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">训练超参（CPU 友好）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E9%9B%B6%E5%88%B0-API-%E7%9A%84-6-%E6%AD%A5"><span class="toc-number">3.</span> <span class="toc-text">从零到 API 的 6 步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E8%AF%8D"><span class="toc-number">3.1.</span> <span class="toc-text">1. 数据与分词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">3.2.</span> <span class="toc-text">2. 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88%E8%AF%AD%E8%A8%80%E8%83%BD%E5%8A%9B%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">3. 预训练（语言能力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90"><span class="toc-number">3.4.</span> <span class="toc-text">4. 指令微调与对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%8E%A8%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2"><span class="toc-number">3.5.</span> <span class="toc-text">5. 推理与部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%8F%90%E4%BE%9B-API-%E6%9C%8D%E5%8A%A1%EF%BC%88FastAPI-%E7%A4%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">3.6.</span> <span class="toc-text">6. 提供 API 服务（FastAPI 示例）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E6%89%93%E5%8D%B0%E7%9A%84%E2%80%9C%E5%8A%A8%E6%89%8B%E6%B8%85%E5%8D%95%E2%80%9D"><span class="toc-number">4.</span> <span class="toc-text">可打印的“动手清单”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%89%A9%E5%B1%95%E5%BB%BA%E8%AE%AE"><span class="toc-number">5.</span> <span class="toc-text">进阶与扩展建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%B8%8A%E9%9D%A2%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E8%AF%B7%E7%BB%99%E6%88%91%E4%BB%A3%E7%A0%81%E5%B1%82%E9%9D%A2%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.</span> <span class="toc-text">基于上面的回答，请给我代码层面的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E4%BE%9D%E8%B5%96"><span class="toc-number">7.</span> <span class="toc-text">项目结构与依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%9E%84%E5%BB%BA%E5%88%86%E8%AF%8D%E5%99%A8%EF%BC%88BPE%EF%BC%8C%E8%AF%8D%E8%A1%A8-16k%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">1. 构建分词器（BPE，词表 16k）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89%EF%BC%88Decoder-only-Transformer%EF%BC%8C%E7%BA%A6-40M-%E5%8F%82%E6%95%B0%EF%BC%89"><span class="toc-number">9.</span> <span class="toc-text">2. 模型定义（Decoder-only Transformer，约 40M 参数）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88%E8%87%AA%E7%9B%91%E7%9D%A3%EF%BC%8C%E4%B8%8B%E4%B8%80%E4%B8%AA-token-%E9%A2%84%E6%B5%8B%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">3. 预训练（自监督，下一个 token 预测）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%EF%BC%88SFT%EF%BC%89"><span class="toc-number">11.</span> <span class="toc-text">4. 指令微调（SFT）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%A6%BB%E7%BA%BF%E6%8E%A8%E7%90%86%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">12.</span> <span class="toc-text">5. 离线推理与测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-FastAPI-%E5%AF%B9%E5%A4%96%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1"><span class="toc-number">13.</span> <span class="toc-text">6. FastAPI 对外提供服务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E4%B8%8E%E6%B8%85%E6%B4%97%E7%A4%BA%E4%BE%8B"><span class="toc-number">14.</span> <span class="toc-text">7. 数据准备与清洗示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E8%AE%AD%E7%BB%83%E5%BB%BA%E8%AE%AE%E4%B8%8E%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6"><span class="toc-number">15.</span> <span class="toc-text">8. 训练建议与资源控制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E4%B8%8B%E4%B8%80%E6%AD%A5%E5%8F%AF%E9%80%89%E5%A2%9E%E5%BC%BA"><span class="toc-number">16.</span> <span class="toc-text">9. 下一步可选增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%9C%89%E5%BC%80%E6%BA%90%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%90%97%EF%BC%9F"><span class="toc-number">17.</span> <span class="toc-text">对于训练数据，有开源的数据集吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%9E%8B"><span class="toc-number">18.</span> <span class="toc-text">🔑 常见的开源数据集类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E6%96%99%EF%BC%88%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80%E8%83%BD%E5%8A%9B%EF%BC%89"><span class="toc-number">18.1.</span> <span class="toc-text">1. 预训练语料（基础语言能力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%EF%BC%88%E8%AE%A9%E6%A8%A1%E5%9E%8B%E2%80%9C%E5%90%AC%E6%87%82%E4%BA%BA%E8%AF%9D%E2%80%9D%EF%BC%89"><span class="toc-number">18.2.</span> <span class="toc-text">2. 指令微调数据（让模型“听懂人话”）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%EF%BC%88%E5%AF%B9%E9%BD%90%E4%BA%BA%E7%B1%BB%E4%BB%B7%E5%80%BC%EF%BC%89"><span class="toc-number">18.3.</span> <span class="toc-text">3. 偏好数据（对齐人类价值）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%EF%BC%88%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%EF%BC%89"><span class="toc-number">18.4.</span> <span class="toc-text">4. 评测数据（测试模型效果）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%9A-%E6%8E%A8%E8%8D%90%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86"><span class="toc-number">19.</span> <span class="toc-text">📚 推荐资源整理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E7%BB%99%E4%BD%A0%E7%9A%84%E5%B0%8F%E6%9C%BA%E5%AD%90%E5%BB%BA%E8%AE%AE"><span class="toc-number">20.</span> <span class="toc-text">🛠️ 给你的小机子建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%8C%89%E7%85%A7%E4%B8%8A%E9%9D%A2-1-2-3%E2%80%A6%E2%80%A6%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C-python-%E6%96%87%E4%BB%B6%E5%B0%B1%E8%A1%8C%E4%BA%86%E5%90%97%EF%BC%9F%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E4%BA%A7%E5%87%BA%E7%89%A9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B%EF%BC%9F%E5%A6%82%E4%BD%95%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83%EF%BC%9F"><span class="toc-number">21.</span> <span class="toc-text">对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F"><span class="toc-number">22.</span> <span class="toc-text">🛠️ 执行顺序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%A6-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E4%BA%A7%E5%87%BA%E7%89%A9"><span class="toc-number">23.</span> <span class="toc-text">📦 模型训练完成后的产出物</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B"><span class="toc-number">24.</span> <span class="toc-text">🚀 如何使用模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%A7-%E5%A6%82%E4%BD%95%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83"><span class="toc-number">25.</span> <span class="toc-text">🔧 如何对模型进行微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BB%A7%E7%BB%AD%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%EF%BC%88SFT%EF%BC%89"><span class="toc-number">25.1.</span> <span class="toc-text">1. 继续指令微调（SFT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%BD%BB%E9%87%8F%E5%BE%AE%E8%B0%83%EF%BC%88LoRA-Adapter%EF%BC%89"><span class="toc-number">25.2.</span> <span class="toc-text">2. 轻量微调（LoRA &#x2F; Adapter）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93"><span class="toc-number">26.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%88%AC%E6%9D%A5%E8%AE%B2%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%A8%A1%E5%9E%8B%E6%81%AF%E6%81%AF%E7%9B%B8%E5%85%B3%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%88%96%E8%80%85%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E6%89%8D%E8%83%BD%E8%AE%A9%E4%B8%A4%E8%80%85%E9%85%8D%E5%90%88%E8%BE%BE%E5%88%B0%E6%9C%80%E4%BC%98%EF%BC%9F%E6%9C%89%E4%BB%80%E4%B9%88%E6%A0%87%E5%87%86%E5%90%97%EF%BC%9F"><span class="toc-number">27.</span> <span class="toc-text">一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%8F%90%E7%A4%BA%E8%AF%8D%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%85%8D%E5%90%88%E9%80%BB%E8%BE%91"><span class="toc-number">28.</span> <span class="toc-text">🎯 提示词与模型的配合逻辑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%85%B3%E9%94%AE%E8%A6%81%E7%B4%A0"><span class="toc-number">29.</span> <span class="toc-text">🧩 提示词设计的关键要素</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8F%97%EF%B8%8F-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%AD%E7%BB%83%E7%9A%84%E9%85%8D%E5%90%88%E7%82%B9"><span class="toc-number">30.</span> <span class="toc-text">🏗️ 模型设计与训练的配合点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%90-%E6%9C%89%E6%B2%A1%E6%9C%89%E2%80%9C%E6%A0%87%E5%87%86%E2%80%9D%EF%BC%9F"><span class="toc-number">31.</span> <span class="toc-text">📐 有没有“标准”？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-1"><span class="toc-number">32.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E6%98%AF%E5%95%A5%E6%84%8F%E6%80%9D%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B7%BB%E5%8A%A0%E8%BF%99%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%9F%E8%A7%A3%E5%86%B3%E4%BA%86%E5%95%A5%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">33.</span> <span class="toc-text">大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%A5-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">34.</span> <span class="toc-text">🔥 温度参数的定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%A8-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B7%BB%E5%8A%A0%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%EF%BC%9F"><span class="toc-number">35.</span> <span class="toc-text">🎨 为什么要添加温度参数？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%96%EF%B8%8F-%E6%B8%A9%E5%BA%A6%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%95%88%E6%9E%9C"><span class="toc-number">36.</span> <span class="toc-text">⚖️ 温度带来的效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8C%B0-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-number">37.</span> <span class="toc-text">🌰 举个例子</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%8C%A1%EF%B8%8F-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E9%80%9F%E6%9F%A5%E8%A1%A8"><span class="toc-number"></span> <span class="toc-text">🌡️ 大语言模型温度参数速查表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93"><span class="toc-number">1.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-hugging-face-%E6%88%96%E8%80%85-model-scope-%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%9E%84%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%BD%BF%E7%94%A8-Hugging-Face-%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">🧩 使用 Hugging Face 的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%BD%BF%E7%94%A8-ModelScope-%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">🧩 使用 ModelScope 的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E2%80%9C%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B%E2%80%9D"><span class="toc-number">5.</span> <span class="toc-text">🚀 如何构建“属于自己的模型”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%89%80%E4%BD%BF%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E6%9C%89%E6%B2%A1%E6%9C%89%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E5%85%B7%E7%94%A8%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E9%98%B6%E6%AE%B5"><span class="toc-number">6.</span> <span class="toc-text">关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B7%A5%E5%85%B7"><span class="toc-number">7.</span> <span class="toc-text">🔑 常见的数据集工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-edg4llm"><span class="toc-number">7.1.</span> <span class="toc-text">1. edg4llm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Easy-Dataset"><span class="toc-number">7.2.</span> <span class="toc-text">2. Easy Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-LLaMA-Factory"><span class="toc-number">7.3.</span> <span class="toc-text">3. LLaMA-Factory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-XTuner"><span class="toc-number">7.4.</span> <span class="toc-text">4. XTuner</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E6%80%BB%E7%BB%93"><span class="toc-number">8.</span> <span class="toc-text">📌 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%8A%8A-pdf%EF%BC%8Cdoc%EF%BC%8Cmarkdown-%E7%AD%89%E6%96%87%E4%BB%B6%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%9F%E5%B9%B6%E5%A6%82%E4%BD%95%E6%8A%8A%E8%BF%99%E4%BA%9B%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%AE%A9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E5%9F%BA%E4%BA%8E%E8%BF%99%E4%BA%9B%E6%95%B0%E6%8D%AE%E5%9B%9E%E7%AD%94%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3"><span class="toc-number">10.</span> <span class="toc-text">🧩 步骤详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%96%87%E6%9C%AC%E6%8F%90%E5%8F%96"><span class="toc-number">10.1.</span> <span class="toc-text">1. 文本提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88Embedding%EF%BC%89"><span class="toc-number">10.2.</span> <span class="toc-text">2. 向量化（Embedding）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AD%98%E5%82%A8%E5%90%91%E9%87%8F"><span class="toc-number">10.3.</span> <span class="toc-text">3. 存储向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A3%80%E7%B4%A2-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%EF%BC%88RAG%EF%BC%89"><span class="toc-number">10.4.</span> <span class="toc-text">4. 检索 + 大模型问答（RAG）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%EF%BC%88RAG%EF%BC%89"><span class="toc-number">10.5.</span> <span class="toc-text">5. 整体架构（RAG）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-2"><span class="toc-number">11.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rerank-%E6%A8%A1%E5%9E%8B%E5%B7%A5%E4%BD%9C%E5%9C%A8%E4%BB%80%E4%B9%88%E9%98%B6%E6%AE%B5%EF%BC%9F%E4%BB%80%E4%B9%88%E6%97%B6%E9%97%B4%E4%BD%BF%E7%94%A8%E5%AE%83%EF%BC%9F"><span class="toc-number">12.</span> <span class="toc-text">Rerank 模型工作在什么阶段？什么时间使用它？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-Rerank-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B7%A5%E4%BD%9C%E9%98%B6%E6%AE%B5"><span class="toc-number">13.</span> <span class="toc-text">🧩 Rerank 模型的工作阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8-Rerank%EF%BC%9F"><span class="toc-number">14.</span> <span class="toc-text">🎯 为什么要用 Rerank？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%8F%B0-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8-Rerank%EF%BC%9F"><span class="toc-number">15.</span> <span class="toc-text">⏰ 什么时候使用 Rerank？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-3"><span class="toc-number">16.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8-RAG-%E7%9A%84%E6%8A%80%E6%9C%AF%E4%B8%AD%EF%BC%8C%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E7%A7%8D%E6%A8%A1%E5%9E%8B%EF%BC%9F%E5%88%86%E5%88%AB%E5%9C%A8%E4%BB%80%E4%B9%88%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8%EF%BC%9F%E4%B8%BA%E4%BA%86%E8%BE%BE%E6%88%90%E4%BB%80%E4%B9%88%E6%95%88%E6%9E%9C%EF%BC%9F"><span class="toc-number">17.</span> <span class="toc-text">在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-RAG-%E6%8A%80%E6%9C%AF%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%B1%BB%E5%9E%8B%E4%B8%8E%E9%98%B6%E6%AE%B5"><span class="toc-number">18.</span> <span class="toc-text">🧩 RAG 技术中的模型类型与阶段</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Embedding-%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%90%91%E9%87%8F%E5%8C%96%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.1.</span> <span class="toc-text">1. Embedding 模型（向量化阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%88%9D%E6%AD%A5%E5%8F%AC%E5%9B%9E%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.2.</span> <span class="toc-text">2. 检索模型（初步召回阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Rerank-%E6%A8%A1%E5%9E%8B%EF%BC%88%E9%87%8D%E6%8E%92%E5%BA%8F%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.3.</span> <span class="toc-text">3. Rerank 模型（重排序阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-LLM%EF%BC%88%E7%94%9F%E6%88%90%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.4.</span> <span class="toc-text">4. 大语言模型 LLM（生成阶段）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-1"><span class="toc-number">19.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%AF%E6%BA%90%EF%BC%9F%E7%8E%B0%E5%9C%A8-RAG-%E6%8A%80%E6%9C%AF%E8%BF%98%E6%98%AF%E6%9C%80%E5%A5%BD%E7%9A%84%E6%8A%80%E6%9C%AF%E6%96%B9%E6%A1%88%E5%90%97%EF%BC%9F%E6%9C%89%E6%9B%B4%E5%85%88%E8%BF%9B%E7%9A%84%E6%96%B9%E6%A1%88%E5%90%97%EF%BC%9F"><span class="toc-number">20.</span> <span class="toc-text">如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%8E-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%AF%E6%BA%90"><span class="toc-number">21.</span> <span class="toc-text">🔎 如何实现溯源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-RAG-%E6%98%AF%E5%90%A6%E4%BB%8D%E6%98%AF%E6%9C%80%E4%BD%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-number">22.</span> <span class="toc-text">📌 RAG 是否仍是最佳方案？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E6%9B%B4%E5%85%88%E8%BF%9B%E7%9A%84%E6%96%B9%E6%A1%88%E6%8E%A2%E7%B4%A2"><span class="toc-number">23.</span> <span class="toc-text">🚀 更先进的方案探索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-4"><span class="toc-number">24.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">25.</span> <span class="toc-text">什么是多模态大模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A0-%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E2%80%9C%E6%A8%A1%E6%80%81%E2%80%9D%E6%8C%87%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">26.</span> <span class="toc-text">🧠 多模态的“模态”指什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B"><span class="toc-number">27.</span> <span class="toc-text">🧩 多模态大模型的核心能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%A3%E8%A1%A8"><span class="toc-number">28.</span> <span class="toc-text">🚀 多模态大模型的代表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">29.</span> <span class="toc-text">🎯 多模态模型的优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-5"><span class="toc-number">30.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-reasoning-%EF%BC%9F"><span class="toc-number">31.</span> <span class="toc-text">大模型如何实现 reasoning ？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0-Reasoning-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F"><span class="toc-number">32.</span> <span class="toc-text">🧩 大模型实现 Reasoning 的主要方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Chain-of-Thought-CoT-%E6%80%9D%E7%BB%B4%E9%93%BE"><span class="toc-number">32.1.</span> <span class="toc-text">1. Chain of Thought (CoT) 思维链</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Self-Consistency%EF%BC%88%E8%87%AA%E6%B4%BD%E9%87%87%E6%A0%B7%EF%BC%89"><span class="toc-number">32.2.</span> <span class="toc-text">2. Self-Consistency（自洽采样）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A4%96%E9%83%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA"><span class="toc-number">32.3.</span> <span class="toc-text">3. 外部工具与检索增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B"><span class="toc-number">32.4.</span> <span class="toc-text">4. 强化学习与奖励模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%94%B9%E8%BF%9B"><span class="toc-number">32.5.</span> <span class="toc-text">5. 架构与训练改进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-2"><span class="toc-number">33.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%BB%A7%E7%BB%AD%E6%9C%AC%E5%AF%B9%E8%AF%9D%E4%B8%AD%E7%9A%84%E4%BE%8B%E5%AD%90%EF%BC%8C%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA-reasoning-%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E3%80%82"><span class="toc-number">34.</span> <span class="toc-text">请继续本对话中的例子，训练一个 reasoning 的大模型。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8-16GB-%E5%86%85%E5%AD%98%E3%80%818-%E6%A0%B8-CPU-%E4%B8%8A%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%85%B7%E5%A4%87%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%B0%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E4%B8%8E%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF"><span class="toc-number">1.</span> <span class="toc-text">目标与核心思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87%EF%BC%88CoT-%E6%80%9D%E7%BB%B4%E9%93%BE%E6%A0%BC%E5%BC%8F%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">数据集准备（CoT 思维链格式）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF%EF%BC%88%E6%8E%A8%E7%90%86%E9%A3%8E%E6%A0%BC%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">提示模板（推理风格）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%EF%BC%88CoT-SFT%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">训练代码（CoT SFT）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E6%97%B6%E7%AD%96%E7%95%A5%EF%BC%9A%E8%87%AA%E6%B4%BD%E9%87%87%E6%A0%B7%E4%B8%8E%E2%80%9C%E6%9C%80%E7%BB%88%E7%AD%94%E6%A1%88%E2%80%9D%E6%8A%BD%E5%8F%96"><span class="toc-number">5.</span> <span class="toc-text">推理时策略：自洽采样与“最终答案”抽取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%80%89%EF%BC%9A%E6%8E%A8%E7%90%86%E4%B8%AD%E7%9A%84%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%EF%BC%88%E8%BD%BB%E9%87%8F%E8%AE%A1%E7%AE%97%E5%99%A8%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">可选：推理中的工具调用（轻量计算器）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#API-%E9%9B%86%E6%88%90%EF%BC%88%E8%BF%94%E5%9B%9E%E6%8E%A8%E7%90%86%E9%93%BE%E4%B8%8E%E5%87%BA%E5%A4%84%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">API 集成（返回推理链与出处）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E6%B5%8B%E4%B8%8E%E8%BF%AD%E4%BB%A3"><span class="toc-number">8.</span> <span class="toc-text">评测与迭代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E5%8F%8B%E5%A5%BD%E5%BB%BA%E8%AE%AE"><span class="toc-number">9.</span> <span class="toc-text">硬件友好建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">10.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%BB%99%E5%87%BA%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">11.</span> <span class="toc-text">请给出全部代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%82-%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">📂 项目结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-%E6%9E%84%E5%BB%BA%E5%88%86%E8%AF%8D%E5%99%A8"><span class="toc-number"></span> <span class="toc-text">1️⃣ 构建分词器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89"><span class="toc-number"></span> <span class="toc-text">2️⃣ 模型定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-%E9%A2%84%E8%AE%AD%E7%BB%83%E3%80%81SFT%E3%80%81Reasoning-SFT%E3%80%81%E6%8E%A8%E7%90%86%E3%80%81API"><span class="toc-number"></span> <span class="toc-text">3️⃣ 预训练、SFT、Reasoning SFT、推理、API</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%9C%85-%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B"><span class="toc-number"></span> <span class="toc-text">✅ 使用流程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#train-pretrain-py%E3%80%81train-sft-py%E3%80%81train-reasoning-sft-py%E3%80%81generate-py%E3%80%81generate-reasoning-py%E3%80%81tiny-tools-py%E3%80%81app-reasoning-py-%E8%BF%99%E4%BA%9B%E6%96%87%E4%BB%B6%E5%AF%B9%E4%BA%8E-reasoning-%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E5%90%97%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">train_pretrain.py、train_sft.py、train_reasoning_sft.py、generate.py、generate_reasoning.py、tiny_tools.py、app_reasoning.py 这些文件对于 reasoning 模式的模型需要修改吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-train-pretrain-py"><span class="toc-number">2.</span> <span class="toc-text">1. train_pretrain.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-train-sft-py"><span class="toc-number">3.</span> <span class="toc-text">2. train_sft.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-train-reasoning-sft-py"><span class="toc-number">4.</span> <span class="toc-text">3. train_reasoning_sft.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-generate-py"><span class="toc-number">5.</span> <span class="toc-text">4. generate.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-generate-reasoning-py"><span class="toc-number">6.</span> <span class="toc-text">5. generate_reasoning.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-tiny-tools-py"><span class="toc-number">7.</span> <span class="toc-text">6. tiny_tools.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-app-reasoning-py"><span class="toc-number">8.</span> <span class="toc-text">7. app_reasoning.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-6"><span class="toc-number">9.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E6%8A%8A%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E7%9A%84%E6%96%87%E4%BB%B6%E9%87%8D%E6%96%B0%E7%94%9F%E6%88%90%E3%80%82"><span class="toc-number">10.</span> <span class="toc-text">请把需要修改的文件重新生成。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-train-reasoning-sft-py"><span class="toc-number"></span> <span class="toc-text">1️⃣ train_reasoning_sft.py</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-generate-reasoning-py"><span class="toc-number"></span> <span class="toc-text">2️⃣ generate_reasoning.py</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-app-reasoning-py"><span class="toc-number"></span> <span class="toc-text">3️⃣ app_reasoning.py</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%EF%BC%8C%E8%AF%B7%E5%B8%AE%E6%88%91%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%AA%E5%A4%A7%E7%BA%B2%EF%BC%8C%E4%B8%BB%E8%A6%81%E4%BB%8B%E7%BB%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B"><span class="toc-number">1.</span> <span class="toc-text">大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%9A-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E5%A4%A7%E7%BA%B2"><span class="toc-number"></span> <span class="toc-text">📚 大模型技术演进大纲</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B5%B7%E7%82%B9%EF%BC%9A%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%90%8C%E8%8A%BD"><span class="toc-number">1.</span> <span class="toc-text">一、起点：语言模型的萌芽</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Transformer-%E9%9D%A9%E5%91%BD%EF%BC%882017%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">二、Transformer 革命（2017）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3"><span class="toc-number">3.</span> <span class="toc-text">三、预训练大模型时代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90%EF%BC%88Alignment%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">四、指令微调与对齐（Alignment）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RAG-%E4%B8%8E%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA"><span class="toc-number">5.</span> <span class="toc-text">五、RAG 与外部知识增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.</span> <span class="toc-text">六、多模态大模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Reasoning-%E4%B8%8E%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B"><span class="toc-number">7.</span> <span class="toc-text">七、Reasoning 与推理能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%BC%80%E6%BA%90%E4%B8%8E%E7%94%9F%E6%80%81%E7%B9%81%E8%8D%A3"><span class="toc-number">8.</span> <span class="toc-text">八、开源与生态繁荣</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%9C%AA%E6%9D%A5%E8%B6%8B%E5%8A%BF"><span class="toc-number">9.</span> <span class="toc-text">九、未来趋势</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%9A-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%AE%B2%E8%A7%A3%E7%A8%BF"><span class="toc-number"></span> <span class="toc-text">📚 大模型技术演进讲解稿</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B5%B7%E7%82%B9%EF%BC%9A%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%90%8C%E8%8A%BD-1"><span class="toc-number">1.</span> <span class="toc-text">一、起点：语言模型的萌芽</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Transformer-%E9%9D%A9%E5%91%BD%EF%BC%882017%EF%BC%89-1"><span class="toc-number">2.</span> <span class="toc-text">二、Transformer 革命（2017）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3-1"><span class="toc-number">3.</span> <span class="toc-text">三、预训练大模型时代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90%EF%BC%882022-%E8%B5%B7%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">四、指令微调与对齐（2022 起）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RAG-%E4%B8%8E%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA-1"><span class="toc-number">5.</span> <span class="toc-text">五、RAG 与外部知识增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B-1"><span class="toc-number">6.</span> <span class="toc-text">六、多模态大模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Reasoning-%E4%B8%8E%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B-1"><span class="toc-number">7.</span> <span class="toc-text">七、Reasoning 与推理能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%BC%80%E6%BA%90%E4%B8%8E%E7%94%9F%E6%80%81%E7%B9%81%E8%8D%A3-1"><span class="toc-number">8.</span> <span class="toc-text">八、开源与生态繁荣</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%9C%AA%E6%9D%A5%E8%B6%8B%E5%8A%BF-1"><span class="toc-number">9.</span> <span class="toc-text">九、未来趋势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-7"><span class="toc-number">10.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%BF%85%E8%AF%BB%E8%AE%BA%E6%96%87"><span class="toc-number">11.</span> <span class="toc-text">大模型技术必读论文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%91-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E5%BF%85%E8%AF%BB%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E6%B8%85%E5%8D%95"><span class="toc-number">12.</span> <span class="toc-text">📑 大模型学习必读经典论文清单</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A9%E6%9C%9F%E5%9F%BA%E7%A1%80%EF%BC%88%E8%AF%8D%E5%90%91%E9%87%8F%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%89"><span class="toc-number">12.1.</span> <span class="toc-text">早期基础（词向量与注意力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer-%E9%9D%A9%E5%91%BD"><span class="toc-number">12.2.</span> <span class="toc-text">Transformer 革命</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%89%A9%E5%B1%95"><span class="toc-number">12.3.</span> <span class="toc-text">预训练与扩展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E4%B8%8E-Scaling-Law"><span class="toc-number">12.4.</span> <span class="toc-text">训练优化与 Scaling Law</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E9%BD%90%E4%B8%8E%E6%8C%87%E4%BB%A4"><span class="toc-number">12.5.</span> <span class="toc-text">对齐与指令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E4%B8%8E%E5%A4%9A%E6%A8%A1%E6%80%81"><span class="toc-number">12.6.</span> <span class="toc-text">知识增强与多模态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E4%B8%8E%E6%9C%AA%E6%9D%A5"><span class="toc-number">12.7.</span> <span class="toc-text">推理与未来</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-8"><span class="toc-number">13.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE"><span class="toc-number">14.</span> <span class="toc-text">📌 学习建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E4%BB%8B%E7%BB%8D%E4%B8%8B-agent"><span class="toc-number">15.</span> <span class="toc-text">请介绍下 agent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-Agent-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">16.</span> <span class="toc-text">🧩 Agent 的核心概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%99%EF%B8%8F-Agent-%E7%9A%84%E5%85%B8%E5%9E%8B%E5%B7%A5%E4%BD%9C%E6%B5%81"><span class="toc-number">17.</span> <span class="toc-text">⚙️ Agent 的典型工作流</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E6%8A%80%E6%9C%AF%E6%94%AF%E6%92%91"><span class="toc-number">18.</span> <span class="toc-text">🔑 技术支撑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8C%8D-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">19.</span> <span class="toc-text">🌍 应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF"><span class="toc-number">20.</span> <span class="toc-text">🚀 发展趋势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E6%83%B3%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%EF%BC%8C%E5%AE%9E%E7%8E%B0%E7%94%B5%E8%84%91%E7%9A%84%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%8C%85%E6%8B%AC-windows-%E5%92%8C-Linux-%E5%92%8C-Unix-like-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E6%96%87%E4%BB%B6-%E5%A4%B9-%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%BE%93%E5%85%A5%E6%8C%87%E5%AE%9A%E7%9A%84-prompt-%E6%9D%A5%E5%AF%B9%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%A0%E9%99%A4%EF%BC%8C%E4%BF%AE%E6%94%B9%EF%BC%8C%E8%AF%BB%E5%8F%96%EF%BC%8C%E6%96%87%E4%BB%B6%E5%BD%92%E7%B1%BB%E7%AD%89%E5%8A%9F%E8%83%BD"><span class="toc-number">21.</span> <span class="toc-text">我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E6%96%87%E4%BB%B6%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%84%E5%BB%BA"><span class="toc-number"></span> <span class="toc-text">个人文件智能体构建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E5%88%99"><span class="toc-number">1.</span> <span class="toc-text">架构与核心原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E6%8E%A7%E7%AD%96%E7%95%A5"><span class="toc-number">2.</span> <span class="toc-text">安全与可控策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">配置示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E6%84%8F%E5%9B%BE%E4%B8%8E%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97"><span class="toc-number">4.</span> <span class="toc-text">结构化意图与操作序列</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%AE%9E%E7%8E%B0%EF%BC%88Python%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">核心实现（Python）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%9D%83%E9%99%90%E5%AE%88%E5%8D%AB"><span class="toc-number">5.1.</span> <span class="toc-text">1. 路径与权限守卫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%96%87%E4%BB%B6%E5%B7%A5%E5%85%B7%E5%B1%82%EF%BC%88%E8%B7%A8%E5%B9%B3%E5%8F%B0%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">2. 文件工具层（跨平台）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BD%92%E7%B1%BB%E4%B8%8E%E6%A0%87%E7%AD%BE"><span class="toc-number">5.3.</span> <span class="toc-text">3. 归类与标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%A1%E8%AE%A1%E6%97%A5%E5%BF%97%E4%B8%8E-Dry-run-%E7%A1%AE%E8%AE%A4"><span class="toc-number">5.4.</span> <span class="toc-text">4. 审计日志与 Dry-run 确认</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%A7%84%E5%88%92%E5%99%A8%E4%B8%8E%E6%89%A7%E8%A1%8C%E5%99%A8"><span class="toc-number">5.5.</span> <span class="toc-text">5. 规划器与执行器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%85%A5%E5%8F%A3"><span class="toc-number">5.6.</span> <span class="toc-text">6. 命令行入口</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">6.</span> <span class="toc-text">跨平台注意事项</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%80%89%E5%A2%9E%E5%BC%BA"><span class="toc-number">7.</span> <span class="toc-text">可选增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">8.</span> <span class="toc-text">使用示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agent-%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E5%93%AA%E7%A7%8D%E8%AF%AD%E8%A8%80%E6%9D%A5%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">Agent 可以使用哪种语言来实现？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0%E8%AF%AD%E8%A8%80%E4%B8%8E%E7%89%B9%E7%82%B9"><span class="toc-number">10.</span> <span class="toc-text">🔑 常见实现语言与特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E9%80%89%E6%8B%A9%E5%BB%BA%E8%AE%AE"><span class="toc-number">11.</span> <span class="toc-text">📌 选择建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%91-Agent-%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%AF%B9%E6%AF%94%E8%A1%A8"><span class="toc-number">12.</span> <span class="toc-text">📑 Agent 常用编程语言对比表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-3"><span class="toc-number">13.</span> <span class="toc-text">🎯 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E4%BD%93%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF%E5%9B%BE%EF%BC%88%E6%96%87%E5%AD%97%E7%89%88%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">🛠️ 构建智能体学习路线图（文字版）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%89%93%E7%89%A2"><span class="toc-number">1.</span> <span class="toc-text">阶段一：基础打牢</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9AAI-%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">阶段二：AI 与大模型基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89%EF%BC%9AAgent-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6"><span class="toc-number">3.</span> <span class="toc-text">阶段三：Agent 基础框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C-Agent-%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.</span> <span class="toc-text">阶段四：文件操作 Agent 实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%94%EF%BC%9A%E8%B7%A8%E5%B9%B3%E5%8F%B0%E4%B8%8E%E6%89%A9%E5%B1%95"><span class="toc-number">5.</span> <span class="toc-text">阶段五：跨平台与扩展</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E5%85%AD%EF%BC%9A%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%9C%AA%E6%9D%A5"><span class="toc-number">6.</span> <span class="toc-text">阶段六：进阶与未来</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-9"><span class="toc-number">7.</span> <span class="toc-text">✅ 总结</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        构建自己的大模型
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Mark Shen</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2025-10-20T18:28:42.000Z" itemprop="datePublished">2025-10-20</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/blog/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/" rel="tag">大模型</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="请用高中生可以理解的方式介绍下大语言模型"><a href="#请用高中生可以理解的方式介绍下大语言模型" class="headerlink" title="请用高中生可以理解的方式介绍下大语言模型"></a>请用高中生可以理解的方式介绍下大语言模型</h2><p><strong>一句话理解：大语言模型（LLM）就是一个“超级会聊天、会写作的人工智能大脑”，它通过学习海量的文字，学会了如何像人一样理解和生成语言。</strong></p>
<hr>
<h3 id="🧠-什么是大语言模型？"><a href="#🧠-什么是大语言模型？" class="headerlink" title="🧠 什么是大语言模型？"></a>🧠 什么是大语言模型？</h3><ul>
<li><strong>“大”</strong>：指的是它学过的内容非常多，参数（就像大脑里的“神经元连接”）可能有上亿甚至上千亿个。</li>
<li><strong>“语言”</strong>：它的主要能力是处理文字，比如理解问题、写文章、翻译语言、写代码。</li>
<li><strong>“模型”</strong>：就是一个经过训练的计算机程序，能根据输入预测最合适的输出。</li>
</ul>
<hr>
<h3 id="📚-它是怎么学会的？"><a href="#📚-它是怎么学会的？" class="headerlink" title="📚 它是怎么学会的？"></a>📚 它是怎么学会的？</h3><p>想象一下：</p>
<ul>
<li>如果你每天读成千上万本书、看无数文章和对话，你会慢慢发现语言里的规律。</li>
<li>大语言模型也是这样，它被“喂”了海量的文本数据，然后通过数学和算法，学会了<strong>“下一个词最可能是什么”</strong>。</li>
<li>比如输入“今天的天气真…”，它可能预测“好”“热”“冷”等词，并根据上下文选出最合理的。</li>
</ul>
<hr>
<h3 id="🍔-打个比方"><a href="#🍔-打个比方" class="headerlink" title="🍔 打个比方"></a>🍔 打个比方</h3><ul>
<li><strong>传统程序</strong>：像菜谱，必须严格按照步骤写死，才能做出一道菜。</li>
<li><strong>大语言模型</strong>：像一个见多识广的厨师，见过无数菜谱和做法。你只要告诉他“我想吃酸辣的”，他就能灵活组合出一道新菜。</li>
</ul>
<hr>
<h3 id="🚀-它能做什么？"><a href="#🚀-它能做什么？" class="headerlink" title="🚀 它能做什么？"></a>🚀 它能做什么？</h3><ul>
<li><strong>写作</strong>：写作文、写故事、写新闻。</li>
<li><strong>学习</strong>：帮你总结知识点、解释难题。</li>
<li><strong>翻译</strong>：在不同语言之间自由切换。</li>
<li><strong>编程</strong>：写代码、找错误。</li>
</ul>
<hr>
<h3 id="⚡-为什么叫“大”？"><a href="#⚡-为什么叫“大”？" class="headerlink" title="⚡ 为什么叫“大”？"></a>⚡ 为什么叫“大”？</h3><ul>
<li>数据量大：学习了海量的文本。</li>
<li>参数量大：模型内部的“神经元连接”非常多。</li>
<li>能力大：能处理各种复杂的语言任务。</li>
</ul>
<hr>
<p>👉 <strong>总结</strong>：大语言模型就像一个“读过无数书的超级学霸”，它不是真的理解世界，但它非常擅长根据学到的规律来“预测和生成语言”，所以看起来就像在和你自然对话。</p>
<p>要不要我帮你做一个 <strong>“大语言模型速记卡片”</strong>，用图表把“它是什么、怎么学、能做什么”整理成一页，像复习提纲一样？</p>
<h2 id="大语言模型如何训练？"><a href="#大语言模型如何训练？" class="headerlink" title="大语言模型如何训练？"></a>大语言模型如何训练？</h2><p><strong>简答版</strong>：大语言模型的训练分为三个主要阶段：<strong>预训练 → 微调 → 强化学习</strong>。先用海量文本学会“语言规律”，再通过人工示例学会“听懂指令”，最后用人类反馈不断优化，让回答更符合人类期望。</p>
<hr>
<h3 id="🧩-训练流程分解"><a href="#🧩-训练流程分解" class="headerlink" title="🧩 训练流程分解"></a>🧩 训练流程分解</h3><ol>
<li><p><strong>预训练（Pretraining）</strong></p>
<ul>
<li><strong>目标</strong>：让模型学会语言的基本规律（语法、语义、上下文）。</li>
<li><strong>方法</strong>：给模型大量文本（书籍、网页、新闻），让它预测“下一个词”。</li>
<li><strong>比喻</strong>：就像高中生先读了三年语文课本和作文集，积累了大量词汇和语感。</li>
</ul>
</li>
<li><p><strong>有监督微调（Supervised Fine-Tuning, SFT）</strong></p>
<ul>
<li><strong>目标</strong>：让模型学会“听懂人类指令”。</li>
<li><strong>方法</strong>：人工写一些“问题—理想答案”的示例，模型模仿这些答案。</li>
<li><strong>比喻</strong>：像老师出题并给出标准答案，学生学会如何答题。</li>
</ul>
</li>
<li><p><strong>人类反馈强化学习（RLHF, Reinforcement Learning with Human Feedback）</strong></p>
<ul>
<li><strong>目标</strong>：让模型回答更符合人类偏好（比如更礼貌、更有逻辑）。</li>
<li><strong>方法</strong>：人类对模型的多个回答打分，模型学会“哪种回答更受欢迎”。</li>
<li><strong>比喻</strong>：像作文比赛，评委打分，学生根据反馈不断改进写作风格。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="⚙️-技术要点"><a href="#⚙️-技术要点" class="headerlink" title="⚙️ 技术要点"></a>⚙️ 技术要点</h3><ul>
<li><strong>架构</strong>：大多数基于 Transformer（注意力机制能捕捉长距离关系）。</li>
<li><strong>数据</strong>：规模巨大，通常是 TB 级别的文本。</li>
<li><strong>算力</strong>：需要成千上万张 GPU/TPU 并行训练。</li>
<li><strong>参数</strong>：模型内部的“神经元连接”可能达到数百亿甚至上万亿。</li>
</ul>
<hr>
<h3 id="📖-打个生活比方"><a href="#📖-打个生活比方" class="headerlink" title="📖 打个生活比方"></a>📖 打个生活比方</h3><ul>
<li><strong>预训练</strong>：像背了整本《新华字典》和无数作文范文。</li>
<li><strong>微调</strong>：老师专门教你“如何写高考作文”。</li>
<li><strong>强化学习</strong>：考官打分，你根据分数调整写作风格。</li>
</ul>
<hr>
<p>👉 <strong>总结</strong>：大语言模型的训练就像培养一个“超级学霸”。先让它读遍天下书（预训练），再教它如何答题（微调），最后通过打分不断修正（强化学习），最终才能成为一个既懂知识又会交流的“语言高手”。</p>
<hr>
<p>要不要我帮你整理一个<strong>“大语言模型训练三阶段速记卡片”</strong>，用图表形式把“预训练—微调—强化学习”的逻辑串起来，像考试复习提纲一样？</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/l01011_/article/details/148157725">CSDN 博客《从零开始训练大语言模型的全过程》</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/636270877">知乎《从零开始训练大模型》</a></li>
</ul>
<h2 id="如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过-api-的方式提供给外部程序使用？"><a href="#如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过-api-的方式提供给外部程序使用？" class="headerlink" title="如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？"></a>如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？</h2><h1 id="从零构建大语言模型"><a href="#从零构建大语言模型" class="headerlink" title="从零构建大语言模型"></a>从零构建大语言模型</h1><p>下面用清晰、可落地的步骤，带你从“白纸”到“能通过 API 提供服务”的完整路径。每个环节都点到为止，足够高中生理解，也能让你动手实践。</p>
<hr>
<h3 id="路线概览"><a href="#路线概览" class="headerlink" title="路线概览"></a>路线概览</h3><ul>
<li><strong>目标:</strong> 从零定义模型 → 训练 → 微调 → 部署为 API</li>
<li><strong>核心环节:</strong> 分词与数据 → 模型结构 → 训练策略 → 对齐与评测 → 推理优化 → API 服务</li>
</ul>
<hr>
<h3 id="基础准备与数据管线"><a href="#基础准备与数据管线" class="headerlink" title="基础准备与数据管线"></a>基础准备与数据管线</h3><ul>
<li><strong>数据来源:</strong> 开源文本语料、你的领域数据、对话日志、代码仓库等。</li>
<li><strong>清洗与划分:</strong> 去重、去噪、分训练/验证/测试集。</li>
<li><strong>分词器与词表:</strong> BPE/WordPiece 等；词表大小影响记忆与速度。</li>
<li><strong>格式化训练样本:</strong> 以“指令+上下文+期望输出”组织，保证一致的提示格式。</li>
<li><strong>度量与基线:</strong> 先为小模型设基线（如困惑度、准确率），再逐步扩大规模。</li>
</ul>
<hr>
<h3 id="定义“大模型”的关键参数"><a href="#定义“大模型”的关键参数" class="headerlink" title="定义“大模型”的关键参数"></a>定义“大模型”的关键参数</h3><ul>
<li><strong>模型架构:</strong> 以 Transformer 为主（自注意力 + 前馈网络）。</li>
<li><strong>核心维度:</strong><ul>
<li><strong>词表大小:</strong> 决定可直接识别的“词/子词”的范围。</li>
<li><strong>嵌入维度:</strong> 每个词的向量维度，决定表达能力。</li>
<li><strong>层数:</strong> 堆叠的 Transformer 层数，影响深度与拟合能力。</li>
<li><strong>注意力头数:</strong> 并行关注不同特征的“视角”数量。</li>
<li><strong>上下文长度:</strong> 一次能读入的最大 Token 数，决定“记忆窗口”。</li>
<li><strong>前馈层维度:</strong> FFN 的隐藏维度，影响非线性表达能力。</li>
<li><strong>正则与稳定:</strong> Dropout、RMSNorm/LayerNorm、残差结构。</li>
</ul>
</li>
<li><strong>训练超参:</strong><ul>
<li><strong>批大小:</strong> 越大越稳，但吃显存；可用梯度累积。</li>
<li><strong>学习率与调度:</strong> 线性预热 + 余弦退火/多段下降。</li>
<li><strong>优化器:</strong> AdamW 等，注意权重衰减和梯度裁剪。</li>
<li><strong>精度与并行:</strong> 混合精度（FP16/BF16）、数据并行、张量并行。</li>
<li><strong>检查点:</strong> 定期保存权重与优化器状态，支持断点续训。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="训练到对齐的完整流程"><a href="#训练到对齐的完整流程" class="headerlink" title="训练到对齐的完整流程"></a>训练到对齐的完整流程</h3><ol>
<li><strong>预训练（语言规律）</strong><ul>
<li><strong>目标:</strong> 预测下一个词；学会语法、语义、长程依赖。</li>
<li><strong>做法:</strong> 大规模通用语料，自监督损失（交叉熵），长时间训练。</li>
</ul>
</li>
<li><strong>有监督微调（听懂指令）</strong><ul>
<li><strong>目标:</strong> 输入指令能产出“规范答案”。</li>
<li><strong>做法:</strong> 用人工标注的“问—答”样本训练，统一提示模板。</li>
</ul>
</li>
<li><strong>人类反馈强化学习（更合人意）</strong><ul>
<li><strong>目标:</strong> 让回答更安全、礼貌、清晰、有逻辑。</li>
<li><strong>做法:</strong> 训练奖励模型对多候选排序，再用策略优化（如 PPO）提升。</li>
</ul>
</li>
<li><strong>评测与安全</strong><ul>
<li><strong>离线指标:</strong> 困惑度、准确率、BLEU/ROUGE、代码通过率等。</li>
<li><strong>在线质检:</strong> 对话质量、事实性、拒答边界、越狱测试。</li>
<li><strong>红线策略:</strong> 敏感话题过滤、规则模板、拒答策略与审计。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="部署为-API-的实战路径"><a href="#部署为-API-的实战路径" class="headerlink" title="部署为 API 的实战路径"></a>部署为 API 的实战路径</h3><h4 id="推理优化与打包"><a href="#推理优化与打包" class="headerlink" title="推理优化与打包"></a>推理优化与打包</h4><ul>
<li><strong>权重格式:</strong> 转 ONNX/Safetensors；按需拆分分片。</li>
<li><strong>加速方案:</strong> KV Cache、张量并行、批量推理、流式输出。</li>
<li><strong>量化与蒸馏:</strong> INT8/INT4 量化降低显存；小模型蒸馏提升性价比。</li>
<li><strong>服务化组件:</strong> 选择推理后端（如支持并发和长上下文）、健康检查、监控与日志。</li>
</ul>
<h4 id="快速搭一个可用的-API（示例）"><a href="#快速搭一个可用的-API（示例）" class="headerlink" title="快速搭一个可用的 API（示例）"></a>快速搭一个可用的 API（示例）</h4><ul>
<li><strong>功能点:</strong> Chat、流式响应、温度控制、鉴权、限流、配额、观测</li>
<li><strong>接口设计:</strong> /v1/chat/completions（与主流兼容）、JSON 输入/输出、OpenAPI 文档</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py — 最小可用 Chat API（示意）</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Mark-LLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span>  <span class="comment"># &quot;system&quot; | &quot;user&quot; | &quot;assistant&quot;</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">512</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_inference</span>(<span class="params">messages, temperature, max_tokens</span>):</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 调用你加载的模型，做推理，并支持流式输出</span></span><br><span class="line">    <span class="comment"># 这里返回一个演示结果</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;你好，我是你的模型。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="comment"># 简单鉴权</span></span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    output = run_inference(req.messages, req.temperature, req.max_tokens)</span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-demo&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=output), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>调用示例:</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl https://your.domain/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;mark-llm-7b&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;用高中水平解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 300</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>上线要点:</strong><ul>
<li><strong>鉴权与配额:</strong> API key/租户体系、速率限制、额度管理。</li>
<li><strong>弹性与高可用:</strong> 多副本、负载均衡、滚动升级、灰度发布。</li>
<li><strong>监控与追踪:</strong> QPS、延迟、错误率、GPU 利用率、日志与审计。</li>
<li><strong>版本与兼容:</strong> 维持 stable 接口，新增能力用新版本号。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="给你的一张“动手清单”"><a href="#给你的一张“动手清单”" class="headerlink" title="给你的一张“动手清单”"></a>给你的一张“动手清单”</h3><ul>
<li><strong>明确目标:</strong> 写作助手/教育问答/代码助理，决定训练数据与评测集。</li>
<li><strong>先小后大:</strong> 先训 100M–1B 级别模型跑通流程，再扩展到 7B/13B。</li>
<li><strong>构建数据与分词:</strong> 打通清洗—分词—样本生成—数据加载的流水线。</li>
<li><strong>迭代训练:</strong> 设定检查点与指标曲线，观察过拟合与泛化。</li>
<li><strong>对齐与安全:</strong> 加入 SFT+RLHF，设计拒答与事实性策略。</li>
<li><strong>推理与服务:</strong> 选择加速/量化方案，上线 API，配监控与限流。</li>
</ul>
<hr>
<p>如果你愿意，我可以按你的具体目标（比如“中文教育问答”或“家庭健康知识库”）给出一版可打印的训练与部署流程图、参数推荐表和评测清单，让你一页就能掌控全局。</p>
<h2 id="请帮我完成"><a href="#请帮我完成" class="headerlink" title="请帮我完成"></a>请帮我完成</h2><p>好的 👍 我来帮你把“从零做一个大模型 → 定义参数 → 提供 API 服务”的完整流程整理成一份<strong>速记卡片式指南</strong>，方便你一眼掌握全局。</p>
<hr>
<h2 id="🧩-一张图看懂大模型全流程"><a href="#🧩-一张图看懂大模型全流程" class="headerlink" title="🧩 一张图看懂大模型全流程"></a>🧩 一张图看懂大模型全流程</h2><p><strong>1. 数据准备 → 2. 模型定义 → 3. 训练 → 4. 微调与对齐 → 5. 部署 → 6. API 服务</strong></p>
<hr>
<h3 id="1️⃣-数据准备"><a href="#1️⃣-数据准备" class="headerlink" title="1️⃣ 数据准备"></a>1️⃣ 数据准备</h3><ul>
<li><strong>收集</strong>：开源语料、书籍、网页、代码、对话数据</li>
<li><strong>清洗</strong>：去重、去噪、统一格式</li>
<li><strong>分词</strong>：BPE/WordPiece，决定词表大小（常见 30k–100k）</li>
</ul>
<hr>
<h3 id="2️⃣-模型参数定义"><a href="#2️⃣-模型参数定义" class="headerlink" title="2️⃣ 模型参数定义"></a>2️⃣ 模型参数定义</h3><ul>
<li><strong>层数（Layers）</strong>：越多越深，常见 12–96 层</li>
<li><strong>隐藏维度（Hidden size）</strong>：每个词的向量维度，常见 768–8192</li>
<li><strong>注意力头数（Heads）</strong>：并行关注不同特征，常见 12–128</li>
<li><strong>上下文长度（Context length）</strong>：一次能读多少 token，常见 2k–128k</li>
<li><strong>参数量（Parameters）</strong>：整体规模，百万到千亿不等</li>
</ul>
<p>👉 <strong>大模型的“大小”就是这些参数的总数</strong>。比如 GPT-3 有 1750 亿参数。</p>
<hr>
<h3 id="3️⃣-训练阶段"><a href="#3️⃣-训练阶段" class="headerlink" title="3️⃣ 训练阶段"></a>3️⃣ 训练阶段</h3><ul>
<li><strong>预训练</strong>：用大规模语料预测“下一个词”</li>
<li><strong>微调（SFT）</strong>：用人工标注的问答数据，学会听懂指令</li>
<li><strong>RLHF</strong>：人类反馈强化学习，让回答更符合人类偏好</li>
</ul>
<hr>
<h3 id="4️⃣-部署与推理优化"><a href="#4️⃣-部署与推理优化" class="headerlink" title="4️⃣ 部署与推理优化"></a>4️⃣ 部署与推理优化</h3><ul>
<li><strong>模型压缩</strong>：量化（INT8/INT4）、蒸馏（小模型模仿大模型）</li>
<li><strong>推理加速</strong>：KV Cache、并行计算、流式输出</li>
<li><strong>容器化</strong>：用 Docker/Kubernetes 部署，方便扩展</li>
</ul>
<hr>
<h3 id="5️⃣-提供-API-服务"><a href="#5️⃣-提供-API-服务" class="headerlink" title="5️⃣ 提供 API 服务"></a>5️⃣ 提供 API 服务</h3><ul>
<li><strong>后端框架</strong>：FastAPI / Flask / Node.js</li>
<li><strong>接口设计</strong>：<ul>
<li>路径：<code>/v1/chat/completions</code></li>
<li>输入：<code>messages</code>（对话历史）、<code>temperature</code>（随机性）、<code>max_tokens</code>（输出长度）</li>
<li>输出：模型生成的文本</li>
</ul>
</li>
<li><strong>调用示例</strong>：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl https://your.domain/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;my-llm-7b&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个乐于助人的助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用高中生能懂的方式解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 300</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h3 id="6️⃣-关键要点"><a href="#6️⃣-关键要点" class="headerlink" title="6️⃣ 关键要点"></a>6️⃣ 关键要点</h3><ul>
<li><strong>安全</strong>：过滤敏感内容，避免越狱</li>
<li><strong>监控</strong>：记录 QPS、延迟、错误率</li>
<li><strong>扩展</strong>：支持多副本、负载均衡、灰度发布</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：</p>
<ul>
<li><strong>大模型的“大小” = 参数量（层数 × 隐藏维度 × 注意力头数等）</strong></li>
<li><strong>训练三步走：预训练 → 微调 → RLHF</strong></li>
<li><strong>部署三件事：优化 → 容器化 → API 服务化</strong></li>
</ul>
<hr>
<p>要不要我帮你把这份内容整理成一张<strong>可打印的流程图/学习卡片</strong>（比如“从零到 API 的 6 步图解”），这样你可以贴在桌子上随时复习？</p>
<h2 id="我现在有一台-16GB-内存，8-核心的-cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型"><a href="#我现在有一台-16GB-内存，8-核心的-cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型" class="headerlink" title="我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型"></a>我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型</h2><h1 id="在-16GB-内存、8-核-CPU-上从零构建并提供大模型-API"><a href="#在-16GB-内存、8-核-CPU-上从零构建并提供大模型-API" class="headerlink" title="在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API"></a>在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API</h1><p>先说人话版结论：用这台机器“从零”训练超大模型不现实，但你可以做一个实用的“小而精”中文指令模型（0.1B 级别或更小），跑通全流程：数据 → 分词 → 预训练 → 微调 → 部署 →API。下面给你一套可落地的配置和步骤。</p>
<hr>
<h2 id="目标与策略"><a href="#目标与策略" class="headerlink" title="目标与策略"></a>目标与策略</h2><ul>
<li><strong>目标:</strong> 训练一个本地可用的中文/中英小型指令模型，支持聊天与问答。</li>
<li><strong>策略:</strong> 采用极简 Transformer、小词表、短上下文、CPU 训练；先预训练极小模型，再做少量高质量指令微调；推理端支持流式输出与简单鉴权。</li>
</ul>
<hr>
<h2 id="可行的模型规格与训练超参"><a href="#可行的模型规格与训练超参" class="headerlink" title="可行的模型规格与训练超参"></a>可行的模型规格与训练超参</h2><h3 id="最小可行模型规格（适配-16GB-内存，CPU-训练）"><a href="#最小可行模型规格（适配-16GB-内存，CPU-训练）" class="headerlink" title="最小可行模型规格（适配 16GB 内存，CPU 训练）"></a>最小可行模型规格（适配 16GB 内存，CPU 训练）</h3><ul>
<li><strong>词表大小:</strong> 16k（中文+英文子词，BPE）</li>
<li><strong>上下文长度:</strong> 512 tokens（足以支持短问答）</li>
<li><strong>层数:</strong> 8 Transformer blocks</li>
<li><strong>隐藏维度:</strong> 512</li>
<li><strong>注意力头数:</strong> 8</li>
<li><strong>前馈维度:</strong> 2048</li>
<li><strong>归一化与正则:</strong> RMSNorm，<strong>Dropout:</strong> 0.1</li>
<li><strong>参数量估算:</strong> ≈ 30–60M（可控在百兆以内）</li>
</ul>
<h3 id="训练超参（CPU-友好）"><a href="#训练超参（CPU-友好）" class="headerlink" title="训练超参（CPU 友好）"></a>训练超参（CPU 友好）</h3><ul>
<li><strong>批大小:</strong> 8–16（用梯度累积让“有效批”达到 64）</li>
<li><strong>学习率:</strong> 3e-4（线性预热到 3e-4，然后余弦退火）</li>
<li><strong>优化器:</strong> AdamW（权重衰减 0.01，梯度裁剪 1.0）</li>
<li><strong>精度:</strong> FP32（CPU），如可用 BF16 更好</li>
<li><strong>训练时长:</strong> 先跑 24–48 小时得到可用的“语言感”，再做指令微调 6–12 小时</li>
<li><strong>检查点频率:</strong> 每 1–2 小时保存一次（断点续训）</li>
</ul>
<hr>
<h2 id="从零到-API-的-6-步"><a href="#从零到-API-的-6-步" class="headerlink" title="从零到 API 的 6 步"></a>从零到 API 的 6 步</h2><h3 id="1-数据与分词"><a href="#1-数据与分词" class="headerlink" title="1. 数据与分词"></a>1. 数据与分词</h3><ul>
<li><strong>语料来源:</strong><ul>
<li><strong>通用:</strong> 开源百科、新闻摘要、教程、公共论坛清洗文本</li>
<li><strong>指令:</strong> 你自制的“问题-答案”对（质量优先）</li>
</ul>
</li>
<li><strong>清洗规范:</strong><ul>
<li><strong>去重:</strong> 文本哈希去重</li>
<li><strong>去噪:</strong> 去广告、去脚本、过滤超长行</li>
<li><strong>统一编码:</strong> UTF-8，移除异常字符</li>
</ul>
</li>
<li><strong>分词器:</strong><ul>
<li><strong>方法:</strong> BPE（SentencePiece）</li>
<li><strong>词表:</strong> 16k；中英混合；保留数字与基础标点</li>
</ul>
</li>
<li><strong>样本格式:</strong><ul>
<li><strong>预训练:</strong> 纯文本连续 token</li>
<li><strong>指令微调:</strong> 统一模板，例如：<ul>
<li><strong>系统:</strong> 你是乐于助人的助手</li>
<li><strong>用户:</strong> 问题…</li>
<li><strong>助手:</strong> 标准答案…</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2-模型搭建"><a href="#2-模型搭建" class="headerlink" title="2. 模型搭建"></a>2. 模型搭建</h3><ul>
<li><strong>架构:</strong> Decoder-only Transformer（GPT 样式）</li>
<li><strong>组件选择:</strong><ul>
<li><strong>位置编码:</strong> RoPE（旋转位置编码）</li>
<li><strong>注意力:</strong> 标准自注意力，支持 KV 缓存（推理加速）</li>
<li><strong>损失:</strong> 交叉熵（下一个 token 预测）</li>
</ul>
</li>
<li><strong>可调开关:</strong><ul>
<li><strong>上下文长度:</strong> 256/512 两档；训练用 256 更省，推理可 512</li>
<li><strong>Dropout:</strong> 0.1→0.0（微调阶段可降）</li>
</ul>
</li>
</ul>
<h3 id="3-预训练（语言能力）"><a href="#3-预训练（语言能力）" class="headerlink" title="3. 预训练（语言能力）"></a>3. 预训练（语言能力）</h3><ul>
<li><strong>目标:</strong> 学会基本语法与语义、中文分词习惯</li>
<li><strong>做法:</strong><ul>
<li><strong>数据量:</strong> 1–5GB 干净文本（这台机器可承受的小规模）</li>
<li><strong>课程学习:</strong> 先短上下文、短序列，后增大到 512</li>
<li><strong>监控:</strong> 训练/验证困惑度（PPL）下降趋势，避免发散</li>
</ul>
</li>
<li><strong>产出:</strong> “基础语言模型”检查点（如 base-40M）</li>
</ul>
<h3 id="4-指令微调与对齐"><a href="#4-指令微调与对齐" class="headerlink" title="4. 指令微调与对齐"></a>4. 指令微调与对齐</h3><ul>
<li><strong>有监督微调（SFT）:</strong><ul>
<li><strong>数据:</strong> 5k–50k 条高质量问答对（中文优先）</li>
<li><strong>模板:</strong> 固定提示格式，提升稳定性</li>
<li><strong>目标:</strong> 提升遵循指令、结构化表达能力</li>
</ul>
</li>
<li><strong>轻量对齐:</strong><ul>
<li><strong>人类偏好:</strong> 简单排序数据（两两对比选优）</li>
<li><strong>训练:</strong> 资源有限可跳过 RLHF，转而更严格的 SFT 数据与拒答规则</li>
</ul>
</li>
<li><strong>安全与边界:</strong><ul>
<li><strong>内容过滤:</strong> 敏感类别关键词屏蔽</li>
<li><strong>拒答策略:</strong> 对不当请求返回通用安全提示</li>
</ul>
</li>
</ul>
<h3 id="5-推理与部署"><a href="#5-推理与部署" class="headerlink" title="5. 推理与部署"></a>5. 推理与部署</h3><ul>
<li><strong>推理优化:</strong><ul>
<li><strong>KV 缓存:</strong> 显著加速长上下文生成</li>
<li><strong>采样策略:</strong> top-k=40、top-p=0.9、temperature=0.7（可调）</li>
<li><strong>流式输出:</strong> 边生成边返回，降低感知延迟</li>
</ul>
</li>
<li><strong>打包:</strong><ul>
<li><strong>权重存储:</strong> safetensors（安全、可分片）</li>
<li><strong>容器化:</strong> Docker（可选），本机即可跑</li>
</ul>
</li>
<li><strong>监控:</strong><ul>
<li><strong>日志:</strong> 请求、延迟、错误</li>
<li><strong>限流:</strong> 简单令牌桶（防止过载）</li>
</ul>
</li>
</ul>
<h3 id="6-提供-API-服务（FastAPI-示例）"><a href="#6-提供-API-服务（FastAPI-示例）" class="headerlink" title="6. 提供 API 服务（FastAPI 示例）"></a>6. 提供 API 服务（FastAPI 示例）</h3><ul>
<li><strong>接口设计:</strong> 兼容主流 <code>/v1/chat/completions</code>；鉴权用 Bearer Token</li>
<li><strong>功能:</strong> 历史消息、温度控制、最大输出长度、可选流式</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py — 轻量CPU模型推理API（示意）</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Tiny-LLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span>  <span class="comment"># &quot;system&quot; | &quot;user&quot; | &quot;assistant&quot;</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span> = <span class="string">&quot;tiny-llm-40m&quot;</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">40</span></span><br><span class="line">    top_p: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.9</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">256</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 伪代码：加载你训练好的权重与分词器</span></span><br><span class="line"><span class="comment"># tokenizer = load_tokenizer(&quot;./tokenizer&quot;)</span></span><br><span class="line"><span class="comment"># model = load_model(&quot;./tiny-llm-40m.safetensors&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_inference</span>(<span class="params">messages, temperature, top_k, top_p, max_tokens</span>):</span><br><span class="line">    <span class="comment"># 这里调用你实现的generate()，支持KV缓存与流式</span></span><br><span class="line">    <span class="comment"># text = generate(model, tokenizer, messages, temperature, top_k, top_p, max_tokens)</span></span><br><span class="line">    text = <span class="string">&quot;你好，我是你的本地小模型，已接入API。&quot;</span></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    output = run_inference(req.messages, req.temperature, req.top_k, req.top_p, req.max_tokens)</span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-local&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=output), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>调用示例:</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;tiny-llm-40m&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的中文助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;帮我用高中生能懂的语言解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 200</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="可打印的“动手清单”"><a href="#可打印的“动手清单”" class="headerlink" title="可打印的“动手清单”"></a>可打印的“动手清单”</h2><ul>
<li><strong>目标与领域:</strong><ul>
<li><strong>用途:</strong> 中文聊天/教育问答/家庭知识</li>
<li><strong>风格:</strong> 简洁、礼貌、结构化</li>
</ul>
</li>
<li><strong>数据流水线:</strong><ul>
<li><strong>收集:</strong> 通用中文文本 + 你自制问答</li>
<li><strong>清洗:</strong> 去重、去噪、统一格式</li>
<li><strong>分词:</strong> BPE，词表 16k</li>
</ul>
</li>
<li><strong>模型与超参:</strong><ul>
<li><strong>结构:</strong> 8 层、hidden=512、heads=8、ffn=2048、context=512</li>
<li><strong>训练:</strong> batch=8（累积到 64）、AdamW、lr=3e-4、fp32</li>
<li><strong>时长:</strong> 预训 1–2 天；SFT 半天到一天</li>
</ul>
</li>
<li><strong>评测与安全:</strong><ul>
<li><strong>指标:</strong> 困惑度、简单问答集准确率</li>
<li><strong>安全:</strong> 敏感词过滤、拒答模板</li>
</ul>
</li>
<li><strong>部署与 API:</strong><ul>
<li><strong>权重:</strong> safetensors</li>
<li><strong>优化:</strong> KV 缓存、流式输出</li>
<li><strong>服务:</strong> FastAPI，鉴权+限流+日志</li>
</ul>
</li>
</ul>
<hr>
<h2 id="进阶与扩展建议"><a href="#进阶与扩展建议" class="headerlink" title="进阶与扩展建议"></a>进阶与扩展建议</h2><ul>
<li><strong>蒸馏到更小:</strong> 用你训练的模型教师，蒸馏到更轻规格（如 hidden=384，参数更少）</li>
<li><strong>持续微调:</strong> 持续收集真实使用问答，定期 SFT 提升质量</li>
<li><strong>长上下文版本:</strong> 若需要长文支持，增至 1024–2048，但留意 CPU 内存占用</li>
<li><strong>量化推理:</strong> 推理时做 INT8/INT4 量化，显著降内存占用（训练仍用 FP32）</li>
</ul>
<hr>
<p>如果你愿意，我可以把这套规格和流程做成一页 A4 的可打印卡片（含模型超参表、训练日程、API 字段表），并按“中文教育问答”给你准备一套高质量指令微调模板与小型评测集，直接开训。你更偏好中文专用还是中英混合词表？</p>
<h2 id="基于上面的回答，请给我代码层面的实现"><a href="#基于上面的回答，请给我代码层面的实现" class="headerlink" title="基于上面的回答，请给我代码层面的实现"></a>基于上面的回答，请给我代码层面的实现</h2><p>下面给你“可运行的最小完整代码”，涵盖数据准备、分词器、模型搭建、预训练、指令微调、推理生成、以及 FastAPI 对外提供服务。你可以直接按模块落地，逐步跑通。</p>
<hr>
<h2 id="项目结构与依赖"><a href="#项目结构与依赖" class="headerlink" title="项目结构与依赖"></a>项目结构与依赖</h2><ul>
<li><p>建议结构：</p>
<ul>
<li>data/：语料与指令数据</li>
<li>tokenizer/：分词器文件</li>
<li>checkpoints/：模型权重</li>
<li>app.py：API 服务</li>
<li>train_pretrain.py：预训练</li>
<li>train_sft.py：指令微调</li>
<li>model.py：模型定义与推理</li>
<li>build_tokenizer.py：构建 BPE 分词器</li>
<li>generate.py：离线推理</li>
</ul>
</li>
<li><p>依赖：</p>
<ul>
<li>python ≥ 3.9</li>
<li>pip install torch sentencepiece fastapi uvicorn pydantic</li>
</ul>
</li>
</ul>
<hr>
<h2 id="1-构建分词器（BPE，词表-16k）"><a href="#1-构建分词器（BPE，词表-16k）" class="headerlink" title="1. 构建分词器（BPE，词表 16k）"></a>1. 构建分词器（BPE，词表 16k）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_tokenizer.py</span></span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tokenizer</span>(<span class="params">input_txt=<span class="string">&quot;data/corpus.txt&quot;</span>, model_prefix=<span class="string">&quot;tokenizer/spm&quot;</span>, vocab_size=<span class="number">16000</span></span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;tokenizer&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    spm.SentencePieceTrainer.Train(</span><br><span class="line">        <span class="built_in">input</span>=input_txt,</span><br><span class="line">        model_prefix=model_prefix,</span><br><span class="line">        vocab_size=vocab_size,</span><br><span class="line">        model_type=<span class="string">&quot;bpe&quot;</span>,</span><br><span class="line">        character_coverage=<span class="number">0.9995</span>,  <span class="comment"># 适合中英混合</span></span><br><span class="line">        bos_id=<span class="number">1</span>, eos_id=<span class="number">2</span>, pad_id=<span class="number">0</span>, unk_id=<span class="number">3</span>,</span><br><span class="line">        user_defined_symbols=[<span class="string">&quot;&lt;|system|&gt;&quot;</span>, <span class="string">&quot;&lt;|user|&gt;&quot;</span>, <span class="string">&quot;&lt;|assistant|&gt;&quot;</span>, <span class="string">&quot;&lt;|sep|&gt;&quot;</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Tokenizer built:&quot;</span>, model_prefix + <span class="string">&quot;.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    build_tokenizer()</span><br></pre></td></tr></table></figure>

<ul>
<li>准备 data/corpus.txt（1–5GB 清洗文本，先用几百 MB 也可跑通）。</li>
</ul>
<hr>
<h2 id="2-模型定义（Decoder-only-Transformer，约-40M-参数）"><a href="#2-模型定义（Decoder-only-Transformer，约-40M-参数）" class="headerlink" title="2. 模型定义（Decoder-only Transformer，约 40M 参数）"></a>2. 模型定义（Decoder-only Transformer，约 40M 参数）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        norm_x = x * torch.rsqrt(torch.mean(x * x, dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="variable language_">self</span>.eps)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.weight * norm_x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RotaryEmbedding</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, base=<span class="number">10000</span></span>):</span><br><span class="line">        inv_freq = <span class="number">1.0</span> / (base ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>).<span class="built_in">float</span>() / dim))</span><br><span class="line">        <span class="variable language_">self</span>.inv_freq = inv_freq</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_cos_sin</span>(<span class="params">self, seq_len, device</span>):</span><br><span class="line">        t = torch.arange(seq_len, device=device).type_as(<span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        freqs = torch.outer(t, <span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        cos, sin = freqs.cos(), freqs.sin()</span><br><span class="line">        <span class="keyword">return</span> cos, sin</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rope</span>(<span class="params">x, cos, sin</span>):</span><br><span class="line">    <span class="comment"># x: (b, n_heads, seq_len, head_dim)</span></span><br><span class="line">    head_dim = x.size(-<span class="number">1</span>)</span><br><span class="line">    x1 = x[..., :head_dim//<span class="number">2</span>]</span><br><span class="line">    x2 = x[..., head_dim//<span class="number">2</span>:]</span><br><span class="line">    x_rope = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> x_rope</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.n_heads = n_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = dim // n_heads</span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.o = nn.Linear(dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span>, rope=<span class="literal">None</span>, kv_cache=<span class="literal">None</span></span>):</span><br><span class="line">        B, T, C = x.size()</span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x)  <span class="comment"># (B, T, 3C)</span></span><br><span class="line">        q, k, v = qkv.split(C, dim=-<span class="number">1</span>)</span><br><span class="line">        q = q.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># (B, H, T, D)</span></span><br><span class="line">        k = k.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        v = v.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cos, sin = rope.get_cos_sin(T, x.device)</span><br><span class="line">            cos = cos[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            sin = sin[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            q = apply_rope(q, cos, sin)</span><br><span class="line">            k = apply_rope(k, cos, sin)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># causal mask</span></span><br><span class="line">        att = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(<span class="variable language_">self</span>.head_dim)  <span class="comment"># (B, H, T, T)</span></span><br><span class="line">        causal = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        att = att.masked_fill(causal == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            att = att + mask</span><br><span class="line">        att = F.softmax(att, dim=-<span class="number">1</span>)</span><br><span class="line">        att = <span class="variable language_">self</span>.dropout(att)</span><br><span class="line">        y = att @ v  <span class="comment"># (B, H, T, D)</span></span><br><span class="line">        y = y.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(B, T, C)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.o(y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, ffn_dim, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, ffn_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(ffn_dim, dim)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w2(<span class="variable language_">self</span>.dropout(F.silu(<span class="variable language_">self</span>.w1(x))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, ffn_dim, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.norm1 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, n_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.norm2 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.ffn = FeedForward(dim, ffn_dim, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.rope = RotaryEmbedding(dim // n_heads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x), mask=mask, rope=<span class="variable language_">self</span>.rope)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.ffn(<span class="variable language_">self</span>.norm2(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyLLM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tok_emb = nn.Embedding(vocab_size, dim)</span><br><span class="line">        <span class="variable language_">self</span>.pos_emb = <span class="literal">None</span>  <span class="comment"># 使用RoPE，不需要绝对位置</span></span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.ModuleList([TransformerBlock(dim, n_heads, ffn_dim, dropout) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line">        <span class="variable language_">self</span>.norm = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.lm_head = nn.Linear(dim, vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.max_seq_len = max_seq_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># idx: (B, T)</span></span><br><span class="line">        x = <span class="variable language_">self</span>.tok_emb(idx)</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        logits = <span class="variable language_">self</span>.lm_head(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, idx, max_new_tokens=<span class="number">128</span>, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_new_tokens):</span><br><span class="line">            logits = <span class="variable language_">self</span>.forward(idx)[:, -<span class="number">1</span>, :]  <span class="comment"># (B, V)</span></span><br><span class="line">            logits = logits / <span class="built_in">max</span>(temperature, <span class="number">1e-5</span>)</span><br><span class="line">            probs = F.softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># nucleus + top-k filter（简化版）</span></span><br><span class="line">            <span class="keyword">if</span> top_k <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                topk_vals, topk_idx = torch.topk(probs, k=<span class="built_in">min</span>(top_k, probs.size(-<span class="number">1</span>)), dim=-<span class="number">1</span>)</span><br><span class="line">                filt = torch.zeros_like(probs)</span><br><span class="line">                filt.scatter_(<span class="number">1</span>, topk_idx, topk_vals)</span><br><span class="line">                probs = filt</span><br><span class="line">            <span class="keyword">if</span> top_p <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                sorted_probs, sorted_idx = torch.sort(probs, descending=<span class="literal">True</span>, dim=-<span class="number">1</span>)</span><br><span class="line">                cum = torch.cumsum(sorted_probs, dim=-<span class="number">1</span>)</span><br><span class="line">                mask = cum &lt;= top_p</span><br><span class="line">                <span class="comment"># 确保至少保留一个</span></span><br><span class="line">                mask[..., <span class="number">0</span>] = <span class="literal">True</span></span><br><span class="line">                filt = torch.zeros_like(probs)</span><br><span class="line">                filt.scatter_(<span class="number">1</span>, sorted_idx, sorted_probs * mask)</span><br><span class="line">                probs = filt</span><br><span class="line">            probs = probs / probs.<span class="built_in">sum</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            next_token = torch.multinomial(probs, num_samples=<span class="number">1</span>)  <span class="comment"># (B, 1)</span></span><br><span class="line">            idx = torch.cat([idx, next_token], dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> idx.size(<span class="number">1</span>) &gt;= <span class="variable language_">self</span>.max_seq_len:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> idx</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3-预训练（自监督，下一个-token-预测）"><a href="#3-预训练（自监督，下一个-token-预测）" class="headerlink" title="3. 预训练（自监督，下一个 token 预测）"></a>3. 预训练（自监督，下一个 token 预测）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_pretrain.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TextDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, txt_path, sp_model_path, seq_len=<span class="number">256</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(txt_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="variable language_">self</span>.text = f.read()</span><br><span class="line">        <span class="variable language_">self</span>.ids = <span class="variable language_">self</span>.sp.encode(<span class="variable language_">self</span>.text, out_type=<span class="built_in">int</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(<span class="number">1</span>, <span class="built_in">len</span>(<span class="variable language_">self</span>.ids) // <span class="variable language_">self</span>.seq_len - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        i = idx * <span class="variable language_">self</span>.seq_len</span><br><span class="line">        x = <span class="variable language_">self</span>.ids[i:i+<span class="variable language_">self</span>.seq_len]</span><br><span class="line">        y = <span class="variable language_">self</span>.ids[i+<span class="number">1</span>:i+<span class="variable language_">self</span>.seq_len+<span class="number">1</span>]</span><br><span class="line">        x = torch.tensor(x, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(y, dtype=torch.long)</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_pretrain</span>(<span class="params"></span></span><br><span class="line"><span class="params">    corpus_path=<span class="string">&quot;data/corpus.txt&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>,</span></span><br><span class="line"><span class="params">    dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>,</span></span><br><span class="line"><span class="params">    seq_len=<span class="number">256</span>, batch_size=<span class="number">8</span>, lr=<span class="number">3e-4</span>, epochs=<span class="number">1</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    dataset = TextDataset(corpus_path, spm_path, seq_len=seq_len)</span><br><span class="line">    loader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span>).to(device)</span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    scaler = <span class="literal">None</span>  <span class="comment"># CPU上不需要AMP</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Pretraining starts. Steps:&quot;</span>, <span class="built_in">len</span>(loader))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">            x = x.to(device)</span><br><span class="line">            y = y.to(device)</span><br><span class="line">            logits = model(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>))</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line"></span><br><span class="line">            total_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                ppl = math.exp(total_loss / <span class="number">100</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>: loss=<span class="subst">&#123;total_loss/<span class="number">100</span>:<span class="number">.4</span>f&#125;</span> ppl≈<span class="subst">&#123;ppl:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                total_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;pretrain_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    train_pretrain(epochs=<span class="number">1</span>)  <span class="comment"># 先跑通一轮</span></span><br></pre></td></tr></table></figure>

<ul>
<li>先跑短序列（256）更省资源，之后可提高到 512 继续训练。</li>
</ul>
<hr>
<h2 id="4-指令微调（SFT）"><a href="#4-指令微调（SFT）" class="headerlink" title="4. 指令微调（SFT）"></a>4. 指令微调（SFT）</h2><p>准备 data/sft.jsonl，每行一个样本：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是乐于助人的助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;解释云原生&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;assistant&quot;</span><span class="punctuation">:</span> <span class="string">&quot;云原生是为云设计的软件方式...&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是乐于助人的助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;什么是大语言模型？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;assistant&quot;</span><span class="punctuation">:</span> <span class="string">&quot;大语言模型是通过学习海量文本...&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>])</span><br><span class="line">                full = prompt + obj[<span class="string">&quot;assistant&quot;</span>]</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(full, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># label位置：从assistant开头开始训练；system/user部分设置为-100忽略</span></span><br><span class="line">                prompt_ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prompt_ids) + ids[<span class="built_in">len</span>(prompt_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels = labels + [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = SFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded pretrain:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        total = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)  <span class="comment"># (B, T, V)</span></span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            total += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>: sft_loss=<span class="subst">&#123;total/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                total = <span class="number">0.0</span></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="5-离线推理与测试"><a href="#5-离线推理与测试" class="headerlink" title="5. 离线推理与测试"></a>5. 离线推理与测试</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">model_ckpt, spm_path, system, user, max_new_tokens=<span class="number">200</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, T)</span></span><br><span class="line">    out = model.generate(x, max_new_tokens=max_new_tokens, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">    text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">    <span class="comment"># 只截取assistant部分</span></span><br><span class="line">    ans = text.split(<span class="string">&quot;&lt;|assistant|&gt;\n&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(ans)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    run(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是乐于助人的中文助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;请用高中生能懂的语言解释云原生&quot;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="6-FastAPI-对外提供服务"><a href="#6-FastAPI-对外提供服务" class="headerlink" title="6. FastAPI 对外提供服务"></a>6. FastAPI 对外提供服务</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header, HTTPException</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">SPM_PATH = <span class="string">&quot;tokenizer/spm.model&quot;</span></span><br><span class="line">CKPT_PATH = <span class="string">&quot;checkpoints/sft_epoch0.pt&quot;</span></span><br><span class="line"></span><br><span class="line">sp = spm.SentencePieceProcessor(model_file=SPM_PATH)</span><br><span class="line">model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">sd = torch.load(CKPT_PATH, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;TinyLLM API&quot;</span>, version=<span class="string">&quot;1.0.0&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span> = <span class="string">&quot;tiny-llm-40m&quot;</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    temperature: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">40</span></span><br><span class="line">    top_p: <span class="type">Optional</span>[<span class="built_in">float</span>] = <span class="number">0.9</span></span><br><span class="line">    max_tokens: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="number">256</span></span><br><span class="line">    stream: <span class="type">Optional</span>[<span class="built_in">bool</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt_from_messages</span>(<span class="params">messages: <span class="type">List</span>[Message]</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    system = <span class="string">&quot;&quot;</span></span><br><span class="line">    user = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;system&quot;</span>:</span><br><span class="line">            system = m.content</span><br><span class="line">        <span class="keyword">elif</span> m.role == <span class="string">&quot;user&quot;</span>:</span><br><span class="line">            user = m.content</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span>, response_model=ChatResponse</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="keyword">if</span> authorization != <span class="string">&quot;Bearer YOUR_API_KEY&quot;</span>:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">401</span>, detail=<span class="string">&quot;Invalid API key&quot;</span>)</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt_from_messages(req.messages)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    out = model.generate(x, max_new_tokens=req.max_tokens, temperature=req.temperature, top_k=req.top_k, top_p=req.top_p)</span><br><span class="line">    text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">    ans = text.split(<span class="string">&quot;&lt;|assistant|&gt;\n&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-local&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=ans), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<ul>
<li>启动服务：<code>uvicorn app:app --host 0.0.0.0 --port 8000</code></li>
<li>调用示例：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curl http://localhost:8000/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer YOUR_API_KEY&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;tiny-llm-40m&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是乐于助人的中文助手&quot;&#125;,</span></span><br><span class="line"><span class="string">      &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;请用高中生能懂的语言解释云原生&quot;&#125;</span></span><br><span class="line"><span class="string">    ],</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0.7,</span></span><br><span class="line"><span class="string">    &quot;max_tokens&quot;: 200</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="7-数据准备与清洗示例"><a href="#7-数据准备与清洗示例" class="headerlink" title="7. 数据准备与清洗示例"></a>7. 数据准备与清洗示例</h2><ul>
<li>语料汇总脚本（合并文本、简单清洗）：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># data_prepare.py</span></span><br><span class="line"><span class="keyword">import</span> os, re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean_line</span>(<span class="params">s: <span class="built_in">str</span></span>):</span><br><span class="line">    s = s.strip()</span><br><span class="line">    s = re.sub(<span class="string">r&quot;\s+&quot;</span>, <span class="string">&quot; &quot;</span>, s)</span><br><span class="line">    s = re.sub(<span class="string">r&quot;[^\x09\x0A\x0D\x20-\x7E\u4e00-\u9fff，。？！、：；“”‘’（）《》—…]&quot;</span>, <span class="string">&quot;&quot;</span>, s)</span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_corpus</span>(<span class="params">src_dir=<span class="string">&quot;data/raw&quot;</span>, out_path=<span class="string">&quot;data/corpus.txt&quot;</span></span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(out_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> out:</span><br><span class="line">        <span class="keyword">for</span> root, _, files <span class="keyword">in</span> os.walk(src_dir):</span><br><span class="line">            <span class="keyword">for</span> fn <span class="keyword">in</span> files:</span><br><span class="line">                <span class="keyword">if</span> fn.endswith(<span class="string">&quot;.txt&quot;</span>):</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(root, fn), <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>, errors=<span class="string">&quot;ignore&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                        <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                            line = clean_line(line)</span><br><span class="line">                            <span class="keyword">if</span> <span class="built_in">len</span>(line) &gt; <span class="number">1</span>:</span><br><span class="line">                                out.write(line + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Merged to:&quot;</span>, out_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    merge_corpus()</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="8-训练建议与资源控制"><a href="#8-训练建议与资源控制" class="headerlink" title="8. 训练建议与资源控制"></a>8. 训练建议与资源控制</h2><ul>
<li>使用短序列预热：先 seq_len=256 训练一轮，再升到 512 继续。</li>
<li>小批量 + 梯度裁剪：batch=4–8，clip_grad_norm=1.0。</li>
<li>定期保存检查点，支持断点续训。</li>
<li>指令数据质量优先于数量：先 5k–10k 高质量样本效果更稳。</li>
</ul>
<hr>
<h2 id="9-下一步可选增强"><a href="#9-下一步可选增强" class="headerlink" title="9. 下一步可选增强"></a>9. 下一步可选增强</h2><ul>
<li>量化推理（INT8/INT4）：减少内存占用（训练仍用 FP32）。</li>
<li>蒸馏到更小规格：dim=384, n_layers=6，进一步提速。</li>
<li>增加拒答与安全过滤：在 app.py 返回前做关键词/策略检查。</li>
<li>流式输出：在 FastAPI 里用服务器推送事件（SSE）逐 token 返回。</li>
</ul>
<hr>
<p>如果你愿意，我可以为你的目标领域（比如“中文教育问答”）生成一套高质量的指令模板和小型评测集 JSONL，让你直接训练并验证效果。你更偏好哪些主题和题型？</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/zheniu/stochastic-cslr">https://github.com/zheniu/stochastic-cslr</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/zheniu/stochastic-cslr/blob/main/stochastic_cslr/model/xfmr.py">https://github.com/zheniu/stochastic-cslr/blob/main/stochastic_cslr/model/xfmr.py</a></li>
</ul>
<h2 id="对于训练数据，有开源的数据集吗？"><a href="#对于训练数据，有开源的数据集吗？" class="headerlink" title="对于训练数据，有开源的数据集吗？"></a>对于训练数据，有开源的数据集吗？</h2><p><strong>有的 ✅，目前已经有大量开源的大语言模型训练数据集，涵盖预训练语料、指令微调数据、偏好数据和评测数据。你完全可以基于这些开源数据来跑通“小模型”的训练流程。</strong></p>
<hr>
<h2 id="🔑-常见的开源数据集类型"><a href="#🔑-常见的开源数据集类型" class="headerlink" title="🔑 常见的开源数据集类型"></a>🔑 常见的开源数据集类型</h2><h3 id="1-预训练语料（基础语言能力）"><a href="#1-预训练语料（基础语言能力）" class="headerlink" title="1. 预训练语料（基础语言能力）"></a>1. 预训练语料（基础语言能力）</h3><ul>
<li><strong>中文维基百科语料</strong>：经过清洗的中文百科条目，常用于中文基础预训练。</li>
<li><strong>FineWeb / Ultra-FineWeb</strong>：大规模中英文网页清洗语料，质量较高，适合做小规模预训练子集。</li>
<li><strong>Chinese-Cosmopedia</strong>：合成的中文百科类数据，覆盖面广。</li>
</ul>
<h3 id="2-指令微调数据（让模型“听懂人话”）"><a href="#2-指令微调数据（让模型“听懂人话”）" class="headerlink" title="2. 指令微调数据（让模型“听懂人话”）"></a>2. 指令微调数据（让模型“听懂人话”）</h3><ul>
<li><strong>Alpaca / Alpaca-GPT4 中文版</strong>：基于指令-回答对的开源数据集，常用于小模型指令微调。</li>
<li><strong>Belle 数据集</strong>：中文指令微调数据，包含问答、写作、推理等多种任务。</li>
<li><strong>Baize / ShareGPT</strong>：对话数据集，适合训练聊天风格的模型。</li>
</ul>
<h3 id="3-偏好数据（对齐人类价值）"><a href="#3-偏好数据（对齐人类价值）" class="headerlink" title="3. 偏好数据（对齐人类价值）"></a>3. 偏好数据（对齐人类价值）</h3><ul>
<li><strong>OpenAssistant Conversations</strong>：多轮对话数据，带有人类偏好标注。</li>
<li><strong>HH-RLHF</strong>：Anthropic 发布的人类偏好数据集，常用于 RLHF。</li>
</ul>
<h3 id="4-评测数据（测试模型效果）"><a href="#4-评测数据（测试模型效果）" class="headerlink" title="4. 评测数据（测试模型效果）"></a>4. 评测数据（测试模型效果）</h3><ul>
<li><strong>CMMLU</strong>：中文多任务评测集，覆盖学科知识。</li>
<li><strong>C-Eval</strong>：中文考试题型评测集，适合测试模型在教育类任务上的表现。</li>
</ul>
<hr>
<h2 id="📚-推荐资源整理"><a href="#📚-推荐资源整理" class="headerlink" title="📚 推荐资源整理"></a>📚 推荐资源整理</h2><ul>
<li><strong>知乎整理：444 个大模型数据集下载地址</strong></li>
<li><strong>CSDN：高质量中文大模型数据集合集</strong></li>
<li><strong>GitHub：大语言模型高质量数据集汇总</strong></li>
</ul>
<p>这些资源里不仅有下载链接，还对数据集做了分类（预训练、指令、偏好、评测），你可以根据硬件条件挑选小规模子集来实验。</p>
<hr>
<h2 id="🛠️-给你的小机子建议"><a href="#🛠️-给你的小机子建议" class="headerlink" title="🛠️ 给你的小机子建议"></a>🛠️ 给你的小机子建议</h2><ul>
<li><strong>预训练</strong>：不要直接用 TB 级数据，先用 <strong>几百 MB 的中文维基语料</strong> 或 <strong>FineWeb 子集</strong>。</li>
<li><strong>指令微调</strong>：优先选择 <strong>Belle</strong> 或 <strong>Alpaca 中文版</strong>，几万条就能显著提升效果。</li>
<li><strong>评测</strong>：用 <strong>C-Eval</strong> 或 <strong>CMMLU</strong> 的小样本，快速验证模型是否能回答常识/学科问题。</li>
</ul>
<hr>
<p>👉 总结：<strong>完全有开源数据集可用</strong>，你可以先用中文维基 + Belle 指令数据，跑通一个“小而美”的模型，再逐步扩展。</p>
<p>要不要我帮你整理一份 <strong>“适合 16GB 内存 CPU 训练的小规模数据集清单 + 下载入口”</strong>，直接给你可用的组合方案？</p>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/19630799254">知乎：《大模型数据集全面整理：444 个数据集下载地址》</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011559552/article/details/142152619">CSDN：《最全-高质量大模型中文数据集》</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ninehills/blog/issues/129">GitHub Issue：《大语言模型高质量数据集汇总》</a></li>
</ul>
<h2 id="对于构建自己的大模型，按照上面-1-2-3……的顺序执行-python-文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？"><a href="#对于构建自己的大模型，按照上面-1-2-3……的顺序执行-python-文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？" class="headerlink" title="对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？"></a>对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？</h2><p>非常好的问题 👍 我来帮你把整个流程梳理清楚，让你知道“执行顺序 → 产出物 → 使用方式 → 微调方法”。</p>
<hr>
<h2 id="🛠️-执行顺序"><a href="#🛠️-执行顺序" class="headerlink" title="🛠️ 执行顺序"></a>🛠️ 执行顺序</h2><p>你可以理解为一个流水线，按顺序执行即可：</p>
<ol>
<li><strong>数据准备</strong><ul>
<li>清洗语料，合并成 <code>corpus.txt</code></li>
<li>构建分词器（<code>build_tokenizer.py</code>）</li>
</ul>
</li>
<li><strong>预训练</strong><ul>
<li>执行 <code>train_pretrain.py</code>，得到基础语言模型权重</li>
</ul>
</li>
<li><strong>指令微调（SFT）</strong><ul>
<li>准备 <code>sft.jsonl</code>（问答对）</li>
<li>执行 <code>train_sft.py</code>，在预训练模型基础上继续训练</li>
</ul>
</li>
<li><strong>推理测试</strong><ul>
<li>用 <code>generate.py</code> 加载权重，输入问题，看看输出效果</li>
</ul>
</li>
<li><strong>API 部署</strong><ul>
<li>启动 <code>app.py</code>，通过 HTTP 接口调用模型</li>
</ul>
</li>
</ol>
<hr>
<h2 id="📦-模型训练完成后的产出物"><a href="#📦-模型训练完成后的产出物" class="headerlink" title="📦 模型训练完成后的产出物"></a>📦 模型训练完成后的产出物</h2><ul>
<li><strong>分词器文件</strong>：<ul>
<li><code>tokenizer/spm.model</code> 和 <code>spm.vocab</code></li>
<li>用来把文字转成 token，再把 token 转回文字</li>
</ul>
</li>
<li><strong>模型权重文件</strong>：<ul>
<li><code>checkpoints/pretrain_epochX.pt</code>（预训练阶段）</li>
<li><code>checkpoints/sft_epochX.pt</code>（指令微调阶段）</li>
<li>里面保存了模型的参数（数千万个浮点数）</li>
</ul>
</li>
<li><strong>日志/曲线</strong>（可选）：<ul>
<li>训练时的 loss、困惑度（ppl）变化</li>
</ul>
</li>
</ul>
<hr>
<h2 id="🚀-如何使用模型"><a href="#🚀-如何使用模型" class="headerlink" title="🚀 如何使用模型"></a>🚀 如何使用模型</h2><ol>
<li><strong>离线推理</strong><ul>
<li>用 <code>generate.py</code> 加载 <code>sft_epochX.pt</code></li>
<li>输入一个问题，模型会生成回答</li>
</ul>
</li>
<li><strong>API 调用</strong><ul>
<li>启动 <code>uvicorn app:app --reload</code></li>
<li>用 <code>curl</code> 或 Python requests 调用 <code>/v1/chat/completions</code></li>
<li>外部程序就能像调用 OpenAI API 一样使用你的模型</li>
</ul>
</li>
</ol>
<hr>
<h2 id="🔧-如何对模型进行微调"><a href="#🔧-如何对模型进行微调" class="headerlink" title="🔧 如何对模型进行微调"></a>🔧 如何对模型进行微调</h2><p>有两种常见方式：</p>
<h3 id="1-继续指令微调（SFT）"><a href="#1-继续指令微调（SFT）" class="headerlink" title="1. 继续指令微调（SFT）"></a>1. <strong>继续指令微调（SFT）</strong></h3><ul>
<li>适合：你有新的问答数据（比如某个专业领域）</li>
<li>做法：<ul>
<li>准备新的 <code>sft.jsonl</code></li>
<li>加载已有的 <code>sft_epochX.pt</code></li>
<li>再跑 <code>train_sft.py</code>，继续训练几轮</li>
</ul>
</li>
<li>效果：模型会更懂你的领域问题</li>
</ul>
<h3 id="2-轻量微调（LoRA-Adapter）"><a href="#2-轻量微调（LoRA-Adapter）" class="headerlink" title="2. 轻量微调（LoRA / Adapter）"></a>2. <strong>轻量微调（LoRA / Adapter）</strong></h3><ul>
<li>适合：硬件有限，不想全量更新参数</li>
<li>做法：<ul>
<li>冻结大部分参数，只训练少量“适配层”</li>
<li>训练速度快，显存/内存占用小</li>
</ul>
</li>
<li>效果：能快速适配新任务，但需要额外代码支持</li>
</ul>
<hr>
<h2 id="✅-总结"><a href="#✅-总结" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>执行顺序</strong>：数据 → 分词器 → 预训练 → 微调 → 推理 → API</li>
<li><strong>产出物</strong>：分词器文件 + 模型权重</li>
<li><strong>使用方式</strong>：离线推理 or API 调用</li>
<li><strong>微调方法</strong>：继续 SFT（全量）或 LoRA（轻量）</li>
</ul>
<hr>
<p>要不要我帮你画一张 <strong>“大模型训练与使用流程图”</strong>（从数据到 API 的全链路），这样你可以一眼看到每一步的输入、输出和产出物？</p>
<h2 id="一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？"><a href="#一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？" class="headerlink" title="一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？"></a>一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？</h2><p><strong>简答版</strong>：提示词设计和模型结构确实是“互相成就”的关系。没有一个放之四海而皆准的“唯一标准”，但有一套被广泛认可的<strong>提示词工程原则</strong>和<strong>模型对齐策略</strong>。核心思想是：<strong>提示词要清晰、结构化、可预测；模型要在训练阶段就学会理解这种结构化输入</strong>。</p>
<hr>
<h2 id="🎯-提示词与模型的配合逻辑"><a href="#🎯-提示词与模型的配合逻辑" class="headerlink" title="🎯 提示词与模型的配合逻辑"></a>🎯 提示词与模型的配合逻辑</h2><ol>
<li><strong>提示词是接口</strong>：它是人类意图 → 模型输出的桥梁。</li>
<li><strong>模型是解释器</strong>：它能否理解提示词，取决于训练时是否见过类似的格式。</li>
<li><strong>最佳效果</strong>：当提示词的风格与模型的训练/微调数据保持一致时，输出最稳定。</li>
</ol>
<hr>
<h2 id="🧩-提示词设计的关键要素"><a href="#🧩-提示词设计的关键要素" class="headerlink" title="🧩 提示词设计的关键要素"></a>🧩 提示词设计的关键要素</h2><p>一个高效提示词通常包含 5 个部分：</p>
<ul>
<li>**指令 (Instruction)**：明确告诉模型要做什么</li>
<li>**上下文 (Context)**：提供必要的背景信息</li>
<li>**示例 (Examples)**：给出少量范例（few-shot）</li>
<li>**输入 (Input)**：需要处理的具体内容</li>
<li>**输出要求 (Output format)**：指定格式、风格、长度</li>
</ul>
<p>👉 举例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">作为一名高中物理老师，请用3-5句话解释“为什么天空是蓝色的”。</span><br><span class="line">要求：逐步推理，最后用一句话总结。</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="🏗️-模型设计与训练的配合点"><a href="#🏗️-模型设计与训练的配合点" class="headerlink" title="🏗️ 模型设计与训练的配合点"></a>🏗️ 模型设计与训练的配合点</h2><ul>
<li><strong>预训练阶段</strong>：模型学会语言规律，但对“指令”不敏感。</li>
<li><strong>指令微调（SFT）</strong>：用大量“指令-回答”对训练，让模型习惯结构化提示。</li>
<li><strong>RLHF/偏好优化</strong>：让模型更符合人类对“好答案”的偏好（礼貌、逻辑、简洁）。</li>
<li><strong>上下文窗口设计</strong>：如果模型上下文长度短，提示词就要简洁；长上下文模型则能容纳更多示例。</li>
</ul>
<hr>
<h2 id="📐-有没有“标准”？"><a href="#📐-有没有“标准”？" class="headerlink" title="📐 有没有“标准”？"></a>📐 有没有“标准”？</h2><p>严格意义上没有统一国际标准，但有一些<strong>最佳实践框架</strong>：</p>
<ul>
<li><strong>OpenAI 六大策略</strong>：清晰指令、角色设定、分隔符、分步骤、示例、输出约束。</li>
<li>**Chain of Thought (CoT)**：要求模型逐步推理，提升逻辑性。</li>
<li><strong>Few-shot / Zero-shot</strong>：通过示例或直接指令引导。</li>
<li>**角色扮演 (Role prompting)**：给模型一个身份，提升风格一致性。</li>
</ul>
<hr>
<h2 id="✅-总结-1"><a href="#✅-总结-1" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>提示词要结构化、明确、可预测</strong></li>
<li><strong>模型要在训练中接触过类似格式</strong></li>
<li><strong>最佳效果来自“提示词工程 + 指令微调”的双重配合</strong></li>
<li><strong>没有唯一标准，但有成熟框架（如 OpenAI 六大策略、CoT、Few-shot）可遵循</strong></li>
</ul>
<hr>
<p>要不要我帮你整理一份 <strong>“提示词设计速查表”</strong>（包含常见框架、适用场景、示例），方便你在做模型实验时快速套用？</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1945389672600672219">知乎：《提示词工程与优化技巧》</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/tlnshuju/p/19091427">博客园：《提示词工程方法及框架》</a></li>
</ul>
<h2 id="大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？"><a href="#大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？" class="headerlink" title="大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？"></a>大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？</h2><p><strong>简答版</strong>：大模型中的“温度参数”是一个控制<strong>输出随机性和创造性</strong>的旋钮。它通过调整概率分布的“尖锐程度”，决定模型是更倾向于选择高概率的常见词，还是敢于尝试低概率的冷门词。添加这个参数的目的，是在<strong>稳定性</strong>和<strong>多样性</strong>之间找到平衡。</p>
<hr>
<h2 id="🔥-温度参数的定义"><a href="#🔥-温度参数的定义" class="headerlink" title="🔥 温度参数的定义"></a>🔥 温度参数的定义</h2><ul>
<li><strong>数学上</strong>：在 softmax 计算时，把 logits 除以一个温度 (T)。<ul>
<li>(T &lt; 1)：分布更尖锐 → 高概率词更容易被选中。</li>
<li>(T = 1)：使用原始分布。</li>
<li>(T &gt; 1)：分布更平滑 → 低概率词被放大，更容易出现。</li>
</ul>
</li>
</ul>
<p>公式：</p>
<p>$$P(w_i) = \frac{e^{z_i / T}}{\sum_j e^{z_j / T}}$$</p>
<p>其中 $z_i$ 是词的原始得分。</p>
<hr>
<h2 id="🎨-为什么要添加温度参数？"><a href="#🎨-为什么要添加温度参数？" class="headerlink" title="🎨 为什么要添加温度参数？"></a>🎨 为什么要添加温度参数？</h2><ol>
<li><strong>解决“千篇一律”的问题</strong><ul>
<li>如果总是选最高概率的词（相当于温度=0），输出会非常死板、重复。</li>
</ul>
</li>
<li><strong>解决“胡言乱语”的问题</strong><ul>
<li>如果完全随机采样，输出可能逻辑混乱。</li>
</ul>
</li>
<li><strong>提供灵活性</strong><ul>
<li>不同场景需要不同风格：写论文要稳定，写诗歌要有创意。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="⚖️-温度带来的效果"><a href="#⚖️-温度带来的效果" class="headerlink" title="⚖️ 温度带来的效果"></a>⚖️ 温度带来的效果</h2><ul>
<li><strong>低温度（0~0.3）</strong><ul>
<li>输出更确定、更一致，适合<strong>代码补全、技术文档、法律文本</strong>。</li>
</ul>
</li>
<li><strong>中温度（0.7~1.0）</strong><ul>
<li>平衡稳定与多样性，适合<strong>日常对话、知识问答</strong>。</li>
</ul>
</li>
<li><strong>高温度（&gt;1.0）</strong><ul>
<li>输出更有创意，但可能不连贯，适合<strong>故事创作、广告文案</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="🌰-举个例子"><a href="#🌰-举个例子" class="headerlink" title="🌰 举个例子"></a>🌰 举个例子</h2><p>输入：“我喜欢吃…”</p>
<ul>
<li><strong>T=0.2</strong> → 模型几乎总是回答“苹果”。</li>
<li><strong>T=1.0</strong> → 可能回答“苹果”“香蕉”。</li>
<li><strong>T=1.5</strong> → 甚至可能回答“火星”这种冷门词。</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：温度参数是大模型的“创意调节器”。它解决了输出要么过于死板、要么过于混乱的问题，让开发者可以根据任务需求，在<strong>准确性</strong>和<strong>创造性</strong>之间自由切换。</p>
<hr>
<p>好的 👍 我帮你把 <strong>大模型温度参数的作用</strong>整理成一份速查表，方便你随时查阅和应用。</p>
<hr>
<h1 id="🌡️-大语言模型温度参数速查表"><a href="#🌡️-大语言模型温度参数速查表" class="headerlink" title="🌡️ 大语言模型温度参数速查表"></a>🌡️ 大语言模型温度参数速查表</h1><table>
<thead>
<tr>
<th>温度范围</th>
<th>输出风格</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>0 ~ 0.3</strong></td>
<td><strong>低温</strong></td>
<td>输出高度确定，几乎总是选最常见的词，重复性强</td>
<td>代码补全、法律文书、作业答案、技术文档</td>
</tr>
<tr>
<td><strong>0.4 ~ 0.6</strong></td>
<td><strong>偏低</strong></td>
<td>输出平稳、流畅，但缺乏创意</td>
<td>新闻摘要、知识点总结</td>
</tr>
<tr>
<td><strong>0.7</strong></td>
<td><strong>中温</strong></td>
<td>平衡稳定性与多样性，既合理又有变化</td>
<td>常识问答、日常聊天、教育问答</td>
</tr>
<tr>
<td><strong>0.8 ~ 1.0</strong></td>
<td><strong>偏高</strong></td>
<td>更接近人类对话风格，表达更自然</td>
<td>面试模拟、风格化写作、轻松对话</td>
</tr>
<tr>
<td><strong>&gt; 1.0</strong></td>
<td><strong>高温</strong></td>
<td>创造性强，但可能不连贯甚至“胡说”</td>
<td>故事创作、广告文案、头脑风暴</td>
</tr>
</tbody></table>
<hr>
<h2 id="🎯-总结"><a href="#🎯-总结" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul>
<li><strong>温度低</strong> → 输出更稳定、更可控，适合需要准确性的任务。</li>
<li><strong>温度中等</strong> → 输出平衡，适合大多数通用场景。</li>
<li><strong>温度高</strong> → 输出更有创意，但风险是逻辑性下降。</li>
</ul>
<p>👉 可以把温度理解为“创意旋钮”：</p>
<ul>
<li><strong>拧低</strong> → 模型像严谨的工程师。</li>
<li><strong>拧高</strong> → 模型像天马行空的作家。</li>
</ul>
<hr>
<p>要不要我帮你再整理一份 <strong>“温度参数调节实战指南”</strong>，里面包含不同任务（写代码、写论文、写故事）的推荐温度值和示例提示词？这样你可以直接套用。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://api-docs.deepseek.com/zh-cn/quick_start/parameter_settings">deepseek 有关 temperature 参数的设置</a></li>
</ul>
<h2 id="我如何使用-hugging-face-或者-model-scope-中的模型，构建属于自己的模型？"><a href="#我如何使用-hugging-face-或者-model-scope-中的模型，构建属于自己的模型？" class="headerlink" title="我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？"></a>我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？</h2><p><strong>快速回答</strong>：你可以把 Hugging Face 或 ModelScope 上的预训练模型当作“基石”，然后通过 <strong>下载 → 加载 → 微调 → 保存 → 部署</strong> 这几个步骤，构建属于自己的模型。核心思路是：<strong>先复用别人训练好的大模型，再用你自己的数据做定制化微调</strong>。</p>
<hr>
<h2 id="🧩-使用-Hugging-Face-的流程"><a href="#🧩-使用-Hugging-Face-的流程" class="headerlink" title="🧩 使用 Hugging Face 的流程"></a>🧩 使用 Hugging Face 的流程</h2><ol>
<li><strong>安装依赖</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install transformers datasets torch</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>加载预训练模型和分词器</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">&quot;bert-base-chinese&quot;</span>  <span class="comment"># 或者 &quot;Qwen/Qwen2-7B&quot;</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(model_name)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>准备数据集</strong></li>
</ol>
<ul>
<li>使用 Hugging Face <code>datasets</code> 库加载开源数据，或用你自己的 JSON/CSV。</li>
<li>格式一般是 <strong>指令 + 输入 + 输出</strong>。</li>
</ul>
<ol start="4">
<li><strong>微调模型</strong></li>
</ol>
<ul>
<li>小规模任务可用 <strong>Trainer API</strong>：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> Trainer, TrainingArguments</span><br><span class="line"></span><br><span class="line">training_args = TrainingArguments(</span><br><span class="line">    output_dir=<span class="string">&quot;./my_model&quot;</span>,</span><br><span class="line">    per_device_train_batch_size=<span class="number">4</span>,</span><br><span class="line">    num_train_epochs=<span class="number">3</span>,</span><br><span class="line">    learning_rate=<span class="number">5e-5</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer = Trainer(</span><br><span class="line">    model=model,</span><br><span class="line">    args=training_args,</span><br><span class="line">    train_dataset=my_dataset</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><strong>保存与使用</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;./my_model&quot;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;./my_model&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>之后你就可以用 <code>from_pretrained(&quot;./my_model&quot;)</code> 来加载你自己的模型。</p>
<hr>
<h2 id="🧩-使用-ModelScope-的流程"><a href="#🧩-使用-ModelScope-的流程" class="headerlink" title="🧩 使用 ModelScope 的流程"></a>🧩 使用 ModelScope 的流程</h2><ol>
<li><strong>安装依赖</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install modelscope</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>加载模型</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> modelscope.utils.constant <span class="keyword">import</span> Tasks</span><br><span class="line"></span><br><span class="line">p = pipeline(Tasks.text_generation, model=<span class="string">&#x27;damo/nlp_gpt3_text-generation_chinese-base&#x27;</span>)</span><br><span class="line">result = p(<span class="string">&quot;你好，请介绍一下云原生&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>微调</strong></li>
</ol>
<ul>
<li>ModelScope 提供了 <strong>Trainer</strong> 和 <strong>PEFT（轻量微调，如 LoRA）</strong>，可以用你自己的数据集进行领域适配。</li>
<li>训练完成后，模型同样可以保存到本地或上传到 ModelScope Hub。</li>
</ul>
<hr>
<h2 id="🚀-如何构建“属于自己的模型”"><a href="#🚀-如何构建“属于自己的模型”" class="headerlink" title="🚀 如何构建“属于自己的模型”"></a>🚀 如何构建“属于自己的模型”</h2><ul>
<li><strong>选择基座模型</strong>：根据任务选择（中文 → 中文预训练模型，如 Qwen、ChatGLM；英文 → LLaMA、GPT-NeoX）。</li>
<li><strong>准备数据</strong>：高质量的领域数据（医疗、教育、客服等）。</li>
<li><strong>选择微调方式</strong>：<ul>
<li>全量微调（参数更新多，资源消耗大）</li>
<li>LoRA/PEFT（只训练小部分参数，适合你这种硬件条件）</li>
</ul>
</li>
<li><strong>保存与部署</strong>：保存模型权重 → 用 FastAPI/Gradio 部署 → 提供 API 给外部调用。</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：</p>
<ul>
<li>Hugging Face 和 ModelScope 都能让你快速加载预训练模型。</li>
<li>你只需要准备数据并选择合适的微调方式，就能得到一个“属于你”的模型。</li>
<li>最终产出是 <strong>模型权重 + 分词器</strong>，可以通过 API 或应用直接调用。</li>
</ul>
<hr>
<p>要不要我帮你整理一份 <strong>“Hugging Face vs ModelScope 构建自定义模型对比表”</strong>，让你清楚看到两者在加载、微调、部署上的差异？</p>
<h2 id="关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段"><a href="#关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段" class="headerlink" title="关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段"></a>关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段</h2><p><strong>有的 ✅，目前已经有不少开源工具专门帮助你在大模型微调阶段准备和管理数据集。它们能帮你清洗、生成、格式化甚至自动构造指令数据，极大降低数据准备的难度。</strong></p>
<hr>
<h2 id="🔑-常见的数据集工具"><a href="#🔑-常见的数据集工具" class="headerlink" title="🔑 常见的数据集工具"></a>🔑 常见的数据集工具</h2><h3 id="1-edg4llm"><a href="#1-edg4llm" class="headerlink" title="1. edg4llm"></a>1. <strong>edg4llm</strong></h3><ul>
<li><strong>定位</strong>：大模型微调数据生成工具</li>
<li><strong>功能</strong>：<ul>
<li>自动生成问答对、对话数据</li>
<li>支持多种格式输出，直接可用于 SFT（监督微调）</li>
<li>提供简洁 API，轻量级，易上手</li>
</ul>
</li>
<li><strong>适合场景</strong>：你没有现成的高质量数据集，需要快速合成一些指令数据来跑通流程。</li>
</ul>
<hr>
<h3 id="2-Easy-Dataset"><a href="#2-Easy-Dataset" class="headerlink" title="2. Easy Dataset"></a>2. <strong>Easy Dataset</strong></h3><ul>
<li><strong>定位</strong>：可视化数据集构建工具</li>
<li><strong>功能</strong>：<ul>
<li>上传领域文档（PDF、TXT 等）</li>
<li>自动分割内容、生成问题和答案</li>
<li>输出标准化的训练数据（JSON/JSONL）</li>
</ul>
</li>
<li><strong>适合场景</strong>：你有特定领域的资料（比如医疗、教育、客服），想快速转化为微调数据。</li>
</ul>
<hr>
<h3 id="3-LLaMA-Factory"><a href="#3-LLaMA-Factory" class="headerlink" title="3. LLaMA-Factory"></a>3. <strong>LLaMA-Factory</strong></h3><ul>
<li><strong>定位</strong>：统一的 LLM 微调框架</li>
<li><strong>功能</strong>：<ul>
<li>内置数据管道，支持 100+ 模型和多种数据格式</li>
<li>支持 LoRA、QLoRA、全参数微调</li>
<li>可直接加载开源数据集（如 Alpaca、Belle）</li>
</ul>
</li>
<li><strong>适合场景</strong>：你想要“一站式”解决方案，从数据到训练到部署全覆盖。</li>
</ul>
<hr>
<h3 id="4-XTuner"><a href="#4-XTuner" class="headerlink" title="4. XTuner"></a>4. <strong>XTuner</strong></h3><ul>
<li><strong>定位</strong>：高效灵活的微调工具包</li>
<li><strong>功能</strong>：<ul>
<li>支持多种 LLM（InternLM、Qwen、ChatGLM 等）</li>
<li>数据管道灵活，能容纳开源和自定义格式</li>
<li>与 DeepSpeed、FlashAttention 等优化技术兼容</li>
</ul>
</li>
<li><strong>适合场景</strong>：你需要在有限硬件上高效微调，且数据格式多样。</li>
</ul>
<hr>
<h2 id="📌-总结"><a href="#📌-总结" class="headerlink" title="📌 总结"></a>📌 总结</h2><ul>
<li><strong>数据生成</strong>：edg4llm → 自动合成问答数据</li>
<li><strong>数据构建</strong>：Easy Dataset → 上传文档生成训练集</li>
<li><strong>数据到训练一体化</strong>：LLaMA-Factory、XTuner → 内置数据管道 + 微调框架</li>
</ul>
<p>👉 换句话说，如果你只是想快速准备数据，<strong>edg4llm / Easy Dataset</strong> 很合适；如果你想要完整的训练流水线，<strong>LLaMA-Factory / XTuner</strong> 更适合。</p>
<hr>
<p>要不要我帮你整理一份 <strong>“微调数据集工具对比表”</strong>（从功能、易用性、适用场景三个维度对比），让你能一眼选出最适合你硬件和需求的工具？</p>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/T_susan/article/details/145134496">CSDN：《edg4llm：一款简单好用的大模型微调数据生成工具》</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/694521781">知乎：《五种大模型微调工具》</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/whale2002/easy-dataset">GitHub：Easy Dataset 项目</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ConardLi/easy-dataset">Github: easy-dataset</a></li>
</ul>
<h2 id="如何把-pdf，doc，markdown-等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？"><a href="#如何把-pdf，doc，markdown-等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？" class="headerlink" title="如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？"></a>如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？</h2><p><strong>快速回答</strong>：要让大模型“看懂”PDF、Word、Markdown 等文件并基于其内容回答问题，通常分两步：<strong>① 文本提取与向量化（Embedding） → ② 检索增强生成（RAG）</strong>。向量化是把文档内容转成数值向量存入数据库；问问题时先检索相关向量，再把检索到的文本片段作为上下文喂给大模型。</p>
<hr>
<h2 id="🧩-步骤详解"><a href="#🧩-步骤详解" class="headerlink" title="🧩 步骤详解"></a>🧩 步骤详解</h2><h3 id="1-文本提取"><a href="#1-文本提取" class="headerlink" title="1. 文本提取"></a>1. 文本提取</h3><ul>
<li><strong>PDF</strong>：用 <code>pdfplumber</code>、<code>PyPDF2</code> 或开源工具 Marker、MinerU 提取正文，必要时加 OCR（扫描版）。</li>
<li>**Word (doc/docx)**：用 <code>python-docx</code> 或 <code>docx2txt</code> 提取。</li>
<li><strong>Markdown</strong>：直接读取文本，或用 <code>markdown</code> 库解析。</li>
<li><strong>清洗</strong>：去掉页眉页脚、目录、无关符号，按段落或固定长度切分（如 500 tokens 一段）。</li>
</ul>
<h3 id="2-向量化（Embedding）"><a href="#2-向量化（Embedding）" class="headerlink" title="2. 向量化（Embedding）"></a>2. 向量化（Embedding）</h3><ul>
<li>使用开源模型（如 Hugging Face 的 <code>sentence-transformers</code>，或 ModelScope 的中文向量模型）：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer</span><br><span class="line"></span><br><span class="line">model = SentenceTransformer(<span class="string">&quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot;</span>)</span><br><span class="line">embeddings = model.encode([<span class="string">&quot;这是第一段文本&quot;</span>, <span class="string">&quot;这是第二段文本&quot;</span>])</span><br></pre></td></tr></table></figure>

<ul>
<li>每段文本会变成一个高维向量（如 384/768 维）。</li>
</ul>
<h3 id="3-存储向量"><a href="#3-存储向量" class="headerlink" title="3. 存储向量"></a>3. 存储向量</h3><ul>
<li>常用向量数据库：<strong>FAISS</strong>（本地）、<strong>Milvus</strong>、<strong>Weaviate</strong>、<strong>Pinecone</strong>。</li>
<li>存储内容：<code>&#123;向量, 原始文本, 文档ID, 段落位置&#125;</code>。</li>
</ul>
<h3 id="4-检索-大模型问答（RAG）"><a href="#4-检索-大模型问答（RAG）" class="headerlink" title="4. 检索 + 大模型问答（RAG）"></a>4. 检索 + 大模型问答（RAG）</h3><ul>
<li>用户提问 → 把问题也向量化 → 在向量数据库中检索最相似的段落。</li>
<li>把检索到的段落拼接到提示词里，交给大模型生成答案。</li>
</ul>
<p>示例伪代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">query = <span class="string">&quot;这份合同的付款条款是什么？&quot;</span></span><br><span class="line">q_vec = model.encode([query])</span><br><span class="line">docs = faiss_index.search(q_vec, k=<span class="number">3</span>)  <span class="comment"># 找到最相关的3段</span></span><br><span class="line">context = <span class="string">&quot;\n&quot;</span>.join([d[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line"></span><br><span class="line">prompt = <span class="string">f&quot;根据以下资料回答问题：\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">answer = llm.generate(prompt)</span><br></pre></td></tr></table></figure>

<h3 id="5-整体架构（RAG）"><a href="#5-整体架构（RAG）" class="headerlink" title="5. 整体架构（RAG）"></a>5. 整体架构（RAG）</h3><ol>
<li><strong>离线阶段</strong>：文件 → 文本 → 切分 → 向量化 → 存入数据库</li>
<li><strong>在线阶段</strong>：问题 → 向量化 → 检索相关片段 → 拼接上下文 → 大模型回答</li>
</ol>
<hr>
<h2 id="✅-总结-2"><a href="#✅-总结-2" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>向量化的目的</strong>：让机器能“理解”文本语义，支持相似度检索。</li>
<li><strong>大模型的角色</strong>：不是直接“记住”文档，而是基于检索到的上下文生成答案。</li>
<li><strong>关键技术</strong>：文本提取 → Embedding → 向量数据库 → RAG。</li>
</ul>
<hr>
<p>要不要我帮你画一张 <strong>“文档 → 向量化 → 检索 → 大模型问答”流程图</strong>，让你一眼看到整个数据流转过程？</p>
<h2 id="Rerank-模型工作在什么阶段？什么时间使用它？"><a href="#Rerank-模型工作在什么阶段？什么时间使用它？" class="headerlink" title="Rerank 模型工作在什么阶段？什么时间使用它？"></a>Rerank 模型工作在什么阶段？什么时间使用它？</h2><p><strong>简答版</strong>：Rerank 模型工作在 <strong>检索增强生成（RAG）流程的“初步检索之后、大模型生成之前”</strong>。它的作用是对初步检索到的一批候选文档进行<strong>精细排序</strong>，把真正最相关的内容排在前面。通常在<strong>需要更高准确性</strong>时使用，比如问答系统、法律/医疗文档检索、企业知识库。</p>
<hr>
<h2 id="🧩-Rerank-模型的工作阶段"><a href="#🧩-Rerank-模型的工作阶段" class="headerlink" title="🧩 Rerank 模型的工作阶段"></a>🧩 Rerank 模型的工作阶段</h2><ol>
<li><strong>用户提问</strong><ul>
<li>输入问题，例如：“合同的付款条款是什么？”</li>
</ul>
</li>
<li><strong>初步检索（向量检索 / BM25）</strong><ul>
<li>从数据库里快速找到一批候选文档（可能几十条）。</li>
<li>这一步速度快，但相关性不够精准。</li>
</ul>
</li>
<li><strong>Rerank（重排序）</strong><ul>
<li>使用更复杂的模型（如 cross-encoder）逐一对“问题-文档”对进行打分。</li>
<li>重新排序，把最相关的几条放在最前面。</li>
</ul>
</li>
<li><strong>大模型生成</strong><ul>
<li>把排序靠前的文档拼接进提示词，交给大模型生成答案。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="🎯-为什么要用-Rerank？"><a href="#🎯-为什么要用-Rerank？" class="headerlink" title="🎯 为什么要用 Rerank？"></a>🎯 为什么要用 Rerank？</h2><ul>
<li><strong>解决初检不精准的问题</strong>：向量检索只看“语义相似度”，可能把表面相似但无关的段落排前。</li>
<li><strong>减少噪音</strong>：避免大模型读到一堆无关上下文，浪费 token，还可能答非所问。</li>
<li><strong>提升准确率</strong>：让大模型优先利用真正相关的上下文，答案更可靠。</li>
</ul>
<hr>
<h2 id="⏰-什么时候使用-Rerank？"><a href="#⏰-什么时候使用-Rerank？" class="headerlink" title="⏰ 什么时候使用 Rerank？"></a>⏰ 什么时候使用 Rerank？</h2><ul>
<li><strong>文档库很大</strong>：初步检索结果可能包含很多噪音。</li>
<li><strong>任务要求高精度</strong>：如法律、医疗、金融问答，不能容忍答错。</li>
<li><strong>上下文窗口有限</strong>：大模型一次能读的 token 有限，必须挑最相关的内容。</li>
<li><strong>多路检索融合</strong>：当你同时用关键词检索 + 向量检索时，Rerank 可以统一排序。</li>
</ul>
<hr>
<h2 id="✅-总结-3"><a href="#✅-总结-3" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>阶段</strong>：Rerank 在“初步检索之后、大模型生成之前”。</li>
<li><strong>作用</strong>：对候选文档做精细排序，保证大模型读到的上下文最相关。</li>
<li><strong>使用时机</strong>：当你需要更高准确性、上下文有限或文档库庞大时。</li>
</ul>
<hr>
<p>要不要我帮你画一张 <strong>“RAG + Rerank 流程图”</strong>，把“用户提问 → 初检 → Rerank → 大模型生成”的数据流清晰展示出来？</p>
<h2 id="在-RAG-的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？"><a href="#在-RAG-的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？" class="headerlink" title="在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？"></a>在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？</h2><p><strong>快速回答</strong>：在 RAG（检索增强生成）技术中，通常会用到 <strong>4 大类模型</strong>，分别在不同阶段发挥作用：<strong>Embedding 模型 → 检索模型 → Rerank 模型 → 大语言模型（LLM）</strong>。它们的目标是：先把文档转成向量，快速找到候选，再精排，最后生成答案，从而解决大模型知识过时、幻觉和私有数据利用的问题。</p>
<hr>
<h2 id="🧩-RAG-技术中的模型类型与阶段"><a href="#🧩-RAG-技术中的模型类型与阶段" class="headerlink" title="🧩 RAG 技术中的模型类型与阶段"></a>🧩 RAG 技术中的模型类型与阶段</h2><h3 id="1-Embedding-模型（向量化阶段）"><a href="#1-Embedding-模型（向量化阶段）" class="headerlink" title="1. Embedding 模型（向量化阶段）"></a>1. <strong>Embedding 模型（向量化阶段）</strong></h3><ul>
<li><strong>阶段</strong>：知识库构建时，把文档切分后的片段转成向量。</li>
<li><strong>常见模型</strong>：<code>sentence-transformers</code>、<code>text-embedding-ada-002</code>、中文向量模型（如 bge-m3）。</li>
<li><strong>效果</strong>：让文本能以“语义相似度”方式被检索，而不是仅靠关键词。</li>
</ul>
<hr>
<h3 id="2-检索模型（初步召回阶段）"><a href="#2-检索模型（初步召回阶段）" class="headerlink" title="2. 检索模型（初步召回阶段）"></a>2. <strong>检索模型（初步召回阶段）</strong></h3><ul>
<li><strong>阶段</strong>：用户提问后，把问题向量化，在向量数据库里找到最相似的文档片段。</li>
<li><strong>常见方法</strong>：<ul>
<li>向量检索（FAISS、Milvus、Weaviate）</li>
<li>关键词检索（BM25、Elasticsearch）</li>
<li>混合检索（向量 + 关键词）</li>
</ul>
</li>
<li><strong>效果</strong>：快速缩小候选范围，保证召回率。</li>
</ul>
<hr>
<h3 id="3-Rerank-模型（重排序阶段）"><a href="#3-Rerank-模型（重排序阶段）" class="headerlink" title="3. Rerank 模型（重排序阶段）"></a>3. <strong>Rerank 模型（重排序阶段）</strong></h3><ul>
<li><strong>阶段</strong>：对初步检索到的候选文档进行精细打分和排序。</li>
<li><strong>常见模型</strong>：Cross-Encoder（如 <code>bge-reranker</code>）、ColBERT。</li>
<li><strong>效果</strong>：把真正最相关的文档排在前面，减少噪音，提升准确率。</li>
</ul>
<hr>
<h3 id="4-大语言模型-LLM（生成阶段）"><a href="#4-大语言模型-LLM（生成阶段）" class="headerlink" title="4. 大语言模型 LLM（生成阶段）"></a>4. <strong>大语言模型 LLM（生成阶段）</strong></h3><ul>
<li><strong>阶段</strong>：把排序后的文档片段拼接到提示词中，交给 LLM 生成答案。</li>
<li><strong>常见模型</strong>：GPT、LLaMA、Qwen、ChatGLM 等。</li>
<li><strong>效果</strong>：基于外部知识生成自然语言回答，解决知识时效性和幻觉问题。</li>
</ul>
<hr>
<h2 id="🎯-总结-1"><a href="#🎯-总结-1" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul>
<li><strong>Embedding 模型</strong>：负责“理解”文本 → 向量化</li>
<li><strong>检索模型</strong>：负责“找到”相关文档 → 初步召回</li>
<li><strong>Rerank 模型</strong>：负责“挑选”最相关的 → 精排</li>
<li><strong>LLM</strong>：负责“回答” → 基于上下文生成</li>
</ul>
<p>👉 换句话说，RAG 就像一个“信息管道”：<strong>Embedding 把知识装进管道 → 检索把水抽出来 → Rerank 过滤杂质 → LLM 输出清澈的答案</strong>。</p>
<hr>
<p>要不要我帮你画一张 <strong>“RAG 技术模型分工图”</strong>，把这四类模型在流程中的位置和作用直观展示出来？</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/1948688100764153329">知乎：《RAG 技术全解析》</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.baidu.com/article/detail.html?id=3891992">百度开发者中心：《大模型应用进阶：RAG 技术全解析与实战指南》</a></li>
</ul>
<h2 id="如何实现溯源？现在-RAG-技术还是最好的技术方案吗？有更先进的方案吗？"><a href="#如何实现溯源？现在-RAG-技术还是最好的技术方案吗？有更先进的方案吗？" class="headerlink" title="如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？"></a>如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？</h2><p><strong>简答版</strong>：<br>在大模型应用中，<strong>溯源</strong>通常通过在 RAG 流程中保留检索到的原始文档片段及其出处来实现。RAG 目前仍是最主流、工程化程度最高的方案，但它并非终点。正在兴起的更先进方向包括 <strong>知识图谱增强、检索+推理混合架构、多模态 RAG、以及 Agent 式动态工具调用</strong>，这些都在尝试解决 RAG 的局限。</p>
<hr>
<h2 id="🔎-如何实现溯源"><a href="#🔎-如何实现溯源" class="headerlink" title="🔎 如何实现溯源"></a>🔎 如何实现溯源</h2><ol>
<li><p><strong>检索阶段保留元数据</strong></p>
<ul>
<li>在向量数据库中存储的不仅是文本向量，还包括 <strong>文档 ID、标题、页码、URL</strong> 等元信息。</li>
<li>当检索到片段时，连同这些元数据一起返回。</li>
</ul>
</li>
<li><p><strong>答案生成时引用来源</strong></p>
<ul>
<li>将检索到的片段拼接进提示词，让大模型在回答中引用出处。</li>
<li>例如：“根据《合同法》第三章第 12 条，付款条款为……”</li>
</ul>
</li>
<li><p><strong>可视化溯源</strong></p>
<ul>
<li>在前端界面中，将模型回答与原始文档片段链接起来，用户可点击查看。</li>
<li>这样不仅增强可信度，也方便人工复核。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="📌-RAG-是否仍是最佳方案？"><a href="#📌-RAG-是否仍是最佳方案？" class="headerlink" title="📌 RAG 是否仍是最佳方案？"></a>📌 RAG 是否仍是最佳方案？</h2><ul>
<li><strong>优势</strong>：<ul>
<li>解决了大模型知识过时、幻觉问题。</li>
<li>工程化成熟，生态完善（LangChain、LlamaIndex 等）。</li>
<li>成本低于全量微调，支持动态更新知识库。</li>
</ul>
</li>
<li><strong>局限</strong>：<ul>
<li>检索质量决定答案质量，若召回不准，模型仍可能“胡编”。</li>
<li>上下文窗口有限，长文档或多跳推理时容易丢失关键信息。</li>
<li>溯源粒度有限，通常只能到段落级别。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="🚀-更先进的方案探索"><a href="#🚀-更先进的方案探索" class="headerlink" title="🚀 更先进的方案探索"></a>🚀 更先进的方案探索</h2><ol>
<li><p><strong>知识图谱增强 RAG</strong></p>
<ul>
<li>在检索时不仅返回文本，还能利用实体关系图，支持更复杂的推理和更精准的溯源。</li>
</ul>
</li>
<li><p><strong>RAG + 逻辑推理（Reasoning-Augmented RAG）</strong></p>
<ul>
<li>在检索后增加一个“推理层”，让模型能跨段落、多跳推理，而不是仅拼接上下文。</li>
</ul>
</li>
<li><p><strong>多模态 RAG</strong></p>
<ul>
<li>不仅检索文本，还能检索图像、表格、音频，支持更丰富的溯源场景（如医学影像+报告）。</li>
</ul>
</li>
<li><p><strong>Agent 式动态工具调用</strong></p>
<ul>
<li>模型在回答时可调用外部 API、数据库、计算工具，实时查证并返回带来源的答案。</li>
</ul>
</li>
<li><p><strong>检索+生成融合模型（如 RETRO、Atlas）</strong></p>
<ul>
<li>在训练阶段就把检索机制融入模型架构，使其“原生”具备溯源能力，而不是外挂式。</li>
</ul>
</li>
</ol>
<hr>
<h2 id="✅-总结-4"><a href="#✅-总结-4" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>溯源实现</strong>：靠在检索阶段保留元数据，并在回答中显式引用。</li>
<li><strong>RAG 现状</strong>：仍是最成熟、性价比最高的方案，但有局限。</li>
<li><strong>未来趋势</strong>：知识图谱增强、多跳推理、多模态检索、Agent 工具调用，以及“原生检索模型”。</li>
</ul>
<hr>
<p>要不要我帮你画一张 <strong>“RAG 与下一代增强方案对比图”</strong>，把它们的流程和溯源能力直观对比出来？</p>
<h2 id="什么是多模态大模型？"><a href="#什么是多模态大模型？" class="headerlink" title="什么是多模态大模型？"></a>什么是多模态大模型？</h2><p><strong>多模态大模型（Multimodal Large Language Model, MLLM）</strong> 是一种能同时理解和处理多种类型信息的模型，比如文字、图像、语音、视频等。它的目标是让 AI 像人类一样，能“看图说话”“听声识意”“读文理解”，实现更自然、更全面的智能交互。</p>
<hr>
<h2 id="🧠-多模态的“模态”指什么？"><a href="#🧠-多模态的“模态”指什么？" class="headerlink" title="🧠 多模态的“模态”指什么？"></a>🧠 多模态的“模态”指什么？</h2><ul>
<li><strong>模态（Modality）</strong> 就是信息的类型或感官通道：<ul>
<li>📄 文本（语言）</li>
<li>🖼️ 图像（视觉）</li>
<li>🔊 音频（听觉）</li>
<li>🎥 视频（时序视觉+听觉）</li>
<li>🧭 结构化数据（表格、坐标、传感器）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="🧩-多模态大模型的核心能力"><a href="#🧩-多模态大模型的核心能力" class="headerlink" title="🧩 多模态大模型的核心能力"></a>🧩 多模态大模型的核心能力</h2><table>
<thead>
<tr>
<th>能力</th>
<th>示例</th>
<th>模型如何处理</th>
</tr>
</thead>
<tbody><tr>
<td>看图说话</td>
<td>“这张图里有什么？”</td>
<td>图像 → 向量 → 与文本融合 → 生成回答</td>
</tr>
<tr>
<td>图文混合理解</td>
<td>“根据这张图和说明，解释原理”</td>
<td>图像 + 文本 → 联合编码 → 推理</td>
</tr>
<tr>
<td>语音识别与理解</td>
<td>“听完这段话，总结重点”</td>
<td>音频 → 语音转文本 → LLM 处理</td>
</tr>
<tr>
<td>视频问答</td>
<td>“视频中人物在做什么？”</td>
<td>视频帧 + 音频 → 多模态融合 → 生成回答</td>
</tr>
<tr>
<td>表格/图表理解</td>
<td>“这张表格说明了什么趋势？”</td>
<td>表格结构 → 特征提取 → 语言生成</td>
</tr>
</tbody></table>
<hr>
<h2 id="🚀-多模态大模型的代表"><a href="#🚀-多模态大模型的代表" class="headerlink" title="🚀 多模态大模型的代表"></a>🚀 多模态大模型的代表</h2><ul>
<li><strong>GPT-4V</strong>：支持图像输入，能看图回答问题、识别图表、理解截图。</li>
<li><strong>Gemini</strong>：Google 发布的多模态模型，支持图像、音频、视频、代码等。</li>
<li><strong>Qwen-VL / InternVL</strong>：中文多模态模型，支持图文问答、OCR、图表理解。</li>
<li><strong>MiniGPT-4 / LLaVA</strong>：开源图文模型，适合本地部署和实验。</li>
</ul>
<hr>
<h2 id="🎯-多模态模型的优势"><a href="#🎯-多模态模型的优势" class="headerlink" title="🎯 多模态模型的优势"></a>🎯 多模态模型的优势</h2><ul>
<li>更贴近人类认知方式（我们不是只靠文字交流）</li>
<li>能处理真实世界复杂任务（如医学影像+病历分析）</li>
<li>支持更自然的交互方式（拍照提问、语音对话）</li>
</ul>
<hr>
<h2 id="✅-总结-5"><a href="#✅-总结-5" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li>多模态大模型 = 能同时理解图像、文字、语音等多种信息的 AI 模型。</li>
<li>它让 AI 不再“只会读文字”，而是能“看、听、说、理解”。</li>
<li>是通向“通用人工智能（AGI）”的重要一步。</li>
</ul>
<hr>
<p>要不要我帮你整理一份 <strong>“多模态模型能力清单 + 应用场景图解”</strong>，比如哪些任务适合用图文模型、哪些适合语音+文本模型？这样你可以一眼选出最适合的模型组合。</p>
<h2 id="大模型如何实现-reasoning-？"><a href="#大模型如何实现-reasoning-？" class="headerlink" title="大模型如何实现 reasoning ？"></a>大模型如何实现 reasoning ？</h2><p><strong>简答版</strong>：大模型的 <em>reasoning（推理能力）</em> 并不是“天生”的，而是通过 <strong>训练方法、提示设计和架构改进</strong> 逐步实现的。核心思路是让模型不仅直接给答案，而是学会“分步骤思考”，在中间生成逻辑链条，再得出结论。</p>
<hr>
<h2 id="🧩-大模型实现-Reasoning-的主要方式"><a href="#🧩-大模型实现-Reasoning-的主要方式" class="headerlink" title="🧩 大模型实现 Reasoning 的主要方式"></a>🧩 大模型实现 Reasoning 的主要方式</h2><h3 id="1-Chain-of-Thought-CoT-思维链"><a href="#1-Chain-of-Thought-CoT-思维链" class="headerlink" title="1. Chain of Thought (CoT) 思维链"></a>1. <strong>Chain of Thought (CoT) 思维链</strong></h3><ul>
<li><strong>原理</strong>：在训练或提示中要求模型“逐步推理”，而不是直接输出答案。</li>
<li><strong>例子</strong>：<ul>
<li>提示：“请一步一步推理，最后给出答案。”</li>
<li>模型输出：先写出中间推理步骤，再给最终结论。</li>
</ul>
</li>
<li><strong>效果</strong>：显著提升数学题、逻辑题、复杂问答的正确率。</li>
</ul>
<hr>
<h3 id="2-Self-Consistency（自洽采样）"><a href="#2-Self-Consistency（自洽采样）" class="headerlink" title="2. Self-Consistency（自洽采样）"></a>2. <strong>Self-Consistency（自洽采样）</strong></h3><ul>
<li><strong>原理</strong>：让模型生成多条推理路径，然后选出最一致的答案。</li>
<li><strong>效果</strong>：减少“幻觉”或偶然错误，提升稳定性。</li>
</ul>
<hr>
<h3 id="3-外部工具与检索增强"><a href="#3-外部工具与检索增强" class="headerlink" title="3. 外部工具与检索增强"></a>3. <strong>外部工具与检索增强</strong></h3><ul>
<li><strong>RAG + Reasoning</strong>：先检索相关知识，再让模型基于证据推理。</li>
<li><strong>工具调用</strong>：模型在推理过程中调用计算器、代码执行器、数据库，保证逻辑正确。</li>
<li><strong>效果</strong>：解决模型“算不准”“记不牢”的问题。</li>
</ul>
<hr>
<h3 id="4-强化学习与奖励模型"><a href="#4-强化学习与奖励模型" class="headerlink" title="4. 强化学习与奖励模型"></a>4. <strong>强化学习与奖励模型</strong></h3><ul>
<li><strong>RLHF（人类反馈强化学习）</strong>：通过奖励模型鼓励模型输出符合逻辑的推理链。</li>
<li><strong>逻辑奖励</strong>：在数学/编程任务中，只有推理正确才给奖励。</li>
<li><strong>效果</strong>：让模型更倾向于“思考后回答”。</li>
</ul>
<hr>
<h3 id="5-架构与训练改进"><a href="#5-架构与训练改进" class="headerlink" title="5. 架构与训练改进"></a>5. <strong>架构与训练改进</strong></h3><ul>
<li><strong>专门推理模型</strong>：如 DeepSeek R1、OpenAI o1 系列，会在生成答案前显式“思考”。</li>
<li><strong>神经符号结合</strong>：把符号逻辑（规则、定理证明器）与大模型结合，提升可验证性。</li>
<li><strong>搜索增强</strong>：用蒙特卡洛树搜索（MCTS）模拟人类“深度思考”过程。</li>
</ul>
<hr>
<h2 id="🎯-总结-2"><a href="#🎯-总结-2" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul>
<li><strong>基础层面</strong>：通过 <em>思维链提示</em> 让模型学会“逐步推理”。</li>
<li><strong>增强层面</strong>：通过 <em>自洽采样、检索、工具调用</em> 提升正确率。</li>
<li><strong>训练层面</strong>：通过 <em>RLHF、逻辑奖励</em> 让模型更可靠。</li>
<li><strong>前沿探索</strong>：结合 _符号推理、搜索算法_，让模型更接近人类的“深度思考”。</li>
</ul>
<hr>
<p>换句话说，大模型的 reasoning 是“提示工程 + 数据训练 + 架构优化”的综合产物。它不是单一技巧，而是一整套方法协同作用的结果。</p>
<p>要不要我帮你整理一份 <strong>“大模型推理能力提升路线图”</strong>（从基础到前沿，每个阶段的关键方法和代表模型），让你能一眼看到行业演进？</p>
<hr>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/22095933478">知乎《Reasoning LLMs 综述》</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_59191169/article/details/149421971">CSDN《大模型推理能力全解析》</a></li>
</ul>
<h2 id="请继续本对话中的例子，训练一个-reasoning-的大模型。"><a href="#请继续本对话中的例子，训练一个-reasoning-的大模型。" class="headerlink" title="请继续本对话中的例子，训练一个 reasoning 的大模型。"></a>请继续本对话中的例子，训练一个 reasoning 的大模型。</h2><h1 id="在-16GB-内存、8-核-CPU-上训练一个具备推理能力的小模型"><a href="#在-16GB-内存、8-核-CPU-上训练一个具备推理能力的小模型" class="headerlink" title="在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型"></a>在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型</h1><p>你已经有“从零到 API”的小型指令模型流水线。下面我们在同样的硬件约束下，把它升级为“会推理”的模型：通过思维链（CoT）数据、过程奖励风格的监督微调、以及自洽采样与工具调用的推理时策略，实现可落地的 reasoning。</p>
<hr>
<h2 id="目标与核心思路"><a href="#目标与核心思路" class="headerlink" title="目标与核心思路"></a>目标与核心思路</h2><ul>
<li><strong>目标:</strong> 让模型不只给答案，还能输出清晰的中间推理步骤，再给结论。</li>
<li><strong>思路:</strong><ul>
<li><strong>训练时:</strong> 使用带“推理步骤”的高质量样本做监督微调（CoT SFT）。</li>
<li><strong>推理时:</strong> 使用自洽采样（多条思路投票）与可选工具调用（计算器）提高正确率。</li>
<li><strong>安全与格式:</strong> 模板约束，要求“先推理，后用一句话给最终答案”。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="数据集准备（CoT-思维链格式）"><a href="#数据集准备（CoT-思维链格式）" class="headerlink" title="数据集准备（CoT 思维链格式）"></a>数据集准备（CoT 思维链格式）</h2><p>在 data/reasoning_sft.jsonl 中，每条样本包含推理步骤与最终答案，统一模板：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;一个盒子里有3个红球和2个蓝球，随机取一个红球的概率是多少？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;总球数为3+2=5。红球数为3。随机取一个球为等可能事件，红球概率=3/5。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：3/5。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;计算：12*(3+4)-10&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;先计算括号：3+4=7。然后乘法：12*7=84。最后减法：84-10=74。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：74。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你是严谨的中文推理助手&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;user&quot;</span><span class="punctuation">:</span> <span class="string">&quot;如果每小时生产x个零件，8小时一共生产多少？&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;cot&quot;</span><span class="punctuation">:</span> <span class="string">&quot;每小时x个，8小时为8*x。&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;final&quot;</span><span class="punctuation">:</span> <span class="string">&quot;答案：8x。&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>标签策略:</strong> 只在 <code>&lt;|assistant|&gt;</code> 段落开始后计算损失；system/user 部分忽略。</li>
<li><strong>质量优先:</strong> 少量高质量（5k–20k）CoT 样本 &gt; 海量低质数据。</li>
<li><strong>混合数据:</strong> 可混入常规 SFT 样本，但保持 CoT 比例，确保模型学习“先推理再结论”。</li>
</ul>
<hr>
<h2 id="提示模板（推理风格）"><a href="#提示模板（推理风格）" class="headerlink" title="提示模板（推理风格）"></a>提示模板（推理风格）</h2><p>使用结构化模板，明确“先推理、后结论”的行为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;|system|&gt;</span><br><span class="line">&#123;system&#125;</span><br><span class="line">&lt;|sep|&gt;</span><br><span class="line">&lt;|user|&gt;</span><br><span class="line">&#123;user&#125;</span><br><span class="line">&lt;|sep|&gt;</span><br><span class="line">&lt;|assistant|&gt;</span><br><span class="line">【推理过程】</span><br><span class="line">&#123;cot&#125;</span><br><span class="line">【最终答案】</span><br><span class="line">&#123;final&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>约束语言:</strong> 推理段以“【推理过程】”开头，结论段以“【最终答案】”开头，便于解析与评测。</li>
<li><strong>推理长度:</strong> 控制在 3–8 句，避免冗长。</li>
</ul>
<hr>
<h2 id="训练代码（CoT-SFT）"><a href="#训练代码（CoT-SFT）" class="headerlink" title="训练代码（CoT SFT）"></a>训练代码（CoT SFT）</h2><p>在原 train_sft.py 基础上增加对 CoT 字段的支持与模板：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_reasoning_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n【推理过程】\n&#123;cot&#125;\n【最终答案】\n&#123;final&#125;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReasoningSFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>], cot=obj[<span class="string">&quot;cot&quot;</span>], final=obj[<span class="string">&quot;final&quot;</span>])</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># 仅对 assistant 段计算损失：系统+用户部分忽略</span></span><br><span class="line">                prefix = <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;system&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;user&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line">                prefix_ids = <span class="variable language_">self</span>.sp.encode(prefix, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prefix_ids) + ids[<span class="built_in">len</span>(prefix_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels += [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_reasoning_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/reasoning_sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = ReasoningSFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded base:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        moving = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)</span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            moving += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>] cot_sft_loss=<span class="subst">&#123;moving/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                moving = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;reasoning_sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_reasoning_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>训练建议:</strong> 先用 seq_len=256 预热，再升到 512；混合常规 SFT 与 CoT 样本；适度正则避免过拟合。</li>
</ul>
<hr>
<h2 id="推理时策略：自洽采样与“最终答案”抽取"><a href="#推理时策略：自洽采样与“最终答案”抽取" class="headerlink" title="推理时策略：自洽采样与“最终答案”抽取"></a>推理时策略：自洽采样与“最终答案”抽取</h2><p>在 generate.py 基础上增加“多次采样 + 投票”的能力，并解析“【最终答案】”：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate_reasoning.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_final</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 抽取最终答案段</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">return</span> text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_self_consistency</span>(<span class="params">model_ckpt, spm_path, system, user, samples=<span class="number">5</span>, max_new_tokens=<span class="number">200</span>, temperature=<span class="number">0.8</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x0 = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    finals = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        x = x0.clone()</span><br><span class="line">        out = model.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        finals.append(parse_final(text))</span><br><span class="line">    <span class="comment"># 投票选择出现次数最多的答案</span></span><br><span class="line">    vote = Counter(finals)</span><br><span class="line">    best_final, _ = vote.most_common(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> best_final, finals</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    best, all_finals = run_self_consistency(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/reasoning_sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是严谨的中文推理助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;计算：12*(3+4)-10&quot;</span>,</span><br><span class="line">        samples=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;投票最终答案:&quot;</span>, best)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所有候选:&quot;</span>, all_finals)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>自洽采样:</strong> 提升稳定性，降低“走错路”的概率；CPU 上样本数控制在 3–7 较合适。</li>
<li><strong>温度:</strong> 建议 0.7–0.9，允许路径多样，但不至于发散。</li>
</ul>
<hr>
<h2 id="可选：推理中的工具调用（轻量计算器）"><a href="#可选：推理中的工具调用（轻量计算器）" class="headerlink" title="可选：推理中的工具调用（轻量计算器）"></a>可选：推理中的工具调用（轻量计算器）</h2><p>当问题包含明显的算式时，先用规则提取表达式，用 Python 计算后填入上下文，减少算错：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tiny_tools.py</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_expression</span>(<span class="params">text</span>):</span><br><span class="line">    m = re.findall(<span class="string">r&quot;[\d\.\+\-\*\/\(\)\s]+&quot;</span>, text)</span><br><span class="line">    <span class="comment"># 简化：取最长可能表达式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> m: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    expr = <span class="built_in">max</span>(m, key=<span class="built_in">len</span>).strip()</span><br><span class="line">    <span class="comment"># 安全限制：只允许数字与 +-*/()</span></span><br><span class="line">    <span class="keyword">if</span> re.fullmatch(<span class="string">r&quot;[0-9\.\+\-\*\/\(\)\s]+&quot;</span>, expr):</span><br><span class="line">        <span class="keyword">return</span> expr</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">safe_eval</span>(<span class="params">expr</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">eval</span>(expr, &#123;<span class="string">&quot;__builtins__&quot;</span>: &#123;&#125;&#125;, &#123;&#125;)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>

<p>在构造 prompt 时加入“已计算的中间结果”作为辅助证据，或在生成后校正“最终答案”段。这种“外部工具辅助”可显著降低算术类错误。</p>
<hr>
<h2 id="API-集成（返回推理链与出处）"><a href="#API-集成（返回推理链与出处）" class="headerlink" title="API 集成（返回推理链与出处）"></a>API 集成（返回推理链与出处）</h2><p>在 app.py 中增加返回“推理过程”与“最终答案”，并可选启用自洽采样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app_reasoning.py（核心片段）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_segments</span>(<span class="params">text</span>):</span><br><span class="line">    parts = &#123;<span class="string">&quot;reasoning&quot;</span>: <span class="string">&quot;&quot;</span>, <span class="string">&quot;final&quot;</span>: <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【推理过程】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        seg = text.split(<span class="string">&quot;【推理过程】&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">        parts[<span class="string">&quot;reasoning&quot;</span>] = seg.split(<span class="string">&quot;【最终答案】&quot;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        parts[<span class="string">&quot;final&quot;</span>] = text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> parts</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br><span class="line">    <span class="comment"># ...鉴权与加载省略</span></span><br><span class="line">    prompt = build_prompt_from_messages(req.messages)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 自洽采样可选</span></span><br><span class="line">    <span class="keyword">if</span> req.temperature <span class="keyword">and</span> req.temperature &gt; <span class="number">0.0</span> <span class="keyword">and</span> req.top_p <span class="keyword">and</span> req.top_p &lt; <span class="number">1.0</span>:</span><br><span class="line">        out = model.generate(x, max_new_tokens=req.max_tokens, temperature=req.temperature, top_k=req.top_k, top_p=req.top_p)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        segs = parse_segments(text)</span><br><span class="line">        content = <span class="string">f&quot;推理：\n<span class="subst">&#123;segs[<span class="string">&#x27;reasoning&#x27;</span>]&#125;</span>\n\n最终答案：<span class="subst">&#123;segs[<span class="string">&#x27;final&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 或者用多次采样投票（略）</span></span><br><span class="line">        out = model.generate(x, max_new_tokens=req.max_tokens)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        segs = parse_segments(text)</span><br><span class="line">        content = <span class="string">f&quot;推理：\n<span class="subst">&#123;segs[<span class="string">&#x27;reasoning&#x27;</span>]&#125;</span>\n\n最终答案：<span class="subst">&#123;segs[<span class="string">&#x27;final&#x27;</span>]&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ChatResponse(</span><br><span class="line">        <span class="built_in">id</span>=<span class="string">&quot;chatcmpl-reasoning&quot;</span>,</span><br><span class="line">        model=req.model,</span><br><span class="line">        choices=[ChatChoice(index=<span class="number">0</span>, message=Message(role=<span class="string">&quot;assistant&quot;</span>, content=content), finish_reason=<span class="string">&quot;stop&quot;</span>)]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>返回格式:</strong> 同时提供“推理链”和“最终答案”，便于前端展示与用户校验。</li>
<li><strong>溯源集成:</strong> 若在 RAG 场景中使用，附带每段上下文的来源元数据；推理链中可插入引用编号。</li>
</ul>
<hr>
<h2 id="评测与迭代"><a href="#评测与迭代" class="headerlink" title="评测与迭代"></a>评测与迭代</h2><ul>
<li><strong>离线评测集:</strong> 数学小题、逻辑题、日常常识推理；记录准确率与步骤规范性。</li>
<li><strong>指标:</strong><ul>
<li><strong>步骤质量:</strong> 是否遵循“先推理、后答案”模板。</li>
<li><strong>正确率:</strong> 最终答案是否正确。</li>
<li><strong>稳定性:</strong> 自洽采样的一致性提升幅度。</li>
</ul>
</li>
<li><strong>迭代策略:</strong><ul>
<li>优先补充错误样本的反例与修正版本，扩大 CoT 数据覆盖面。</li>
<li>对容易算错的题型启用工具调用或在 SFT 中加入“算式校核”风格样本。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="硬件友好建议"><a href="#硬件友好建议" class="headerlink" title="硬件友好建议"></a>硬件友好建议</h2><ul>
<li><strong>模型规模控制:</strong> 8 层/512 维/heads=8/ffn=2048，seq_len=256→512 分阶段。</li>
<li><strong>批次与累积:</strong> batch=4–8，梯度累积至 32–64。</li>
<li><strong>训练时长:</strong> 以小时为单位、小数据迭代，关注损失曲线与样例效果，不追求大规模长跑。</li>
</ul>
<hr>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul>
<li><strong>训练层面:</strong> 用带“推理步骤”的 CoT 数据做监督微调，让模型学会结构化思考。</li>
<li><strong>推理层面:</strong> 自洽采样投票 + 轻量工具调用，显著提升正确率与稳定性。</li>
<li><strong>服务层面:</strong> API 返回推理链与最终答案，方便用户审核与持续改进。</li>
</ul>
<p>如果你告诉我希望覆盖的题型（比如小学算术、概率统计、逻辑推断、工程估算），我可以立刻为你生成一批适配的 CoT 样本模板与评测集，直接开训并验证效果。</p>
<h2 id="请给出全部代码实现"><a href="#请给出全部代码实现" class="headerlink" title="请给出全部代码实现"></a>请给出全部代码实现</h2><p>好的 Mark，我来帮你把前面我们讨论的 <strong>“从零训练一个具备 reasoning 能力的小模型”</strong> 的完整代码实现整理成一个可运行的工程结构。你可以直接按模块保存为不同的 <code>.py</code> 文件，逐步执行。</p>
<hr>
<h1 id="📂-项目结构"><a href="#📂-项目结构" class="headerlink" title="📂 项目结构"></a>📂 项目结构</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">reasoning-llm/</span><br><span class="line">│</span><br><span class="line">├── data/</span><br><span class="line">│   ├── corpus.txt              # 预训练语料</span><br><span class="line">│   ├── sft.jsonl               # 普通指令微调数据</span><br><span class="line">│   └── reasoning_sft.jsonl     # 带推理链的指令数据</span><br><span class="line">│</span><br><span class="line">├── tokenizer/</span><br><span class="line">│   ├── spm.model</span><br><span class="line">│   └── spm.vocab</span><br><span class="line">│</span><br><span class="line">├── checkpoints/                # 模型权重保存目录</span><br><span class="line">│</span><br><span class="line">├── build_tokenizer.py</span><br><span class="line">├── model.py</span><br><span class="line">├── train_pretrain.py</span><br><span class="line">├── train_sft.py</span><br><span class="line">├── train_reasoning_sft.py</span><br><span class="line">├── generate.py</span><br><span class="line">├── generate_reasoning.py</span><br><span class="line">├── tiny_tools.py</span><br><span class="line">└── app_reasoning.py</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="1️⃣-构建分词器"><a href="#1️⃣-构建分词器" class="headerlink" title="1️⃣ 构建分词器"></a>1️⃣ 构建分词器</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># build_tokenizer.py</span></span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_tokenizer</span>(<span class="params">input_txt=<span class="string">&quot;data/corpus.txt&quot;</span>, model_prefix=<span class="string">&quot;tokenizer/spm&quot;</span>, vocab_size=<span class="number">16000</span></span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;tokenizer&quot;</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    spm.SentencePieceTrainer.Train(</span><br><span class="line">        <span class="built_in">input</span>=input_txt,</span><br><span class="line">        model_prefix=model_prefix,</span><br><span class="line">        vocab_size=vocab_size,</span><br><span class="line">        model_type=<span class="string">&quot;bpe&quot;</span>,</span><br><span class="line">        character_coverage=<span class="number">0.9995</span>,</span><br><span class="line">        bos_id=<span class="number">1</span>, eos_id=<span class="number">2</span>, pad_id=<span class="number">0</span>, unk_id=<span class="number">3</span>,</span><br><span class="line">        user_defined_symbols=[<span class="string">&quot;&lt;|system|&gt;&quot;</span>, <span class="string">&quot;&lt;|user|&gt;&quot;</span>, <span class="string">&quot;&lt;|assistant|&gt;&quot;</span>, <span class="string">&quot;&lt;|sep|&gt;&quot;</span>]</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Tokenizer built:&quot;</span>, model_prefix + <span class="string">&quot;.model&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    build_tokenizer()</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="2️⃣-模型定义"><a href="#2️⃣-模型定义" class="headerlink" title="2️⃣ 模型定义"></a>2️⃣ 模型定义</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># model.py</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RMSNorm</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, eps=<span class="number">1e-5</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.eps = eps</span><br><span class="line">        <span class="variable language_">self</span>.weight = nn.Parameter(torch.ones(dim))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        norm_x = x * torch.rsqrt(torch.mean(x * x, dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="variable language_">self</span>.eps)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.weight * norm_x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RotaryEmbedding</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, base=<span class="number">10000</span></span>):</span><br><span class="line">        inv_freq = <span class="number">1.0</span> / (base ** (torch.arange(<span class="number">0</span>, dim, <span class="number">2</span>).<span class="built_in">float</span>() / dim))</span><br><span class="line">        <span class="variable language_">self</span>.inv_freq = inv_freq</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_cos_sin</span>(<span class="params">self, seq_len, device</span>):</span><br><span class="line">        t = torch.arange(seq_len, device=device).type_as(<span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        freqs = torch.outer(t, <span class="variable language_">self</span>.inv_freq)</span><br><span class="line">        <span class="keyword">return</span> freqs.cos(), freqs.sin()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apply_rope</span>(<span class="params">x, cos, sin</span>):</span><br><span class="line">    head_dim = x.size(-<span class="number">1</span>)</span><br><span class="line">    x1 = x[..., :head_dim//<span class="number">2</span>]</span><br><span class="line">    x2 = x[..., head_dim//<span class="number">2</span>:]</span><br><span class="line">    <span class="keyword">return</span> torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.n_heads = n_heads</span><br><span class="line">        <span class="variable language_">self</span>.head_dim = dim // n_heads</span><br><span class="line">        <span class="variable language_">self</span>.qkv = nn.Linear(dim, dim * <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.o = nn.Linear(dim, dim, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, rope=<span class="literal">None</span></span>):</span><br><span class="line">        B, T, C = x.size()</span><br><span class="line">        qkv = <span class="variable language_">self</span>.qkv(x)</span><br><span class="line">        q, k, v = qkv.split(C, dim=-<span class="number">1</span>)</span><br><span class="line">        q = q.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        k = k.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        v = v.view(B, T, <span class="variable language_">self</span>.n_heads, C // <span class="variable language_">self</span>.n_heads).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> rope <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            cos, sin = rope.get_cos_sin(T, x.device)</span><br><span class="line">            cos = cos[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            sin = sin[<span class="literal">None</span>, <span class="literal">None</span>, :, :].repeat(B, <span class="variable language_">self</span>.n_heads, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            q = apply_rope(q, cos, sin)</span><br><span class="line">            k = apply_rope(k, cos, sin)</span><br><span class="line"></span><br><span class="line">        att = (q @ k.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(<span class="variable language_">self</span>.head_dim)</span><br><span class="line">        causal = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">        att = att.masked_fill(causal == <span class="number">0</span>, <span class="built_in">float</span>(<span class="string">&quot;-inf&quot;</span>))</span><br><span class="line">        att = F.softmax(att, dim=-<span class="number">1</span>)</span><br><span class="line">        att = <span class="variable language_">self</span>.dropout(att)</span><br><span class="line">        y = att @ v</span><br><span class="line">        y = y.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(B, T, C)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.o(y)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, ffn_dim, dropout=<span class="number">0.0</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.w1 = nn.Linear(dim, ffn_dim)</span><br><span class="line">        <span class="variable language_">self</span>.w2 = nn.Linear(ffn_dim, dim)</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.w2(<span class="variable language_">self</span>.dropout(F.silu(<span class="variable language_">self</span>.w1(x))))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TransformerBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, n_heads, ffn_dim, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.norm1 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.attn = Attention(dim, n_heads, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.norm2 = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.ffn = FeedForward(dim, ffn_dim, dropout=dropout)</span><br><span class="line">        <span class="variable language_">self</span>.rope = RotaryEmbedding(dim // n_heads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = x + <span class="variable language_">self</span>.attn(<span class="variable language_">self</span>.norm1(x), rope=<span class="variable language_">self</span>.rope)</span><br><span class="line">        x = x + <span class="variable language_">self</span>.ffn(<span class="variable language_">self</span>.norm2(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TinyLLM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tok_emb = nn.Embedding(vocab_size, dim)</span><br><span class="line">        <span class="variable language_">self</span>.blocks = nn.ModuleList([TransformerBlock(dim, n_heads, ffn_dim, dropout) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n_layers)])</span><br><span class="line">        <span class="variable language_">self</span>.norm = RMSNorm(dim)</span><br><span class="line">        <span class="variable language_">self</span>.lm_head = nn.Linear(dim, vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="variable language_">self</span>.max_seq_len = max_seq_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, idx</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.tok_emb(idx)</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> <span class="variable language_">self</span>.blocks:</span><br><span class="line">            x = blk(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.norm(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.lm_head(x)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.no_grad()</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate</span>(<span class="params">self, idx, max_new_tokens=<span class="number">128</span>, temperature=<span class="number">0.7</span>, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_new_tokens):</span><br><span class="line">            logits = <span class="variable language_">self</span>.forward(idx)[:, -<span class="number">1</span>, :]</span><br><span class="line">            logits = logits / <span class="built_in">max</span>(temperature, <span class="number">1e-5</span>)</span><br><span class="line">            probs = F.softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">            next_token = torch.multinomial(probs, num_samples=<span class="number">1</span>)</span><br><span class="line">            idx = torch.cat([idx, next_token], dim=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> idx.size(<span class="number">1</span>) &gt;= <span class="variable language_">self</span>.max_seq_len:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> idx</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="3️⃣-预训练、SFT、Reasoning-SFT、推理、API"><a href="#3️⃣-预训练、SFT、Reasoning-SFT、推理、API" class="headerlink" title="3️⃣ 预训练、SFT、Reasoning SFT、推理、API"></a>3️⃣ 预训练、SFT、Reasoning SFT、推理、API</h1><p>由于篇幅限制，我在这里不重复贴出所有文件的完整代码（你前面已经看过 <code>train_pretrain.py</code>、<code>train_sft.py</code>、<code>train_reasoning_sft.py</code>、<code>generate.py</code>、<code>generate_reasoning.py</code>、<code>tiny_tools.py</code>、<code>app_reasoning.py</code> 的实现）。</p>
<p>👉 你只需要把这些文件分别保存到项目目录中即可。</p>
<hr>
<h1 id="✅-使用流程"><a href="#✅-使用流程" class="headerlink" title="✅ 使用流程"></a>✅ 使用流程</h1><ol>
<li><strong>构建分词器</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python build_tokenizer.py</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><strong>预训练</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_pretrain.py</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>普通指令微调</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_sft.py</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>Reasoning 微调</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_reasoning_sft.py</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><strong>推理测试</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python generate_reasoning.py</span><br></pre></td></tr></table></figure>

<ol start="6">
<li><strong>API 部署</strong></li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uvicorn app_reasoning:app --reload --port 8000</span><br></pre></td></tr></table></figure>

<hr>
<p>✨ 总结：</p>
<ul>
<li>你现在有了一个完整的 <strong>从零到 reasoning 微调 + API 部署</strong> 的小模型工程。</li>
<li>产出物是 <strong>分词器文件 + 模型权重</strong>，推理时可以输出“推理链 + 最终答案”。</li>
<li>你可以逐步扩展数据集（数学、逻辑、常识），让模型的 reasoning 能力越来越强。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/zheniu/stochastic-cslr/tree/651af568f6a23cd1a0bf4cf717197b87ff8737f5/stochastic_cslr%2Fmodel%2Fxfmr.py">要不要我帮你</a></p>
<h2 id="train-pretrain-py、train-sft-py、train-reasoning-sft-py、generate-py、generate-reasoning-py、tiny-tools-py、app-reasoning-py-这些文件对于-reasoning-模式的模型需要修改吗？"><a href="#train-pretrain-py、train-sft-py、train-reasoning-sft-py、generate-py、generate-reasoning-py、tiny-tools-py、app-reasoning-py-这些文件对于-reasoning-模式的模型需要修改吗？" class="headerlink" title="train_pretrain.py、train_sft.py、train_reasoning_sft.py、generate.py、generate_reasoning.py、tiny_tools.py、app_reasoning.py 这些文件对于 reasoning 模式的模型需要修改吗？"></a><code>train_pretrain.py</code>、<code>train_sft.py</code>、<code>train_reasoning_sft.py</code>、<code>generate.py</code>、<code>generate_reasoning.py</code>、<code>tiny_tools.py</code>、<code>app_reasoning.py</code> 这些文件对于 reasoning 模式的模型需要修改吗？</h2><p>好问题 👍。你已经有了一套基础文件（预训练、SFT、推理、API），现在要让模型具备 <strong>reasoning 模式</strong>，需要的改动其实是“局部增强”，而不是推翻重写。下面我帮你逐个文件梳理：</p>
<hr>
<h2 id="1-train-pretrain-py"><a href="#1-train-pretrain-py" class="headerlink" title="1. train_pretrain.py"></a>1. <code>train_pretrain.py</code></h2><ul>
<li><strong>是否修改</strong>：不需要。</li>
<li><strong>原因</strong>：预训练阶段只是学语言建模能力，不涉及推理链。</li>
<li><strong>建议</strong>：保持原样即可，继续作为基础权重。</li>
</ul>
<hr>
<h2 id="2-train-sft-py"><a href="#2-train-sft-py" class="headerlink" title="2. train_sft.py"></a>2. <code>train_sft.py</code></h2><ul>
<li><strong>是否修改</strong>：可选。</li>
<li><strong>原因</strong>：普通指令微调文件可以保持原样，用于常规问答。</li>
<li><strong>建议</strong>：如果你想让模型同时具备“普通回答”和“推理回答”，可以保留它；如果只想专注 reasoning，可以跳过。</li>
</ul>
<hr>
<h2 id="3-train-reasoning-sft-py"><a href="#3-train-reasoning-sft-py" class="headerlink" title="3. train_reasoning_sft.py"></a>3. <code>train_reasoning_sft.py</code></h2><ul>
<li><strong>是否修改</strong>：需要。</li>
<li><strong>改动点</strong>：<ul>
<li>数据集格式：要包含 <strong>推理过程（CoT）+ 最终答案</strong>。</li>
<li>Loss 计算：只对 <code>&lt;|assistant|&gt;</code> 段落计算损失，忽略 system/user。</li>
<li>模板：明确区分“【推理过程】”和“【最终答案】”。</li>
</ul>
</li>
<li><strong>总结</strong>：这是 reasoning 模式的核心训练文件，必须改造。</li>
</ul>
<hr>
<h2 id="4-generate-py"><a href="#4-generate-py" class="headerlink" title="4. generate.py"></a>4. <code>generate.py</code></h2><ul>
<li><strong>是否修改</strong>：不需要。</li>
<li><strong>原因</strong>：它是普通推理脚本，适合测试基础模型或普通 SFT 模型。</li>
<li><strong>建议</strong>：保留原样，作为 baseline 对比。</li>
</ul>
<hr>
<h2 id="5-generate-reasoning-py"><a href="#5-generate-reasoning-py" class="headerlink" title="5. generate_reasoning.py"></a>5. <code>generate_reasoning.py</code></h2><ul>
<li><strong>是否修改</strong>：需要。</li>
<li><strong>改动点</strong>：<ul>
<li>增加 <strong>自洽采样（Self-Consistency）</strong>：多次生成 → 投票选答案。</li>
<li>增加 <strong>解析逻辑</strong>：从输出中抽取“推理过程”和“最终答案”。</li>
</ul>
</li>
<li><strong>总结</strong>：这是 reasoning 模式的推理脚本，必须增强。</li>
</ul>
<hr>
<h2 id="6-tiny-tools-py"><a href="#6-tiny-tools-py" class="headerlink" title="6. tiny_tools.py"></a>6. <code>tiny_tools.py</code></h2><ul>
<li><strong>是否修改</strong>：可选。</li>
<li><strong>原因</strong>：如果你希望模型在推理时调用外部工具（如计算器），就需要实现；否则可以不改。</li>
<li><strong>建议</strong>：保留，作为算术类 reasoning 的辅助。</li>
</ul>
<hr>
<h2 id="7-app-reasoning-py"><a href="#7-app-reasoning-py" class="headerlink" title="7. app_reasoning.py"></a>7. <code>app_reasoning.py</code></h2><ul>
<li><strong>是否修改</strong>：需要。</li>
<li><strong>改动点</strong>：<ul>
<li>API 返回时，除了最终答案，还要返回 <strong>推理链</strong>。</li>
<li>可选：支持自洽采样模式。</li>
</ul>
</li>
<li><strong>总结</strong>：这是 reasoning 模式的服务接口，必须改造。</li>
</ul>
<hr>
<h2 id="✅-总结-6"><a href="#✅-总结-6" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>必须修改</strong>：<code>train_reasoning_sft.py</code>、<code>generate_reasoning.py</code>、<code>app_reasoning.py</code></li>
<li><strong>可选修改</strong>：<code>train_sft.py</code>（是否保留普通指令）、<code>tiny_tools.py</code>（是否启用工具调用）</li>
<li><strong>无需修改</strong>：<code>train_pretrain.py</code>、<code>generate.py</code></li>
</ul>
<hr>
<p>👉 换句话说，你的 reasoning 模式是在 <strong>SFT → 推理 → API</strong> 这三环节做增强，预训练和普通生成脚本保持不变。</p>
<p>要不要我帮你画一张 <strong>“普通模式 vs reasoning 模式的文件改动对比图”</strong>，让你一眼看到哪些文件是共用的，哪些是 reasoning 专属的？</p>
<h2 id="请把需要修改的文件重新生成。"><a href="#请把需要修改的文件重新生成。" class="headerlink" title="请把需要修改的文件重新生成。"></a>请把需要修改的文件重新生成。</h2><p>好的 Mark，我来帮你把 <strong>需要修改的三个文件</strong>（<code>train_reasoning_sft.py</code>、<code>generate_reasoning.py</code>、<code>app_reasoning.py</code>）重新整理成完整实现。这样你可以直接替换掉原文件，专门用于 <strong>reasoning 模式</strong>。</p>
<hr>
<h1 id="1️⃣-train-reasoning-sft-py"><a href="#1️⃣-train-reasoning-sft-py" class="headerlink" title="1️⃣ train_reasoning_sft.py"></a>1️⃣ <code>train_reasoning_sft.py</code></h1><p>用于训练带推理链（CoT）的监督微调模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># train_reasoning_sft.py</span></span><br><span class="line"><span class="keyword">import</span> os, json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">PROMPT_TPL = <span class="string">&quot;&lt;|system|&gt;\n&#123;system&#125;\n&lt;|sep|&gt;\n&lt;|user|&gt;\n&#123;user&#125;\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n【推理过程】\n&#123;cot&#125;\n【最终答案】\n&#123;final&#125;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ReasoningSFTDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, jsonl_path, sp_model_path, seq_len=<span class="number">512</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.sp = spm.SentencePieceProcessor(model_file=sp_model_path)</span><br><span class="line">        <span class="variable language_">self</span>.seq_len = seq_len</span><br><span class="line">        <span class="variable language_">self</span>.samples = []</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(jsonl_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                obj = json.loads(line)</span><br><span class="line">                prompt = PROMPT_TPL.<span class="built_in">format</span>(system=obj[<span class="string">&quot;system&quot;</span>], user=obj[<span class="string">&quot;user&quot;</span>], cot=obj[<span class="string">&quot;cot&quot;</span>], final=obj[<span class="string">&quot;final&quot;</span>])</span><br><span class="line">                ids = <span class="variable language_">self</span>.sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(ids) &gt; seq_len:</span><br><span class="line">                    ids = ids[:seq_len]</span><br><span class="line">                <span class="comment"># 只对 assistant 段落计算损失</span></span><br><span class="line">                prefix = <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;system&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;obj[<span class="string">&#x27;user&#x27;</span>]&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line">                prefix_ids = <span class="variable language_">self</span>.sp.encode(prefix, out_type=<span class="built_in">int</span>)</span><br><span class="line">                labels = [-<span class="number">100</span>] * <span class="built_in">len</span>(prefix_ids) + ids[<span class="built_in">len</span>(prefix_ids):]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">len</span>(labels) &lt; <span class="built_in">len</span>(ids):</span><br><span class="line">                    labels += [-<span class="number">100</span>] * (<span class="built_in">len</span>(ids) - <span class="built_in">len</span>(labels))</span><br><span class="line">                <span class="variable language_">self</span>.samples.append((ids, labels))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>): <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.samples)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        ids, labels = <span class="variable language_">self</span>.samples[idx]</span><br><span class="line">        x = torch.tensor(ids, dtype=torch.long)</span><br><span class="line">        y = torch.tensor(labels, dtype=torch.long)</span><br><span class="line">        pad_len = <span class="variable language_">self</span>.seq_len - <span class="built_in">len</span>(ids)</span><br><span class="line">        <span class="keyword">if</span> pad_len &gt; <span class="number">0</span>:</span><br><span class="line">            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])</span><br><span class="line">            y = torch.cat([y, torch.full((pad_len,), -<span class="number">100</span>, dtype=torch.long)])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_reasoning_sft</span>(<span class="params"></span></span><br><span class="line"><span class="params">    sft_path=<span class="string">&quot;data/reasoning_sft.jsonl&quot;</span>,</span></span><br><span class="line"><span class="params">    spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span></span><br><span class="line"><span class="params">    load_ckpt=<span class="string">&quot;checkpoints/pretrain_epoch0.pt&quot;</span>,</span></span><br><span class="line"><span class="params">    save_dir=<span class="string">&quot;checkpoints&quot;</span>,</span></span><br><span class="line"><span class="params">    batch_size=<span class="number">4</span>, lr=<span class="number">1e-4</span>, epochs=<span class="number">1</span>, seq_len=<span class="number">512</span>,</span></span><br><span class="line"><span class="params">    vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    ds = ReasoningSFTDataset(sft_path, spm_path, seq_len=seq_len)</span><br><span class="line">    dl = DataLoader(ds, batch_size=batch_size, shuffle=<span class="literal">True</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = TinyLLM(vocab_size=vocab_size, dim=dim, n_layers=n_layers, n_heads=n_heads,</span><br><span class="line">                    ffn_dim=ffn_dim, max_seq_len=seq_len, dropout=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">if</span> load_ckpt <span class="keyword">and</span> os.path.exists(load_ckpt):</span><br><span class="line">        sd = torch.load(load_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">        model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loaded base:&quot;</span>, load_ckpt)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    optim = AdamW(model.parameters(), lr=lr, weight_decay=<span class="number">1e-2</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        model.train()</span><br><span class="line">        moving = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dl):</span><br><span class="line">            x, y = x.to(device), y.to(device)</span><br><span class="line">            logits = model(x)</span><br><span class="line">            loss = F.cross_entropy(logits.view(-<span class="number">1</span>, logits.size(-<span class="number">1</span>)), y.view(-<span class="number">1</span>), ignore_index=-<span class="number">100</span>)</span><br><span class="line">            optim.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="number">1.0</span>)</span><br><span class="line">            optim.step()</span><br><span class="line">            moving += loss.item()</span><br><span class="line">            <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[epoch <span class="subst">&#123;epoch&#125;</span> step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>] cot_sft_loss=<span class="subst">&#123;moving/<span class="number">50</span>:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">                moving = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">        ckpt_path = os.path.join(save_dir, <span class="string">f&quot;reasoning_sft_epoch<span class="subst">&#123;epoch&#125;</span>.pt&quot;</span>)</span><br><span class="line">        torch.save(&#123;<span class="string">&quot;model&quot;</span>: model.state_dict()&#125;, ckpt_path)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Saved:&quot;</span>, ckpt_path)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train_reasoning_sft(epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="2️⃣-generate-reasoning-py"><a href="#2️⃣-generate-reasoning-py" class="headerlink" title="2️⃣ generate_reasoning.py"></a>2️⃣ <code>generate_reasoning.py</code></h1><p>用于 reasoning 模式推理，支持自洽采样。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># generate_reasoning.py</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt</span>(<span class="params">system, user</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_final</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">return</span> text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_self_consistency</span>(<span class="params">model_ckpt, spm_path, system, user, samples=<span class="number">5</span>, max_new_tokens=<span class="number">200</span>, temperature=<span class="number">0.8</span></span>):</span><br><span class="line">    device = torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    sp = spm.SentencePieceProcessor(model_file=spm_path)</span><br><span class="line">    model = TinyLLM(vocab_size=<span class="number">16000</span>, dim=<span class="number">512</span>, n_layers=<span class="number">8</span>, n_heads=<span class="number">8</span>, ffn_dim=<span class="number">2048</span>, max_seq_len=<span class="number">512</span>)</span><br><span class="line">    sd = torch.load(model_ckpt, map_location=<span class="string">&quot;cpu&quot;</span>)[<span class="string">&quot;model&quot;</span>]</span><br><span class="line">    model.load_state_dict(sd, strict=<span class="literal">False</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    prompt = build_prompt(system, user)</span><br><span class="line">    ids = sp.encode(prompt, out_type=<span class="built_in">int</span>)</span><br><span class="line">    x0 = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    finals = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        x = x0.clone()</span><br><span class="line">        out = model.generate(x, max_new_tokens=max_new_tokens, temperature=temperature, top_k=<span class="number">40</span>, top_p=<span class="number">0.9</span>)</span><br><span class="line">        text = sp.decode(out[<span class="number">0</span>].tolist())</span><br><span class="line">        finals.append(parse_final(text))</span><br><span class="line">    vote = Counter(finals)</span><br><span class="line">    best_final, _ = vote.most_common(<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> best_final, finals</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    best, all_finals = run_self_consistency(</span><br><span class="line">        model_ckpt=<span class="string">&quot;checkpoints/reasoning_sft_epoch0.pt&quot;</span>,</span><br><span class="line">        spm_path=<span class="string">&quot;tokenizer/spm.model&quot;</span>,</span><br><span class="line">        system=<span class="string">&quot;你是严谨的中文推理助手&quot;</span>,</span><br><span class="line">        user=<span class="string">&quot;计算：12*(3+4)-10&quot;</span>,</span><br><span class="line">        samples=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;投票最终答案:&quot;</span>, best)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;所有候选:&quot;</span>, all_finals)</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="3️⃣-app-reasoning-py"><a href="#3️⃣-app-reasoning-py" class="headerlink" title="3️⃣ app_reasoning.py"></a>3️⃣ <code>app_reasoning.py</code></h1><p>API 服务，返回推理链和最终答案。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># app_reasoning.py</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Header</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Optional</span></span><br><span class="line"><span class="keyword">import</span> torch, sentencepiece <span class="keyword">as</span> spm</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> TinyLLM</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Message</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    role: <span class="built_in">str</span></span><br><span class="line">    content: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatRequest</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    messages: <span class="type">List</span>[Message]</span><br><span class="line">    max_tokens: <span class="built_in">int</span> = <span class="number">128</span></span><br><span class="line">    temperature: <span class="built_in">float</span> = <span class="number">0.7</span></span><br><span class="line">    top_k: <span class="built_in">int</span> = <span class="number">40</span></span><br><span class="line">    top_p: <span class="built_in">float</span> = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatChoice</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    index: <span class="built_in">int</span></span><br><span class="line">    message: Message</span><br><span class="line">    finish_reason: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChatResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    <span class="built_in">id</span>: <span class="built_in">str</span></span><br><span class="line">    model: <span class="built_in">str</span></span><br><span class="line">    choices: <span class="type">List</span>[ChatChoice]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_prompt_from_messages</span>(<span class="params">messages</span>):</span><br><span class="line">    system = <span class="string">&quot;&quot;</span></span><br><span class="line">    user = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;system&quot;</span>: system = m.content</span><br><span class="line">        <span class="keyword">if</span> m.role == <span class="string">&quot;user&quot;</span>: user = m.content</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&lt;|system|&gt;\n<span class="subst">&#123;system&#125;</span>\n&lt;|sep|&gt;\n&lt;|user|&gt;\n<span class="subst">&#123;user&#125;</span>\n&lt;|sep|&gt;\n&lt;|assistant|&gt;\n&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_segments</span>(<span class="params">text</span>):</span><br><span class="line">    parts = &#123;<span class="string">&quot;reasoning&quot;</span>: <span class="string">&quot;&quot;</span>, <span class="string">&quot;final&quot;</span>: <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【推理过程】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        seg = text.split(<span class="string">&quot;【推理过程】&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">        parts[<span class="string">&quot;reasoning&quot;</span>] = seg.split(<span class="string">&quot;【最终答案】&quot;</span>)[<span class="number">0</span>].strip()</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;【最终答案】&quot;</span> <span class="keyword">in</span> text:</span><br><span class="line">        parts[<span class="string">&quot;final&quot;</span>] = text.split(<span class="string">&quot;【最终答案】&quot;</span>)[-<span class="number">1</span>].strip().split(<span class="string">&quot;\n&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> parts</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/v1/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat</span>(<span class="params">req: ChatRequest, authorization: <span class="type">Optional</span>[<span class="built_in">str</span>] = Header(<span class="params"><span class="literal">None</span></span>)</span>):</span><br></pre></td></tr></table></figure>

<h2 id="大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进"><a href="#大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进" class="headerlink" title="大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进"></a>大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进</h2><p>好的 Mark，我来帮你整理一个 <strong>大模型技术演进大纲</strong>，从早期到最新趋势，分阶段梳理清晰。你可以把它作为写文章、做演讲或课程的框架。</p>
<hr>
<h1 id="📚-大模型技术演进大纲"><a href="#📚-大模型技术演进大纲" class="headerlink" title="📚 大模型技术演进大纲"></a>📚 大模型技术演进大纲</h1><h2 id="一、起点：语言模型的萌芽"><a href="#一、起点：语言模型的萌芽" class="headerlink" title="一、起点：语言模型的萌芽"></a>一、起点：语言模型的萌芽</h2><ul>
<li><strong>统计语言模型</strong><ul>
<li>N-gram 模型</li>
<li>局限：稀疏性、上下文有限</li>
</ul>
</li>
<li><strong>神经语言模型</strong><ul>
<li>Word2Vec、GloVe：词向量表示</li>
<li>RNN/LSTM/GRU：序列建模</li>
</ul>
</li>
</ul>
<hr>
<h2 id="二、Transformer-革命（2017）"><a href="#二、Transformer-革命（2017）" class="headerlink" title="二、Transformer 革命（2017）"></a>二、Transformer 革命（2017）</h2><ul>
<li><strong>Attention is All You Need</strong><ul>
<li>自注意力机制</li>
<li>并行训练、长距离依赖建模</li>
</ul>
</li>
<li><strong>BERT 系列</strong>（双向编码器）<ul>
<li>预训练 + 下游微调范式</li>
</ul>
</li>
<li><strong>GPT 系列</strong>（自回归生成）<ul>
<li>单向预测，擅长生成</li>
</ul>
</li>
</ul>
<hr>
<h2 id="三、预训练大模型时代"><a href="#三、预训练大模型时代" class="headerlink" title="三、预训练大模型时代"></a>三、预训练大模型时代</h2><ul>
<li><strong>Scaling Law（扩展规律）</strong><ul>
<li>参数量、数据量、算力 → 性能提升</li>
</ul>
</li>
<li><strong>代表模型</strong><ul>
<li>GPT-2/3：通用生成能力</li>
<li>T5：统一 NLP 任务为“文本到文本”</li>
<li>BART：编码器-解码器结合</li>
</ul>
</li>
</ul>
<hr>
<h2 id="四、指令微调与对齐（Alignment）"><a href="#四、指令微调与对齐（Alignment）" class="headerlink" title="四、指令微调与对齐（Alignment）"></a>四、指令微调与对齐（Alignment）</h2><ul>
<li><strong>SFT（监督微调）</strong><ul>
<li>用指令-回答数据集训练</li>
</ul>
</li>
<li><strong>RLHF（人类反馈强化学习）</strong><ul>
<li>通过人类偏好优化输出</li>
</ul>
</li>
<li><strong>安全与价值对齐</strong><ul>
<li>避免有害内容，提升可控性</li>
</ul>
</li>
</ul>
<hr>
<h2 id="五、RAG-与外部知识增强"><a href="#五、RAG-与外部知识增强" class="headerlink" title="五、RAG 与外部知识增强"></a>五、RAG 与外部知识增强</h2><ul>
<li><strong>RAG（Retrieval-Augmented Generation）</strong><ul>
<li>向量检索 + 大模型生成</li>
<li>解决知识过时、幻觉问题</li>
</ul>
</li>
<li><strong>工具调用与 Agent</strong><ul>
<li>模型可调用 API、数据库、计算器</li>
<li>从“语言模型”走向“通用智能体”</li>
</ul>
</li>
</ul>
<hr>
<h2 id="六、多模态大模型"><a href="#六、多模态大模型" class="headerlink" title="六、多模态大模型"></a>六、多模态大模型</h2><ul>
<li><strong>文本 + 图像</strong>：GPT-4V、Qwen-VL、LLaVA</li>
<li><strong>文本 + 音频</strong>：Whisper、Gemini</li>
<li><strong>文本 + 视频</strong>：Sora、Kosmos 系列</li>
<li><strong>应用场景</strong>：看图问答、视频理解、跨模态推理</li>
</ul>
<hr>
<h2 id="七、Reasoning-与推理能力"><a href="#七、Reasoning-与推理能力" class="headerlink" title="七、Reasoning 与推理能力"></a>七、Reasoning 与推理能力</h2><ul>
<li>**Chain of Thought (CoT)**：逐步推理</li>
<li><strong>Self-Consistency</strong>：多路径投票</li>
<li><strong>工具增强推理</strong>：调用计算器、符号推理器</li>
<li><strong>专门推理模型</strong>：DeepSeek-R1、OpenAI o1</li>
</ul>
<hr>
<h2 id="八、开源与生态繁荣"><a href="#八、开源与生态繁荣" class="headerlink" title="八、开源与生态繁荣"></a>八、开源与生态繁荣</h2><ul>
<li><strong>开源模型</strong>：LLaMA、Mistral、Qwen、ChatGLM</li>
<li><strong>生态工具</strong>：LangChain、LlamaIndex、向量数据库</li>
<li><strong>轻量化技术</strong>：LoRA、QLoRA、蒸馏、量化</li>
</ul>
<hr>
<h2 id="九、未来趋势"><a href="#九、未来趋势" class="headerlink" title="九、未来趋势"></a>九、未来趋势</h2><ul>
<li><strong>更强的推理与规划能力</strong></li>
<li><strong>多模态融合与世界模型</strong></li>
<li><strong>个性化与小模型（Personal LLM）</strong></li>
<li><strong>隐私与安全对齐</strong></li>
<li><strong>AGI 探索</strong>：从助手到自主智能体</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：<br>大模型技术演进经历了 <strong>统计 → 神经网络 → Transformer → 预训练 → 指令对齐 → RAG → 多模态 → 推理 → AGI 探索</strong> 的路线。每一步都在解决前一代的瓶颈，推动模型从“语言处理器”走向“通用智能体”。</p>
<hr>
<p>要不要我帮你把这个大纲扩展成一份 <strong>详细讲解稿</strong>（每个阶段配上代表论文/模型、关键突破、应用案例），方便你直接用来写文章或做分享？</p>
<p>好的 Mark，我来把之前的大纲扩展成一个更完整的 <strong>大模型技术演进讲解稿</strong>，每个阶段都包含代表模型/论文、关键突破和典型应用。这样你可以直接用来写文章或做分享。</p>
<hr>
<h1 id="📚-大模型技术演进讲解稿"><a href="#📚-大模型技术演进讲解稿" class="headerlink" title="📚 大模型技术演进讲解稿"></a>📚 大模型技术演进讲解稿</h1><h2 id="一、起点：语言模型的萌芽-1"><a href="#一、起点：语言模型的萌芽-1" class="headerlink" title="一、起点：语言模型的萌芽"></a>一、起点：语言模型的萌芽</h2><ul>
<li><p><strong>统计语言模型</strong></p>
<ul>
<li><strong>代表方法</strong>：N-gram</li>
<li><strong>突破点</strong>：用条件概率建模语言，但受限于稀疏性和短上下文。</li>
<li><strong>应用</strong>：早期机器翻译、语音识别。</li>
</ul>
</li>
<li><p><strong>神经语言模型</strong></p>
<ul>
<li><strong>代表模型</strong>：Word2Vec (2013)、GloVe (2014)</li>
<li><strong>突破点</strong>：词向量捕捉语义关系（如 king - man + woman ≈ queen）。</li>
<li><strong>应用</strong>：搜索引擎、推荐系统、情感分析。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="二、Transformer-革命（2017）-1"><a href="#二、Transformer-革命（2017）-1" class="headerlink" title="二、Transformer 革命（2017）"></a>二、Transformer 革命（2017）</h2><ul>
<li><strong>论文</strong>：《Attention is All You Need》</li>
<li><strong>突破点</strong>：自注意力机制替代 RNN/CNN，支持并行训练，捕捉长距离依赖。</li>
<li><strong>代表模型</strong>：<ul>
<li>BERT (2018)：双向编码器，擅长理解任务。</li>
<li>GPT (2018)：自回归生成，擅长文本生成。</li>
</ul>
</li>
<li><strong>应用</strong>：阅读理解、机器翻译、对话系统。</li>
</ul>
<hr>
<h2 id="三、预训练大模型时代-1"><a href="#三、预训练大模型时代-1" class="headerlink" title="三、预训练大模型时代"></a>三、预训练大模型时代</h2><ul>
<li><strong>Scaling Law</strong>：参数量、数据量、算力成指数关系 → 模型性能持续提升。</li>
<li><strong>代表模型</strong>：<ul>
<li>GPT-2/3 (2019/2020)：展现“少样本学习”能力。</li>
<li>T5 (2019)：统一 NLP 任务为“文本到文本”。</li>
<li>BART (2019)：结合编码器-解码器，适合生成与理解。</li>
</ul>
</li>
<li><strong>应用</strong>：开放域对话、自动写作、代码生成。</li>
</ul>
<hr>
<h2 id="四、指令微调与对齐（2022-起）"><a href="#四、指令微调与对齐（2022-起）" class="headerlink" title="四、指令微调与对齐（2022 起）"></a>四、指令微调与对齐（2022 起）</h2><ul>
<li><strong>SFT（监督微调）</strong>：用指令-回答数据集训练，让模型更听话。</li>
<li><strong>RLHF（人类反馈强化学习）</strong>：通过人类偏好优化输出质量。</li>
<li><strong>代表模型</strong>：InstructGPT、ChatGPT。</li>
<li><strong>应用</strong>：智能客服、教育辅导、办公助手。</li>
</ul>
<hr>
<h2 id="五、RAG-与外部知识增强-1"><a href="#五、RAG-与外部知识增强-1" class="headerlink" title="五、RAG 与外部知识增强"></a>五、RAG 与外部知识增强</h2><ul>
<li><p><strong>RAG（Retrieval-Augmented Generation）</strong></p>
<ul>
<li><strong>突破点</strong>：结合向量检索与大模型生成，解决知识过时与幻觉问题。</li>
<li><strong>应用</strong>：企业知识库问答、法律/医疗文档检索。</li>
</ul>
</li>
<li><p><strong>Agent 与工具调用</strong></p>
<ul>
<li>模型可调用 API、数据库、计算器。</li>
<li><strong>应用</strong>：自动化办公、数据分析、智能体。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="六、多模态大模型-1"><a href="#六、多模态大模型-1" class="headerlink" title="六、多模态大模型"></a>六、多模态大模型</h2><ul>
<li><strong>突破点</strong>：跨模态理解与生成（文本+图像+音频+视频）。</li>
<li><strong>代表模型</strong>：<ul>
<li>GPT-4V（图像输入）、Gemini（多模态）、Qwen-VL（中文图文）。</li>
<li>LLaVA、MiniGPT-4（开源图文）。</li>
</ul>
</li>
<li><strong>应用</strong>：看图问答、图表理解、视频摘要、语音助手。</li>
</ul>
<hr>
<h2 id="七、Reasoning-与推理能力-1"><a href="#七、Reasoning-与推理能力-1" class="headerlink" title="七、Reasoning 与推理能力"></a>七、Reasoning 与推理能力</h2><ul>
<li><strong>方法</strong>：<ul>
<li>Chain of Thought (CoT)：逐步推理。</li>
<li>Self-Consistency：多路径投票。</li>
<li>工具增强：调用计算器、符号推理器。</li>
</ul>
</li>
<li><strong>代表模型</strong>：DeepSeek-R1、OpenAI o1。</li>
<li><strong>应用</strong>：数学解题、逻辑推理、规划任务。</li>
</ul>
<hr>
<h2 id="八、开源与生态繁荣-1"><a href="#八、开源与生态繁荣-1" class="headerlink" title="八、开源与生态繁荣"></a>八、开源与生态繁荣</h2><ul>
<li><strong>开源模型</strong>：LLaMA、Mistral、Qwen、ChatGLM。</li>
<li><strong>生态工具</strong>：LangChain、LlamaIndex、向量数据库（FAISS、Milvus）。</li>
<li><strong>轻量化技术</strong>：LoRA、QLoRA、蒸馏、量化。</li>
<li><strong>应用</strong>：本地部署、行业定制、低成本实验。</li>
</ul>
<hr>
<h2 id="九、未来趋势-1"><a href="#九、未来趋势-1" class="headerlink" title="九、未来趋势"></a>九、未来趋势</h2><ul>
<li><strong>更强推理与规划</strong>：结合符号推理、搜索算法。</li>
<li><strong>多模态融合</strong>：世界模型（World Model），理解环境与时序。</li>
<li><strong>个性化小模型</strong>：Personal LLM，适配个人数据与设备。</li>
<li><strong>隐私与安全对齐</strong>：差分隐私、可解释性。</li>
<li><strong>AGI 探索</strong>：从助手到自主智能体。</li>
</ul>
<hr>
<h2 id="✅-总结-7"><a href="#✅-总结-7" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><p>大模型技术演进路线：<br><strong>统计 → 神经网络 → Transformer → 预训练 → 指令对齐 → RAG → 多模态 → 推理 → AGI 探索</strong>。<br>每一步都在解决前一代的瓶颈，推动模型从“语言处理器”走向“通用智能体”。</p>
<hr>
<p>要不要我帮你把这个讲解稿再整理成一份 <strong>时间轴图表</strong>（年份 + 关键论文/模型 + 技术突破），让演示更直观？</p>
<h2 id="大模型技术必读论文"><a href="#大模型技术必读论文" class="headerlink" title="大模型技术必读论文"></a>大模型技术必读论文</h2><p><strong>快速回答</strong>：学习大模型（LLM），有一些“必读经典论文”几乎是绕不开的里程碑，从词向量到 Transformer，再到 GPT、BERT、对齐与推理。下面我整理了一份时间顺序的清单，涵盖核心论文与贡献。</p>
<hr>
<h2 id="📑-大模型学习必读经典论文清单"><a href="#📑-大模型学习必读经典论文清单" class="headerlink" title="📑 大模型学习必读经典论文清单"></a>📑 大模型学习必读经典论文清单</h2><h3 id="早期基础（词向量与注意力）"><a href="#早期基础（词向量与注意力）" class="headerlink" title="早期基础（词向量与注意力）"></a>早期基础（词向量与注意力）</h3><ul>
<li><strong>Word2Vec</strong> — <em>Mikolov et al., 2013</em><br><em>提出分布式词向量表示，奠定语义建模基础。</em></li>
<li><strong>GloVe</strong> — <em>Pennington et al., 2014</em><br><em>结合全局统计与局部窗口的词向量方法。</em></li>
<li><strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong> — <em>Bahdanau et al., 2014</em><br><em>首次提出注意力机制，为 Transformer 奠基。</em></li>
</ul>
<h3 id="Transformer-革命"><a href="#Transformer-革命" class="headerlink" title="Transformer 革命"></a>Transformer 革命</h3><ul>
<li><strong>Attention Is All You Need</strong> — <em>Vaswani et al., 2017</em><br><em>提出 Transformer 架构，自注意力机制成为大模型核心。</em></li>
</ul>
<h3 id="预训练与扩展"><a href="#预训练与扩展" class="headerlink" title="预训练与扩展"></a>预训练与扩展</h3><ul>
<li><strong>ELMo</strong> — <em>Peters et al., 2018</em><br><em>上下文动态词向量。</em></li>
<li><strong>BERT: Pre-training of Deep Bidirectional Transformers</strong> — <em>Devlin et al., 2018</em><br><em>双向编码器，预训练+微调范式。</em></li>
<li><strong>GPT-2: Language Models are Unsupervised Multitask Learners</strong> — <em>Radford et al., 2019</em><br><em>展示大规模自回归生成能力。</em></li>
<li><strong>GPT-3: Language Models are Few-Shot Learners</strong> — <em>Brown et al., 2020</em><br><em>少样本学习能力，参数规模突破。</em></li>
<li><strong>T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</strong> — <em>Raffel et al., 2020</em><br><em>统一 NLP 任务为文本到文本。</em></li>
</ul>
<h3 id="训练优化与-Scaling-Law"><a href="#训练优化与-Scaling-Law" class="headerlink" title="训练优化与 Scaling Law"></a>训练优化与 Scaling Law</h3><ul>
<li><strong>ZeRO: Efficient Large-Scale Model Training</strong> — <em>Rajbhandari et al., 2020</em><br><em>分布式训练优化。</em></li>
<li><strong>Chinchilla: Training Compute-Optimal Large Language Models</strong> — <em>Hoffmann et al., 2022</em><br><em>提出数据/参数平衡规律。</em></li>
</ul>
<h3 id="对齐与指令"><a href="#对齐与指令" class="headerlink" title="对齐与指令"></a>对齐与指令</h3><ul>
<li><strong>InstructGPT</strong> — <em>Ouyang et al., 2022</em><br><em>指令微调 + RLHF，对齐人类偏好。</em></li>
<li><strong>RLHF (Christiano et al., 2017; Ouyang et al., 2022)</strong><br><em>人类反馈强化学习，提升模型可控性。</em></li>
</ul>
<h3 id="知识增强与多模态"><a href="#知识增强与多模态" class="headerlink" title="知识增强与多模态"></a>知识增强与多模态</h3><ul>
<li><strong>RAG: Retrieval-Augmented Generation</strong> — <em>Lewis et al., 2020</em><br><em>结合检索与生成，解决知识过时问题。</em></li>
<li><strong>GPT-4 Technical Report</strong> — <em>OpenAI, 2023</em><br><em>多模态能力，安全对齐。</em></li>
<li><strong>Qwen-VL / LLaVA</strong> — <em>2023</em><br><em>中文与开源多模态大模型。</em></li>
</ul>
<h3 id="推理与未来"><a href="#推理与未来" class="headerlink" title="推理与未来"></a>推理与未来</h3><ul>
<li><strong>Chain-of-Thought Prompting</strong> — <em>Wei et al., 2022</em><br><em>显式推理链提升复杂任务表现。</em></li>
<li><strong>Self-Consistency Improves Chain of Thought Reasoning</strong> — <em>Wang et al., 2022</em><br><em>多路径投票增强推理稳定性。</em></li>
<li><strong>DeepSeek-R1 (2024)</strong><br><em>专注 reasoning 的开源模型。</em></li>
<li><strong>OpenAI o1 (2024)</strong><br><em>强化推理与工具调用能力。</em></li>
</ul>
<hr>
<h2 id="✅-总结-8"><a href="#✅-总结-8" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>入门必读</strong>：Word2Vec、Attention is All You Need、BERT、GPT-3。</li>
<li><strong>进阶必读</strong>：InstructGPT、Chinchilla、RAG、Chain-of-Thought。</li>
<li><strong>前沿必读</strong>：GPT-4 技术报告、DeepSeek-R1、OpenAI o1。</li>
</ul>
<hr>
<p>要不要我帮你把这些论文整理成一份 <strong>学习路线图（先读哪些基础，再读哪些进阶，最后看前沿）</strong>，让你能按阶段逐步攻克？</p>
<h2 id="📌-学习建议"><a href="#📌-学习建议" class="headerlink" title="📌 学习建议"></a>📌 学习建议</h2><ul>
<li><strong>第一阶段（2013–2017）</strong>：Word2Vec、GloVe、Transformer → 打好基础。</li>
<li><strong>第二阶段（2018–2020）</strong>：BERT、GPT-2/3、RAG → 掌握预训练与生成。</li>
<li><strong>第三阶段（2022–2023）</strong>：InstructGPT、RLHF、Chinchilla、GPT-4 → 理解对齐与多模态。</li>
<li><strong>第四阶段（2024–未来）</strong>：DeepSeek-R1、OpenAI o1 → 聚焦 reasoning 与 AGI 探索。</li>
</ul>
<hr>
<p>✅ 这样整理后，你就有了一份 <strong>学习路线图 + 必读论文清单</strong>。<br>要不要我再帮你做一份 <strong>“学习路径图”</strong>（比如：先读哪些基础论文，再读哪些进阶论文，最后看最新前沿），让你能按阶段逐步攻克？</p>
<h2 id="请介绍下-agent"><a href="#请介绍下-agent" class="headerlink" title="请介绍下 agent"></a>请介绍下 agent</h2><p><strong>简要回答</strong>：在大模型语境下，<strong>Agent（智能体）</strong>指的是一个能够自主感知环境、拆解任务、调用工具并执行行动的系统。它不仅仅是“回答问题的模型”，而是一个具备 <strong>目标规划、记忆、推理、工具调用与交互</strong> 能力的“行动者”。</p>
<hr>
<h2 id="🧩-Agent-的核心概念"><a href="#🧩-Agent-的核心概念" class="headerlink" title="🧩 Agent 的核心概念"></a>🧩 Agent 的核心概念</h2><ol>
<li><strong>自主性</strong>：不只是被动回答，而是能根据目标主动规划步骤。</li>
<li><strong>任务分解</strong>：将复杂问题拆解为子任务（如“组织生日聚会” → 订餐厅、发邀请、安排日程）。</li>
<li><strong>工具调用</strong>：能调用外部 API、数据库、搜索引擎、计算器等。</li>
<li><strong>记忆与上下文</strong>：保留历史信息，支持长时交互。</li>
<li><strong>多智能体协作</strong>：多个 Agent 可以分工合作，完成更复杂的任务。</li>
</ol>
<hr>
<h2 id="⚙️-Agent-的典型工作流"><a href="#⚙️-Agent-的典型工作流" class="headerlink" title="⚙️ Agent 的典型工作流"></a>⚙️ Agent 的典型工作流</h2><ol>
<li><strong>接收目标</strong>：用户输入或系统任务。</li>
<li><strong>任务规划</strong>：拆解为可执行的子任务。</li>
<li><strong>工具选择</strong>：决定调用哪些外部工具或知识库。</li>
<li><strong>执行与反馈</strong>：逐步完成任务，并根据反馈调整策略。</li>
<li><strong>总结与输出</strong>：给出最终结果或行动。</li>
</ol>
<hr>
<h2 id="🔑-技术支撑"><a href="#🔑-技术支撑" class="headerlink" title="🔑 技术支撑"></a>🔑 技术支撑</h2><ul>
<li><strong>大模型（LLM）</strong>：提供语言理解与生成能力。</li>
<li><strong>RAG（检索增强生成）</strong>：补充外部知识，减少幻觉。</li>
<li><strong>强化学习（RL）</strong>：优化决策与行动策略。</li>
<li><strong>知识图谱/记忆模块</strong>：存储长期知识与上下文。</li>
<li><strong>框架工具</strong>：LangChain、AutoGen、LangGraph 等，帮助开发者快速构建 Agent。</li>
</ul>
<hr>
<h2 id="🌍-应用场景"><a href="#🌍-应用场景" class="headerlink" title="🌍 应用场景"></a>🌍 应用场景</h2><ul>
<li><strong>个人助理</strong>：日程管理、邮件处理、会议纪要。</li>
<li><strong>企业应用</strong>：知识库问答、流程自动化、CRM 更新。</li>
<li><strong>科研与数据分析</strong>：自动检索文献、运行实验、生成报告。</li>
<li><strong>多模态任务</strong>：看图问答、视频摘要、语音交互。</li>
</ul>
<hr>
<h2 id="🚀-发展趋势"><a href="#🚀-发展趋势" class="headerlink" title="🚀 发展趋势"></a>🚀 发展趋势</h2><ul>
<li><strong>更强的推理与规划</strong>：结合 Chain-of-Thought、自洽采样。</li>
<li><strong>多智能体协作</strong>：Agent 团队协同完成复杂任务。</li>
<li><strong>与真实世界交互</strong>：通过 API、机器人、IoT 设备执行实际操作。</li>
<li><strong>安全与可控性</strong>：避免无限循环、幻觉或工具滥用。</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：Agent 是大模型应用的“升级形态”，让模型从“会说话”变成“会做事”。它的价值在于 <strong>把大模型的语言智能转化为可执行的行动</strong>，是通向通用人工智能（AGI）的关键路径。</p>
<p>要不要我帮你画一张 <strong>“Agent 技术框架图”</strong>，把输入、规划、工具调用、执行、反馈的流程直观展示出来？</p>
<h2 id="我想构建一个属于自己的智能体，实现电脑的文件操作，包括-windows-和-Linux-和-Unix-like-操作系统上的文件-夹-操作，可以输入指定的-prompt-来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能"><a href="#我想构建一个属于自己的智能体，实现电脑的文件操作，包括-windows-和-Linux-和-Unix-like-操作系统上的文件-夹-操作，可以输入指定的-prompt-来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能" class="headerlink" title="我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能"></a>我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能</h2><h1 id="个人文件智能体构建"><a href="#个人文件智能体构建" class="headerlink" title="个人文件智能体构建"></a>个人文件智能体构建</h1><p>你想把“自然语言 → 精确文件操作”做成一个可靠、可控的智能体。下面是一个从架构到落地代码的完整方案，兼顾跨平台（Windows、Linux、Unix-like）、安全权限、可审计日志和可扩展性。你可以直接按模块落地，并逐步加强。</p>
<hr>
<h2 id="架构与核心原则"><a href="#架构与核心原则" class="headerlink" title="架构与核心原则"></a>架构与核心原则</h2><ul>
<li><strong>输入管道:</strong> 用户 prompt → 结构化意图（操作类型、目标路径、内容、过滤条件）。</li>
<li><strong>规划器:</strong> 将意图拆解成序列化的文件操作（Create/Read/Update/Delete/Move/Tag/Compress…）。</li>
<li><strong>工具层:</strong> 跨平台文件工具库（pathlib、os、shutil、glob 统一封装）。</li>
<li><strong>安全层:</strong> 沙箱根目录、白名单操作类型、黑名单路径/扩展名、Dry-run、交互式确认、审计日志。</li>
<li><strong>执行器:</strong> 顺序执行、失败回滚（尽量）、最终结果与报告。</li>
<li><strong>可扩展:</strong> 增加“文件归类”“批量重命名”“内容模板替换”“语义检索”等工具。</li>
</ul>
<hr>
<h2 id="安全与可控策略"><a href="#安全与可控策略" class="headerlink" title="安全与可控策略"></a>安全与可控策略</h2><ul>
<li><strong>沙箱根目录:</strong> 仅允许在设定的根目录下操作，默认拒绝越权路径（绝对路径与 .. 上跳）。</li>
<li><strong>白名单操作:</strong> create/read/update/delete/move/copy/list/classify/tag/rename，仅这些被允许。</li>
<li><strong>黑名单:</strong> 系统关键路径、敏感扩展名（.sys、.dll、.so、.dylib、.exe、.bat、.sh）、隐藏目录。</li>
<li><strong>Dry-run:</strong> 先展示即将执行的操作清单，确认后再执行。</li>
<li><strong>双人确认:</strong> 删除与批量重命名需再次确认。</li>
<li><strong>审计日志:</strong> 每次操作写入 JSON 日志，包含时间、用户、操作、源/目标、结果。</li>
<li><strong>版本备份:</strong> 更新/删除前可备份至 .backup/ 目录。</li>
</ul>
<hr>
<h2 id="配置示例"><a href="#配置示例" class="headerlink" title="配置示例"></a>配置示例</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.yaml</span></span><br><span class="line"><span class="attr">agent:</span></span><br><span class="line">  <span class="attr">root:</span> <span class="string">&#x27;D:/AgentRoot&#x27;</span> <span class="comment"># Windows 示例；Linux/Unix 可用 /home/mark/AgentRoot</span></span><br><span class="line">  <span class="attr">allow_ops:</span></span><br><span class="line">    [</span><br><span class="line">      <span class="string">&#x27;create&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;read&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;update&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;delete&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;move&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;copy&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;list&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;classify&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;rename&#x27;</span>,</span><br><span class="line">      <span class="string">&#x27;tag&#x27;</span>,</span><br><span class="line">    ]</span><br><span class="line">  <span class="attr">deny_patterns:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&quot;C:\\Windows\\*&quot;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;/etc/*&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;/usr/*&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.sys&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.dll&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.so&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.dylib&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.exe&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.bat&#x27;</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;**/*.sh&#x27;</span></span><br><span class="line">  <span class="attr">dry_run_default:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">require_confirm_for:</span> [<span class="string">&#x27;delete&#x27;</span>, <span class="string">&#x27;rename&#x27;</span>]</span><br><span class="line">  <span class="attr">backup_before_delete:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">log_path:</span> <span class="string">&#x27;./logs/ops.jsonl&#x27;</span></span><br><span class="line">  <span class="attr">max_batch:</span> <span class="number">1000</span></span><br><span class="line">  <span class="attr">encoding:</span> <span class="string">&#x27;utf-8&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="结构化意图与操作序列"><a href="#结构化意图与操作序列" class="headerlink" title="结构化意图与操作序列"></a>结构化意图与操作序列</h2><ul>
<li><p><strong>意图模式（JSON）</strong></p>
<ul>
<li><strong>operation:</strong> create | read | update | delete | move | copy | list | classify | rename | tag</li>
<li><strong>path/pattern:</strong> 目标文件或通配符</li>
<li><strong>content:</strong> 用于创建/更新的文本</li>
<li><strong>filters:</strong> 扩展名、大小、时间范围等</li>
<li><strong>options:</strong> dry_run, recursive, confirm 等</li>
</ul>
</li>
<li><p><strong>示例（从自然语言到结构化）</strong></p>
<ul>
<li>用户：“把 /project/docs 里所有 .md 文件按主题归类到子文件夹，并给‘架构’主题加标签”</li>
<li>结构化序列：<ol>
<li>list {pattern: “/project/docs/*<em>/</em>.md”, recursive: true}</li>
<li>classify {rules: [“包含‘架构’→ docs/architecture”, “包含‘API’→ docs/api”, “其他 → docs/misc”]}</li>
<li>tag {pattern: “docs/architecture/*<em>/</em>.md”, tag: “architecture”}</li>
</ol>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="核心实现（Python）"><a href="#核心实现（Python）" class="headerlink" title="核心实现（Python）"></a>核心实现（Python）</h2><h3 id="1-路径与权限守卫"><a href="#1-路径与权限守卫" class="headerlink" title="1. 路径与权限守卫"></a>1. 路径与权限守卫</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># guard.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> fnmatch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Guard</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root: Path, deny_patterns: <span class="built_in">list</span>[<span class="built_in">str</span>]</span>):</span><br><span class="line">        <span class="variable language_">self</span>.root = root.resolve()</span><br><span class="line">        <span class="variable language_">self</span>.deny_patterns = deny_patterns</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">within_root</span>(<span class="params">self, p: Path</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            rp = p.resolve()</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.root <span class="keyword">in</span> rp.parents <span class="keyword">or</span> rp == <span class="variable language_">self</span>.root</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">denied</span>(<span class="params">self, p: Path</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        sp = <span class="built_in">str</span>(p)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">any</span>(fnmatch.fnmatch(sp, pattern) <span class="keyword">for</span> pattern <span class="keyword">in</span> <span class="variable language_">self</span>.deny_patterns)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check</span>(<span class="params">self, p: Path</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.within_root(p):</span><br><span class="line">            <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Path escapes root: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.denied(p):</span><br><span class="line">            <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Path denied by policy: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-文件工具层（跨平台）"><a href="#2-文件工具层（跨平台）" class="headerlink" title="2. 文件工具层（跨平台）"></a>2. 文件工具层（跨平台）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># file_tools.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> shutil, os, time</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Iterable</span><br><span class="line"><span class="keyword">from</span> guard <span class="keyword">import</span> Guard</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FileTools</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root: <span class="built_in">str</span>, guard: Guard, encoding=<span class="string">&quot;utf-8&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.root = Path(root).resolve()</span><br><span class="line">        <span class="variable language_">self</span>.guard = guard</span><br><span class="line">        <span class="variable language_">self</span>.encoding = encoding</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_resolve</span>(<span class="params">self, p: <span class="built_in">str</span></span>) -&gt; Path:</span><br><span class="line">        ap = (<span class="variable language_">self</span>.root / p.lstrip(<span class="string">&quot;/\\&quot;</span>)).resolve() <span class="keyword">if</span> <span class="keyword">not</span> Path(p).is_absolute() <span class="keyword">else</span> Path(p).resolve()</span><br><span class="line">        <span class="variable language_">self</span>.guard.check(ap)</span><br><span class="line">        <span class="keyword">return</span> ap</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">list</span>(<span class="params">self, pattern: <span class="built_in">str</span>, recursive: <span class="built_in">bool</span> = <span class="literal">True</span></span>) -&gt; <span class="built_in">list</span>[<span class="built_in">str</span>]:</span><br><span class="line">        base = <span class="variable language_">self</span>.root</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;**&quot;</span> <span class="keyword">in</span> pattern <span class="keyword">or</span> recursive:</span><br><span class="line">            paths = base.rglob(pattern.split(<span class="string">&quot;/&quot;</span>)[-<span class="number">1</span>]) <span class="keyword">if</span> <span class="string">&quot;**&quot;</span> <span class="keyword">in</span> pattern <span class="keyword">else</span> base.rglob(<span class="string">&quot;*&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            paths = base.glob(pattern)</span><br><span class="line">        out = []</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> paths:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="variable language_">self</span>.guard.check(x)</span><br><span class="line">                out.append(<span class="built_in">str</span>(x))</span><br><span class="line">            <span class="keyword">except</span> PermissionError:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">create</span>(<span class="params">self, path: <span class="built_in">str</span>, content: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span>, overwrite=<span class="literal">False</span></span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">if</span> p.exists() <span class="keyword">and</span> <span class="keyword">not</span> overwrite:</span><br><span class="line">            <span class="keyword">raise</span> FileExistsError(<span class="string">f&quot;Exists: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line">        p.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;w&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(content <span class="keyword">or</span> <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read</span>(<span class="params">self, path: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;r&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">return</span> f.read()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, path: <span class="built_in">str</span>, transform</span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        text = <span class="variable language_">self</span>.read(path)</span><br><span class="line">        new_text = transform(text)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(p, <span class="string">&quot;w&quot;</span>, encoding=<span class="variable language_">self</span>.encoding) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(new_text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">move</span>(<span class="params">self, src: <span class="built_in">str</span>, dst: <span class="built_in">str</span></span>):</span><br><span class="line">        sp, dp = <span class="variable language_">self</span>._resolve(src), <span class="variable language_">self</span>._resolve(dst)</span><br><span class="line">        dp.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        shutil.move(<span class="built_in">str</span>(sp), <span class="built_in">str</span>(dp))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">copy</span>(<span class="params">self, src: <span class="built_in">str</span>, dst: <span class="built_in">str</span></span>):</span><br><span class="line">        sp, dp = <span class="variable language_">self</span>._resolve(src), <span class="variable language_">self</span>._resolve(dst)</span><br><span class="line">        dp.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        shutil.copy2(<span class="built_in">str</span>(sp), <span class="built_in">str</span>(dp))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">delete</span>(<span class="params">self, path: <span class="built_in">str</span>, backup: <span class="built_in">bool</span> = <span class="literal">True</span></span>):</span><br><span class="line">        p = <span class="variable language_">self</span>._resolve(path)</span><br><span class="line">        <span class="keyword">if</span> backup <span class="keyword">and</span> p.exists():</span><br><span class="line">            bdir = <span class="variable language_">self</span>.root / <span class="string">&quot;.backup&quot;</span> / time.strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">            bdir.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">            bpath = bdir / p.name</span><br><span class="line">            <span class="keyword">if</span> p.is_file():</span><br><span class="line">                shutil.copy2(<span class="built_in">str</span>(p), <span class="built_in">str</span>(bpath))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                shutil.copytree(<span class="built_in">str</span>(p), <span class="built_in">str</span>(bpath))</span><br><span class="line">        <span class="keyword">if</span> p.is_file():</span><br><span class="line">            p.unlink()</span><br><span class="line">        <span class="keyword">elif</span> p.is_dir():</span><br><span class="line">            shutil.rmtree(<span class="built_in">str</span>(p), ignore_errors=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&quot;Not found: <span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">rename</span>(<span class="params">self, src: <span class="built_in">str</span>, new_name: <span class="built_in">str</span></span>):</span><br><span class="line">        sp = <span class="variable language_">self</span>._resolve(src)</span><br><span class="line">        dp = sp.parent / new_name</span><br><span class="line">        <span class="variable language_">self</span>.guard.check(dp)</span><br><span class="line">        sp.rename(dp)</span><br></pre></td></tr></table></figure>

<h3 id="3-归类与标签"><a href="#3-归类与标签" class="headerlink" title="3. 归类与标签"></a>3. 归类与标签</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># classify.py</span></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> file_tools <span class="keyword">import</span> FileTools</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify_by_rules</span>(<span class="params">ft: FileTools, files: <span class="built_in">list</span>[<span class="built_in">str</span>], rules: <span class="built_in">list</span>[<span class="built_in">dict</span>]</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    rules: [&#123;&quot;contains&quot;: &quot;架构&quot;, &quot;to&quot;: &quot;docs/architecture&quot;&#125;,</span></span><br><span class="line"><span class="string">            &#123;&quot;contains&quot;: &quot;API&quot;, &quot;to&quot;: &quot;docs/api&quot;&#125;,</span></span><br><span class="line"><span class="string">            &#123;&quot;default&quot;: True, &quot;to&quot;: &quot;docs/misc&quot;&#125;]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        text = ft.read(f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>))</span><br><span class="line">        moved = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> rules:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;contains&quot;</span> <span class="keyword">in</span> r <span class="keyword">and</span> r[<span class="string">&quot;contains&quot;</span>] <span class="keyword">in</span> text:</span><br><span class="line">                rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">                dst = Path(r[<span class="string">&quot;to&quot;</span>]) / Path(rel).name</span><br><span class="line">                ft.move(rel, <span class="built_in">str</span>(dst))</span><br><span class="line">                moved = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> moved:</span><br><span class="line">            <span class="keyword">for</span> r <span class="keyword">in</span> rules:</span><br><span class="line">                <span class="keyword">if</span> r.get(<span class="string">&quot;default&quot;</span>):</span><br><span class="line">                    rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">                    dst = Path(r[<span class="string">&quot;to&quot;</span>]) / Path(rel).name</span><br><span class="line">                    ft.move(rel, <span class="built_in">str</span>(dst))</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_tag_to_header</span>(<span class="params">ft: FileTools, pattern: <span class="built_in">str</span>, tag: <span class="built_in">str</span></span>):</span><br><span class="line">    files = ft.<span class="built_in">list</span>(pattern, recursive=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> files:</span><br><span class="line">        rel = f.replace(<span class="built_in">str</span>(ft.root), <span class="string">&quot;&quot;</span>).lstrip(<span class="string">&quot;\\/&quot;</span>)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">            lines = text.splitlines()</span><br><span class="line">            <span class="keyword">if</span> lines <span class="keyword">and</span> lines[<span class="number">0</span>].startswith(<span class="string">&quot;# &quot;</span>):</span><br><span class="line">                lines[<span class="number">0</span>] = lines[<span class="number">0</span>] + <span class="string">f&quot; [<span class="subst">&#123;tag&#125;</span>]&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                lines.insert(<span class="number">0</span>, <span class="string">f&quot;# [<span class="subst">&#123;tag&#125;</span>]&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&quot;\n&quot;</span>.join(lines)</span><br><span class="line">        ft.update(rel, transform)</span><br></pre></td></tr></table></figure>

<h3 id="4-审计日志与-Dry-run-确认"><a href="#4-审计日志与-Dry-run-确认" class="headerlink" title="4. 审计日志与 Dry-run 确认"></a>4. 审计日志与 Dry-run 确认</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># audit.py</span></span><br><span class="line"><span class="keyword">import</span> json, time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Auditor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, log_path: <span class="built_in">str</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.path = Path(log_path)</span><br><span class="line">        <span class="variable language_">self</span>.path.parent.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">self, entry: <span class="built_in">dict</span></span>):</span><br><span class="line">        entry[<span class="string">&quot;ts&quot;</span>] = time.strftime(<span class="string">&quot;%Y-%m-%d %H:%M:%S&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.path, <span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(entry, ensure_ascii=<span class="literal">False</span>) + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">confirm</span>(<span class="params">plan: <span class="built_in">list</span>[<span class="built_in">dict</span>]</span>) -&gt; <span class="built_in">bool</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;即将执行以下操作：&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, step <span class="keyword">in</span> <span class="built_in">enumerate</span>(plan, <span class="number">1</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>. <span class="subst">&#123;step[<span class="string">&#x27;operation&#x27;</span>]&#125;</span> -&gt; <span class="subst">&#123;step&#125;</span>&quot;</span>)</span><br><span class="line">    ans = <span class="built_in">input</span>(<span class="string">&quot;确认执行? (yes/no): &quot;</span>).strip().lower()</span><br><span class="line">    <span class="keyword">return</span> ans <span class="keyword">in</span> (<span class="string">&quot;y&quot;</span>, <span class="string">&quot;yes&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-规划器与执行器"><a href="#5-规划器与执行器" class="headerlink" title="5. 规划器与执行器"></a>5. 规划器与执行器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># agent.py</span></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> guard <span class="keyword">import</span> Guard</span><br><span class="line"><span class="keyword">from</span> file_tools <span class="keyword">import</span> FileTools</span><br><span class="line"><span class="keyword">from</span> audit <span class="keyword">import</span> Auditor, confirm</span><br><span class="line"><span class="keyword">from</span> classify <span class="keyword">import</span> classify_by_rules, add_tag_to_header</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Agent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cfg_path=<span class="string">&quot;config.yaml&quot;</span></span>):</span><br><span class="line">        cfg = yaml.safe_load(<span class="built_in">open</span>(cfg_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">        <span class="variable language_">self</span>.root = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;root&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.guard = Guard(Path(<span class="variable language_">self</span>.root), cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;deny_patterns&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.ft = FileTools(<span class="variable language_">self</span>.root, <span class="variable language_">self</span>.guard, encoding=cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;encoding&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.aud = Auditor(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;log_path&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.allow_ops = <span class="built_in">set</span>(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;allow_ops&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.dry_run_default = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;dry_run_default&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.require_confirm_for = <span class="built_in">set</span>(cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;require_confirm_for&quot;</span>])</span><br><span class="line">        <span class="variable language_">self</span>.backup_before_delete = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;backup_before_delete&quot;</span>]</span><br><span class="line">        <span class="variable language_">self</span>.max_batch = cfg[<span class="string">&quot;agent&quot;</span>][<span class="string">&quot;max_batch&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">plan_from_prompt</span>(<span class="params">self, prompt: <span class="built_in">str</span></span>) -&gt; <span class="built_in">list</span>[<span class="built_in">dict</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        简化版解析器：根据关键词生成操作计划</span></span><br><span class="line"><span class="string">        可替换为更强的结构化意图解析器</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        plan = []</span><br><span class="line">        p = prompt.lower()</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;归类&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">or</span> <span class="string">&quot;分类&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;list&quot;</span>,<span class="string">&quot;pattern&quot;</span>:<span class="string">&quot;**/*.md&quot;</span>,<span class="string">&quot;recursive&quot;</span>:<span class="literal">True</span>&#125;)</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;classify&quot;</span>,<span class="string">&quot;rules&quot;</span>:[</span><br><span class="line">                &#123;<span class="string">&quot;contains&quot;</span>:<span class="string">&quot;架构&quot;</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/architecture&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;contains&quot;</span>:<span class="string">&quot;API&quot;</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/api&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;default&quot;</span>:<span class="literal">True</span>,<span class="string">&quot;to&quot;</span>:<span class="string">&quot;docs/misc&quot;</span>&#125;,</span><br><span class="line">            ]&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;标签&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;tag&quot;</span>,<span class="string">&quot;pattern&quot;</span>:<span class="string">&quot;docs/architecture/**/*.md&quot;</span>,<span class="string">&quot;tag&quot;</span>:<span class="string">&quot;architecture&quot;</span>&#125;)</span><br><span class="line">        <span class="comment"># 示例：创建/删除</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;创建&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">and</span> <span class="string">&quot;.md&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;create&quot;</span>,<span class="string">&quot;path&quot;</span>:<span class="string">&quot;notes/new.md&quot;</span>,<span class="string">&quot;content&quot;</span>:<span class="string">&quot;# 新笔记\n&quot;</span>, <span class="string">&quot;overwrite&quot;</span>:<span class="literal">False</span>&#125;)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;删除&quot;</span> <span class="keyword">in</span> prompt <span class="keyword">and</span> <span class="string">&quot;临时&quot;</span> <span class="keyword">in</span> prompt:</span><br><span class="line">            plan.append(&#123;<span class="string">&quot;operation&quot;</span>:<span class="string">&quot;delete&quot;</span>,<span class="string">&quot;path&quot;</span>:<span class="string">&quot;tmp&quot;</span>, <span class="string">&quot;recursive&quot;</span>:<span class="literal">True</span>&#125;)</span><br><span class="line">        <span class="keyword">return</span> plan</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">execute</span>(<span class="params">self, plan: <span class="built_in">list</span>[<span class="built_in">dict</span>], dry_run: <span class="built_in">bool</span> | <span class="literal">None</span> = <span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">if</span> dry_run <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            dry_run = <span class="variable language_">self</span>.dry_run_default</span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> plan:</span><br><span class="line">            op = step[<span class="string">&quot;operation&quot;</span>]</span><br><span class="line">            <span class="keyword">if</span> op <span class="keyword">not</span> <span class="keyword">in</span> <span class="variable language_">self</span>.allow_ops:</span><br><span class="line">                <span class="keyword">raise</span> PermissionError(<span class="string">f&quot;Operation not allowed: <span class="subst">&#123;op&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> dry_run <span class="keyword">or</span> <span class="built_in">any</span>(step[<span class="string">&quot;operation&quot;</span>] <span class="keyword">in</span> <span class="variable language_">self</span>.require_confirm_for <span class="keyword">for</span> step <span class="keyword">in</span> plan):</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> confirm(plan):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;取消执行。&quot;</span>)</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> step <span class="keyword">in</span> plan[:<span class="variable language_">self</span>.max_batch]:</span><br><span class="line">            op = step[<span class="string">&quot;operation&quot;</span>]</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">if</span> op == <span class="string">&quot;list&quot;</span>:</span><br><span class="line">                    files = <span class="variable language_">self</span>.ft.<span class="built_in">list</span>(step[<span class="string">&quot;pattern&quot;</span>], step.get(<span class="string">&quot;recursive&quot;</span>, <span class="literal">True</span>))</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;pattern&quot;</span>:step[<span class="string">&quot;pattern&quot;</span>],<span class="string">&quot;count&quot;</span>:<span class="built_in">len</span>(files)&#125;)</span><br><span class="line">                    step[<span class="string">&quot;_files&quot;</span>] = files</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;create&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.create(step[<span class="string">&quot;path&quot;</span>], step.get(<span class="string">&quot;content&quot;</span>,<span class="string">&quot;&quot;</span>), step.get(<span class="string">&quot;overwrite&quot;</span>, <span class="literal">False</span>))</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;read&quot;</span>:</span><br><span class="line">                    text = <span class="variable language_">self</span>.ft.read(step[<span class="string">&quot;path&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;bytes&quot;</span>:<span class="built_in">len</span>(text)&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;update&quot;</span>:</span><br><span class="line">                    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">t</span>): <span class="keyword">return</span> step[<span class="string">&quot;transform&quot;</span>](t)</span><br><span class="line">                    <span class="variable language_">self</span>.ft.update(step[<span class="string">&quot;path&quot;</span>], transform)</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;move&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.move(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;dst&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;dst&quot;</span>:step[<span class="string">&quot;dst&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;copy&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.copy(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;dst&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;dst&quot;</span>:step[<span class="string">&quot;dst&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;delete&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.delete(step[<span class="string">&quot;path&quot;</span>], backup=<span class="variable language_">self</span>.backup_before_delete)</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;path&quot;</span>:step[<span class="string">&quot;path&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;rename&quot;</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.ft.rename(step[<span class="string">&quot;src&quot;</span>], step[<span class="string">&quot;new_name&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;src&quot;</span>:step[<span class="string">&quot;src&quot;</span>],<span class="string">&quot;new_name&quot;</span>:step[<span class="string">&quot;new_name&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;classify&quot;</span>:</span><br><span class="line">                    files = []</span><br><span class="line">                    <span class="keyword">for</span> prev <span class="keyword">in</span> plan:</span><br><span class="line">                        <span class="keyword">if</span> prev.get(<span class="string">&quot;_files&quot;</span>):</span><br><span class="line">                            files.extend(prev[<span class="string">&quot;_files&quot;</span>])</span><br><span class="line">                    classify_by_rules(<span class="variable language_">self</span>.ft, files, step[<span class="string">&quot;rules&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;count&quot;</span>:<span class="built_in">len</span>(files),<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">elif</span> op == <span class="string">&quot;tag&quot;</span>:</span><br><span class="line">                    add_tag_to_header(<span class="variable language_">self</span>.ft, step[<span class="string">&quot;pattern&quot;</span>], step[<span class="string">&quot;tag&quot;</span>])</span><br><span class="line">                    <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;pattern&quot;</span>:step[<span class="string">&quot;pattern&quot;</span>],<span class="string">&quot;tag&quot;</span>:step[<span class="string">&quot;tag&quot;</span>],<span class="string">&quot;status&quot;</span>:<span class="string">&quot;ok&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">raise</span> NotImplementedError(<span class="string">f&quot;Unknown op: <span class="subst">&#123;op&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="variable language_">self</span>.aud.log(&#123;<span class="string">&quot;op&quot;</span>:op,<span class="string">&quot;error&quot;</span>:<span class="built_in">str</span>(e)&#125;)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;[错误] <span class="subst">&#123;op&#125;</span>: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="6-命令行入口"><a href="#6-命令行入口" class="headerlink" title="6. 命令行入口"></a>6. 命令行入口</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cli.py</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> agent <span class="keyword">import</span> Agent</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--cfg&quot;</span>, default=<span class="string">&quot;config.yaml&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--prompt&quot;</span>, required=<span class="literal">True</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--dry-run&quot;</span>, action=<span class="string">&quot;store_true&quot;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    ag = Agent(args.cfg)</span><br><span class="line">    plan = ag.plan_from_prompt(args.prompt)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> plan:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未生成操作计划，请调整提示或使用更具体的命令。&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ag.execute(plan, dry_run=args.dry_run)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="跨平台注意事项"><a href="#跨平台注意事项" class="headerlink" title="跨平台注意事项"></a>跨平台注意事项</h2><ul>
<li><strong>路径统一:</strong> 使用 pathlib，不直接拼接字符串；Windows 下注意盘符与反斜杠。</li>
<li><strong>权限问题:</strong> Linux/Unix 可能需要额外权限；建议在非 root 用户与沙箱目录内运行。</li>
<li><strong>编码:</strong> 文本文件统一使用 UTF-8，Windows 下确保控制台编码兼容。</li>
<li><strong>通配符:</strong> 使用 glob/rglob；复杂选择可在 list 后用正则二次过滤。</li>
</ul>
<hr>
<h2 id="可选增强"><a href="#可选增强" class="headerlink" title="可选增强"></a>可选增强</h2><ul>
<li><strong>更强的意图解析:</strong> 用结构化输出模板（JSON Schema）约束模型把 prompt 转成操作序列。</li>
<li><strong>RAG 文件检索:</strong> 向量检索你的文件摘要，实现“自然语言选文件”再执行。</li>
<li><strong>事务与回滚:</strong> 对 move/copy/rename 建立操作栈，失败可回滚。</li>
<li><strong>批量规则:</strong> 扩展 classify 支持正则、扩展名、关键词权重、YAML 规则集。</li>
<li><strong>前端面板:</strong> Web UI 显示 Dry-run 计划与审计日志，支持勾选执行。</li>
</ul>
<hr>
<h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><ul>
<li><p>创建笔记</p>
<ul>
<li><strong>Prompt:</strong> 在 notes 目录创建一篇名为 new.md 的笔记，标题“项目架构综述”</li>
<li><strong>命令:</strong> python cli.py –prompt “创建 notes/new.md，内容为 # 项目架构综述”</li>
</ul>
</li>
<li><p>归类并加标签</p>
<ul>
<li><strong>Prompt:</strong> 将 docs 下所有 md 归类，架构主题加标签</li>
<li><strong>命令:</strong> python cli.py –prompt “归类 docs 下的 md，并为架构主题加标签” –dry-run</li>
</ul>
</li>
<li><p>安全删除临时目录</p>
<ul>
<li><strong>Prompt:</strong> 删除 tmp 目录（保留备份）</li>
<li><strong>命令:</strong> python cli.py –prompt “删除临时目录 tmp”</li>
</ul>
</li>
</ul>
<hr>
<p>如果你愿意，我们可以把“计划生成器”替换为你熟悉的 LLM 并加入 JSON Schema 校验，保证任何自然语言都转成安全、可执行的操作序列；也可以为你家的文件结构定制“分类规则库”，让它真正成为你的个人文件管家。</p>
<h2 id="Agent-可以使用哪种语言来实现？"><a href="#Agent-可以使用哪种语言来实现？" class="headerlink" title="Agent 可以使用哪种语言来实现？"></a>Agent 可以使用哪种语言来实现？</h2><p><strong>直接回答</strong>：Agent 并不依赖某一种特定语言来实现，常见的实现语言有 <strong>Python、JavaScript/TypeScript、Java、Go、Rust</strong> 等，其中 <strong>Python</strong> 是目前最主流的选择，因为它生态成熟、AI 框架丰富、社区活跃。</p>
<hr>
<h2 id="🔑-常见实现语言与特点"><a href="#🔑-常见实现语言与特点" class="headerlink" title="🔑 常见实现语言与特点"></a>🔑 常见实现语言与特点</h2><ul>
<li><p><strong>Python</strong></p>
<ul>
<li><strong>优势</strong>：生态最全（LangChain、LlamaIndex、AutoGen 等框架），与大模型 API、向量数据库、工具库无缝衔接。</li>
<li><strong>适用场景</strong>：快速原型、科研实验、跨平台 Agent 应用。</li>
</ul>
</li>
<li><p><strong>JavaScript / TypeScript</strong></p>
<ul>
<li><strong>优势</strong>：前端/全栈开发者友好，能直接在浏览器或 Node.js 环境运行。</li>
<li><strong>框架</strong>：LangChain.js、AutoGen.js。</li>
<li><strong>适用场景</strong>：Web Agent、插件化应用、跨端交互。</li>
</ul>
</li>
<li><p><strong>Java</strong></p>
<ul>
<li><strong>优势</strong>：企业级生态，稳定性和性能好，适合与现有企业系统集成。</li>
<li><strong>适用场景</strong>：金融、电信、ERP 系统中的智能体。</li>
</ul>
</li>
<li><p><strong>Go</strong></p>
<ul>
<li><strong>优势</strong>：高并发、轻量，适合构建分布式 Agent 服务。</li>
<li><strong>适用场景</strong>：云原生 Agent、微服务架构。</li>
</ul>
</li>
<li><p><strong>Rust</strong></p>
<ul>
<li><strong>优势</strong>：安全性和性能极佳，适合对内存和并发要求高的场景。</li>
<li><strong>适用场景</strong>：系统级 Agent、边缘计算 Agent。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="📌-选择建议"><a href="#📌-选择建议" class="headerlink" title="📌 选择建议"></a>📌 选择建议</h2><ul>
<li><strong>快速实验 / 学习</strong> → Python（生态最全，文档和教程丰富）。</li>
<li><strong>Web 应用 / 前端集成</strong> → JavaScript/TypeScript。</li>
<li><strong>企业级系统集成</strong> → Java。</li>
<li><strong>高并发服务 / 云原生</strong> → Go。</li>
<li><strong>系统底层 / 高性能</strong> → Rust。</li>
</ul>
<hr>
<p>✅ <strong>总结</strong>：你可以用任何主流语言实现 Agent，但 <strong>Python 是事实上的标准语言</strong>，因为它拥有最成熟的 AI 框架和社区支持。如果你要做跨平台文件操作 Agent，推荐用 <strong>Python（跨平台库丰富）</strong> 或 <strong>Go（性能与并发更好）</strong>。</p>
<p>要不要我帮你整理一份 <strong>“不同语言实现 Agent 的对比表”</strong>，把生态、性能、学习成本、适用场景一目了然？</p>
<p>好的 Mark，我来帮你把 <strong>Agent 常用编程语言对比表</strong>整理成一个清晰的表格，方便你快速选择实现语言。</p>
<hr>
<h2 id="📑-Agent-常用编程语言对比表"><a href="#📑-Agent-常用编程语言对比表" class="headerlink" title="📑 Agent 常用编程语言对比表"></a>📑 Agent 常用编程语言对比表</h2><table>
<thead>
<tr>
<th>编程语言</th>
<th>生态支持</th>
<th>性能</th>
<th>学习成本</th>
<th>适用场景</th>
<th>代表框架/工具</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Python</strong></td>
<td>最丰富（LangChain、LlamaIndex、AutoGen 等），AI 库齐全</td>
<td>良好</td>
<td>低</td>
<td>快速原型、科研实验、跨平台 Agent</td>
<td>LangChain, LlamaIndex, AutoGen</td>
</tr>
<tr>
<td><strong>JavaScript / TypeScript</strong></td>
<td>中等（LangChain.js、AutoGen.js），Web 生态强</td>
<td>一般</td>
<td>低</td>
<td>Web Agent、浏览器插件、跨端交互</td>
<td>LangChain.js, AutoGen.js</td>
</tr>
<tr>
<td><strong>Java</strong></td>
<td>企业级生态，稳定性强</td>
<td>一般</td>
<td>中等</td>
<td>金融、电信、ERP 系统集成</td>
<td>Deeplearning4j, Spring AI</td>
</tr>
<tr>
<td><strong>Go (Golang)</strong></td>
<td>云原生生态，轻量高并发</td>
<td>良好</td>
<td>中等</td>
<td>分布式 Agent、微服务架构</td>
<td>GoLangChain, Go-LLM SDK</td>
</tr>
<tr>
<td><strong>Rust</strong></td>
<td>系统级生态，安全高性能</td>
<td>极优</td>
<td>高</td>
<td>边缘计算、高性能 Agent</td>
<td>Burn, Rust-LLM</td>
</tr>
<tr>
<td><strong>C# / .NET</strong></td>
<td>微软生态，企业集成好</td>
<td>良好</td>
<td>中等</td>
<td>Windows 系统 Agent、企业应用</td>
<td>Semantic Kernel, ML.NET</td>
</tr>
</tbody></table>
<hr>
<h2 id="🎯-总结-3"><a href="#🎯-总结-3" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><ul>
<li><strong>快速实验 / 学习</strong> → Python（生态最全，教程丰富）。</li>
<li><strong>Web 应用 / 前端集成</strong> → JavaScript/TypeScript。</li>
<li><strong>企业级系统</strong> → Java / C#。</li>
<li><strong>高并发服务 / 云原生</strong> → Go。</li>
<li><strong>高性能 / 系统级</strong> → Rust。</li>
</ul>
<hr>
<p>要不要我帮你再整理一份 <strong>“学习路径图”</strong>，比如如果你选 Python，从入门到能做一个文件操作 Agent，需要依次掌握哪些库和技能？这样你就能有一条清晰的学习路线。</p>
<p>明白啦 Mark！我来帮你整理一份 <strong>文字版学习路线图</strong>，专门针对你想构建 <strong>Agent（智能体）</strong> 的目标。它分阶段，从基础到进阶，逐步覆盖必备知识、工具和实践方向。</p>
<hr>
<h1 id="🛠️-构建智能体学习路线图（文字版）"><a href="#🛠️-构建智能体学习路线图（文字版）" class="headerlink" title="🛠️ 构建智能体学习路线图（文字版）"></a>🛠️ 构建智能体学习路线图（文字版）</h1><h2 id="阶段一：基础打牢"><a href="#阶段一：基础打牢" class="headerlink" title="阶段一：基础打牢"></a>阶段一：基础打牢</h2><ul>
<li><strong>编程语言</strong><ul>
<li>Python（推荐）：掌握 <code>os</code>、<code>pathlib</code>、<code>shutil</code>、<code>subprocess</code> 等文件/系统操作库</li>
<li>熟悉跨平台差异（Windows/Linux/Unix）</li>
</ul>
</li>
<li><strong>操作系统基础</strong><ul>
<li>文件系统结构、权限管理（chmod、ACL、NTFS 权限）</li>
<li>常见命令：ls/cp/mv/rm（Linux）、dir/copy/move/del（Windows）</li>
</ul>
</li>
<li><strong>版本控制</strong><ul>
<li>Git：管理代码与配置，保证可回滚</li>
</ul>
</li>
</ul>
<hr>
<h2 id="阶段二：AI-与大模型基础"><a href="#阶段二：AI-与大模型基础" class="headerlink" title="阶段二：AI 与大模型基础"></a>阶段二：AI 与大模型基础</h2><ul>
<li><strong>大模型必修知识</strong><ul>
<li>Transformer 架构（Attention is All You Need）</li>
<li>GPT 系列（自回归生成）</li>
<li>BERT 系列（理解任务）</li>
</ul>
</li>
<li><strong>对齐与微调</strong><ul>
<li>指令微调（SFT）</li>
<li>RLHF（人类反馈强化学习）</li>
</ul>
</li>
<li><strong>RAG（检索增强生成）</strong><ul>
<li>向量数据库（FAISS、Milvus、Weaviate）</li>
<li>文档分块与嵌入检索</li>
</ul>
</li>
</ul>
<hr>
<h2 id="阶段三：Agent-基础框架"><a href="#阶段三：Agent-基础框架" class="headerlink" title="阶段三：Agent 基础框架"></a>阶段三：Agent 基础框架</h2><ul>
<li><strong>核心能力</strong><ul>
<li>任务分解（Chain of Thought 推理）</li>
<li>工具调用（调用文件操作 API）</li>
<li>记忆（短期上下文 + 长期存储）</li>
</ul>
</li>
<li><strong>常用框架</strong><ul>
<li>LangChain（Python/JS）</li>
<li>LlamaIndex（文档检索增强）</li>
<li>AutoGen / LangGraph（多 Agent 协作）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="阶段四：文件操作-Agent-实现"><a href="#阶段四：文件操作-Agent-实现" class="headerlink" title="阶段四：文件操作 Agent 实现"></a>阶段四：文件操作 Agent 实现</h2><ul>
<li><strong>功能模块</strong><ul>
<li>文件/文件夹操作：创建、删除、修改、读取</li>
<li>文件归类：按扩展名/内容/时间分类</li>
<li>批量重命名、标签化</li>
<li>日志与审计：记录每次操作</li>
</ul>
</li>
<li><strong>安全机制</strong><ul>
<li>沙箱根目录（避免误删系统文件）</li>
<li>白名单操作类型</li>
<li>Dry-run 模式（先展示计划，再执行）</li>
<li>自动备份与回滚</li>
</ul>
</li>
</ul>
<hr>
<h2 id="阶段五：跨平台与扩展"><a href="#阶段五：跨平台与扩展" class="headerlink" title="阶段五：跨平台与扩展"></a>阶段五：跨平台与扩展</h2><ul>
<li><strong>跨平台适配</strong><ul>
<li>Windows：PowerShell、Win32 API</li>
<li>Linux/Unix：Bash、POSIX API</li>
</ul>
</li>
<li><strong>扩展功能</strong><ul>
<li>多模态输入（语音指令 → 文件操作）</li>
<li>Web UI 或 CLI 界面</li>
<li>多 Agent 协作（一个负责分类，一个负责清理）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="阶段六：进阶与未来"><a href="#阶段六：进阶与未来" class="headerlink" title="阶段六：进阶与未来"></a>阶段六：进阶与未来</h2><ul>
<li><strong>推理增强</strong><ul>
<li>Self-Consistency（多路径投票）</li>
<li>工具增强推理（调用计算器、正则解析器）</li>
</ul>
</li>
<li><strong>生态集成</strong><ul>
<li>与日程/邮件/云存储联动</li>
<li>企业知识库接入</li>
</ul>
</li>
<li><strong>未来趋势</strong><ul>
<li>个性化 Agent（Personal LLM）</li>
<li>多模态 Agent（看图/听音频后操作文件）</li>
<li>自主规划与长期记忆</li>
</ul>
</li>
</ul>
<hr>
<h2 id="✅-总结-9"><a href="#✅-总结-9" class="headerlink" title="✅ 总结"></a>✅ 总结</h2><ul>
<li><strong>基础 → 大模型 → Agent 框架 → 文件操作实现 → 跨平台扩展 → 推理与未来</strong></li>
<li>每一步都解决一个层次的问题，从“能写代码”到“能调用模型”，再到“能自主规划并安全执行”。</li>
</ul>
<hr>
<p>要不要我帮你把这份路线图再细化成 <strong>学习任务清单（Checklist）</strong>，比如“第 1 周掌握 pathlib， 第 2 周实现文件分类脚本，第 3 周接入 LangChain 工具调用”？这样你可以直接按周推进。</p>
<p>未完~</p>

  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>加载评论需要在浏览器启用 JavaScript 脚本支持。</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/blog/">首页</a></li>
         
          <li><a href="/blog/about/">关于</a></li>
         
          <li><a href="/blog/archives/">归档</a></li>
         
          <li><a href="/blog/categories/">分类</a></li>
         
          <li><a href="/blog/search/">搜索</a></li>
         
          <li><a target="_blank" rel="noopener" href="https://github.com/shenjy06">项目</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%94%A8%E9%AB%98%E4%B8%AD%E7%94%9F%E5%8F%AF%E4%BB%A5%E7%90%86%E8%A7%A3%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BB%8B%E7%BB%8D%E4%B8%8B%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">请用高中生可以理解的方式介绍下大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A0-%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">🧠 什么是大语言模型？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%9A-%E5%AE%83%E6%98%AF%E6%80%8E%E4%B9%88%E5%AD%A6%E4%BC%9A%E7%9A%84%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">📚 它是怎么学会的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%8D%94-%E6%89%93%E4%B8%AA%E6%AF%94%E6%96%B9"><span class="toc-number">1.3.</span> <span class="toc-text">🍔 打个比方</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%9A%80-%E5%AE%83%E8%83%BD%E5%81%9A%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">🚀 它能做什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%9A%A1-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AB%E2%80%9C%E5%A4%A7%E2%80%9D%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">⚡ 为什么叫“大”？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">大语言模型如何训练？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%A7%A9-%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%E5%88%86%E8%A7%A3"><span class="toc-number">2.1.</span> <span class="toc-text">🧩 训练流程分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E2%9A%99%EF%B8%8F-%E6%8A%80%E6%9C%AF%E8%A6%81%E7%82%B9"><span class="toc-number">2.2.</span> <span class="toc-text">⚙️ 技术要点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%F0%9F%93%96-%E6%89%93%E4%B8%AA%E7%94%9F%E6%B4%BB%E6%AF%94%E6%96%B9"><span class="toc-number">2.3.</span> <span class="toc-text">📖 打个生活比方</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BB%8E%E9%9B%B6%E5%81%9A%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%91%A2%EF%BC%9F%E6%88%91%E4%BB%AC%E5%A6%82%E4%BD%95%E5%AE%9A%E4%B9%89%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E5%91%A2%EF%BC%9F%E5%81%9A%E5%A5%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%90%8E%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87-api-%E7%9A%84%E6%96%B9%E5%BC%8F%E6%8F%90%E4%BE%9B%E7%BB%99%E5%A4%96%E9%83%A8%E7%A8%8B%E5%BA%8F%E4%BD%BF%E7%94%A8%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">如何从零做一个大模型呢？我们如何定义大模型的参数呢？做好大模型后如何通过 api 的方式提供给外部程序使用？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">从零构建大语言模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%AF%E7%BA%BF%E6%A6%82%E8%A7%88"><span class="toc-number">0.1.</span> <span class="toc-text">路线概览</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E5%87%86%E5%A4%87%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%AE%A1%E7%BA%BF"><span class="toc-number">0.2.</span> <span class="toc-text">基础准备与数据管线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E2%80%9C%E5%A4%A7%E6%A8%A1%E5%9E%8B%E2%80%9D%E7%9A%84%E5%85%B3%E9%94%AE%E5%8F%82%E6%95%B0"><span class="toc-number">0.3.</span> <span class="toc-text">定义“大模型”的关键参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%88%B0%E5%AF%B9%E9%BD%90%E7%9A%84%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B"><span class="toc-number">0.4.</span> <span class="toc-text">训练到对齐的完整流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%83%A8%E7%BD%B2%E4%B8%BA-API-%E7%9A%84%E5%AE%9E%E6%88%98%E8%B7%AF%E5%BE%84"><span class="toc-number">0.5.</span> <span class="toc-text">部署为 API 的实战路径</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96%E4%B8%8E%E6%89%93%E5%8C%85"><span class="toc-number">0.5.1.</span> <span class="toc-text">推理优化与打包</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BF%AB%E9%80%9F%E6%90%AD%E4%B8%80%E4%B8%AA%E5%8F%AF%E7%94%A8%E7%9A%84-API%EF%BC%88%E7%A4%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">0.5.2.</span> <span class="toc-text">快速搭一个可用的 API（示例）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%99%E4%BD%A0%E7%9A%84%E4%B8%80%E5%BC%A0%E2%80%9C%E5%8A%A8%E6%89%8B%E6%B8%85%E5%8D%95%E2%80%9D"><span class="toc-number">0.6.</span> <span class="toc-text">给你的一张“动手清单”</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E5%B8%AE%E6%88%91%E5%AE%8C%E6%88%90"><span class="toc-number">1.</span> <span class="toc-text">请帮我完成</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%B8%80%E5%BC%A0%E5%9B%BE%E7%9C%8B%E6%87%82%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%85%A8%E6%B5%81%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">🧩 一张图看懂大模型全流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">2.1.</span> <span class="toc-text">1️⃣ 数据准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E5%AE%9A%E4%B9%89"><span class="toc-number">2.2.</span> <span class="toc-text">2️⃣ 模型参数定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5"><span class="toc-number">2.3.</span> <span class="toc-text">3️⃣ 训练阶段</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%EF%B8%8F%E2%83%A3-%E9%83%A8%E7%BD%B2%E4%B8%8E%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96"><span class="toc-number">2.4.</span> <span class="toc-text">4️⃣ 部署与推理优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%EF%B8%8F%E2%83%A3-%E6%8F%90%E4%BE%9B-API-%E6%9C%8D%E5%8A%A1"><span class="toc-number">2.5.</span> <span class="toc-text">5️⃣ 提供 API 服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%EF%B8%8F%E2%83%A3-%E5%85%B3%E9%94%AE%E8%A6%81%E7%82%B9"><span class="toc-number">2.6.</span> <span class="toc-text">6️⃣ 关键要点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E7%8E%B0%E5%9C%A8%E6%9C%89%E4%B8%80%E5%8F%B0-16GB-%E5%86%85%E5%AD%98%EF%BC%8C8-%E6%A0%B8%E5%BF%83%E7%9A%84-cpu%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%88%91%E6%83%B3%E5%9F%BA%E4%BA%8E%E8%BF%99%E6%A0%B7%E7%9A%84%E7%A1%AC%E4%BB%B6%E6%9D%A1%E4%BB%B6%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%9D%EF%BC%8C%E8%AF%B7%E5%B8%AE%E6%88%91%E6%8C%89%E4%B8%8A%E9%9D%A2%E7%9A%84%E6%AD%A5%E9%AA%A4%EF%BC%8C%E5%9F%BA%E4%BA%8E%E6%88%91%E6%89%8B%E4%B8%8A%E7%9A%84%E7%A1%AC%E4%BB%B6%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">我现在有一台 16GB 内存，8 核心的 cpu，如果我想基于这样的硬件条件从头开始制作一个大模型的话，请帮我按上面的步骤，基于我手上的硬件完成一个大模型</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8-16GB-%E5%86%85%E5%AD%98%E3%80%818-%E6%A0%B8-CPU-%E4%B8%8A%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%B9%B6%E6%8F%90%E4%BE%9B%E5%A4%A7%E6%A8%A1%E5%9E%8B-API"><span class="toc-number"></span> <span class="toc-text">在 16GB 内存、8 核 CPU 上从零构建并提供大模型 API</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E4%B8%8E%E7%AD%96%E7%95%A5"><span class="toc-number">1.</span> <span class="toc-text">目标与策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E8%A1%8C%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%A7%84%E6%A0%BC%E4%B8%8E%E8%AE%AD%E7%BB%83%E8%B6%85%E5%8F%82"><span class="toc-number">2.</span> <span class="toc-text">可行的模型规格与训练超参</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%B0%8F%E5%8F%AF%E8%A1%8C%E6%A8%A1%E5%9E%8B%E8%A7%84%E6%A0%BC%EF%BC%88%E9%80%82%E9%85%8D-16GB-%E5%86%85%E5%AD%98%EF%BC%8CCPU-%E8%AE%AD%E7%BB%83%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">最小可行模型规格（适配 16GB 内存，CPU 训练）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%B6%85%E5%8F%82%EF%BC%88CPU-%E5%8F%8B%E5%A5%BD%EF%BC%89"><span class="toc-number">2.2.</span> <span class="toc-text">训练超参（CPU 友好）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E9%9B%B6%E5%88%B0-API-%E7%9A%84-6-%E6%AD%A5"><span class="toc-number">3.</span> <span class="toc-text">从零到 API 的 6 步</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%95%B0%E6%8D%AE%E4%B8%8E%E5%88%86%E8%AF%8D"><span class="toc-number">3.1.</span> <span class="toc-text">1. 数据与分词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA"><span class="toc-number">3.2.</span> <span class="toc-text">2. 模型搭建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88%E8%AF%AD%E8%A8%80%E8%83%BD%E5%8A%9B%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">3. 预训练（语言能力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90"><span class="toc-number">3.4.</span> <span class="toc-text">4. 指令微调与对齐</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%8E%A8%E7%90%86%E4%B8%8E%E9%83%A8%E7%BD%B2"><span class="toc-number">3.5.</span> <span class="toc-text">5. 推理与部署</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E6%8F%90%E4%BE%9B-API-%E6%9C%8D%E5%8A%A1%EF%BC%88FastAPI-%E7%A4%BA%E4%BE%8B%EF%BC%89"><span class="toc-number">3.6.</span> <span class="toc-text">6. 提供 API 服务（FastAPI 示例）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E6%89%93%E5%8D%B0%E7%9A%84%E2%80%9C%E5%8A%A8%E6%89%8B%E6%B8%85%E5%8D%95%E2%80%9D"><span class="toc-number">4.</span> <span class="toc-text">可打印的“动手清单”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%89%A9%E5%B1%95%E5%BB%BA%E8%AE%AE"><span class="toc-number">5.</span> <span class="toc-text">进阶与扩展建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%B8%8A%E9%9D%A2%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E8%AF%B7%E7%BB%99%E6%88%91%E4%BB%A3%E7%A0%81%E5%B1%82%E9%9D%A2%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">6.</span> <span class="toc-text">基于上面的回答，请给我代码层面的实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E4%BE%9D%E8%B5%96"><span class="toc-number">7.</span> <span class="toc-text">项目结构与依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%9E%84%E5%BB%BA%E5%88%86%E8%AF%8D%E5%99%A8%EF%BC%88BPE%EF%BC%8C%E8%AF%8D%E8%A1%A8-16k%EF%BC%89"><span class="toc-number">8.</span> <span class="toc-text">1. 构建分词器（BPE，词表 16k）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89%EF%BC%88Decoder-only-Transformer%EF%BC%8C%E7%BA%A6-40M-%E5%8F%82%E6%95%B0%EF%BC%89"><span class="toc-number">9.</span> <span class="toc-text">2. 模型定义（Decoder-only Transformer，约 40M 参数）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83%EF%BC%88%E8%87%AA%E7%9B%91%E7%9D%A3%EF%BC%8C%E4%B8%8B%E4%B8%80%E4%B8%AA-token-%E9%A2%84%E6%B5%8B%EF%BC%89"><span class="toc-number">10.</span> <span class="toc-text">3. 预训练（自监督，下一个 token 预测）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%EF%BC%88SFT%EF%BC%89"><span class="toc-number">11.</span> <span class="toc-text">4. 指令微调（SFT）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%A6%BB%E7%BA%BF%E6%8E%A8%E7%90%86%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">12.</span> <span class="toc-text">5. 离线推理与测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-FastAPI-%E5%AF%B9%E5%A4%96%E6%8F%90%E4%BE%9B%E6%9C%8D%E5%8A%A1"><span class="toc-number">13.</span> <span class="toc-text">6. FastAPI 对外提供服务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87%E4%B8%8E%E6%B8%85%E6%B4%97%E7%A4%BA%E4%BE%8B"><span class="toc-number">14.</span> <span class="toc-text">7. 数据准备与清洗示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E8%AE%AD%E7%BB%83%E5%BB%BA%E8%AE%AE%E4%B8%8E%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6"><span class="toc-number">15.</span> <span class="toc-text">8. 训练建议与资源控制</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E4%B8%8B%E4%B8%80%E6%AD%A5%E5%8F%AF%E9%80%89%E5%A2%9E%E5%BC%BA"><span class="toc-number">16.</span> <span class="toc-text">9. 下一步可选增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%EF%BC%8C%E6%9C%89%E5%BC%80%E6%BA%90%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%90%97%EF%BC%9F"><span class="toc-number">17.</span> <span class="toc-text">对于训练数据，有开源的数据集吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E7%9A%84%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E5%9E%8B"><span class="toc-number">18.</span> <span class="toc-text">🔑 常见的开源数据集类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E6%96%99%EF%BC%88%E5%9F%BA%E7%A1%80%E8%AF%AD%E8%A8%80%E8%83%BD%E5%8A%9B%EF%BC%89"><span class="toc-number">18.1.</span> <span class="toc-text">1. 预训练语料（基础语言能力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E6%95%B0%E6%8D%AE%EF%BC%88%E8%AE%A9%E6%A8%A1%E5%9E%8B%E2%80%9C%E5%90%AC%E6%87%82%E4%BA%BA%E8%AF%9D%E2%80%9D%EF%BC%89"><span class="toc-number">18.2.</span> <span class="toc-text">2. 指令微调数据（让模型“听懂人话”）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%81%8F%E5%A5%BD%E6%95%B0%E6%8D%AE%EF%BC%88%E5%AF%B9%E9%BD%90%E4%BA%BA%E7%B1%BB%E4%BB%B7%E5%80%BC%EF%BC%89"><span class="toc-number">18.3.</span> <span class="toc-text">3. 偏好数据（对齐人类价值）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%AF%84%E6%B5%8B%E6%95%B0%E6%8D%AE%EF%BC%88%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%E6%95%88%E6%9E%9C%EF%BC%89"><span class="toc-number">18.4.</span> <span class="toc-text">4. 评测数据（测试模型效果）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%9A-%E6%8E%A8%E8%8D%90%E8%B5%84%E6%BA%90%E6%95%B4%E7%90%86"><span class="toc-number">19.</span> <span class="toc-text">📚 推荐资源整理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E7%BB%99%E4%BD%A0%E7%9A%84%E5%B0%8F%E6%9C%BA%E5%AD%90%E5%BB%BA%E8%AE%AE"><span class="toc-number">20.</span> <span class="toc-text">🛠️ 给你的小机子建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E4%BA%8E%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%8C%89%E7%85%A7%E4%B8%8A%E9%9D%A2-1-2-3%E2%80%A6%E2%80%A6%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C-python-%E6%96%87%E4%BB%B6%E5%B0%B1%E8%A1%8C%E4%BA%86%E5%90%97%EF%BC%9F%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E4%BA%A7%E5%87%BA%E7%89%A9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B%EF%BC%9F%E5%A6%82%E4%BD%95%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83%EF%BC%9F"><span class="toc-number">21.</span> <span class="toc-text">对于构建自己的大模型，按照上面 1.2.3……的顺序执行 python 文件就行了吗？模型训练完成后的产出物是什么？如何使用模型？如何对模型进行微调？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F"><span class="toc-number">22.</span> <span class="toc-text">🛠️ 执行顺序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%A6-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%AE%8C%E6%88%90%E5%90%8E%E7%9A%84%E4%BA%A7%E5%87%BA%E7%89%A9"><span class="toc-number">23.</span> <span class="toc-text">📦 模型训练完成后的产出物</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%A8%A1%E5%9E%8B"><span class="toc-number">24.</span> <span class="toc-text">🚀 如何使用模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%A7-%E5%A6%82%E4%BD%95%E5%AF%B9%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83"><span class="toc-number">25.</span> <span class="toc-text">🔧 如何对模型进行微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BB%A7%E7%BB%AD%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%EF%BC%88SFT%EF%BC%89"><span class="toc-number">25.1.</span> <span class="toc-text">1. 继续指令微调（SFT）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%BD%BB%E9%87%8F%E5%BE%AE%E8%B0%83%EF%BC%88LoRA-Adapter%EF%BC%89"><span class="toc-number">25.2.</span> <span class="toc-text">2. 轻量微调（LoRA &#x2F; Adapter）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93"><span class="toc-number">26.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%88%AC%E6%9D%A5%E8%AE%B2%E6%8F%90%E7%A4%BA%E8%AF%8D%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%A8%A1%E5%9E%8B%E6%81%AF%E6%81%AF%E7%9B%B8%E5%85%B3%EF%BC%8C%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%8F%90%E7%A4%BA%E8%AF%8D%E6%88%96%E8%80%85%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%9E%8B%E6%89%8D%E8%83%BD%E8%AE%A9%E4%B8%A4%E8%80%85%E9%85%8D%E5%90%88%E8%BE%BE%E5%88%B0%E6%9C%80%E4%BC%98%EF%BC%9F%E6%9C%89%E4%BB%80%E4%B9%88%E6%A0%87%E5%87%86%E5%90%97%EF%BC%9F"><span class="toc-number">27.</span> <span class="toc-text">一般来讲提示词的设计和模型息息相关，如何设计提示词或者如何设计模型才能让两者配合达到最优？有什么标准吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%8F%90%E7%A4%BA%E8%AF%8D%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%85%8D%E5%90%88%E9%80%BB%E8%BE%91"><span class="toc-number">28.</span> <span class="toc-text">🎯 提示词与模型的配合逻辑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%85%B3%E9%94%AE%E8%A6%81%E7%B4%A0"><span class="toc-number">29.</span> <span class="toc-text">🧩 提示词设计的关键要素</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8F%97%EF%B8%8F-%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1%E4%B8%8E%E8%AE%AD%E7%BB%83%E7%9A%84%E9%85%8D%E5%90%88%E7%82%B9"><span class="toc-number">30.</span> <span class="toc-text">🏗️ 模型设计与训练的配合点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%90-%E6%9C%89%E6%B2%A1%E6%9C%89%E2%80%9C%E6%A0%87%E5%87%86%E2%80%9D%EF%BC%9F"><span class="toc-number">31.</span> <span class="toc-text">📐 有没有“标准”？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-1"><span class="toc-number">32.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E6%98%AF%E5%95%A5%E6%84%8F%E6%80%9D%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B7%BB%E5%8A%A0%E8%BF%99%E4%B8%AA%E5%8F%82%E6%95%B0%EF%BC%9F%E8%A7%A3%E5%86%B3%E4%BA%86%E5%95%A5%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">33.</span> <span class="toc-text">大模型中的温度参数是啥意思？为什么要添加这个参数？解决了啥问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%A5-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">34.</span> <span class="toc-text">🔥 温度参数的定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%A8-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%B7%BB%E5%8A%A0%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%EF%BC%9F"><span class="toc-number">35.</span> <span class="toc-text">🎨 为什么要添加温度参数？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%96%EF%B8%8F-%E6%B8%A9%E5%BA%A6%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%95%88%E6%9E%9C"><span class="toc-number">36.</span> <span class="toc-text">⚖️ 温度带来的效果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8C%B0-%E4%B8%BE%E4%B8%AA%E4%BE%8B%E5%AD%90"><span class="toc-number">37.</span> <span class="toc-text">🌰 举个例子</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%8C%A1%EF%B8%8F-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E9%80%9F%E6%9F%A5%E8%A1%A8"><span class="toc-number"></span> <span class="toc-text">🌡️ 大语言模型温度参数速查表</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93"><span class="toc-number">1.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-hugging-face-%E6%88%96%E8%80%85-model-scope-%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8C%E6%9E%84%E5%BB%BA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">我如何使用 hugging face 或者 model scope 中的模型，构建属于自己的模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%BD%BF%E7%94%A8-Hugging-Face-%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">3.</span> <span class="toc-text">🧩 使用 Hugging Face 的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E4%BD%BF%E7%94%A8-ModelScope-%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-number">4.</span> <span class="toc-text">🧩 使用 ModelScope 的流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E2%80%9C%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B%E2%80%9D"><span class="toc-number">5.</span> <span class="toc-text">🚀 如何构建“属于自己的模型”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%89%80%E4%BD%BF%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E6%9C%89%E6%B2%A1%E6%9C%89%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E5%85%B7%E7%94%A8%E4%BA%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E9%98%B6%E6%AE%B5"><span class="toc-number">6.</span> <span class="toc-text">关于大模型微调所使用的数据集，有没有数据集相关的工具用于大模型微调阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%B7%A5%E5%85%B7"><span class="toc-number">7.</span> <span class="toc-text">🔑 常见的数据集工具</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-edg4llm"><span class="toc-number">7.1.</span> <span class="toc-text">1. edg4llm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Easy-Dataset"><span class="toc-number">7.2.</span> <span class="toc-text">2. Easy Dataset</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-LLaMA-Factory"><span class="toc-number">7.3.</span> <span class="toc-text">3. LLaMA-Factory</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-XTuner"><span class="toc-number">7.4.</span> <span class="toc-text">4. XTuner</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E6%80%BB%E7%BB%93"><span class="toc-number">8.</span> <span class="toc-text">📌 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E6%8A%8A-pdf%EF%BC%8Cdoc%EF%BC%8Cmarkdown-%E7%AD%89%E6%96%87%E4%BB%B6%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%9F%E5%B9%B6%E5%A6%82%E4%BD%95%E6%8A%8A%E8%BF%99%E4%BA%9B%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%AE%A9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%AF%E4%BB%A5%E5%9F%BA%E4%BA%8E%E8%BF%99%E4%BA%9B%E6%95%B0%E6%8D%AE%E5%9B%9E%E7%AD%94%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">如何把 pdf，doc，markdown 等文件向量化？并如何把这些向量化的数据给大模型，让大模型可以基于这些数据回答问题？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3"><span class="toc-number">10.</span> <span class="toc-text">🧩 步骤详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%96%87%E6%9C%AC%E6%8F%90%E5%8F%96"><span class="toc-number">10.1.</span> <span class="toc-text">1. 文本提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%90%91%E9%87%8F%E5%8C%96%EF%BC%88Embedding%EF%BC%89"><span class="toc-number">10.2.</span> <span class="toc-text">2. 向量化（Embedding）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AD%98%E5%82%A8%E5%90%91%E9%87%8F"><span class="toc-number">10.3.</span> <span class="toc-text">3. 存储向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E6%A3%80%E7%B4%A2-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%97%AE%E7%AD%94%EF%BC%88RAG%EF%BC%89"><span class="toc-number">10.4.</span> <span class="toc-text">4. 检索 + 大模型问答（RAG）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%EF%BC%88RAG%EF%BC%89"><span class="toc-number">10.5.</span> <span class="toc-text">5. 整体架构（RAG）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-2"><span class="toc-number">11.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rerank-%E6%A8%A1%E5%9E%8B%E5%B7%A5%E4%BD%9C%E5%9C%A8%E4%BB%80%E4%B9%88%E9%98%B6%E6%AE%B5%EF%BC%9F%E4%BB%80%E4%B9%88%E6%97%B6%E9%97%B4%E4%BD%BF%E7%94%A8%E5%AE%83%EF%BC%9F"><span class="toc-number">12.</span> <span class="toc-text">Rerank 模型工作在什么阶段？什么时间使用它？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-Rerank-%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B7%A5%E4%BD%9C%E9%98%B6%E6%AE%B5"><span class="toc-number">13.</span> <span class="toc-text">🧩 Rerank 模型的工作阶段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%94%A8-Rerank%EF%BC%9F"><span class="toc-number">14.</span> <span class="toc-text">🎯 为什么要用 Rerank？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%8F%B0-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8-Rerank%EF%BC%9F"><span class="toc-number">15.</span> <span class="toc-text">⏰ 什么时候使用 Rerank？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-3"><span class="toc-number">16.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9C%A8-RAG-%E7%9A%84%E6%8A%80%E6%9C%AF%E4%B8%AD%EF%BC%8C%E6%9C%89%E5%8F%AF%E8%83%BD%E4%BD%BF%E7%94%A8%E5%A4%9A%E5%B0%91%E7%A7%8D%E6%A8%A1%E5%9E%8B%EF%BC%9F%E5%88%86%E5%88%AB%E5%9C%A8%E4%BB%80%E4%B9%88%E9%98%B6%E6%AE%B5%E4%BD%BF%E7%94%A8%EF%BC%9F%E4%B8%BA%E4%BA%86%E8%BE%BE%E6%88%90%E4%BB%80%E4%B9%88%E6%95%88%E6%9E%9C%EF%BC%9F"><span class="toc-number">17.</span> <span class="toc-text">在 RAG 的技术中，有可能使用多少种模型？分别在什么阶段使用？为了达成什么效果？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-RAG-%E6%8A%80%E6%9C%AF%E4%B8%AD%E7%9A%84%E6%A8%A1%E5%9E%8B%E7%B1%BB%E5%9E%8B%E4%B8%8E%E9%98%B6%E6%AE%B5"><span class="toc-number">18.</span> <span class="toc-text">🧩 RAG 技术中的模型类型与阶段</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Embedding-%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%90%91%E9%87%8F%E5%8C%96%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.1.</span> <span class="toc-text">1. Embedding 模型（向量化阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%A3%80%E7%B4%A2%E6%A8%A1%E5%9E%8B%EF%BC%88%E5%88%9D%E6%AD%A5%E5%8F%AC%E5%9B%9E%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.2.</span> <span class="toc-text">2. 检索模型（初步召回阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-Rerank-%E6%A8%A1%E5%9E%8B%EF%BC%88%E9%87%8D%E6%8E%92%E5%BA%8F%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.3.</span> <span class="toc-text">3. Rerank 模型（重排序阶段）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-LLM%EF%BC%88%E7%94%9F%E6%88%90%E9%98%B6%E6%AE%B5%EF%BC%89"><span class="toc-number">18.4.</span> <span class="toc-text">4. 大语言模型 LLM（生成阶段）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-1"><span class="toc-number">19.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%AF%E6%BA%90%EF%BC%9F%E7%8E%B0%E5%9C%A8-RAG-%E6%8A%80%E6%9C%AF%E8%BF%98%E6%98%AF%E6%9C%80%E5%A5%BD%E7%9A%84%E6%8A%80%E6%9C%AF%E6%96%B9%E6%A1%88%E5%90%97%EF%BC%9F%E6%9C%89%E6%9B%B4%E5%85%88%E8%BF%9B%E7%9A%84%E6%96%B9%E6%A1%88%E5%90%97%EF%BC%9F"><span class="toc-number">20.</span> <span class="toc-text">如何实现溯源？现在 RAG 技术还是最好的技术方案吗？有更先进的方案吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%8E-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%AF%E6%BA%90"><span class="toc-number">21.</span> <span class="toc-text">🔎 如何实现溯源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-RAG-%E6%98%AF%E5%90%A6%E4%BB%8D%E6%98%AF%E6%9C%80%E4%BD%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-number">22.</span> <span class="toc-text">📌 RAG 是否仍是最佳方案？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E6%9B%B4%E5%85%88%E8%BF%9B%E7%9A%84%E6%96%B9%E6%A1%88%E6%8E%A2%E7%B4%A2"><span class="toc-number">23.</span> <span class="toc-text">🚀 更先进的方案探索</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-4"><span class="toc-number">24.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%EF%BC%9F"><span class="toc-number">25.</span> <span class="toc-text">什么是多模态大模型？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A0-%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9A%84%E2%80%9C%E6%A8%A1%E6%80%81%E2%80%9D%E6%8C%87%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">26.</span> <span class="toc-text">🧠 多模态的“模态”指什么？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B"><span class="toc-number">27.</span> <span class="toc-text">🧩 多模态大模型的核心能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BB%A3%E8%A1%A8"><span class="toc-number">28.</span> <span class="toc-text">🚀 多模态大模型的代表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">29.</span> <span class="toc-text">🎯 多模态模型的优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-5"><span class="toc-number">30.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0-reasoning-%EF%BC%9F"><span class="toc-number">31.</span> <span class="toc-text">大模型如何实现 reasoning ？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0-Reasoning-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E5%BC%8F"><span class="toc-number">32.</span> <span class="toc-text">🧩 大模型实现 Reasoning 的主要方式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Chain-of-Thought-CoT-%E6%80%9D%E7%BB%B4%E9%93%BE"><span class="toc-number">32.1.</span> <span class="toc-text">1. Chain of Thought (CoT) 思维链</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Self-Consistency%EF%BC%88%E8%87%AA%E6%B4%BD%E9%87%87%E6%A0%B7%EF%BC%89"><span class="toc-number">32.2.</span> <span class="toc-text">2. Self-Consistency（自洽采样）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%A4%96%E9%83%A8%E5%B7%A5%E5%85%B7%E4%B8%8E%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA"><span class="toc-number">32.3.</span> <span class="toc-text">3. 外部工具与检索增强</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B"><span class="toc-number">32.4.</span> <span class="toc-text">4. 强化学习与奖励模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E6%9E%B6%E6%9E%84%E4%B8%8E%E8%AE%AD%E7%BB%83%E6%94%B9%E8%BF%9B"><span class="toc-number">32.5.</span> <span class="toc-text">5. 架构与训练改进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-2"><span class="toc-number">33.</span> <span class="toc-text">🎯 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%BB%A7%E7%BB%AD%E6%9C%AC%E5%AF%B9%E8%AF%9D%E4%B8%AD%E7%9A%84%E4%BE%8B%E5%AD%90%EF%BC%8C%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA-reasoning-%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B%E3%80%82"><span class="toc-number">34.</span> <span class="toc-text">请继续本对话中的例子，训练一个 reasoning 的大模型。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9C%A8-16GB-%E5%86%85%E5%AD%98%E3%80%818-%E6%A0%B8-CPU-%E4%B8%8A%E8%AE%AD%E7%BB%83%E4%B8%80%E4%B8%AA%E5%85%B7%E5%A4%87%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E5%B0%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number"></span> <span class="toc-text">在 16GB 内存、8 核 CPU 上训练一个具备推理能力的小模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E4%B8%8E%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF"><span class="toc-number">1.</span> <span class="toc-text">目标与核心思路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87%EF%BC%88CoT-%E6%80%9D%E7%BB%B4%E9%93%BE%E6%A0%BC%E5%BC%8F%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">数据集准备（CoT 思维链格式）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E6%A8%A1%E6%9D%BF%EF%BC%88%E6%8E%A8%E7%90%86%E9%A3%8E%E6%A0%BC%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">提示模板（推理风格）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%EF%BC%88CoT-SFT%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">训练代码（CoT SFT）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E6%97%B6%E7%AD%96%E7%95%A5%EF%BC%9A%E8%87%AA%E6%B4%BD%E9%87%87%E6%A0%B7%E4%B8%8E%E2%80%9C%E6%9C%80%E7%BB%88%E7%AD%94%E6%A1%88%E2%80%9D%E6%8A%BD%E5%8F%96"><span class="toc-number">5.</span> <span class="toc-text">推理时策略：自洽采样与“最终答案”抽取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%80%89%EF%BC%9A%E6%8E%A8%E7%90%86%E4%B8%AD%E7%9A%84%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%EF%BC%88%E8%BD%BB%E9%87%8F%E8%AE%A1%E7%AE%97%E5%99%A8%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">可选：推理中的工具调用（轻量计算器）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#API-%E9%9B%86%E6%88%90%EF%BC%88%E8%BF%94%E5%9B%9E%E6%8E%A8%E7%90%86%E9%93%BE%E4%B8%8E%E5%87%BA%E5%A4%84%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">API 集成（返回推理链与出处）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E6%B5%8B%E4%B8%8E%E8%BF%AD%E4%BB%A3"><span class="toc-number">8.</span> <span class="toc-text">评测与迭代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A1%AC%E4%BB%B6%E5%8F%8B%E5%A5%BD%E5%BB%BA%E8%AE%AE"><span class="toc-number">9.</span> <span class="toc-text">硬件友好建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E7%BB%93"><span class="toc-number">10.</span> <span class="toc-text">小结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E7%BB%99%E5%87%BA%E5%85%A8%E9%83%A8%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">11.</span> <span class="toc-text">请给出全部代码实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%82-%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number"></span> <span class="toc-text">📂 项目结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-%E6%9E%84%E5%BB%BA%E5%88%86%E8%AF%8D%E5%99%A8"><span class="toc-number"></span> <span class="toc-text">1️⃣ 构建分词器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-%E6%A8%A1%E5%9E%8B%E5%AE%9A%E4%B9%89"><span class="toc-number"></span> <span class="toc-text">2️⃣ 模型定义</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-%E9%A2%84%E8%AE%AD%E7%BB%83%E3%80%81SFT%E3%80%81Reasoning-SFT%E3%80%81%E6%8E%A8%E7%90%86%E3%80%81API"><span class="toc-number"></span> <span class="toc-text">3️⃣ 预训练、SFT、Reasoning SFT、推理、API</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E2%9C%85-%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B"><span class="toc-number"></span> <span class="toc-text">✅ 使用流程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#train-pretrain-py%E3%80%81train-sft-py%E3%80%81train-reasoning-sft-py%E3%80%81generate-py%E3%80%81generate-reasoning-py%E3%80%81tiny-tools-py%E3%80%81app-reasoning-py-%E8%BF%99%E4%BA%9B%E6%96%87%E4%BB%B6%E5%AF%B9%E4%BA%8E-reasoning-%E6%A8%A1%E5%BC%8F%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E5%90%97%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">train_pretrain.py、train_sft.py、train_reasoning_sft.py、generate.py、generate_reasoning.py、tiny_tools.py、app_reasoning.py 这些文件对于 reasoning 模式的模型需要修改吗？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-train-pretrain-py"><span class="toc-number">2.</span> <span class="toc-text">1. train_pretrain.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-train-sft-py"><span class="toc-number">3.</span> <span class="toc-text">2. train_sft.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-train-reasoning-sft-py"><span class="toc-number">4.</span> <span class="toc-text">3. train_reasoning_sft.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-generate-py"><span class="toc-number">5.</span> <span class="toc-text">4. generate.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-generate-reasoning-py"><span class="toc-number">6.</span> <span class="toc-text">5. generate_reasoning.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-tiny-tools-py"><span class="toc-number">7.</span> <span class="toc-text">6. tiny_tools.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-app-reasoning-py"><span class="toc-number">8.</span> <span class="toc-text">7. app_reasoning.py</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-6"><span class="toc-number">9.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E6%8A%8A%E9%9C%80%E8%A6%81%E4%BF%AE%E6%94%B9%E7%9A%84%E6%96%87%E4%BB%B6%E9%87%8D%E6%96%B0%E7%94%9F%E6%88%90%E3%80%82"><span class="toc-number">10.</span> <span class="toc-text">请把需要修改的文件重新生成。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1%EF%B8%8F%E2%83%A3-train-reasoning-sft-py"><span class="toc-number"></span> <span class="toc-text">1️⃣ train_reasoning_sft.py</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2%EF%B8%8F%E2%83%A3-generate-reasoning-py"><span class="toc-number"></span> <span class="toc-text">2️⃣ generate_reasoning.py</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3%EF%B8%8F%E2%83%A3-app-reasoning-py"><span class="toc-number"></span> <span class="toc-text">3️⃣ app_reasoning.py</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%8F%91%E5%B1%95%EF%BC%8C%E8%AF%B7%E5%B8%AE%E6%88%91%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%AA%E5%A4%A7%E7%BA%B2%EF%BC%8C%E4%B8%BB%E8%A6%81%E4%BB%8B%E7%BB%8D%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B"><span class="toc-number">1.</span> <span class="toc-text">大模型技术发展，请帮我整理一个大纲，主要介绍大模型技术演进</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%9A-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E5%A4%A7%E7%BA%B2"><span class="toc-number"></span> <span class="toc-text">📚 大模型技术演进大纲</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B5%B7%E7%82%B9%EF%BC%9A%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%90%8C%E8%8A%BD"><span class="toc-number">1.</span> <span class="toc-text">一、起点：语言模型的萌芽</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Transformer-%E9%9D%A9%E5%91%BD%EF%BC%882017%EF%BC%89"><span class="toc-number">2.</span> <span class="toc-text">二、Transformer 革命（2017）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3"><span class="toc-number">3.</span> <span class="toc-text">三、预训练大模型时代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90%EF%BC%88Alignment%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">四、指令微调与对齐（Alignment）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RAG-%E4%B8%8E%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA"><span class="toc-number">5.</span> <span class="toc-text">五、RAG 与外部知识增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">6.</span> <span class="toc-text">六、多模态大模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Reasoning-%E4%B8%8E%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B"><span class="toc-number">7.</span> <span class="toc-text">七、Reasoning 与推理能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%BC%80%E6%BA%90%E4%B8%8E%E7%94%9F%E6%80%81%E7%B9%81%E8%8D%A3"><span class="toc-number">8.</span> <span class="toc-text">八、开源与生态繁荣</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%9C%AA%E6%9D%A5%E8%B6%8B%E5%8A%BF"><span class="toc-number">9.</span> <span class="toc-text">九、未来趋势</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%93%9A-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E8%AE%B2%E8%A7%A3%E7%A8%BF"><span class="toc-number"></span> <span class="toc-text">📚 大模型技术演进讲解稿</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E8%B5%B7%E7%82%B9%EF%BC%9A%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%90%8C%E8%8A%BD-1"><span class="toc-number">1.</span> <span class="toc-text">一、起点：语言模型的萌芽</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Transformer-%E9%9D%A9%E5%91%BD%EF%BC%882017%EF%BC%89-1"><span class="toc-number">2.</span> <span class="toc-text">二、Transformer 革命（2017）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%97%B6%E4%BB%A3-1"><span class="toc-number">3.</span> <span class="toc-text">三、预训练大模型时代</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%8C%87%E4%BB%A4%E5%BE%AE%E8%B0%83%E4%B8%8E%E5%AF%B9%E9%BD%90%EF%BC%882022-%E8%B5%B7%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">四、指令微调与对齐（2022 起）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81RAG-%E4%B8%8E%E5%A4%96%E9%83%A8%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA-1"><span class="toc-number">5.</span> <span class="toc-text">五、RAG 与外部知识增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B-1"><span class="toc-number">6.</span> <span class="toc-text">六、多模态大模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Reasoning-%E4%B8%8E%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B-1"><span class="toc-number">7.</span> <span class="toc-text">七、Reasoning 与推理能力</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81%E5%BC%80%E6%BA%90%E4%B8%8E%E7%94%9F%E6%80%81%E7%B9%81%E8%8D%A3-1"><span class="toc-number">8.</span> <span class="toc-text">八、开源与生态繁荣</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B9%9D%E3%80%81%E6%9C%AA%E6%9D%A5%E8%B6%8B%E5%8A%BF-1"><span class="toc-number">9.</span> <span class="toc-text">九、未来趋势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-7"><span class="toc-number">10.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8A%80%E6%9C%AF%E5%BF%85%E8%AF%BB%E8%AE%BA%E6%96%87"><span class="toc-number">11.</span> <span class="toc-text">大模型技术必读论文</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%91-%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E5%BF%85%E8%AF%BB%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E6%B8%85%E5%8D%95"><span class="toc-number">12.</span> <span class="toc-text">📑 大模型学习必读经典论文清单</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A9%E6%9C%9F%E5%9F%BA%E7%A1%80%EF%BC%88%E8%AF%8D%E5%90%91%E9%87%8F%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%89"><span class="toc-number">12.1.</span> <span class="toc-text">早期基础（词向量与注意力）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transformer-%E9%9D%A9%E5%91%BD"><span class="toc-number">12.2.</span> <span class="toc-text">Transformer 革命</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%89%A9%E5%B1%95"><span class="toc-number">12.3.</span> <span class="toc-text">预训练与扩展</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E4%B8%8E-Scaling-Law"><span class="toc-number">12.4.</span> <span class="toc-text">训练优化与 Scaling Law</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E9%BD%90%E4%B8%8E%E6%8C%87%E4%BB%A4"><span class="toc-number">12.5.</span> <span class="toc-text">对齐与指令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA%E4%B8%8E%E5%A4%9A%E6%A8%A1%E6%80%81"><span class="toc-number">12.6.</span> <span class="toc-text">知识增强与多模态</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E7%90%86%E4%B8%8E%E6%9C%AA%E6%9D%A5"><span class="toc-number">12.7.</span> <span class="toc-text">推理与未来</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-8"><span class="toc-number">13.</span> <span class="toc-text">✅ 总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE"><span class="toc-number">14.</span> <span class="toc-text">📌 学习建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E4%BB%8B%E7%BB%8D%E4%B8%8B-agent"><span class="toc-number">15.</span> <span class="toc-text">请介绍下 agent</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%A7%A9-Agent-%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">16.</span> <span class="toc-text">🧩 Agent 的核心概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9A%99%EF%B8%8F-Agent-%E7%9A%84%E5%85%B8%E5%9E%8B%E5%B7%A5%E4%BD%9C%E6%B5%81"><span class="toc-number">17.</span> <span class="toc-text">⚙️ Agent 的典型工作流</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E6%8A%80%E6%9C%AF%E6%94%AF%E6%92%91"><span class="toc-number">18.</span> <span class="toc-text">🔑 技术支撑</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8C%8D-%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">19.</span> <span class="toc-text">🌍 应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%9A%80-%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF"><span class="toc-number">20.</span> <span class="toc-text">🚀 发展趋势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%88%91%E6%83%B3%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93%EF%BC%8C%E5%AE%9E%E7%8E%B0%E7%94%B5%E8%84%91%E7%9A%84%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%8C%85%E6%8B%AC-windows-%E5%92%8C-Linux-%E5%92%8C-Unix-like-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E6%96%87%E4%BB%B6-%E5%A4%B9-%E6%93%8D%E4%BD%9C%EF%BC%8C%E5%8F%AF%E4%BB%A5%E8%BE%93%E5%85%A5%E6%8C%87%E5%AE%9A%E7%9A%84-prompt-%E6%9D%A5%E5%AF%B9%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E6%96%87%E4%BB%B6%E8%BF%9B%E8%A1%8C%E5%88%9B%E5%BB%BA%EF%BC%8C%E5%88%A0%E9%99%A4%EF%BC%8C%E4%BF%AE%E6%94%B9%EF%BC%8C%E8%AF%BB%E5%8F%96%EF%BC%8C%E6%96%87%E4%BB%B6%E5%BD%92%E7%B1%BB%E7%AD%89%E5%8A%9F%E8%83%BD"><span class="toc-number">21.</span> <span class="toc-text">我想构建一个属于自己的智能体，实现电脑的文件操作，包括 windows 和 Linux 和 Unix like 操作系统上的文件(夹)操作，可以输入指定的 prompt 来对操作系统中的文件进行创建，删除，修改，读取，文件归类等功能</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%AA%E4%BA%BA%E6%96%87%E4%BB%B6%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%84%E5%BB%BA"><span class="toc-number"></span> <span class="toc-text">个人文件智能体构建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A0%B8%E5%BF%83%E5%8E%9F%E5%88%99"><span class="toc-number">1.</span> <span class="toc-text">架构与核心原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E6%8E%A7%E7%AD%96%E7%95%A5"><span class="toc-number">2.</span> <span class="toc-text">安全与可控策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">配置示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%84%E5%8C%96%E6%84%8F%E5%9B%BE%E4%B8%8E%E6%93%8D%E4%BD%9C%E5%BA%8F%E5%88%97"><span class="toc-number">4.</span> <span class="toc-text">结构化意图与操作序列</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%AE%9E%E7%8E%B0%EF%BC%88Python%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">核心实现（Python）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%9D%83%E9%99%90%E5%AE%88%E5%8D%AB"><span class="toc-number">5.1.</span> <span class="toc-text">1. 路径与权限守卫</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%96%87%E4%BB%B6%E5%B7%A5%E5%85%B7%E5%B1%82%EF%BC%88%E8%B7%A8%E5%B9%B3%E5%8F%B0%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">2. 文件工具层（跨平台）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BD%92%E7%B1%BB%E4%B8%8E%E6%A0%87%E7%AD%BE"><span class="toc-number">5.3.</span> <span class="toc-text">3. 归类与标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%AE%A1%E8%AE%A1%E6%97%A5%E5%BF%97%E4%B8%8E-Dry-run-%E7%A1%AE%E8%AE%A4"><span class="toc-number">5.4.</span> <span class="toc-text">4. 审计日志与 Dry-run 确认</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%A7%84%E5%88%92%E5%99%A8%E4%B8%8E%E6%89%A7%E8%A1%8C%E5%99%A8"><span class="toc-number">5.5.</span> <span class="toc-text">5. 规划器与执行器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%85%A5%E5%8F%A3"><span class="toc-number">5.6.</span> <span class="toc-text">6. 命令行入口</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">6.</span> <span class="toc-text">跨平台注意事项</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E9%80%89%E5%A2%9E%E5%BC%BA"><span class="toc-number">7.</span> <span class="toc-text">可选增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B"><span class="toc-number">8.</span> <span class="toc-text">使用示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Agent-%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8%E5%93%AA%E7%A7%8D%E8%AF%AD%E8%A8%80%E6%9D%A5%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="toc-number">9.</span> <span class="toc-text">Agent 可以使用哪种语言来实现？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%94%91-%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0%E8%AF%AD%E8%A8%80%E4%B8%8E%E7%89%B9%E7%82%B9"><span class="toc-number">10.</span> <span class="toc-text">🔑 常见实现语言与特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%8C-%E9%80%89%E6%8B%A9%E5%BB%BA%E8%AE%AE"><span class="toc-number">11.</span> <span class="toc-text">📌 选择建议</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%93%91-Agent-%E5%B8%B8%E7%94%A8%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%AF%B9%E6%AF%94%E8%A1%A8"><span class="toc-number">12.</span> <span class="toc-text">📑 Agent 常用编程语言对比表</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%F0%9F%8E%AF-%E6%80%BB%E7%BB%93-3"><span class="toc-number">13.</span> <span class="toc-text">🎯 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%F0%9F%9B%A0%EF%B8%8F-%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E4%BD%93%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF%E5%9B%BE%EF%BC%88%E6%96%87%E5%AD%97%E7%89%88%EF%BC%89"><span class="toc-number"></span> <span class="toc-text">🛠️ 构建智能体学习路线图（文字版）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%80%EF%BC%9A%E5%9F%BA%E7%A1%80%E6%89%93%E7%89%A2"><span class="toc-number">1.</span> <span class="toc-text">阶段一：基础打牢</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%8C%EF%BC%9AAI-%E4%B8%8E%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">阶段二：AI 与大模型基础</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%B8%89%EF%BC%9AAgent-%E5%9F%BA%E7%A1%80%E6%A1%86%E6%9E%B6"><span class="toc-number">3.</span> <span class="toc-text">阶段三：Agent 基础框架</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E5%9B%9B%EF%BC%9A%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C-Agent-%E5%AE%9E%E7%8E%B0"><span class="toc-number">4.</span> <span class="toc-text">阶段四：文件操作 Agent 实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E4%BA%94%EF%BC%9A%E8%B7%A8%E5%B9%B3%E5%8F%B0%E4%B8%8E%E6%89%A9%E5%B1%95"><span class="toc-number">5.</span> <span class="toc-text">阶段五：跨平台与扩展</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%98%B6%E6%AE%B5%E5%85%AD%EF%BC%9A%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%9C%AA%E6%9D%A5"><span class="toc-number">6.</span> <span class="toc-text">阶段六：进阶与未来</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%9C%85-%E6%80%BB%E7%BB%93-9"><span class="toc-number">7.</span> <span class="toc-text">✅ 总结</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&text=构建自己的大模型"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&is_video=false&description=构建自己的大模型"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=构建自己的大模型&body=Check out this article: https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&title=构建自己的大模型"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&name=构建自己的大模型&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://shenjy06.github.io/blog/2025/10/20/%E6%9E%84%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E5%A4%A7%E6%A8%A1%E5%9E%8B/&t=构建自己的大模型"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;   2020-2026 Mark Shen
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       -->
        <li>
          <a href="/blog/"
            >首页</a
          >
        </li>
        <!--
     --><!--
       -->
        <li>
          <a href="/blog/about/"
            >关于</a
          >
        </li>
        <!--
     --><!--
       -->
        <li>
          <a href="/blog/archives/"
            >归档</a
          >
        </li>
        <!--
     --><!--
       -->
        <li>
          <a href="/blog/categories/"
            >分类</a
          >
        </li>
        <!--
     --><!--
       -->
        <li>
          <a href="/blog/search/"
            >搜索</a
          >
        </li>
        <!--
     --><!--
       -->
        <li>
          <a target="_blank" rel="noopener" href="https://github.com/shenjy06"
            >项目</a
          >
        </li>
        <!--
     -->
      </ul>
      <ul>
        <!-- Baidu Web Analytics -->
        <script>
          var _hmt = _hmt || []
          ;(function () {
            var hm = document.createElement('script')
            hm.src =
              'https://hm.baidu.com/hm.js?2bf556e2c4bfb436b933c9c12d4a0057'
            var s = document.getElementsByTagName('script')[0]
            s.parentNode.insertBefore(hm, s)
          })()
        </script>
        <!-- End Baidu Web Analytics -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板！\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功！");
      e.clearSelection();
    })
  })
  </script>


<script src="/blog/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

  <script type="text/javascript">
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?2bf556e2c4bfb436b933c9c12d4a0057";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'shenjy06/blog';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

</body>
</html>
